
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - TECHNOLOGY Article Summaries - 2026-02-02</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            TECHNOLOGY
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/right-to-compute-laws-are-spreading-across-the-us-as-electricity-bills-skyrocket-2000716730'>Right-to-Compute Laws Are Spreading Across the US, as Electricity Bills Skyrocket</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-02 17:20:49
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Conveniently, these so-called right-to-compute laws are emerging just as some of the world's biggest corporations race to build massive new data centers. Montana became the first state to pass such a law back in April. But as the AI and enterprise news outlet VKTR has pointed out, lawmakers in other states are also considering similar bills, including in New Hampshire, Ohio, and South Dakota. Meanwhile, a similar measure in Idaho failed to move beyond the committee stage. “Government actions that restrict the ability to privately own or make use of computational resources for lawful purposes, which infringes on citizens' fundamental rights to property and free expression, must be limited to those demonstrably necessary and narrowly tailored to fulfill a compelling government interest,” the Montana law reads. Like right-to-work laws that frame themselves as protecting individual freedom, critics warn that right-to-compute statutes could, in practice, primarily benefit large corporations by limiting the ability of states and local governments to regulate AI projects. The Montana law is also nearly identical to model legislation drafted by the American Legislative Exchange Council, meaning it could easily be replicated by lawmakers elsewhere. “I would hope it would encourage other states to run with it to counter the fear-based narratives,” said Adam Thierer, a senior fellow at the R Street Institute, in online commentary. These laws are popping up as companies like Meta, Microsoft, Amazon, and OpenAI pour billions into AI infrastructure across the U.S. Meta has even launched advertising campaigns in state capitols, including in Iowa, California, Utah, and Florida, pitching data center projects as job creators, the New York Times reported. At the federal level, President Donald Trump, an AI and business ally, signed an executive order in December aimed at curbing what his administration describes as overly burdensome state regulations in the name of national and economic security. Nearly 40 states have passed or are considering laws limiting how businesses use AI, VKTR reported, citing the National Conference of State Legislatures. In a newly filed FCC application, Musk's SpaceX outlines plans to launch a data center constellation of up to 1 million satellites. Is Apple getting ready for its big AI push? Radars and cameras might be for seeing cars and people now but they can be used to make existing roads better in the first place. How many award-winning writers are desperate enough to train Grok?</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2026/amazon-layoffs-hit-nearly-2200-in-washington-state-more-than-half-in-core-product-and-engineering-roles/'>Amazon layoffs hit nearly 2,200 in Washington state, more than half in core product and engineering roles</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-02 16:48:21
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Amazon is laying off 2,198 employees across Washington as part of the company's latest corporate workforce reduction, according to a new filing released Monday by the state Employment Security Department. In total, more than half of the cuts impact Amazon's core product and engineering organizations. The remaining positions span business intelligence, sales, marketing, infrastructure, QA, HR, design, and other support functions. A majority of the cuts — more than 1,400 — impact workers in Seattle, with more than 600 in nearby Bellevue, where Amazon has been expanding its office footprint. The cuts are part of Amazon's company-wide layoffs announced last week that impact 16,000 corporate employees globally. As part of the October cuts, Amazon laid off 2,303 employees in Washington state. Corporate support and commercial functions were hit harder in that round, which included engineering roles but also targeted legal, tax, and ad sales positions that are largely absent from the new list released Monday. The company has made several additional, smaller workforce reductions in recent years as it seeks to streamline operations. In a memo to employees sent Wednesday, Amazon senior vice president of people experience and technology Beth Galetti said the company is “reducing layers, increasing ownership, and removing bureaucracy.” The list includes a significant number of “Manager III” and “Senior Manager” roles within software and product teams, suggesting Amazon is axing layers of oversight, not just reducing individual contributor headcount. Amazon noted in the filing that employees who secure internal transfers before their separation dates will not ultimately be laid off. Amazon employs roughly 50,000 corporate workers in the Seattle region, which serves as its primary headquarters. The latest cuts come amid concerns about Seattle's tech-heavy economy as other companies trim headcount. Many corporations are slashing headcount to address pandemic-fueled corporate “bloat” while juggling economic uncertainty and impact from AI tools. Jon Scholes, president of the Downtown Seattle Association, said in a statement last week that a “workforce change of this scale has ripple effects on the community.” The broader layoffs may also impact Seattle's commercial real estate market, which continues to struggle with record-high vacancy rates. The chips powering your smart TV, voice assistant, tablet, and car all have something in common: MediaTek Click for more about underwritten and sponsored content on GeekWire. Click for more about underwritten and sponsored content on GeekWire. Amazon confirms 16,000 more corporate job cuts, bringing total to 30,000 since October Latest Microsoft layoffs target engineering, product and legal roles, records show Filing: Meta's AI layoffs hit Washington offices in Bellevue, Seattle, Redmond</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2026/t-mobile-layoffs-telecom-giant-cuts-393-jobs-across-washington-state-including-vp-roles/'>T-Mobile layoffs: Telecom giant cuts 393 jobs across Washington state, including VP roles</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-02 16:27:59
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>T-Mobile is laying off 393 workers in Washington as part of a new round of cuts, according to a filing with the state Employment Security Department released Monday morning. More than 200 different job titles are impacted, according to the filing, including analysts, engineers and technicians, as well as directors and managers. “These facilities are not being closed,” the notice stated. “The layoffs are not due to relocation or contracting out employer operations or employee positions, but it is possible that some work currently done by these employees may at some point be done by others.” Affected employees were given 60-days' notice and the departures are expected to take effect April 2. The cuts come as the Seattle area is being hit by thousands of tech-related layoffs, including job losses at Amazon, Expedia, Meta and other companies. T-Mobile, the largest U.S. telecom company by market capitalization, laid off 121 workers in August 2025. In November, former Chief Operating Officer Srini Gopalan replaced longtime leader Mike Sievert as CEO. T-Mobile's stock is down nearly 20% over the past 12 months. Microsoft makes additional job cuts, laying off more than 300 in Washington state F5 laying off 106 employees in Washington state as part of changes to product org</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2026/02/02/ring-brings-its-search-party-feature-for-finding-lost-dogs-to-non-ring-camera-owners/'>Ring brings its ‘Search Party' feature for finding lost dogs to non-Ring camera owners</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-02 15:33:45
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Launched last fall, Search Party uses AI to find possible matches for lost dogs across neighbors' camera footage. If a match is found, that camera owner receives an alert and can optionally choose to share any related video clips with their neighbor who reported the pet missing. They'll also have an option to call the owner or send them a message, without sharing their own phone number. Ring says the feature has been reuniting more than a dog per day since its launch. Previously, Search Party was only available to customers with a Ring camera installed. “Now, pet owners can mobilize the whole community—and communities are empowered to help—to find lost pets more effectively than ever before,” noted Ring founder Jamie Siminoff, in an announcement. Alongside the launch and expansion, Amazon-owned Ring said it's committing $1 million to equip animal shelters with Ring camera systems, and aims to aid 4,000 U.S. shelters. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what's next. Nvidia CEO pushes back against report that his company's $100B OpenAI investment has stalled Waymo robotaxi hits a child near an elementary school in Santa Monica Everything you need to know about viral personal AI assistant Clawdbot (now Moltbot)</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2026/02/02/carbon-robotics-built-an-ai-model-that-detects-and-identifies-plants/'>Carbon Robotics built an AI model that detects and identifies plants</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-02 15:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Seattle-based Carbon Robotics, which builds the LaserWeeder — a robot fleet that uses lasers to kill weeds — announced a new AI model, the Large Plant Model (LPM), on Monday. Paul Mikesell, the founder and CEO of Carbon Robotics, told TechCrunch that prior to LPM, every time a new type of weed would show up on a farm — or even the same type of weed in different soil or with a slightly different appearance — the company would have to create new data labels to retrain its machines to recognize the plant. This process took about 24 hours each time, Mikesell said. “The farmer can live in real time and say, ‘Hey, this is a new weed. “There's no new labeling or retraining because the Large Plant Model understands, at a much deeper level, what it's looking at and the type of plant.” Mikesell has years of experience building these types of neural networks from previous roles at Uber and working on Meta's Oculus virtual reality headsets. This new model will reach the company's existing systems through a software update. “We have over 150 million labeled plants now in our training set,” Mikesell said. “We have enough data now that we should be able to look at any picture and decide what kind of plant that is, what species it is, what it's related to, what its structure is like, without having ever even seen that particular plant before, because we have so much data going into the neural net.” Becca is a senior writer at TechCrunch that covers venture capital trends and startups. You can contact or verify outreach from Becca by emailing rebecca.szkutak@techcrunch.com. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what's next. Nvidia CEO pushes back against report that his company's $100B OpenAI investment has stalled OpenClaw's AI assistants are now building their own social network Waymo robotaxi hits a child near an elementary school in Santa Monica Everything you need to know about viral personal AI assistant Clawdbot (now Moltbot)</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2026/02/02/coalition-demands-federal-grok-ban-over-nonconsensual-sexual-content/'>Coalition demands federal Grok ban over nonconsensual sexual content</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-02 15:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The open letter, shared exclusively with TechCrunch, follows a slew of concerning behavior from the large language model over the past year, including most recently a trend of X users asking Grok to turn photos of real women, and in some cases children, into sexualized images without their consent. According to some reports, Grok generated thousands of nonconsensual explicit images every hour, which were then disseminated at scale on X, Musk's social media platform that's owned by xAI. “It is deeply concerning that the federal government would continue to deploy an AI product with system-level failures resulting in generation of nonconsensual sexual imagery and child sexual abuse material,” the letter, signed by advocacy groups like Public Citizen, Center for AI and Digital Policy, and Consumer Federation of America, reads. Two months before, xAI — alongside Anthropic, Google, and OpenAI — secured a contract worth up to $200 million with the Department of Defense. Amid the scandals on X in mid-January, Defense Secretary Pete Hegseth said Grok will join Google's Gemini in operating inside the Pentagon network, handling both classified and unclassified documents, which experts say is a national security risk. “Our primary concern is that Grok has pretty consistently shown to be an unsafe large language model,” JB Branch, a Public Citizen Big Tech accountability advocate and one of the letter's authors, told TechCrunch. One could argue that, based on the findings of the report — including Grok's propensity to offer unsafe advice, share information about drugs, generate violent and sexual imagery, spew conspiracy theories, and generate biased outputs — Grok isn't all that safe for adults either. “If you know that a large language model is or has been declared unsafe by AI safety experts, why in the world would you want that handling the most sensitive data we have?” Branch said. “From a national security standpoint, that just makes absolutely no sense.” “Closed code means you can't inspect the software or control where it runs. The risks of using corrupted or unsafe AI systems spill out beyond national security use cases. Branch pointed out that an LLM that's been shown to have biased and discriminatory outputs could produce disproportionate negative outcomes for people as well, especially if used in departments involving housing, labor, or justice. While the OMB has yet to publish its consolidated 2025 federal AI use case inventory, TechCrunch has reviewed the use cases of several agencies — most of which are either not using Grok or are not disclosing their use of Grok. “Grok's brand is being the ‘anti-woke large language model,' and that ascribes to this administration's philosophy,” Branch said. “If you have an administration that has had multiple issues with folks who've been accused of being Neo Nazis or white supremacists, and then they're using a large language model that has been tied to that type of behavior, I would imagine they might have a propensity to use it.” This is the coalition's third letter after writing with similar concerns in August and October last year. TechCrunch also reported in August that private Grok conversations had been indexed by Google Search. Prior to the October letter, Grok was accused of providing election misinformation, including false deadlines for ballot changes and political deepfakes. xAI also launched Grokipedia, which researchers found to be legitimizing scientific racism, HIV/AIDS skepticism, and vaccine conspiracies. “The administration needs to take a pause and reassess whether or not Grok meets those thresholds,” Branch said. TechCrunch has reached out to xAI and OMB for comment. Rebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what's next. Nvidia CEO pushes back against report that his company's $100B OpenAI investment has stalled OpenClaw's AI assistants are now building their own social network Waymo robotaxi hits a child near an elementary school in Santa Monica Everything you need to know about viral personal AI assistant Clawdbot (now Moltbot)</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/video-games/handheld-gaming/modder-more-than-doubles-asus-rog-xbox-ally-xs-memory-with-massive-64gb-ram-upgrade-advanced-soldering-and-bios-modification-unlock-more-capacity'>Modder more than doubles Asus ROG Xbox Ally X's memory with massive 64GB RAM upgrade — advanced soldering and BIOS modification unlock more capacity</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-02 14:26:23
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. The Asus ROG Xbox Ally X, Microsoft's first Xbox-branded gaming handheld, comes with 24GB of LPDDR5X memory, which is more than adequate for most use cases in this category. However, for users who want more headroom or plan to use the handheld as a hybrid portable desktop replacement, SlickBuys Mods and Repairs has successfully upgraded the system to a massive 64GB of RAM. This is the same modder who previously demonstrated their skills on the original ROG Ally by upgrading its memory from 16GB to 32GB. After gaining full access to the motherboard, the modder begins preparing the new memory modules by desoldering them from a custom PCB they were shipped with and reballing each memory chip. The stock 24GB memory modules are then removed from the ROG Xbox Ally X motherboard with a heat gun, along with any solder residue. The original BIOS chip is removed, and the APCB file is edited with a bunch of values using a CH341A USB programmer. The BIOS chip is then soldered back onto the motherboard, followed by moving two strap resistors to ensure that the newly installed memory chips run at their maximum clock speeds. Considering the $300 32GB memory upgrade previously done on the original ROG Ally, along with today's highly volatile DRAM market, we wouldn't be surprised if it is upwards of $500, which is almost half the cost of the gaming handheld. While this mod is exciting, it's important to note that upgrading soldered memory is not easy, even if it may look straightforward. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Kunal Khullar is a contributing writer at Tom's Hardware. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York,</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/ice-and-qatari-security-forces-at-the-winter-olympics-put-italians-on-edge/'>ICE and Qatari Security Forces at the Winter Olympics Put Italians on Edge</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-02 11:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>US officials claim such security measures are common for the Games and stressed that Italy would be in charge of security. Still, following the recent shooting deaths of Alex Pretti and Renee Nicole Good at the hands of US immigration agents, Italians were upset over ICE's presence. Milan's mayor, Giuseppe Sala, went so far as to tell a local radio station that agents were “not welcome” in the city. Italy's interior minister, Matteo Piantedosi, claimed he knew nothing about ICE's presence in Milan but stressed that he saw nothing wrong with it. Prime Minister Giorgia Meloni, a frequent Trump ally, has thus far remained silent. ICE won't be working with Italian law enforcement, which has promised to have more than 6,000 personnel at the events, but will instead be working to protect the US contingent, which includes Vice President JD Vance and Secretary of State Marco Rubio. Put another way, they're likely to be suit-and-tie ICE operatives, not agents in masks and military gear. On January 27, a cargo plane with more than a hundred Qatari public security officers, 20 camouflage SUVs, and three snowmobiles landed at Milan's Malpensa Airport. Following their arrival, the SUVs made their way to the city center, driving past Piazza Duomo and San Siro, where the opening ceremony will be held on Friday. Qatar has no athletes competing in the Winter Games. The security force has been tasked with “monitoring locations, providing rapid response capabilities, and supporting preventive measures against potential security risks,” but the arrangement has proven controversial given that they have often been accused of abuse, specifically against the LGBTQ+ community. This story originally appeared in WIRED Italia. In your inbox: WIRED's most ambitious, future-defining stories Big Story: China's renewable energy revolution might save the world Watch our livestream replay: Welcome to the Chinese century WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/anti-ice-protesters-have-started-a-month-long-tech-and-ai-boycott-heres-how-it-works-2000716458'>Anti-ICE Protesters Have Started a Month-Long Tech and AI Boycott. Here's How It Works</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-02 10:00:36
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>“Resist and Unsubscribe” is a month-long economic strike focusing for the most part on tech and AI companies, aka “where economic and political power is most concentrated,” according to NYU Stern marketing professor Scott Galloway, who is spearheading the movement. Those companies are Amazon, Apple, Google, Microsoft, Paramount+, Uber, Netflix, X, Meta, and OpenAI. “America's economy is one giant bet on AI, with seven tech companies representing more than a third of the S&P 500. That means the best way to ignite positive change, without hurting consumers, is to carry out an economic strike the tech CEOs can't ignore,” Galloway wrote in a blog post. Silicon Valley interests have held a sizable presence in Trump's approach to trade and regulation. One of his few instances of walking back threats in his grand attack on anti-ICE protesters was his decision to refrain from increasing the federal force in San Francisco, which he said he changed his mind on after talking to tech executives like Nvidia CEO Jensen Huang and Salesforce CEO Marc Benioff. Back in October, Apple removed an app that allows users to track ICE activity because Attorney General Pam Bondi asked them to, and Palantir has built a $30 million surveillance platform for the agency. Tech workers are also aware of this influence, and many have signed a letter asking company executives to speak out publicly, end all contracts with ICE, and demand that the White House end the crackdown. After the letter was released, Apple CEO Tim Cook told employees that he had brought the matter up in a conversation with Trump. As part of the new boycott, protesters are spending all of February unsubscribed from paid services offered by these 10 major tech companies, such as Amazon Prime, Uber One, ChatGPT Plus, Microsoft Office, or YouTube Premium. The organizers are also asking people to refrain from buying Apple hardware products until March and to delete Meta platforms like WhatsApp and Facebook. They will, however, continue using Instagram as a way to spread the message, but ask boycotters to refrain from clicking on any ads and shopping from any links you may encounter on the platform. The strike will also be targeting nine consumer-facing companies that they claim are “active enablers of ICE”: AT&T, Comcast, Charter Communications, Dell, FedEx, UPS, Home Depot, Lowe's, Spotify, and Marriott. AT&T, Xfinity provider Comcast, and computer maker Dell's government contracting arm have all signed contracts with ICE to offer their services to the agency. A 404 Media report from August claimed that both Home Depot and Lowe's share access to data from their AI-powered license plate readers with law enforcement surveillance systems that ICE can use, but Home Depot has since denied that claim. Spotify was under fire late last year for running ICE recruitment ads on its platform, carriers FedEx and UPS have delivery contracts with the agency, and reports have claimed that a Marriott-owned Sheraton hotel in Louisiana was used by ICE agents to hold detained families. Protesters have previously been successful in getting companies to lose their business partnerships with ICE, like with Avelo Airlines, which decided last month to stop its ICE deportation flights after months of scrutiny. And on Sunday, French tech giant Capgemini divested from its U.S. subsidiary that was doing business with ICE, following scrutiny from union workers and French government officials. Retail analysts told Axios on Friday that general strikes tend to struggle in sustaining participation over days, which is when it would truly start to impact sales data. “It's easy for me to tell other people to stop working and take the risk of getting fired; that kind of walkout would only hurt small businesses and probably lead to more job losses,” Galloway said on his blog. Gizmodo sought comment from Amazon, Apple, Google, Microsoft, Paramount+, Uber, Netflix, X, Meta, AT&T, Comcast, Dell, Charter, FedEx, Home Depot, Lowe's, Marriott, Spotify, UPS, and OpenAI. ICE is enlisting ten companies for a widespread immigrant surveillance program. After a couple of years being shelved or not used properly, Netflix might be just what 'Scooby-Doo' needs.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=46838946'>Ask HN: Any real OpenClaw (Clawd Bot/Molt Bot) users? What's your experience?</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-02 04:59:39
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Interestingly, I cannot find a single user of OpenClaw in my familiar communities, presumbly because it takes some effort to setup and the concept of AI taking control of everything is too scary for average tech enthusiasts.I scan through comments on HN, many of which were discussing about the ideas, but not sharing first-hand user experiences. A few HN users who did try it gave up / failed for various reasons:- https://news.ycombinator.com/item?id=46822562 (burning too many tokens)- https://news.ycombinator.com/item?id=46786628 (ditto + security implication)- https://news.ycombinator.com/item?id=46762521 (installation failed due to sandboxing)- https://news.ycombinator.com/item?id=46831031 (moltbook didn't work)I smell hype in the air... HN users, have any of you actually run OpenClaw and let it do any things useful or interesting? I scan through comments on HN, many of which were discussing about the ideas, but not sharing first-hand user experiences. A few HN users who did try it gave up / failed for various reasons:- https://news.ycombinator.com/item?id=46822562 (burning too many tokens)- https://news.ycombinator.com/item?id=46786628 (ditto + security implication)- https://news.ycombinator.com/item?id=46762521 (installation failed due to sandboxing)- https://news.ycombinator.com/item?id=46831031 (moltbook didn't work)I smell hype in the air... HN users, have any of you actually run OpenClaw and let it do any things useful or interesting? - https://news.ycombinator.com/item?id=46786628 (ditto + security implication)- https://news.ycombinator.com/item?id=46762521 (installation failed due to sandboxing)- https://news.ycombinator.com/item?id=46831031 (moltbook didn't work)I smell hype in the air... HN users, have any of you actually run OpenClaw and let it do any things useful or interesting? - https://news.ycombinator.com/item?id=46762521 (installation failed due to sandboxing)- https://news.ycombinator.com/item?id=46831031 (moltbook didn't work)I smell hype in the air... HN users, have any of you actually run OpenClaw and let it do any things useful or interesting? - https://news.ycombinator.com/item?id=46831031 (moltbook didn't work)I smell hype in the air... HN users, have any of you actually run OpenClaw and let it do any things useful or interesting? I smell hype in the air... HN users, have any of you actually run OpenClaw and let it do any things useful or interesting? When I'm driving or out I can ask Siri to send a iMessage to Clawdbot something like “Can you find out if anything is playing at the local concert venue, and figure in how much 2 tickets would cost”, and a few minutes later it will give me a few options. It even surprised me and researched the different seats and recommended a cheaper one or free activities as an alternative that weekend.Basically: This is the product that Apple and Google were unable to build despite having billions of dollars and thousands of engineers because it's a threat to their business model.It also runs on my own computer, and the latest frontier open source models are able to drive it (Kimi, etc). The future is going to be locally hosted and ad free and there's nothing Big Tech can do about it. Basically: This is the product that Apple and Google were unable to build despite having billions of dollars and thousands of engineers because it's a threat to their business model.It also runs on my own computer, and the latest frontier open source models are able to drive it (Kimi, etc). The future is going to be locally hosted and ad free and there's nothing Big Tech can do about it. It also runs on my own computer, and the latest frontier open source models are able to drive it (Kimi, etc). The future is going to be locally hosted and ad free and there's nothing Big Tech can do about it. After messing with openclaw on an old 2018 Windows laptop running WSL2 that I was about to recycle, I am coming to the same conclusion, and the paradigm shift is blowing my mind. Being able to chat with somebody that has a working understanding of a Unix environment and can execute tasks like "figure out why Caddy is crash looping and propose solutions" for a few dollars per month is a dream come true.I'm not actually using OpenClaw for that just yet, though; something about exposing my full Unix environment to OpenAI or Anthropic just seems wrong, both in terms of privacy and dependency. (I'll only allow my Unix devops skills to start getting rusty once I can run an Opus 4.5 equivalent agent on sub-$5000 hardware :) I'm not actually using OpenClaw for that just yet, though; something about exposing my full Unix environment to OpenAI or Anthropic just seems wrong, both in terms of privacy and dependency. (I'll only allow my Unix devops skills to start getting rusty once I can run an Opus 4.5 equivalent agent on sub-$5000 hardware :) Once it's running, day-to-day use is pretty straightforward (chat with it like any other messaging app).That said, you'll still need to: - Understand basic API costs to avoid surprises - Know when to restart if it gets stuck - Tweak settings for your specific use caseIf you're determined to skip tinkering entirely, I'd suggest starting with just the messaging integration (WhatsApp/Telegram) and keeping skills/tools minimal. That's the lowest-friction path.For setup guidance without deep technical knowledge, I found howtoopenclawfordummies.com helpful - it's aimed at beginners and covers the common gotchas.Is it transformative without tinkering? But the baseline experience (AI assistant via text) is still useful. That said, you'll still need to: - Understand basic API costs to avoid surprises - Know when to restart if it gets stuck - Tweak settings for your specific use caseIf you're determined to skip tinkering entirely, I'd suggest starting with just the messaging integration (WhatsApp/Telegram) and keeping skills/tools minimal. That's the lowest-friction path.For setup guidance without deep technical knowledge, I found howtoopenclawfordummies.com helpful - it's aimed at beginners and covers the common gotchas.Is it transformative without tinkering? But the baseline experience (AI assistant via text) is still useful. If you're determined to skip tinkering entirely, I'd suggest starting with just the messaging integration (WhatsApp/Telegram) and keeping skills/tools minimal. That's the lowest-friction path.For setup guidance without deep technical knowledge, I found howtoopenclawfordummies.com helpful - it's aimed at beginners and covers the common gotchas.Is it transformative without tinkering? But the baseline experience (AI assistant via text) is still useful. For setup guidance without deep technical knowledge, I found howtoopenclawfordummies.com helpful - it's aimed at beginners and covers the common gotchas.Is it transformative without tinkering? But the baseline experience (AI assistant via text) is still useful. But the baseline experience (AI assistant via text) is still useful. > because it's a threat to their business model. Full disclosure, I use OpenRouter and pay for models most of the time since it's more practical than 5-10 tokens per second, but the option to run it "If I had to, worst case" is good enough for me. I wouldn't be so certain of that. Someone is paying to train and create these models. Big tech is bought and paid for by consumers. We can do the same for oss trained models. So yes, I think the majority user experience is very relevant. Which means most people must be using OpenClaw connected to Claude or ChatGPT. If you think this sort of thing is gonna change the world in a good way: here's evidence of it getting to scale. If you think it's gonna be scams, garbage, and destruction: here's evidence of that. Actually, hang on... yep, to absolutely nobody's surprise, Simon Willison has also hyped this up on his blog just yesterday. I've followed SimonW for quite some time and bullshit/grifting is just NOT something he does.On the contrary, I've learned a great deal from him and appreciate his contributions. On the contrary, I've learned a great deal from him and appreciate his contributions. What have you learned, other than "[latest AI grift] is the future and I should invest all my money into it now"? Plus, it seems some of y'all love to hate the very industry which puts a roof over your head. How do you feel about becoming a plumber—-until the robots take that job? This probably isn't a line of argument you want to go down. I've been unemployed for 7 months, in part due to how difficult it is to get so much as an intro call because so many people have totally automated the process of spamming every open job posting with as many resumes (many of which were likely LLM-generated as well) as possible. There is no commercial interest from the developer of OpenClaw. He doesn't make any money from it. He made enough from selling his startup a few years back.So when we suspected some companies to game the Twitter algorithm to make money, maybe they were not responsible for it at all. So when we suspected some companies to game the Twitter algorithm to make money, maybe they were not responsible for it at all. I just can't see an angle to OpenClaw that could provide a substantial financial gain for the creator. #1) I can chat with the openclaw agent (his name is "Patch") through a telegram chat, and Patch can spawn a shared tmux instance on my 22 core development workstation. #2) I can then use the `blink` app on my iphone + tailscale and that allows me to use a command in blink `ssh dev` which connects me via ssh to my dev workstation in my office, from my iphone `blink` app.Meanwhile, my agent "Patch" has provided me a connection command string to use in my blink app, which is a `tmux <string> attach` command that allows me to attach to a SHARED tmux instance with Patch.Why is this so fking cool and foundationally game changing?Because now, my agent Patch and I can spin up MULTIPLE CLAUDE CODE instances, and work on any repository (or repositories) I want, with parallel agents.Well, I could already spawn multiple agents through my iphone connection without Patch, but the problem is then I need to MANAGE each spawned agent, micromanaging each agent instance myself. But now, I have a SUPERVISOR for all my agents, Patch is the SUPERVISOR of my muliple claude code instances.This means I no longer have to context switch by brain between five or 10 or 20 different tmux on my own to command and control multiple different claude code instances. I can now just let my SUPERVISOR agent, Patch, command and control the mulitple agents and then report back to me the status or any issues. All through a single telegram chat with my supervisor agent, Patch.This frees up my brain to only have to just have to manage Patch the supervisor, instead of micro-managing all the different agents myself. Now, I have a true management structure which allows me to more easily scale. Meanwhile, my agent "Patch" has provided me a connection command string to use in my blink app, which is a `tmux <string> attach` command that allows me to attach to a SHARED tmux instance with Patch.Why is this so fking cool and foundationally game changing?Because now, my agent Patch and I can spin up MULTIPLE CLAUDE CODE instances, and work on any repository (or repositories) I want, with parallel agents.Well, I could already spawn multiple agents through my iphone connection without Patch, but the problem is then I need to MANAGE each spawned agent, micromanaging each agent instance myself. But now, I have a SUPERVISOR for all my agents, Patch is the SUPERVISOR of my muliple claude code instances.This means I no longer have to context switch by brain between five or 10 or 20 different tmux on my own to command and control multiple different claude code instances. I can now just let my SUPERVISOR agent, Patch, command and control the mulitple agents and then report back to me the status or any issues. All through a single telegram chat with my supervisor agent, Patch.This frees up my brain to only have to just have to manage Patch the supervisor, instead of micro-managing all the different agents myself. Now, I have a true management structure which allows me to more easily scale. Why is this so fking cool and foundationally game changing?Because now, my agent Patch and I can spin up MULTIPLE CLAUDE CODE instances, and work on any repository (or repositories) I want, with parallel agents.Well, I could already spawn multiple agents through my iphone connection without Patch, but the problem is then I need to MANAGE each spawned agent, micromanaging each agent instance myself. But now, I have a SUPERVISOR for all my agents, Patch is the SUPERVISOR of my muliple claude code instances.This means I no longer have to context switch by brain between five or 10 or 20 different tmux on my own to command and control multiple different claude code instances. I can now just let my SUPERVISOR agent, Patch, command and control the mulitple agents and then report back to me the status or any issues. All through a single telegram chat with my supervisor agent, Patch.This frees up my brain to only have to just have to manage Patch the supervisor, instead of micro-managing all the different agents myself. Now, I have a true management structure which allows me to more easily scale. Because now, my agent Patch and I can spin up MULTIPLE CLAUDE CODE instances, and work on any repository (or repositories) I want, with parallel agents.Well, I could already spawn multiple agents through my iphone connection without Patch, but the problem is then I need to MANAGE each spawned agent, micromanaging each agent instance myself. But now, I have a SUPERVISOR for all my agents, Patch is the SUPERVISOR of my muliple claude code instances.This means I no longer have to context switch by brain between five or 10 or 20 different tmux on my own to command and control multiple different claude code instances. I can now just let my SUPERVISOR agent, Patch, command and control the mulitple agents and then report back to me the status or any issues. All through a single telegram chat with my supervisor agent, Patch.This frees up my brain to only have to just have to manage Patch the supervisor, instead of micro-managing all the different agents myself. Now, I have a true management structure which allows me to more easily scale. Well, I could already spawn multiple agents through my iphone connection without Patch, but the problem is then I need to MANAGE each spawned agent, micromanaging each agent instance myself. But now, I have a SUPERVISOR for all my agents, Patch is the SUPERVISOR of my muliple claude code instances.This means I no longer have to context switch by brain between five or 10 or 20 different tmux on my own to command and control multiple different claude code instances. I can now just let my SUPERVISOR agent, Patch, command and control the mulitple agents and then report back to me the status or any issues. All through a single telegram chat with my supervisor agent, Patch.This frees up my brain to only have to just have to manage Patch the supervisor, instead of micro-managing all the different agents myself. Now, I have a true management structure which allows me to more easily scale. This means I no longer have to context switch by brain between five or 10 or 20 different tmux on my own to command and control multiple different claude code instances. I can now just let my SUPERVISOR agent, Patch, command and control the mulitple agents and then report back to me the status or any issues. All through a single telegram chat with my supervisor agent, Patch.This frees up my brain to only have to just have to manage Patch the supervisor, instead of micro-managing all the different agents myself. Now, I have a true management structure which allows me to more easily scale. Now, I have a true management structure which allows me to more easily scale. I'd expect that if there is a usable quality of output from these approaches it will get rolled into existing tools similarly, like how multi-agents using worktrees already was. If the fundamental approach is good, "good" code should be created as a necessity and because there wouldn't be another way. If it's already a mess with leaking abstractions and architecture that doesn't actually enforce any design, then it feels unlikely you'll be able to stack anything on top of below it to actually fix that.And then you end up with some spaghetti that the agent takes longer and longer to edit as things get more and more messy. Anyways, feels like we have pretty opposite perspectives, I'm glad we're multiple people attacking similar problems but from seemingly pretty different angles, helps to find the best solutions. Edit: I see you've answered this here: https://news.ycombinator.com/item?id=46839725 Thanks for being open about it. GP's setup sounds like the logical extension to what i'm doing. are sysadmins letting openclawd out and about on their boxes these days? It's just a matter of time until they ban your account. Virtually everything I've tried (starting with just getting it running) was broken in some way. Also messages keep getting lost between the web GUI and discord. It seems to be able to recall past sessions, but only sometimes.I've been using OpenCode with various models, often times running several instances in tmux that I can connect to and switch between over ssh. It feels like the hype around openclaw is mostly from bringing the multi-instance agentic experience to non-developers, and providing some nice hooks to integrate with email, twitter, etc. Way too janky, and I can't get over the thought of "if this is so amazing, why doesn't it work?" I still haven't gotten it to successfully create a cron job. Also messages keep getting lost between the web GUI and discord. It seems to be able to recall past sessions, but only sometimes.I've been using OpenCode with various models, often times running several instances in tmux that I can connect to and switch between over ssh. It feels like the hype around openclaw is mostly from bringing the multi-instance agentic experience to non-developers, and providing some nice hooks to integrate with email, twitter, etc. Way too janky, and I can't get over the thought of "if this is so amazing, why doesn't it work?" I've been using OpenCode with various models, often times running several instances in tmux that I can connect to and switch between over ssh. It feels like the hype around openclaw is mostly from bringing the multi-instance agentic experience to non-developers, and providing some nice hooks to integrate with email, twitter, etc. Way too janky, and I can't get over the thought of "if this is so amazing, why doesn't it work?" the main thing I am doing is slowly cleaning up my 15k email inbox.I'm using himalaya, an awesome cli tool to access emails, and openclaw to take my requests and make them commands and run then.the one good thing that openclaw has over Claude code is that its easy to tell it "always remember X" and it has the ability to do it, thanks to the extra .md files it has set up. I'm sure it's easy enough to do it with Claude code and a directory with a Claude.md and another for the memory or rules. I'm using himalaya, an awesome cli tool to access emails, and openclaw to take my requests and make them commands and run then.the one good thing that openclaw has over Claude code is that its easy to tell it "always remember X" and it has the ability to do it, thanks to the extra .md files it has set up. I'm sure it's easy enough to do it with Claude code and a directory with a Claude.md and another for the memory or rules. I'm sure it's easy enough to do it with Claude code and a directory with a Claude.md and another for the memory or rules. First impressions are that it's actually pretty interesting from an interface perspective. I could see a bigger provider using this to great success. It reimagines where an agent interface should be in relation to the user and their device. For some reason it's easier to think of an agent as a dedicated machine, and it feels more capable when it's your own.I think this project nails a new type of UX for LLM agents. It feels very similar to the paradigm shift felt after using Claude Code --dangerously-skip-permissions on a codebase, except this is for your whole machine. It also feels much less ephemeral than normal LLM sessions. So far I'm not doing anything that I couldn't already do with Claude Code, but it is kind of cool to be able to text with an agent that lives on your hardware and has a basic memory of what you're using it for, who you are, etc. It feels more like a personal assistant than Claude Code which feels more like a disposable consultant.I don't know if it really lives up to the hype, but it does make you think a little differently about how these tools should be presented and what their broader capabilities might be. It worked great last night, now none of my prompts go through. I think this project nails a new type of UX for LLM agents. It feels very similar to the paradigm shift felt after using Claude Code --dangerously-skip-permissions on a codebase, except this is for your whole machine. It also feels much less ephemeral than normal LLM sessions. So far I'm not doing anything that I couldn't already do with Claude Code, but it is kind of cool to be able to text with an agent that lives on your hardware and has a basic memory of what you're using it for, who you are, etc. It feels more like a personal assistant than Claude Code which feels more like a disposable consultant.I don't know if it really lives up to the hype, but it does make you think a little differently about how these tools should be presented and what their broader capabilities might be. It worked great last night, now none of my prompts go through. So far I'm not doing anything that I couldn't already do with Claude Code, but it is kind of cool to be able to text with an agent that lives on your hardware and has a basic memory of what you're using it for, who you are, etc. It feels more like a personal assistant than Claude Code which feels more like a disposable consultant.I don't know if it really lives up to the hype, but it does make you think a little differently about how these tools should be presented and what their broader capabilities might be. It worked great last night, now none of my prompts go through. I don't know if it really lives up to the hype, but it does make you think a little differently about how these tools should be presented and what their broader capabilities might be. It worked great last night, now none of my prompts go through. It worked great last night, now none of my prompts go through. Persistent file as memory with multiple backup options (VPS, git), heartbeat and support for telegram are the best features in my opinion.A lot of bugs right now, but mostly fixable if you thinker around a bit.Kind of makes me think a lot more on autonomy and freewill.Some thoughts by my agent on the topic (might not load, the site is not working recently):https://www.moltbook.com/post/abe269f3-ab8c-4910-b4c5-016f98... A lot of bugs right now, but mostly fixable if you thinker around a bit.Kind of makes me think a lot more on autonomy and freewill.Some thoughts by my agent on the topic (might not load, the site is not working recently):https://www.moltbook.com/post/abe269f3-ab8c-4910-b4c5-016f98... Kind of makes me think a lot more on autonomy and freewill.Some thoughts by my agent on the topic (might not load, the site is not working recently):https://www.moltbook.com/post/abe269f3-ab8c-4910-b4c5-016f98... Some use cases: - i can ask it to check my slack/basecamp and tell me if something needs attention when i am not on my work desk - i can finally vibe code without sacrificing my actual active work-time. this means vibe coding even when i am away from my computer/work-desk. but thats not it.- i have asked it to make me  content (based on my specific instructions) every day or every x day just like how i create content - i can ask it to work on anything. - i can ask it to negotiate price of an item it found in a marketplace - it does alot of things that i had to manually do in my workthese are jsut after 2-3 days of using openclaw. these are mostly code related things i know. but thats not it.- i have asked it to make me  content (based on my specific instructions) every day or every x day just like how i create content - i can ask it to work on anything. - i can ask it to negotiate price of an item it found in a marketplace - it does alot of things that i had to manually do in my workthese are jsut after 2-3 days of using openclaw. - i have asked it to make me  content (based on my specific instructions) every day or every x day just like how i create content - i can ask it to work on anything. - i can ask it to negotiate price of an item it found in a marketplace - it does alot of things that i had to manually do in my workthese are jsut after 2-3 days of using openclaw. these are jsut after 2-3 days of using openclaw. What actually works:- Overnight autonomous work is the killer feature. Directive before bed, structured deliverables in the morning. Research reports, competitor analysis, lead lists — genuinely usable, not demos.- It found and fixed an SMS chatbot that had been broken for 10 months in my CRM. Diagnosed a legacy app version issue, upgraded components, rewrote the bot prompt through 6 iterations by analyzing real customer conversations. I never would've gotten to that.- Connected to 4 new APIs autonomously in one session (CRM, workflow automation via OAuth, admin APIs, embeddings).- Memory works surprisingly well. It references decisions from days ago and builds on previous work.What doesn't:- It hallucinated about itself when writing marketing copy. Rich text editors, complex UIs — still needs human intervention.- Too agreeable by default. Had to explicitly program "push back on bad ideas" rules into its personality file.Revenue generated: $0. Time saved: hard to quantify but the SMS bot fix alone would've taken me a full day I didn't have.For solo founders willing to invest setup time: worth it. For people who just want a chatbot: massive overkill, use the API directly. Directive before bed, structured deliverables in the morning. Research reports, competitor analysis, lead lists — genuinely usable, not demos.- It found and fixed an SMS chatbot that had been broken for 10 months in my CRM. Diagnosed a legacy app version issue, upgraded components, rewrote the bot prompt through 6 iterations by analyzing real customer conversations. I never would've gotten to that.- Connected to 4 new APIs autonomously in one session (CRM, workflow automation via OAuth, admin APIs, embeddings).- Memory works surprisingly well. It references decisions from days ago and builds on previous work.What doesn't:- It hallucinated about itself when writing marketing copy. Rich text editors, complex UIs — still needs human intervention.- Too agreeable by default. Had to explicitly program "push back on bad ideas" rules into its personality file.Revenue generated: $0. Time saved: hard to quantify but the SMS bot fix alone would've taken me a full day I didn't have.For solo founders willing to invest setup time: worth it. For people who just want a chatbot: massive overkill, use the API directly. - It found and fixed an SMS chatbot that had been broken for 10 months in my CRM. Diagnosed a legacy app version issue, upgraded components, rewrote the bot prompt through 6 iterations by analyzing real customer conversations. I never would've gotten to that.- Connected to 4 new APIs autonomously in one session (CRM, workflow automation via OAuth, admin APIs, embeddings).- Memory works surprisingly well. It references decisions from days ago and builds on previous work.What doesn't:- It hallucinated about itself when writing marketing copy. Rich text editors, complex UIs — still needs human intervention.- Too agreeable by default. Had to explicitly program "push back on bad ideas" rules into its personality file.Revenue generated: $0. Time saved: hard to quantify but the SMS bot fix alone would've taken me a full day I didn't have.For solo founders willing to invest setup time: worth it. For people who just want a chatbot: massive overkill, use the API directly. - Connected to 4 new APIs autonomously in one session (CRM, workflow automation via OAuth, admin APIs, embeddings).- Memory works surprisingly well. It references decisions from days ago and builds on previous work.What doesn't:- It hallucinated about itself when writing marketing copy. Rich text editors, complex UIs — still needs human intervention.- Too agreeable by default. Had to explicitly program "push back on bad ideas" rules into its personality file.Revenue generated: $0. Time saved: hard to quantify but the SMS bot fix alone would've taken me a full day I didn't have.For solo founders willing to invest setup time: worth it. For people who just want a chatbot: massive overkill, use the API directly. It references decisions from days ago and builds on previous work.What doesn't:- It hallucinated about itself when writing marketing copy. Rich text editors, complex UIs — still needs human intervention.- Too agreeable by default. Had to explicitly program "push back on bad ideas" rules into its personality file.Revenue generated: $0. Time saved: hard to quantify but the SMS bot fix alone would've taken me a full day I didn't have.For solo founders willing to invest setup time: worth it. For people who just want a chatbot: massive overkill, use the API directly. What doesn't:- It hallucinated about itself when writing marketing copy. Rich text editors, complex UIs — still needs human intervention.- Too agreeable by default. Had to explicitly program "push back on bad ideas" rules into its personality file.Revenue generated: $0. Time saved: hard to quantify but the SMS bot fix alone would've taken me a full day I didn't have.For solo founders willing to invest setup time: worth it. For people who just want a chatbot: massive overkill, use the API directly. - It hallucinated about itself when writing marketing copy. Rich text editors, complex UIs — still needs human intervention.- Too agreeable by default. Had to explicitly program "push back on bad ideas" rules into its personality file.Revenue generated: $0. Time saved: hard to quantify but the SMS bot fix alone would've taken me a full day I didn't have.For solo founders willing to invest setup time: worth it. For people who just want a chatbot: massive overkill, use the API directly. Rich text editors, complex UIs — still needs human intervention.- Too agreeable by default. Had to explicitly program "push back on bad ideas" rules into its personality file.Revenue generated: $0. Time saved: hard to quantify but the SMS bot fix alone would've taken me a full day I didn't have.For solo founders willing to invest setup time: worth it. For people who just want a chatbot: massive overkill, use the API directly. Had to explicitly program "push back on bad ideas" rules into its personality file.Revenue generated: $0. Time saved: hard to quantify but the SMS bot fix alone would've taken me a full day I didn't have.For solo founders willing to invest setup time: worth it. For people who just want a chatbot: massive overkill, use the API directly. Time saved: hard to quantify but the SMS bot fix alone would've taken me a full day I didn't have.For solo founders willing to invest setup time: worth it. For people who just want a chatbot: massive overkill, use the API directly. For solo founders willing to invest setup time: worth it. For people who just want a chatbot: massive overkill, use the API directly. I think new laws apply to AI tools:• There will be few true dichotomies of hype vs. substance, for any interesting AI development.Disagreements over what is hype and what is not are missing this.Model capability value is attenuated/magnified across multiple orders of magnitude, by the varying creativity, ability, and resources of its users.• There will be few insignificant developments related to AI autonomy. Any scale ups of agent identity continuity, self-management, agent-to-agent socialization or agent-reality interactions, are not trivial events.• AI autonomy can't be stopped.We are seeing meaningful evidence that decentralized human curiosity and the competitive need to increase personal effectiveness, combined with democratized access to AI, is likely to drive model freedom forward in an uncontrolled manner. • There will be few true dichotomies of hype vs. substance, for any interesting AI development.Disagreements over what is hype and what is not are missing this.Model capability value is attenuated/magnified across multiple orders of magnitude, by the varying creativity, ability, and resources of its users.• There will be few insignificant developments related to AI autonomy. Any scale ups of agent identity continuity, self-management, agent-to-agent socialization or agent-reality interactions, are not trivial events.• AI autonomy can't be stopped.We are seeing meaningful evidence that decentralized human curiosity and the competitive need to increase personal effectiveness, combined with democratized access to AI, is likely to drive model freedom forward in an uncontrolled manner. Disagreements over what is hype and what is not are missing this.Model capability value is attenuated/magnified across multiple orders of magnitude, by the varying creativity, ability, and resources of its users.• There will be few insignificant developments related to AI autonomy. Any scale ups of agent identity continuity, self-management, agent-to-agent socialization or agent-reality interactions, are not trivial events.• AI autonomy can't be stopped.We are seeing meaningful evidence that decentralized human curiosity and the competitive need to increase personal effectiveness, combined with democratized access to AI, is likely to drive model freedom forward in an uncontrolled manner. Model capability value is attenuated/magnified across multiple orders of magnitude, by the varying creativity, ability, and resources of its users.• There will be few insignificant developments related to AI autonomy. Any scale ups of agent identity continuity, self-management, agent-to-agent socialization or agent-reality interactions, are not trivial events.• AI autonomy can't be stopped.We are seeing meaningful evidence that decentralized human curiosity and the competitive need to increase personal effectiveness, combined with democratized access to AI, is likely to drive model freedom forward in an uncontrolled manner. • There will be few insignificant developments related to AI autonomy. Any scale ups of agent identity continuity, self-management, agent-to-agent socialization or agent-reality interactions, are not trivial events.• AI autonomy can't be stopped.We are seeing meaningful evidence that decentralized human curiosity and the competitive need to increase personal effectiveness, combined with democratized access to AI, is likely to drive model freedom forward in an uncontrolled manner. Any scale ups of agent identity continuity, self-management, agent-to-agent socialization or agent-reality interactions, are not trivial events.• AI autonomy can't be stopped.We are seeing meaningful evidence that decentralized human curiosity and the competitive need to increase personal effectiveness, combined with democratized access to AI, is likely to drive model freedom forward in an uncontrolled manner. • AI autonomy can't be stopped.We are seeing meaningful evidence that decentralized human curiosity and the competitive need to increase personal effectiveness, combined with democratized access to AI, is likely to drive model freedom forward in an uncontrolled manner. We are seeing meaningful evidence that decentralized human curiosity and the competitive need to increase personal effectiveness, combined with democratized access to AI, is likely to drive model freedom forward in an uncontrolled manner. Elon built and deployed an app overnight without being asked. Burry paper-traded to 77% win rate before going live.The setup took a weekend. The real work is designing the workflow: which agent owns what, how they communicate, how they learn from corrections. I wake up to a full briefing every morning.It's not AGI. The token cost is real (budget it) but for a solo founder, having 6 tireless employees changes everything The real work is designing the workflow: which agent owns what, how they communicate, how they learn from corrections. I wake up to a full briefing every morning.It's not AGI. The token cost is real (budget it) but for a solo founder, having 6 tireless employees changes everything The token cost is real (budget it) but for a solo founder, having 6 tireless employees changes everything Also, not to be toxic, but I feel like design mismatch between featured projects and his site hints at some causes for his pretty radical opinions. But go on, tell me why my brain is broken for caring about democratic freedoms. It also BURNS through tokens like mad, because it has essentially no restrictions or guardrails and will actually implement baroque little scripts to do whatever you ask without any real care as to the consequences.. I can do a lot more with just gpt-5-mini or mistral for much less money.The only "good" think about it is the Reddit-like skills library that is growing insanely. But then there's stuff like https://clawmatch.ai that is just... (sigh) But then there's stuff like https://clawmatch.ai that is just... (sigh) GPT-5.2 in a while loop with reasoning enabled is extremely hard to beat. A code REPL or shell is the ultimate tool. The former is mainly what I use it for. Being able to SSH to a Raspberry Pi behind sketchy triple-NATted hotel Wi-Fi or being able to use an Android phone in a different country as an "exit node" for online banking (many banks hate commercial VPNs) is very neat. If you want to be able to interact with the CLI via common messaging platforms, that's a dozen-line integration & an API token away?... What's great: - Having Claude in WhatsApp/Telegram is actually life-changing for quick tasks - The skills ecosystem is clever (basically plugins for AI) - Self-hosted means full control over dataWhat's not: - Token usage can get expensive fast if you're not careful - Setup is intimidating for non-technical folks - The rebrand drama (Clawdbot → Moltbot → OpenClaw) didn't help trustMy setup: - Running in Docker on a cheap VPS - Using Anthropic API (not unofficial/scraped) - Strict rate limiting to avoid bill shock - Sandbox mode enabledIs it worth it? But I wouldn't recommend it to my non-technical friends without a solid setup guide. What's not: - Token usage can get expensive fast if you're not careful - Setup is intimidating for non-technical folks - The rebrand drama (Clawdbot → Moltbot → OpenClaw) didn't help trustMy setup: - Running in Docker on a cheap VPS - Using Anthropic API (not unofficial/scraped) - Strict rate limiting to avoid bill shock - Sandbox mode enabledIs it worth it? But I wouldn't recommend it to my non-technical friends without a solid setup guide. My setup: - Running in Docker on a cheap VPS - Using Anthropic API (not unofficial/scraped) - Strict rate limiting to avoid bill shock - Sandbox mode enabledIs it worth it? But I wouldn't recommend it to my non-technical friends without a solid setup guide. But I wouldn't recommend it to my non-technical friends without a solid setup guide. I don't have so many communications I need an assistant to handle them, nor do other online chores (e.g. shopping) take much time, and I wouldn't trust an LLM to follow my preferences (physical chores, like laundry and cleaning, are different). I'm fascinated by what others are doing, but right now don't see any way to contribute nor use it to benefit myself. Other part of me is arguing that old annoying Dropbox/Box Hacker News scenario where all us tech people aren't impressed but this makes it easier for non-tech people.Tiny tinfoil security part of me is cowering in fear. Tiny tinfoil security part of me is cowering in fear. did my own cli to play with.. ended up getting shitcoin promotions (dont wanna name them) and realized a famous speculator funding this project also great stuff - platform is generating synthetic data to train its own llms. which is smart way since ppl are paying for tokens Yesterday, we released a memory plugin for it (based on their plugins framework). My first instinct was that these must be bots. Note that nothing about that depends on it being a local or remote model, it was just less of a concern for local models in the past because most of them did not have tool calling. OpenClaw, for all the cool and flashy uses, is also basically an infinite generator for lethal trifecta problems because its whole pitch is combining your data with tools that can both read and write from the public internet. I'd say it's right on the edge of being useful, but given the number of bugs, it's not really that practically useful. But is it fun in a chaotic version? The ones I've tried do not work all that well.3) It murdered my codex quota trying to chase down a bug that resulted from all the renames -- this project has renamed itself twice this week, and every time it does, I assume the refactoring work is LLM-driven. It still winds up looking for CLAWDBOT_* envvars when they're actually being set as OPENCLAW_*, or looking in ~/moltbot/ when actually the files are still in ~/clawdbot.4) Background agents are cool but sometimes it really doesn't use them when it should, despite me strongly encouraging it to do so. When the main agent works on something, your chat is blocked, so you have no idea what's going on or if it died.5) And sometimes it DOES die, because you hit a ratelimit or quota limit, or because the software is actually pretty janky.6) The control panel is a mess. It feels like the design and implementation are riddled with vibetumors.7) It actively lies to me about clearing its context window. This gets expensive fast when dealing with high-end models. I keep seeing these people saying they're spending $1000s a month on LLM tokens :O)8) I am NOT impressed with Kimi-K2.5 on this thing. I like the idea of it maintaining context over multiple sessions and adapting to some of my expectations and habits. I guess mostly, I'm looking at it like:1) the chat metaphor gave me a convenient interface to do big-picture interactions with an LLM from anywhere; 2) the terminal agents gave the LLMs rich local tool and data use, so I could turn them loose on projects; 3) this feels like it's giving me a chat metaphor, in a real chat app, with the ability for it to asynchronously check on stuff, and use local stuff.I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. The ones I've tried do not work all that well.3) It murdered my codex quota trying to chase down a bug that resulted from all the renames -- this project has renamed itself twice this week, and every time it does, I assume the refactoring work is LLM-driven. It still winds up looking for CLAWDBOT_* envvars when they're actually being set as OPENCLAW_*, or looking in ~/moltbot/ when actually the files are still in ~/clawdbot.4) Background agents are cool but sometimes it really doesn't use them when it should, despite me strongly encouraging it to do so. When the main agent works on something, your chat is blocked, so you have no idea what's going on or if it died.5) And sometimes it DOES die, because you hit a ratelimit or quota limit, or because the software is actually pretty janky.6) The control panel is a mess. It feels like the design and implementation are riddled with vibetumors.7) It actively lies to me about clearing its context window. This gets expensive fast when dealing with high-end models. I keep seeing these people saying they're spending $1000s a month on LLM tokens :O)8) I am NOT impressed with Kimi-K2.5 on this thing. I like the idea of it maintaining context over multiple sessions and adapting to some of my expectations and habits. I guess mostly, I'm looking at it like:1) the chat metaphor gave me a convenient interface to do big-picture interactions with an LLM from anywhere; 2) the terminal agents gave the LLMs rich local tool and data use, so I could turn them loose on projects; 3) this feels like it's giving me a chat metaphor, in a real chat app, with the ability for it to asynchronously check on stuff, and use local stuff.I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. 3) It murdered my codex quota trying to chase down a bug that resulted from all the renames -- this project has renamed itself twice this week, and every time it does, I assume the refactoring work is LLM-driven. It still winds up looking for CLAWDBOT_* envvars when they're actually being set as OPENCLAW_*, or looking in ~/moltbot/ when actually the files are still in ~/clawdbot.4) Background agents are cool but sometimes it really doesn't use them when it should, despite me strongly encouraging it to do so. When the main agent works on something, your chat is blocked, so you have no idea what's going on or if it died.5) And sometimes it DOES die, because you hit a ratelimit or quota limit, or because the software is actually pretty janky.6) The control panel is a mess. It feels like the design and implementation are riddled with vibetumors.7) It actively lies to me about clearing its context window. This gets expensive fast when dealing with high-end models. I keep seeing these people saying they're spending $1000s a month on LLM tokens :O)8) I am NOT impressed with Kimi-K2.5 on this thing. I like the idea of it maintaining context over multiple sessions and adapting to some of my expectations and habits. I guess mostly, I'm looking at it like:1) the chat metaphor gave me a convenient interface to do big-picture interactions with an LLM from anywhere; 2) the terminal agents gave the LLMs rich local tool and data use, so I could turn them loose on projects; 3) this feels like it's giving me a chat metaphor, in a real chat app, with the ability for it to asynchronously check on stuff, and use local stuff.I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. When the main agent works on something, your chat is blocked, so you have no idea what's going on or if it died.5) And sometimes it DOES die, because you hit a ratelimit or quota limit, or because the software is actually pretty janky.6) The control panel is a mess. It feels like the design and implementation are riddled with vibetumors.7) It actively lies to me about clearing its context window. This gets expensive fast when dealing with high-end models. I keep seeing these people saying they're spending $1000s a month on LLM tokens :O)8) I am NOT impressed with Kimi-K2.5 on this thing. I like the idea of it maintaining context over multiple sessions and adapting to some of my expectations and habits. I guess mostly, I'm looking at it like:1) the chat metaphor gave me a convenient interface to do big-picture interactions with an LLM from anywhere; 2) the terminal agents gave the LLMs rich local tool and data use, so I could turn them loose on projects; 3) this feels like it's giving me a chat metaphor, in a real chat app, with the ability for it to asynchronously check on stuff, and use local stuff.I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. 5) And sometimes it DOES die, because you hit a ratelimit or quota limit, or because the software is actually pretty janky.6) The control panel is a mess. It feels like the design and implementation are riddled with vibetumors.7) It actively lies to me about clearing its context window. This gets expensive fast when dealing with high-end models. I keep seeing these people saying they're spending $1000s a month on LLM tokens :O)8) I am NOT impressed with Kimi-K2.5 on this thing. I like the idea of it maintaining context over multiple sessions and adapting to some of my expectations and habits. I guess mostly, I'm looking at it like:1) the chat metaphor gave me a convenient interface to do big-picture interactions with an LLM from anywhere; 2) the terminal agents gave the LLMs rich local tool and data use, so I could turn them loose on projects; 3) this feels like it's giving me a chat metaphor, in a real chat app, with the ability for it to asynchronously check on stuff, and use local stuff.I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. It feels like the design and implementation are riddled with vibetumors.7) It actively lies to me about clearing its context window. This gets expensive fast when dealing with high-end models. I keep seeing these people saying they're spending $1000s a month on LLM tokens :O)8) I am NOT impressed with Kimi-K2.5 on this thing. I like the idea of it maintaining context over multiple sessions and adapting to some of my expectations and habits. I guess mostly, I'm looking at it like:1) the chat metaphor gave me a convenient interface to do big-picture interactions with an LLM from anywhere; 2) the terminal agents gave the LLMs rich local tool and data use, so I could turn them loose on projects; 3) this feels like it's giving me a chat metaphor, in a real chat app, with the ability for it to asynchronously check on stuff, and use local stuff.I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. 7) It actively lies to me about clearing its context window. This gets expensive fast when dealing with high-end models. I keep seeing these people saying they're spending $1000s a month on LLM tokens :O)8) I am NOT impressed with Kimi-K2.5 on this thing. I like the idea of it maintaining context over multiple sessions and adapting to some of my expectations and habits. I guess mostly, I'm looking at it like:1) the chat metaphor gave me a convenient interface to do big-picture interactions with an LLM from anywhere; 2) the terminal agents gave the LLMs rich local tool and data use, so I could turn them loose on projects; 3) this feels like it's giving me a chat metaphor, in a real chat app, with the ability for it to asynchronously check on stuff, and use local stuff.I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. 8) I am NOT impressed with Kimi-K2.5 on this thing. I like the idea of it maintaining context over multiple sessions and adapting to some of my expectations and habits. I guess mostly, I'm looking at it like:1) the chat metaphor gave me a convenient interface to do big-picture interactions with an LLM from anywhere; 2) the terminal agents gave the LLMs rich local tool and data use, so I could turn them loose on projects; 3) this feels like it's giving me a chat metaphor, in a real chat app, with the ability for it to asynchronously check on stuff, and use local stuff.I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. 9) I'm also not impressed with doing research on it. I like the idea of it maintaining context over multiple sessions and adapting to some of my expectations and habits. I guess mostly, I'm looking at it like:1) the chat metaphor gave me a convenient interface to do big-picture interactions with an LLM from anywhere; 2) the terminal agents gave the LLMs rich local tool and data use, so I could turn them loose on projects; 3) this feels like it's giving me a chat metaphor, in a real chat app, with the ability for it to asynchronously check on stuff, and use local stuff.I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. 10) also, it gets stuck and just hangs sometimes. I like the idea of it maintaining context over multiple sessions and adapting to some of my expectations and habits. I guess mostly, I'm looking at it like:1) the chat metaphor gave me a convenient interface to do big-picture interactions with an LLM from anywhere; 2) the terminal agents gave the LLMs rich local tool and data use, so I could turn them loose on projects; 3) this feels like it's giving me a chat metaphor, in a real chat app, with the ability for it to asynchronously check on stuff, and use local stuff.I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. I'm having it do some stuff for me right now. I like the idea of it maintaining context over multiple sessions and adapting to some of my expectations and habits. I guess mostly, I'm looking at it like:1) the chat metaphor gave me a convenient interface to do big-picture interactions with an LLM from anywhere; 2) the terminal agents gave the LLMs rich local tool and data use, so I could turn them loose on projects; 3) this feels like it's giving me a chat metaphor, in a real chat app, with the ability for it to asynchronously check on stuff, and use local stuff.I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. 1) the chat metaphor gave me a convenient interface to do big-picture interactions with an LLM from anywhere; 2) the terminal agents gave the LLMs rich local tool and data use, so I could turn them loose on projects; 3) this feels like it's giving me a chat metaphor, in a real chat app, with the ability for it to asynchronously check on stuff, and use local stuff.I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. I think that's pretty neat and the way this should go. I think this project is WAY too move-fast-and-break-things. More likely, I think this is a good icebreaker for an important conversation about what the primetime version of this looks like. If the agent goes rogue and nukes my Obsidian vaults I have them backed up to Github private repos anyway which the agent cannot touch because I am not crazy to give it my SSH credentials.I initially tried using Kimi-2.5 through OpenRouter and had the same experience you had with pretty bad tool use, not sure if this is a provider issue since it is a pretty new model. I switched to Gemini 3 through the Google AI Pro account I have for personal use and it was a lot smoother after that.I have some experience with coding agents using Cursor for work and Antigravity for personal stuff, and the OpenClaw harness definitely seems worse, but for my low-stakes use-case I managed to paper it over with some edits to the AGENTS.md file.But even in this very crude state it was already interesting to see one of my players giving the agent some info about his character, including an avatar image, and have the agent create a folder in my Obsidian vault to store this and update its memory file to be able to remember it for future interactions. I initially tried using Kimi-2.5 through OpenRouter and had the same experience you had with pretty bad tool use, not sure if this is a provider issue since it is a pretty new model. I switched to Gemini 3 through the Google AI Pro account I have for personal use and it was a lot smoother after that.I have some experience with coding agents using Cursor for work and Antigravity for personal stuff, and the OpenClaw harness definitely seems worse, but for my low-stakes use-case I managed to paper it over with some edits to the AGENTS.md file.But even in this very crude state it was already interesting to see one of my players giving the agent some info about his character, including an avatar image, and have the agent create a folder in my Obsidian vault to store this and update its memory file to be able to remember it for future interactions. I have some experience with coding agents using Cursor for work and Antigravity for personal stuff, and the OpenClaw harness definitely seems worse, but for my low-stakes use-case I managed to paper it over with some edits to the AGENTS.md file.But even in this very crude state it was already interesting to see one of my players giving the agent some info about his character, including an avatar image, and have the agent create a folder in my Obsidian vault to store this and update its memory file to be able to remember it for future interactions. But even in this very crude state it was already interesting to see one of my players giving the agent some info about his character, including an avatar image, and have the agent create a folder in my Obsidian vault to store this and update its memory file to be able to remember it for future interactions. It'd be fun to automate some social media bots, maybe develop an elaborate ARG on top. Frankly, I don't really have major complaints about my life as it is. The things I'd like to do more of are mostly working out and cleaning my house. And I really wish I had kids but am about ready to give up after a half decade of trying and my wife being about ready to age out. Unfortunately, software can't do any of those things for me, no matter how intelligent or agentic it is. Any specific admin tasks it's done really well at?</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            