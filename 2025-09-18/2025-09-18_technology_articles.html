
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - TECHNOLOGY Article Summaries - 2025-09-18</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            TECHNOLOGY
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/09/18/google-now-lets-you-share-your-custom-gemini-ai-assistants-known-as-gems/'>Google now lets you share your custom Gemini AI assistants known as Gems</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 17:35:13
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Google is making it possible to now share your Gemini Gems — custom AI assistants and experts designed for specific tasks — the company announced on Thursday. The feature launched last year, initially as part of the Gemini Advanced paid subscription, allowing users to write instructions to create an AI chatbot for different scenarios. Now, Google says you'll be able to share your Gems with friends, family, or coworkers as easily as you can share a file from Google Drive. It could also help prevent people from building the same Gems as others. For instance, if multiple coworkers were using a similar type of custom Gemini assistant, they could just share the same resource instead of each making their own version that could have slight inconsistencies between them. Google suggests Gem sharing could also be useful for people working on family vacation plans and guides, meal planners, or collaborative writing projects. Also similar to Google Drive, you can control who can view and use your Gems and who's allowed to edit them. Register now and save up to $668.Regular Bird rates end September 26 Every weekday and Sunday, you can get the best of TechCrunch's coverage. TechCrunch Mobility is your destination for transportation news and insight. Startups are the core of TechCrunch, so get our best coverage delivered weekly. Provides movers and shakers with the info they need to start their day. By submitting your email, you agree to our Terms and Privacy Notice.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/09/18/google-brings-gemini-in-chrome-to-us-users-unveils-agentic-browsing-capabilities-and-more/'>Google brings Gemini in Chrome to US users, unveils agentic browsing capabilities, and more</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 17:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The tech giant also announced that it's bringing agentic capabilities to Chrome in the future, adding its AI Mode search feature to the address bar, launching new Gemini features, using AI to combat AI-generated scams, rolling out automatic password resets, and more. U.S. users who have their language set to English can now ask Gemini to clarify complex information on any webpage they're reading using the Gemini icon in the top-right corner of their Chrome window. For example, you could open up a page that features a banana bread recipe and ask Gemini to make the recipe gluten free. For example, you could be planning your flight, hotel, and vacation in multiple tabs and work with Gemini to organize your trip. Or, you might be shopping for a new mattress and want to compare all of the different models you're looking at in multiple tabs. That means you will be able to ask something like “On which site did I see the walnut desk last week?” or “What was that blog I read on back to school shopping?” Google says this will allow users to do things like schedule meetings, see location details, and more more without having to leave the page they're on. Google notes that the AI assistant will be able to complete tedious tasks, like booking a haircut or ordering weekly groceries. Gemini will navigate to the site, add things to your cart, and let you take the final action by checking out with your payment option. Google is also bringing AI Mode, its advanced search feature, directly into the Chrome address bar. For example, instead of searching for “best mattress,” you could type out “I'm a side sleeper with occasional lower back pain, make me a table comparing the different mattress types” directly in the address bar. From there, you could ask follow-up questions and keep your search going with queries like, “How long do memory foam mattresses typically last?” Google says Chrome will also soon be able to use its Gemini Nano model to detect and protect against scams, such as fake virus alerts and fraudulent giveaways. These scams often impersonate trusted brands and use generative AI to create convincing phishing attempts, Google notes. Google also announced that it's using AI to help users fix compromised passwords with a single click on supported sites, like Coursera, Spotify, Duolingo, H&M, and more. Prior to joining the publication in 2021, she was a telecom reporter at MobileSyrup. Register now and save up to $668.Regular Bird rates end September 26 Apple's iOS 26 with the new Liquid Glass design is now available to everyone Spotify will now let free users pick and play tracks Why the Oracle-OpenAI deal caught Wall Street by surprise Elon Musk's Boring Company suspends work on Vegas airport tunnel after ‘crushing injury'</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/seattle-mayoral-front-runner-katie-wilson-on-taxes-tech-sector-and-working-with-amazon/'>Seattle mayoral front-runner Katie Wilson on taxes, tech sector and working with Amazon</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 15:24:20
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>For many Seattle civic leaders, the tech companies operating here have often represented a double-edged sword. As Seattle grapples with persistent issues including homelessness and fentanyl abuse while debating how to fund city services, Wilson wants to engage the tech sector as part of the solution. Wilson helped design and pass Seattle's controversial JumpStart payroll expense tax in 2020. A majority of the revenue — $360 million in 2024 — is generated from 10 companies, including Amazon. “The JumpStart tax, overall, I would call it a very successful policy,” she told GeekWire. The tax evolved from a previous “head tax” proposal in 2018 that drew sharp criticism from Amazon, which later announced that it was moving thousands of jobs to nearby Bellevue. Those tensions have eased during Harrell's term, and Wilson said she aims to work with the company. She touted her coalition building efforts and said collaboration is possible even if parties are not aligned on every issue. The state passed several new taxes on businesses earlier this year to help fund public schools, community safety programs and other services. Wilson supported the measure, while Harrell, Amazon and Microsoft opposed it. Harrell proposed an alternative funding mechanism for public housing from the existing JumpStart tax. In a recent debate, the mayor said he wants affordable housing, but expressed concern about businesses leaving Seattle over higher taxes. Wilson is also a proponent of taxing profits made from the sale of stocks and bonds, though the Seattle City Council last year narrowly rejected a proposed 2% capital gains tax. What the state and city need, Wilson said, “is a progressive tax system that is robust enough that it is funding the public goods and services that we all depend on to have a functional state, to have a functional city.” While tech dominates the Seattle economy, Wilson is interested in diversifying that focus. In a recent post on Reddit, she cautioned that a heavy reliance on the tech sector could pose problems for Seattle down the road. “We've really been blithely riding the tech wave for the past 15 years and I don't think we can just assume that will continue,” she wrote. That would include partnering with the University of Washington and the Port of Seattle to foster job creation around clean energy and other climate technologies. But the recovery remains fragile as downtown vacancy rates are above 30%. That could entail building more housing downtown and converting offices to residential spaces where feasible. The city would also need to add more amenities such as grocery stores, pharmacies and childcare, plus improving safety. Wilson has vowed to establish 4,000 spaces for people experiencing homelessness, including tiny shelters, overnight beds in church facilities, and other emergency solutions. She also wants to explore the creation of a municipal voucher program to help people rent the thousands of vacant apartments that are earmarked for affordable housing, but still too expensive for many renters. But I think we can get there over four years.” Microsoft's mission: empowering every person and organization on the planet to achieve more. Learn how Microsoft is thinking about responsible artificial intelligence, regulation, sustainability, and fundamental rights. ‘They don't have an AI House in Bellevue': Seattle mayor takes a friendly jab at cross-town rival Seattle unveils a ‘responsible AI plan' to guide city's tech use and boost the local economy Ex-Microsoft strategist running for Congress wants a ‘realistic' approach to regulating and guiding AI policy ‘They don't have an AI House in Bellevue': Seattle mayor takes a friendly jab at cross-town rival Seattle mayor, who sits on a federal AI panel, says he'll seek ways to work with Trump administration</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/sold-on-walmart-sent-by-amazon-the-weird-new-world-of-online-retail/'>Sold on Walmart, sent by Amazon: The weird new world of online retail</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 15:22:16
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>In an e-commerce twist almost worthy of The Twilight Zone or Black Mirror, Amazon is now officially supporting orders placed on Walmart.com — allowing sellers to tap into Amazon's logistics network to fulfill purchases made on the site of its biggest retail rival. Amazon is also deepening its Shopify support and plans to begin fulfilling orders from fast-fashion juggernaut Shein later this year. [RELATED STORY: After years of backlash, Amazon ends a practice that sellers loathe] In the process, it's competing more directly with services from rivals like ShipBob, FedEx, UPS, and DHL, in addition to services from Walmart and Shopify themselves. Amazon already supports fulfillment of orders from sites including eBay, Etsy, Temu and others. But using MCF for unsupported platforms requires a manual, cumbersome process. “This is now a direct integration, so that anytime you get a Walmart order, we'll just fulfill it,” said Dharmesh Mehta, Amazon's vice president of selling partner services, in an interview. But they won't have the blue and yellow Walmart logo, either. The company's revenue from third-party seller services — which includes commissions, fulfillment and shipping fees, and related services — reached $156 billion in 2024, or nearly a quarter of its total revenue of $638 billion. The chips powering your smart TV, voice assistant, tablet, and car all have something in common: MediaTek After years of backlash, Amazon finally ends a practice that many sellers have long loathed Amazon unveils new agentic AI tools for sellers amid heightened scrutiny Pandion, an e-commerce delivery startup led by Amazon Air founder, lands $41.5M After years of backlash, Amazon finally ends a practice that many sellers have long loathed Amazon fashion competitor Shein bringing a pop-up experience to Seattle next week</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/microsoft-entra-id-vulnerability-digital-catastrophe/'>This Microsoft Entra ID Vulnerability Could Have Been Catastrophic</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 15:09:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>But with so much riding on these systems, there can be potentially disastrous consequences at a massive scale if something goes wrong. Case in point: Security researcher Dirk-jan Mollema recently stumbled upon a pair of vulnerabilities in Microsoft Azure's identity and access management platform that could have been exploited for a potentially cataclysmic takeover of all Azure customer accounts. Known as Entra ID, the system stores each Azure cloud customer's user identities, sign-in access controls, applications, and subscription management tools. Mollema has studied Entra ID security in depth and published multiple studies about weaknesses in the system, which was formerly known as Azure Active Directory. But while preparing to present at the Black Hat security conference in Las Vegas in July, Mollema discovered two vulnerabilities that he realized could be used to gain global administrator privileges—essentially god mode—and compromise every Entra ID directory, or what is known as a “tenant.” Mollema says that this would have exposed nearly every Entra ID tenant in the world other than, perhaps, government cloud infrastructure. I was like, ‘No, this shouldn''t really happen,'” says Mollema, who runs the Dutch cybersecurity company Outsider Security and specializes in cloud security. “From my own tenants—my test tenant or even a trial tenant—you could request these tokens and you could impersonate basically anybody else in anybody else's tenant,” Mollema adds. Microsoft started investigating the findings that day and issued a fix globally on July 17. “We mitigated the newly identified issue quickly, and accelerated the remediation work underway to decommission this legacy protocol usage, as part of our Secure Future Initiative,” Tom Gallagher, Microsoft's Security Response Center vice president of engineering, told WIRED in a statement. Both vulnerabilities relate to legacy systems still functioning within Entra ID. The first involves a type of Azure authentication token Mollema discovered known as Actor Tokens that are issued by an obscure Azure mechanism called the “Access Control Service.” Actor Tokens have some special system properties that Mollema realized could be useful to an attacker when combined with another vulnerability. The other bug was a major flaw in a historic Azure Active Directory application programming interface known as “Graph” that was used to facilitate access to data stored in Microsoft 365. Microsoft is in the process of retiring Azure Active Directory Graph and transitioning users to its successor, Microsoft Graph, which is designed for Entra ID. The flaw was related to a failure by Azure AD Graph to properly validate which Azure tenant was making an access request, which could be manipulated so the API would accept an Actor Token from a different tenant that should have been rejected. “Microsoft built security controls around identity like conditional access and logs, but this internal impression token mechanism bypasses them all,” says Michael Bargury, the CTO at security firm Zenity. “This is the most impactful vulnerability you can find in an identity provider, effectively allowing full compromise of any tenant of any customer.” “We don't need to guess what the impact may have been; we saw two years ago what happened when Storm-0558 compromised a signing key that allowed them to log in as any user on any tenant,” Bargury says. While the specific technical details are different, Microsoft revealed in July 2023 that the Chinese cyber espionage group known as Storm-0558 had stolen a cryptographic key that allowed them to generate authentication tokens and access cloud-based Outlook email systems, including those belonging to US government departments. These motivated the company to launch its “Secure Future Initiative,” which expanded protections for cloud security systems and set more aggressive goals for responding to vulnerability disclosures and issuing patches. Mollema says that Microsoft was extremely responsive about his findings and seemed to grasp their urgency. But he emphasizes that his findings could have allowed malicious hackers to go even farther than they did in the 2023 incident. In your inbox: Our biggest stories, handpicked for you each day The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/scientists-just-found-south-americas-first-amber-preserved-insects-and-theyre-gorgeous-2000660129'>Scientists Just Found South America's First Amber-Preserved Insects—and They're Stunning</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 15:00:35
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>For the first time, scientists have uncovered a large amber deposit in South America containing fossilized insects and other preserved creatures. The small, half-transparent fossils hold a rich assortment of ancient bugs—and a slice of life from little-known ecosystems from over 100 million years ago. A Communications & Earth Environment study published today details amber samples from Ecuador's Genoveva quarry—the first discovery in South America to yield fossilized insects and other life forms. Amber is fossilized resin, also known as tree sap. Resin remains sticky for a couple of days to several months, trapping the occasional insect or organism that stumbles across its path. Paleontological records indicate that trees have produced resin for over 320 million years, but it's only been within the last 120 million years that amber has “formed in large enough quantities” to create sizable fossil deposits, Delclòs explained. While amber can preserve smaller animals less likely to fossilize, the long process quickly decomposes bodily parts weaker than the exoskeleton of arthropods. The new discovery, for instance, found fragile, thin strands of spider silk. “And this is just the beginning,” he said. “In a very small sample, we already identified six different insect orders. The site promises to be a treasure trove.” To make every observation count, the team relied on a highly multidisciplinary approach involving methods from geochemistry and paleobotany. They even borrowed a synchrotron—that is, a particle accelerator—to light the samples and “reveal the fine anatomical details of insects,” Delclòs explained. “Together, these lines of evidence allow us to reconstruct, with unprecedented accuracy, the ecosystem of a Cretaceous rainforest that once thrived where today lies the Amazon,” he said. The researchers believe there are more undiscovered amber deposits in South America. (No, seriously—he responded to Gizmodo's interview request while out in the field.) By identifying and studying the amber, we'll soon have a better idea of “how this ecosystem started and evolved at the very heart of the equator—something we have never been able to do before in South America,” Delclòs said. Get the best tech, science, and culture news in your inbox daily. News from the future, delivered to your present. A revisit to a pterosaur-abundant fossil site uncovered how two baby pterosaurs met an unusually chilling death 150 million years ago. Sheetweb spiders don't immediately pounce on fireflies caught in their webs, and for good reason, according to new research. Spicomellus clearly didn't need sharp teeth to make an impression. We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/09/18/us-house-committee-summons-ceos-of-discord-twitch-reddit-to-testify-on-online-radicalization/'>US House committee summons CEOs of Discord, Twitch, Reddit to testify on online radicalization</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 14:45:18
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>In a statement, Rep. James Comer, chairman of the Oversight Committee, referenced the murder of Charlie Kirk and “other acts of politically motivated violence” as reasons why Congress has a “duty to oversee the online platforms that radicals have used to advance political violence,” he said. Discord told TechCrunch it looked forward to testifying in October. “We continuously engage with policymakers on these critical issues and look forward to continuing this important dialogue next month,” a spokesperson said. Reddit, meanwhile, told Reuters it was investigating the link between its platform and Kirk's death, saying it hasn't yet seen proof that the suspect in Kirk's death was an active Reddit user. The bullets used were also apparently engraved with memes and references to video games. This piece was updated to add a statement from Discord's spokesperson. Dominic-Madori Davis is a senior venture capital and startup reporter at TechCrunch. Register now and save up to $668.Regular Bird rates end September 26 Apple's iOS 26 with the new Liquid Glass design is now available to everyone Spotify will now let free users pick and play tracks Elon Musk's Boring Company suspends work on Vegas airport tunnel after ‘crushing injury'</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/meta-ray-ban-display-hands-on-the-smart-glasses-you-were-waiting-for-2000660384'>Meta Ray-Ban Display Hands-On: The Smart Glasses You Were Waiting For</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 13:54:20
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>There's one thing people want to know when they see my first-gen Ray-Ban smart glasses, and it's got nothing to do with AI, or cameras, or the surprisingly great open-ear audio they put out. They want to know what's probably front-of-mind right now as you're reading this: Do they have a screen in them? At Meta Connect 2025, Meta finally unveiled its Ray-Ban Display smart glasses that, as you may have gathered from the name, have a screen in them. But first, you probably want to know exactly what's going on in this screen I speak of. For now, though, I want to focus on what that screen feels like. And, no matter what your feelings are about smart glasses that have a screen, that's a good thing, since the display is the whole reason you might spend $800 to own a pair. Once your eyes adjust to the screen (it took me a minute or so), you can get cracking on doing stuff. That's where the Meta Neural Band comes in. The Neural Band is Meta's sEMG wristband, a piece of tech it's been showing off for years now that's been shrunk down into the size of a Whoop fitness band. It reads the electrical signals in your hand to register pinches, swipes, taps, and wrist turns as inputs in the glasses. I was worried at first that its wristband might feel clunky or too conspicuous on my body, but I can inform you that it's not the case—this is about as lightweight as it gets. The smart glasses also felt light and comfortable on my face despite being noticeably thicker than the first-gen Ray-Bans. More importantly than being lightweight and subtle, it's very responsive. Personally, I still had some variability on inputs—you may have to try to input something once or twice before it registers—but I would say that it works well most of the time (at least much better than you'd expect for a literal first-of-its-kind device). I suspect the experience will only get more fluid over time, though, and even better once you really train yourself to navigate the UI properly. But enough about controls; let's get to what you're actually doing with them. I got to briefly experience pretty much everything that the Meta Ray-Ban Display have to offer, and that includes the gamut of phone-adjacent features. One of my favorites is taking pictures in a POV mode, which imposes a window on the glasses display that shows you what you're taking a picture of right in the lens—finally, no guess and check when you're snapping pics. Another “wow” moment here is the ability to pinch your fingers and tweak your wrist (like you're turning a dial) to zoom in. Another standout feature is navigation, which imposes a map on the glasses display to show you where you're going. Obviously, I was limited in testing how that feature works since I couldn't wander off with the glasses in my demo, but the map was quite sharp and bright enough to be used outdoors (I did test this stuff in sunlight, and the 5,000 nits brightness was sufficient). It's hard to say how distracting a HUD would be if you're biking, and it's something that I plan to eventually test in full. Another interesting feature you might actually use is video calling, which pulls up a video of the person you're calling in the bottom-right corner. The interesting part about this feature is that it's POV for the person you're calling, so they can see what you're looking at. It's not something that I'd do in any situation, since usually the person you're calling wants to see you and not just what you're looking at, but I can confirm that it works at least. Speaking of just working, there's also a live transcription feature that can listen in on your environment and superimpose what the other person is saying onto the display of the smart glasses. I had two thoughts when using this feature: the first one is that it could be a game-changer for accessibility. If your hearing is impaired, being able to actually see a live transcript could be hugely helpful. Secondly, such a feature could be great for translation, which is something that Meta has already thought of in this case. I didn't get a chance to use the smart glasses for translating another language, but the potential is there. One problem I foresee here, though, is that the smart glasses may pick up other conversations happening nearby. Meta thought of this too and said that the microphones in the Ray-Ban Display actually beamform to focus just on who you're looking at, and I did get a chance to test that out. While one Meta rep spoke to me in the room, others had their own conversations at a fairly normal volume. While the transcription focused mostly on the person I was looking at, it still picked up stray words here and there. This feels like a bit of an inevitability in loud scenarios, but who knows? Maybe beamforming and AI can fill in the gaps. If you're looking for a killer feature of Meta's Ray-Ban Display smart glasses, I'm not sure there necessarily is one, but one thing I do know is that the coupling of the glasses with its Neural Band should be nothing short of a game-changer. Navigating the UI in smart glasses has been a constant issue in the space, and until now, I haven't seen what I thought was a killer solution, but based on my early demos, I'd say that Meta's “brain-reading” wristband could be the breakthrough we were waiting for—at least until hand or eye tracking at this scale becomes possible. I'll know more about how everything works when I get a chance to use Meta Ray-Ban Display on my own, but for now I'd say Meta is still clearly the frontrunner in the smart glasses race, and its head start just got pretty massive. Get the best tech, science, and culture news in your inbox daily. News from the future, delivered to your present. Follow along with the Gizmodo crew as we cover everything Meta announces at its annual developer conference. We're expecting new smart glasses, upgrades to its AI models, and more. Nothing says Oakley like wraparound shades that you use for cycling. The Fed's rate cut decision was driven by a weaker than expected labor market. We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/metas-ray-ban-smart-glasses-now-have-a-screen-and-a-magic-wristband-2000659760'>Meta's Ray-Ban Smart Glasses Now Have a Screen and a Magic Wristband</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 13:54:20
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Meta's Ray-Bans are back with a new generation, and this time they're finally giving people the one thing they really want—a screen. At Meta's annual Connect developer conference, the company officially took the wraps off its Meta Ray-Ban Display, which are, as the name suggests, its first pair of AI-infused smart glasses to come with a full-color in-lens display. As you might expect, they can do quite a few things that their predecessor can't, including message notifications, turn-by-turn navigation, and telling you when queries to Meta AI are processing. There are several app integrations, including WhatsApp and Instagram, allowing you to watch reels and make video calls natively in the glasses. One major upgrade on the message notifications front is that the Meta Ray-Ban Display will not be limited to only WhatsApp, meaning it will be able to show notifications on both iOS and Android devices. That's not the only major shift in this generation. Meta says its first-ever display has a 600 x 600 resolution and 20-degree field of view. On one hand, that feels like a weird choice, but it also makes sense since this is a gadget you're going to want to use indoors as well as out, and for $800, you should be able to use them for as long as you like without having to take them off. “As long as you like,” in this case, will be no more than 6 hours, according to Meta, which is a lot longer than I was expecting. That solid battery life is thanks in part to what Meta is calling “ultra-narrow steelcan batteries.” I wish I knew exactly what that meant, but for now, I can only look forward to getting more of a deep dive in the future. Glasses are only half the appeal of Meta's Ray-Ban Display, though. The Meta Neural Band, as Meta is calling it, is arguably the most innovative part of its new Ray-Ban package, since no other product like it exists on a commercial scale. Outside of being a first, it also offers a potential solution to a problem that no other maker of smart glasses has quite solved—that problem being, how the hell do you actually use smart glasses? While most smart glasses (Meta's first-gen Ray-Bans included) have a voice assistant for shouting commands like “take a picture” and a fairly simple touch-sensitive bar for physical inputs (i.e., pause/play), neither is ideal in every situation. The fact is, adding a screen complicates smart glasses—the more you can do, the more you'll need to convey to your glasses, and in order to do that, you need an input system as nuanced as the eyewear itself. Not only that, but if you want to use your smart glasses discreetly (or in a normal fashion at all, really), shouting into a crowded subway car is less than ideal. My favorite gesture is a pinch to zoom for taking photos and videos. I got a chance to use Meta's Ray-Bans and its new Neural Band, and you can read my full impressions here. Like previous iterations of Meta's Ray-Ban glasses, this year's edition will also come equipped with cameras and speakers. Despite being a fan of Meta's Ray-Bans (they're the only device I ever want to take calls with), Meta AI has been a weak spot for me. While the voice assistant works well most of the time for basic stuff like taking pictures/videos, playing Spotify, and asking what your battery life is, the heavier AI lifting is hit-or-miss at best. Whether Meta's new smart glasses fix that remains to be seen since I haven't had a chance to use them, but I'm hoping for an upgrade here. But even if AI is still finicky and the cameras and audio are about the same, these smart glasses still have a freaking screen. That's a big step forward, even if functionality is limited for now. When people ask me about my first-gen Ray-Bans, the first thing they want to know is whether they have a display in them, and they're inevitably very disappointed when I have to let them down. Now, I'll actually have something to show them, and if Meta's wristband works, I'll even have something to show them that only Meta can provide. Get the best tech, science, and culture news in your inbox daily. News from the future, delivered to your present. Follow along with the Gizmodo crew as we cover everything Meta announces at its annual developer conference. We're expecting new smart glasses, upgrades to its AI models, and more. Nothing says Oakley like wraparound shades that you use for cycling. We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/video-games/handheld-gaming/microsofts-new-handheld-gaming-mode-exclusive-to-rog-xbox-ally-has-just-leaked-for-every-handheld-running-windows-11-all-you-need-is-the-25h2-update-and-a-few-registry-tweaks'>Microsoft's new handheld gaming mode, exclusive to ROG Xbox Ally, has just leaked for every handheld running Windows 11 — all you need is the 25H2 update and a few registry tweaks</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 11:55:25
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. Earlier this year, Microsoft and Asus announced the ROG Xbox Ally, an update to the first-gen ROG Ally, now adorned with Xbox branding. Along with the new name came new specs, but more importantly, the Xbox partnership wasn't just a token collaboration — rather, a deeply integrated experience finally meant to "fix" Windows on handheld devices. Hence, the ROG Xbox Ally would ship with a new full-screen Xbox app that it would boot into by default, superseding Windows 11 entirely. The Verge's Tom Warren reports that the full-screen Xbox experience meant for ROG Xbox Ally devices has leaked early, and can now be installed on any handheld running Windows. The actual ROG Xbox Ally is set to launch next month, which means that everyone else will get to enjoy Microsoft's new handheld gaming mode before the very device that was set to debut it. There's a full guide on Reddit that breaks down how to install it, and it's relatively easy to follow as long as you know your way around Windows. If you have a regular Ally, Lenovo's Legion Go, or the myriad of PC handhelds out there, you should be eligible. The build resides in the Release Preview channel, so once you've got that going, there are a few registry edits you need to make if you don't see the "Enter full-screen experience on start up" toggle right away. After all is said and done, a restart should boot you directly into the new Xbox experience, where all your favorite games should be consolidated into one place — including stores like Steam, Epic Games, and Battle.net. Windows Central tested the update on an original ROG Ally and saw marked improvements across the board in terms of performance—going from 29 FPS in Shadow of the Tomb Raider to 38 FPS—and even an extra hour gained in battery life. These upgrades mostly come courtesy of disabling unnecessary background processing and startup apps, not some significant underlying change to the Windows kernel itself. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Hassam Nasir is a die-hard hardware enthusiast with years of experience as a tech editor and writer, focusing on detailed CPU comparisons and general hardware news. When he's not working, you'll find him bending tubes for his ever-evolving custom water-loop gaming rig or benchmarking the latest CPUs and GPUs just for fun. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/pc-components/cpus/nvidia-and-intel-announce-jointly-developed-intel-x86-rtx-socs-for-pcs-with-nvidia-graphics-also-custom-nvidia-data-center-x86-processors-nvidia-buys-usd5-billion-in-intel-stock-in-seismic-deal'>Nvidia and Intel announce jointly developed 'Intel x86 RTX SOCs' for PCs with Nvidia graphics, also custom Nvidia data center x86 processors — Nvidia buys $5 billion in Intel stock in seismic deal</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 11:00:11
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. In a surprise announcement that finds two long-time rivals working together, Nvidia and Intel announced today that the companies will jointly develop multiple new generations of x86 products together — a seismic shift with profound implications for the entire world of technology. But representatives tells us it also remains fully committed to other announced product roadmaps and architectures, including the company's Arm-based GB10 Grace Blackwell processors for workstations and the Nvidia Grace CPUs for data centers, as well as the next-gen Vera CPUs. Nvidia says it also remains committed to products on its internal roadmaps that haven't been publicly disclosed yet, indicating that the new roadmap with Intel will merely be additive to existing initiatives. The chip giant hasn't disclosed whether it will use Intel Foundry to produce any of these products yet. However, while Intel has used TSMC to manufacture some recent products, its goal is to bring production of most high-performance products back into its own foundries. This suggests that at least some of the Nvidia-custom x86 silicon, particularly for the data center, could be fabbed on Intel nodes. Intel also uses TSMC to fabricate many of its client x86 processors, however, so we won't know for sure until official announcements are made — particularly for the RTX GPU chiplet. In either case, Nvidia has been mulling using Intel Foundry since 2022, has fabbed test chips there, and participates in the U.S. Defense Dept. The DoD project involves Nvidia already making chips on Intel's 18A process node, so it wouldn't be a total surprise. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. While the two companies have engaged in heated competition in some market segments, Intel and Nvidia have partnered for decades, ensuring interoperability between their hardware and software for products spanning both the client and data center markets. Let's dive into the details we've learned so far. This type of processor will have both CPU and GPU units merged into one compact chip package that externally looks much like a standard CPU, rivaling AMD's competing APU products. This type of tight integration packs all the gaming prowess into one package without an external discrete GPU, providing power and footprint advantages. As such, these chips will be heavily focused on thin-and-light gaming laptops and small form-factor PCs, much like today's APUs from AMD. However, it's possible the new Nvidia/Intel chips could come in multiple flavors and permeate further into the Intel stack over time. Intel has worked on a similar type of chip before with AMD; there is at least one significant technical difference between these initiatives, however. You can see an image of the Intel/AMD chip below. This separate memory package was only usable by the GPU. Intel notoriously axed the Kaby Lake-G products in 2019, and the existing systems were left without proper driver support for quite some time, in part because Intel was responsible for validating the drivers, and then finger-pointing ensued. We're told that both Intel and Nvidia will be responsible for their respective drivers for the new models, with Nvidia naturally providing its own GPU drivers. However, Intel will build and sell the consumer processors. We haven't spoken with Intel yet, but the limited scope of this project means that Intel's proprietary Xe graphics architecture will most assuredly live on as the primary integrated GPU (iGPU) for its mass-market products. Intel's new x86 RTX CPUs will compete directly with AMD's APUs. For AMD, that means it faces intensifying competition from a company with the leading market share in notebook CPUs (Intel ships ~79% of laptop chips worldwide) that's now armed with GPU tech from Nvidia, which ships 92% of the world's gaming GPUs. Intel will fabricate custom x86 data center CPUs for Nvidia, which Nvidia will then sell as its own products to enterprise and data center customers. We do know that Nvidia will employ its NVLink interface, which tells us the chips could leverage Nvidia's new NVLink Fusion tech that enables custom CPUs and accelerators to enable faster, more efficient communication with Nvidia's GPUs than found with the PCIe interface. Intel has long offered custom Xeons to its customers, primarily hyperscalers, often with relatively minor tweaks to clock rates, cache capacities, and other specifications. Intel has long said that it will design completely custom x86 chips for customers as part of its IDM 2.0 strategy. However, aside from a recent announcement of custom AWS chips that sound like the slightly modified Xeons mentioned above, we haven't heard of any large-scale uptake for significantly modified custom x86 processors. Intel announced a new custom chip design unit just two weeks ago, so it will be interesting to learn the extent of the customization for Nvidia's x86 data center CPUs. The likelihood of AMD adopting NVLink Fusion is somewhere around zero, as the company is heavily invested in its own Infinity Fabric (XGMI) and Ultra Accelerator Link (UALink) initiatives, which aim to provide an open-standard interconnect to rival NVLink and democratize rack-scale interconnect technologies. Intel is also a member of UALink, which uses AMD's Infinity Fabric protocol as the foundation. Nvidia's $5 billion purchase of Intel common stock will come at $23.28 a share, roughly 6% below the current market value, but several aspects of this investment remain unclear. Nvidia hasn't stated whether it will have a seat on the board (which is unlikely) or how it will vote on matters requiring shareholder approval. It is also unclear if Intel will issue new stock (primary issuance) for Nvidia to purchase, as it did when the U.S. government recently became an Intel shareholder (that is likely). Naturally, the investment is subject to approval from regulators. The U.S. government won't have a seat on the board and agreed to vote with Intel's board on matters requiring shareholder approval “with limited exceptions.” Softbank has also recently purchased $2 billion worth of primary issuance Intel stock at $23 per share. Altogether, these investments represent a significant cash influx for Intel as it attempts to maintain the heavy cap-ex investments required to compete with TSMC, all while struggling with a negative amount of free cash flow. “AI is powering a new industrial revolution and reinventing every layer of the computing stack — from silicon to systems to software. “This historic collaboration tightly couples NVIDIA's AI and accelerated computing stack with Intel's CPUs and the vast x86 ecosystem—a fusion of two world-class platforms. “Intel's x86 architecture has been foundational to modern computing for decades – and we are innovating across our portfolio to enable the workloads of the future,” said Intel CEO Lip-Bu Tan. “Intel's leading data center and client computing platforms, combined with our process technology, manufacturing and advanced packaging capabilities, will complement Nvidia's AI and accelerated computing leadership to enable new breakthroughs for the industry. We appreciate the confidence Jensen and the Nvidia team have placed in us with their investment and look forward to the work ahead as we innovate for customers and grow our business.” We'll learn more details of the new partnership later today when Nvidia CEO Jensen Huang and Intel CEO Lip-Bu Tan hold a webcast press conference at 10 am PT. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Paul Alcorn is the Editor-in-Chief for Tom's Hardware US. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/sms-blasters-scam-texts/'>Cybercriminals Have a Weird New Way to Target You With Scam Texts</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 11:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>But as phone companies and telecom services have rolled out more tools to detect scams in texts, criminals have started driving around cities with fake cell phone towers that send messages directly to nearby phones. SMS blasters are small devices, which have been found in the back of criminals' cars and sometimes backpacks, that impersonate cell phone towers and force phones into using insecure connections. While not a new type of technology, the use of SMS blasters in scamming was originally detected in Southeast Asian countries and has increasingly spread to Europe and South America—just last week, Switzerland's National Cybersecurity Centre issued a warning about SMS blasters. The Swiss agency said some blasters are able to send messages to all phones in a radius of 1,000 meters, while reports about an incident in Bangkok say a blaster was used to send around 100,000 SMS messages per hour. “This is essentially the first time that we have seen large-scale use of mobile radio-transmitting devices by criminal groups,” says Cathal Mc Daid, VP of technology at telecommunication and cybersecurity firm Enea, who has been tracking the use of SMS blasters. This has been shown by reports of arrests of people who have been basically paid to drive around areas with SMS blasters in cars or vans.” The blasters are not dissimilar to so-called IMSI catchers, or “Stingrays,” which law enforcement officials have used to scoop up people's phone data. But instead of being used for surveillance, they broadcast false signals to targeted devices. “The whole process—4G capture, downgrade to 2G, sending of SMS and release—can take less than 10 seconds,” Mc Daid explains. It's something people who receive the messages may not even notice. The growth of SMS blasters comes at a time when scams are rampant. This month, UK telecom Virgin Media O2 said it has blocked more than 600 million scam text messages during 2025, which is more than its combined totals for the last two years. Because blasters operate outside of traditional mobile networks, the messages they send are not subject to the security measures that have been put in place by mobile providers. “None of our security controls apply to the messages that phones receive from them,” says Anton Reynaldo Bonifacio, the chief information security officer and chief AI officer at Philippines communications firm Globe Telecom. Back in 2022, Globe Telecom made the decision to stop delivering SMS messages that contain URLs, and Bonifacio says he believes scammers use the blasters to “bypass” these measures. “The technology used to be more niche, but I think sales and assembly of these IMSI catcher devices have become more prevalent for criminal organizations,” he says. Researchers have found SMS blasters being sold openly online for thousands of dollars. “It might be a problem in one or two regions, but then we tend to see these things pop up in different regions,” Kight says. Reporting from Commsrisk and Risky Business, have highlighted reports of SMS blasters being used in Thailand, Vietnam, Japan, New Zealand, Qatar, Indonesia, Oman, Brazil, Hong Kong, and more in recent months. Law enforcement officials in London say they have so far seized seven SMS blasters, and in June, a student from China was sentenced to jail for more than a year after being caught using one of the devices. Kight says that tackling SMS blasters involves telecom operators and government regulators being aware of the devices, law enforcement agencies taking actions, as well as people recognizing and reporting scam messages to the relevant authorities. “Once enabled, your device will no longer scan for or connect to 2G cell towers,” Nasser says, adding the only exception is if an emergency call is being made and 3G, 4G and 5G are not available. Android's Advanced Protection mode will also disable 2G automatically on some newer phones. Apple did not answer WIRED's request for comment by the time of publication, although its Lockdown Mode will disable 2G connections. “It's a new way of doing the same thing,” Hurley says. “It's changed how we have to investigate it, but actually it's not changed the end result,” he says, adding that people should always be cautious of clicking links in unknown messages and take a moment before acting if the message feels suspicious. As with all cybercrime, though, there is a chance that those operating the schemes and blasters could evolve their tactics. If criminals are able to gain access to more sophisticated technology and expertise, he says, “this could be the beginning of a cat and mouse game.” In your inbox: Our biggest stories, handpicked for you each day WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/metas-new-smart-glasses-got-a-subtle-name-change-it-speaks-volumes-about-whats-wrong-with-them/'>Meta's New Smart Glasses Got a Subtle Name Change. It Speaks Volumes About What's Wrong With Them</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 10:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>As the company grew, Zuckerberg—in an interview with WIRED— started to distance himself from, or at least temper, those mantras. But with Wednesday's announcement of the Meta Ray-Ban Display smart glasses, it feels like some of that old mentality might have started to creep back in. “Our goal is to build great-looking glasses that deliver personal superintelligence,” said Zuckerberg yesterday at the very start of the Meta Connect event. He then immediately outlined some “clear values” that Meta holds sacrosanct for smart glasses. Number-one for Zuckerberg was “they need to be great glasses first” with “refined aesthetics” that “shave every millimeter” from the hardware. No doubt Meta has shaved every millimeter it can from its new flagship specs, but in a rush to fully realize these next-gen glasses it looks like Meta has broken that primary value right out the gate. I got a chance to demo the Meta Ray-Ban Display, ahead of Meta Connect, at a preview event in London. The big news is they feature a small display built into the right lens that gives users visual prompts and guidance. They come with a wristband that understands hand gestures, which can be used to interact with the things displayed on the screen. Meta has labeled them the “world's most advanced AI glasses,” and having tried them, it‘s easy to agree. And that's not even because of the arguably punchy $800 price tag. The thing that truly lets them down is their aesthetic, and that's not what I expected from the company that made such a success of the original Ray-Ban Metas because of their design. While the originals (and their just-announced successors) basically look like Ray-Ban glasses, these, in what can only be described as a glaring faux pas, are far from being fashion-first. They look like smart glasses, but the old kind you don't really want to be seen wearing. At a glance, you can tell that something is going on with them. Which of the two brands made that call hasn't been made clear, but these are Meta's self-branded, tech-first glasses, and that feels a like misstep, especially considering the experience Meta already has in the market. The new Meta Ray-Ban Display glasses on a human model. In her recent piece for WIRED, Amy Francombe notes how vitally important aesthetics are in creating mass acceptance of products such as this: “In the world of wearable tech, aesthetics have killed more ideas than poor battery life. No one wants to wear a prototype on their face.” Too right. Meta knows how to build the platforms, she adds, but not necessarily the products people want to wear. Having shown off its prototype Orion AR glasses at Meta Connect last year, the announcement of Meta Ray-Ban Display this year feels like a forced attempt to solidify the company's position as the leader of the product category, but by embracing the old mantras of its founding company and moving first. This creates an aesthetic compromise, where the tech is clearly not quite ready to fit into the tried and tested formula that Meta, and Essilor Luxottica, knows sells in its millions. But perhaps Meta isn't ready for that anyway. We know that the Meta Ray-Ban Display are going to launch initially in the US only, and in limited numbers. An in-store fitting requirement will also slow adoption, as will a high price that makes them far from a spontaneous purchase. With the Meta Ray-Ban Display, it feels like Meta is dipping its toe in, testing the water, while simultaneously bragging about what it's capable of and seeing if customers will swallow this compromise of form and function. It's a bold move for a company that has already proved the model for success, and yet so quickly is actively choosing to go against it. Yes, the Display glasses look fine—we're nowhere near Google Glass or Snapchat Spectacles territory here—but I would definitely feel self-conscious walking around with these on my face in a way I don't in Ray-Ban Meta. In your inbox: Our biggest stories, handpicked for you each day Meet the guys betting big on AI gambling agents WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/cyber-security/shai-hulud-malware-campaign-dubbed-the-largest-and-most-dangerous-npm-supply-chain-compromise-in-history-hundreds-of-javascript-packages-affected'>Shai-Hulud malware campaign dubbed 'the largest and most dangerous npm supply-chain compromise in history' — 'hundreds' of JavaScript packages affected</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-18 09:42:31
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. It's a bad time to be a JavaScript developer, after Koi Security revealed yesterday that it is tracking "the largest and most dangerous npm supply-chain compromise in history. And the problem is probably going to get worse before it gets better, because the malware in question is a worm that autonomously spreads from package to package. "Attackers published malicious versions of @ctrl/tinycolor and other npm packages, injecting a large obfuscated script (bundle.js) that executes automatically during installation," Koi Security said in the blog post revealing this campaign. "This payload repackages and republishes maintainer projects, enabling the malware to spread laterally across related packages without direct developer involvement. "To be clear: This campaign is distinct from the incident that we covered on Sept. 9, which saw multiple npm packages with billions of weekly downloads compromised in a bid to steal cryptocurrency. "The injected script performs credential harvesting and persistence operations," Koi Security said. It also writes a hidden GitHub Actions workflow file (.github/workflows/shai-hulud-workflow.yml) that exfiltrates secrets during CI/CD runs, ensuring long-term access even after the initial infection. This dual focus on endpoint secret theft and backdoors makes Shai-Hulud one of the most dangerous campaigns ever compared to previous compromises. But the long and short of it is that Shai-Hulud is using a well-known offensive security tool (TruffleHog) alongside developer tooling (GitHub Actions) in an environment that is designed specifically to help distribute software without much developer involvement (npm).We suggested in our previous report that whoever compromised the npm packages to steal cryptocurrency did us a favor, because they could have used their access to those packages to accomplish far worse attacks. Now it seems that someone is looking to do just that — and it's hard to feign surprise when the Node.js ecosystem and the tooling built around it were practically built to enable widespread attacks like this.Koi Security is updating its blog post with a list of npm packages known to have been compromised via the Shai-Hulud campaign. StepSecurity has also published indicators of compromise alongside a technical breakdown of how the malware spreads, what it does, and how organizations should respond if they discover that a compromised package has been used somewhere in their infrastructure. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Nathaniel Mott is a freelance news and features writer for Tom's Hardware US, covering breaking news, security, and the silliest aspects of the tech industry. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            