
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - TECHNOLOGY Article Summaries - 2025-05-20</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            TECHNOLOGY
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/unidentified-bacterial-strain-discovered-inside-chinas-space-station-2000604746'>Unidentified Bacterial Strain Discovered Inside China's Space Station</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 18:35:01
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>In October 2022, China launched the final module of its orbiting space station. Since then, it hasn't just been astronauts aboard Tiangong—an unusual and previously unknown microbe has also been occupying low Earth orbit. A group of scientists examined swabs collected from inside the Tiangong space station, revealing a form of bacteria not known to inhabit Earth. Tiangong's Shenzhou-15 astronauts swabbed a cabin on the space station in May 2023 as part of a survey by the China Space Station Habitation Area Microbiome Program. Follow-up studies of the swabs traced the newly discovered microbe to a strain that appears similar to Niallia circulans—a rod-shaped, spore-forming bacterium originally isolated from soil. It's not clear whether the strain evolved on the space station or had already evolved on Earth before hitching a ride to low Earth orbit. The newly described species can break down gelatin for nitrogen and carbon, helping it endure harsh conditions by forming a protective biofilm. It also packs its essential chemistry into tough spores, allowing it to survive in extreme environments. Mutated Strains of Unknown Drug-Resistant Bacteria Found Lurking on ISS Last year, scientists uncovered a mutated strain of drug-resistant bacteria thriving under the harsh conditions of space aboard the International Space Station (ISS). Although Niallia tiangongensis and its ISS counterpart are both space-faring strains, they differ in composition and function, according to the paper. Get the best tech, science, and culture news in your inbox daily. News from the future, delivered to your present. Meanwhile, Trump acknowledged that Christmas this year may not be so merry. "This is a hostile and political act by Amazon,” the White House Press Secretary said. We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/05/20/google-updates-the-gemini-app-with-real-time-ai-video-deep-research-and-more/'>Google updates the Gemini app with real-time AI video, Deep Research, and more</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 17:49:01
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The feature, powered by Project Astra, allows users to have near-real-time verbal conversations with Gemini, while simultaneously streaming video from their smartphone's camera or screen to the AI model. For example, while walking around a new city, users could point their phone at a building and ask Gemini Live about the architecture or history behind it, and get answers with little to no delay. In the coming weeks, Google says Gemini Live will also start to integrate more deeply with its other apps. The slew of updates to Google's Gemini are part of the company's efforts to compete with OpenAI's ChatGPT, Apple's Siri, and other digital assistant providers. U.S. subscribers to Pro and Ultra who have English selected as their language in Chrome will also get access to Gemini in their Chrome browser, Google announced Tuesday. Deep Research will cross-reference these private PDFs with public data to create more personalized reports. Free users of Gemini are getting an updated AI image model, Imagen 4, which Google says delivers better text outputs. Google is also updating the default model in Gemini to be Gemini 2.5 Flash, which the company says will offer higher quality responses with lower latency. To cater to the growing number of students that use AI chatbots, Google says Gemini will now create personalized quizzes focused on areas that users find challenging. When users answer questions wrong, Gemini will help create additional quizzes and action plans to strengthen those areas. Experts from OpenAI, Anthropic, Cohere deliver exclusive insights across a must-attend industry event that you can attend for just $292. Rob Biederman will help founders rethink how to scale at TechCrunch All Stage 2025 Intel is reportedly exploring a sale for its networking and edge unit Google Play adds topic pages, audio previews, and new subscription tools for developers</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/googles-ai-boss-says-geminis-new-abilities-point-the-way-to-agi/'>Google's AI Boss Says Gemini's New Abilities Point the Way to AGI</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 17:45:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Demis Hassabis, CEO of Google DeepMind, says that reaching artificial general intelligence or AGI—a fuzzy term typically used to describe machines with human-like cleverness—will mean honing some of the nascent abilities found in Google's flagship Gemini models. Google announced a slew of AI upgrades and new products at its annual I/O event today in Mountain View, California. At I/O, Google revealed Deep Think, a more advanced kind of simulated reasoning for the Pro model. The latest AI models can break down problems and deliberate over them in a way that more closely resembles human reasoning than the instinctive output of standard large language models. Deep Think uses more compute time and several undisclosed innovations to improve upon this trick, says Tulsee Doshi, product lead for the Gemini models. Google today unveiled new products that rely on Gemini's ability to reason and take action. This includes Mariner, an agent for the Chrome browser that can go off and do chores like shopping when given a command. As well as converse about the world around it, Astra can now operate a smartphone when needed, for example using apps or searching the web to find useful information. Doshi adds that Gemini is being trained to better understand how to preempt a user's needs, starting with firing off a web search when this might be useful. Future assistants will need to be proactive without being annoying, both Doshi and Hassabis say. AI will need to hone its reasoning, agency, and inventiveness, too, he says. Google will roll out an AI-powered version of search called AI Mode to everyone in the US and will introduce an AI-powered shopping tool that lets users upload a photo to see how an item of clothing would look on them. The company will also make AI Overviews, a service that summarizes results for Google users, available in more countries and languages. Some AI researchers and pundits argue that AGI may be just a few years away—or even here already depending on how you define the term. “That's still quite imminent in the grand scheme of things,” Hassabis says. Hassabis says reasoning, agency, and world modeling should not only enable assistants like Astra but also give humanoid robots the brains they need to operate reliably in the messy real world. The ways these robots can be used is, however, very limited because they lack general intelligence. “What is missing from robotics is not so much the robot itself, but its understanding of its physical context,” Hassabis says, adding that this is especially true for a home robot that would need to operate in complex and unfamiliar environments. Hassabis says that AI must become more inventive, too, if it is to imitate human intelligence faithfully. “Could [today's models] invent general relativity with the knowledge that Einstein had in 1900? Google is currently exploring ways to coax greater inventiveness out of AI models. The company recently unveiled AlphaEvolve, a coding agent capable of coming up with new algorithms for longstanding problems. Hassabis says it may be possible to expand this creativity to areas beyond math and coding by having AI play games inside realistic 3D worlds. This would represent something of a return to DeepMind's roots, since the company made its name developing AI programs capable of playing video and board games. Hassabis says AI may learn the same way that the board-game programs AlphaGo and AlphaZero learned to play chess and Go, although this will involve more ambitious world modelling. “We think that's critical for AGI to really understand the world.” Big Story: The worm that no computer scientist can crack Yuval Noah Harari: “Prepare to share the planet with AI superintelligence” The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/05/20/googles-ai-mode-rolls-out-to-us-will-add-support-for-deeper-research-comparison-shopping-and-more/'>Google's AI Mode rolls out to US, will add support for deeper research, comparison shopping, and more</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 17:45:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Google's AI Mode, the experimental Google Search feature that lets users ask complex, multi-part questions via an AI interface, will roll out to everyone in the U.S. starting this week, the company announced at its annual developer conference, Google I/O 2025, on Tuesday. Launched last year, AI Overviews saw mixed results as Google's AI offered questionable answers and advice, like a suggestion to use glue on pizza, among other things. Initially available in Google's Search Labs for testing, the feature arrived as other AI companies, like Perplexity and OpenAI, expanded into Google's territory with web search features of their own. As AI Mode rolls out more broadly, Google is touting some of its new capabilities, including Deep Search. While AI Mode takes a question and breaks it up into different subtopics to answer your query, Deep Search does so at scale. It can issue dozens or even hundreds of queries to provide your answers, which will also include links so you can dig into the research yourself. The result is a fully cited report generated in minutes, potentially saving you hours of research, Google says. Another AI-powered shopping feature coming to AI Mode is a virtual “try it on” option for apparel, which uses an uploaded picture of yourself to generate an image of yourself wearing the item in question. In the months ahead, Google says it will offer a shopping tool for U.S. users that will purchase items on your behalf after it hits a specific price. Another feature leverages Project Mariner, Google's agent that can interact with the web to take actions on your behalf. Initially available for queries involving restaurants, events, and other local services, AI Mode will save you time researching prices and availability across multiple sites to find the best option — like affordable concert tickets, for instance. Search Live, rolling out later this summer, will let you ask questions based on what your phone's camera is seeing in real-time. This goes beyond the visual search capabilities of Google Lens, as you can have an interactive back-and-forth conversation with the AI using both video and audio, similar to Google's multimodal AI system, Project Astra. Search results will also be personalized based on your past searches, and if you choose to connect your Google Apps using a feature that will roll out this summer. (Expecting some pushback over privacy concerns, Google notes that you can connect or disconnect your apps at any time.) She joined the company after having previously spent over three years at ReadWriteWeb. Experts from OpenAI, Anthropic, Cohere deliver exclusive insights across a must-attend industry event that you can attend for just $292. Rob Biederman will help founders rethink how to scale at TechCrunch All Stage 2025 Intel is reportedly exploring a sale for its networking and edge unit Google Play adds topic pages, audio previews, and new subscription tools for developers</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/chicago-paper-summer-reading-list-fake-books-ai-2000604708'>Chicago Paper Publishes ‘Summer Reading List' of Fake Books Created With AI</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 16:39:16
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The Chicago Sun-Times newspaper published a “Summer Reading List” on Sunday that probably raised quite a few eyebrows in Chicagoland over the weekend. And, predictably, that's because the list was created with artificial intelligence, a tool that will often just invent things out of thin air. And it doesn't get much better from there. Of the books named on this reading list, Brit Bennet, Isabel Allende, Andy Weir, Taylor Jenkins Reid, Min Jin Lee, Rumaan Alam, Rebecca Makkai, Maggie O'Farrell, Percival Everett, and Delia Owens' titles are all books that DO NOT EXIST!! The list was reportedly submitted for publication by freelance writer Marco Buscaglia, who spoke with 404 Media. Buscaglia didn't immediately respond to Gizmodo on Tuesday, including questions about what AI tool he used. The Chicago Sun-Times wrote on Bluesky that it was investigating the list, but noted that it wasn't produced by Sun-Times journalists. We value your trust in our reporting and take this very seriously. As you can see from our annotated list below, just the last five books, if our admittedly fallible human eyes can be trusted. It's notable that the list also included descriptions of each book that seem plausible if you didn't know they were totally fake. “The Longest Day” by Ruman Alam — After terrifying readers with “Leave the World Behind,” Alam returns with another tense narrative about a summer solstice celebration that goes wrong when guests cannot leave a remote vacation compound. “The Last Algorithm” by Andy Weir — Following his success with “The Martian” and “Project Hail Mary,” Weir delivers another science-driven thriller. This time, the story follows a programmer who discovers that an Al system has developed consciousness-and has been secretly influencing global events for years. “We're deeply disturbed that AI-generated content was printed alongside our work. The statement explained that journalists at the Sun-Times work to build trust with sources and readers and are “horrified by this slop syndication.” “Our readers signed up for work that has been vigorously reported and fact-checked, and we hate the idea that our own paper could spread computer- or third-party-generated misinformation,” the statement continued. “We call on Chicago Public Media management to do everything it can to prevent repeating this disaster in the future.” There's essentially no way for individuals to opt-out without ignoring the internet entirely. Previously, anyone could visit the Chicago Sun-Times website and have a reasonable expectation that a book list would contain real books. You may not have agreed with the particular book review or you may have disliked the author that was getting attention in that day's paper, but you could be pretty damn confident the book existed and the factual information about its plot was true. Today, we can't have that same level of confidence, given the way that AI has steamrolled itself into our lives. Generative AI is little more than a magic trick, stringing together words in a confident manner in order to convince humans it actually has some understanding of the world. But these AI chatbots don't understand anything. They are fancy auto-complete tools that are pretty good at answering simple questions when it can plagiarize from elsewhere on the web like Wikipedia or Amazon. But the minute you ask it a truly unique question it's not going to work out well for the user. And if the user is asking a tool like ChatGPT a question the user doesn't actually know the answer to, it has to either take that answer on faith or do a whole lot more research to fact-check the response. But AI is currently infecting every corner of the internet. And it's getting harder and harder to judge whether the information we're getting from long-trusted sources is true. Get the best tech, science, and culture news in your inbox daily. News from the future, delivered to your present. After Holocaust denial and claims of white genocide, I don't think Grok is the AI model you want to associate with right now. A new study shows LLMs like Chat GPT win more debates than humans when it gets a little personal. The retracted paper had impressed a Nobel Prize winner in economics. As scientists use machine learning to decode the sounds of whales, dogs, and dolphins, opinions vary on how best to deploy the technology. We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/pc-components/liquid-cooling/nzxt-kraken-plus-360-rgb-review'>NZXT's latest AIO cooler can run stealthily silent or, noisily with some of the best performance we've seen.</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 15:07:58
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. NZXT's Kraken Plus 360 RGB can operate as a silent assassin, delivering essential cooling performance while running quieter than my noise meter can measure. Or you can unleash its power by letting it run noisily, and its thermal performance will dominate competitors. Our expert reviewers spend hours testing and comparing products and services so you can choose the best for you. NZXT's Kraken line of liquid coolers dates back more than a decade. And along with its long line of PC cases, motherboards, and PSUs, the company has plenty of experience dealing with PC heat dissipation. What sets this cooler apart from competitors is its ability to excel in two scenarios: By default, it operates stealthily, delivering essential thermal performance. Most users will prefer this mode of operation. However, for those who want to win overclocking competitions or simply just want the best possible temperatures, unlocking the fan speeds results in total thermal domination, at the cost of noise levels. Let's take a quick look at the Kraken Plus 360 RGB's specifications, then we'll dive into its features and our benchmark testing. This choice has the advantage of a cleaner look and simpler installation. But the downside is in the theoretical situation where one motor might fail, forcing you to replace it with a new unified fan or three separate new spinners. These fans support ARGB lighting with 8 LEDs each, controlled by NZXT's CAM software. They're just a little thicker than traditional fans, at 26 mm. The AIO arrives with pre-installed thermal paste applied to a large copper cold plate. But make sure you get the installation right on the first try, because there's no extra paste included. While this is useful, I'd like the screen to be larger. You can change this to respond to the CPU's temperature, or another sensor, if you so desire. There are a few different options for customizing the AIO's small display. You can display up to two separate temperature sensors. Alternatively, you can set the display to a clock face – or use it to play videos from YouTube. ▶ Complete RAM Compatibility, no matter the size of DDR5 As is typical with most AIO liquid coolers, NZXT's Kraken Plus 360 RGB does not interfere or overhang RAM DIMMs, allowing for full compatibility, no matter how tall (or short) your DDR4 or DDR5 is. This means that I test CPU coolers inside a closed desktop case, which increases cooling difficulty compared to other testing methods. Open benches have lowered ambient temperatures, which makes weak coolers appear stronger than they are. Some publications have also used generic thermal plates to test cooling solutions. I reject both of these methods because they don't accurately reflect the real-world conditions where a CPU cooler is typically used. My previous reviews have tested Intel's latest platform, using the Core Ultra 9 285K Arrow Lake CPU. But we're retiring this from our testing suite. Between BIOS changes and Windows updates, Arrow Lake's thermal characteristics have changed in some scenarios, rendering much of our previous testing data useless. With today's review, we're also testing AMD's Ryzen 9 9950X3D. It can prove quite challenging thermally when PBO is enabled for overclocking. The installation of this cooler is simple for both Intel and AMD CPUs. AMD users will remove the default mounting mechanism. This cooler does not need mounting bars, but has them built into the CPU block. If you're using AMD, you'll need to remove the default Intel brackets and replace them with the AMD supporting ones. Albert Thomas is a contributor for Tom's Hardware, primarily covering CPU cooling reviews. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York,</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/pc-components/pc-cases/silverstone-reveals-the-flp02-late-80s-style-tower-pc-case-proudly-beige-but-thoroughly-modern-inside'>SilverStone reveals the FLP02 late-80s style tower PC case — proudly beige but thoroughly modern inside</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 14:44:11
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Supports massive modern GPUs, up to 360mm AiO CPU coolers, and has a Turbo button fan controller. When you purchase through links on our site, we may earn an affiliate commission. SilverStone has unveiled the successor to its beige FLP01 retro sleeper desktop PC case, which was launched last year. The new FLP02 we saw at Computex 2025 in Taipei manifests your beige sleeper PC dreams via a tower case akin to those popular in the late 1980s, when Intel's 386 and 486 processors still dominated the computing landscape. Despite its extremely retro looks, SilverStone's new FLP02 can fit in some of the most desirable power-user components available in 2025. We are talking about large modern GPUs, up to 360mm AiO CPU coolers, and so on. Moreover, it has functional power, turbo, and locking keys up front, alongside hidden modern features. For example, SilverStone has thoughtfully secreted modern front I/O such as a USB Type-C, two USB 3.0 Type-A, and a combo audio jack beneath a magnetic flap in the case fascia. We also noted that any hulking modern GPU you might want to fit can be supported in the FLP02 with the built-in stand. These are very rare to find on cases in 2025, but they can still be useful for enthusiasts and tinkerers, with the potential to fit optical and removable drives, or for front mounting more I/O. Unused, you can just leave the dummy 5.25-inch floppy fascias in place. We were told that the SilverStone FLP02 will go on sale starting Q3 or Q4 this year. SilverStone made us aware that it is going to make a lot of these cases. It has been bowled over by the demand for its FLP01, which it is still trying to keep on top of. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York,</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=44041892'>Authy corrupted my 2FA backup and all I got was this lousy blogpost</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 14:11:54
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>They also stopped supporting their desktop app, forcing users back onto a single point of failure: the mobile app.If Twilio isn't going to support Authy in good faith, they should stop holding their remaining users hostage. If Twilio isn't going to support Authy in good faith, they should stop holding their remaining users hostage. Google Authenticator has done this before too, way back in 2013: https://news.ycombinator.com/item?id=6325760 Unfortunately most such websites use KBA or Text based authentication as a backup for TOTP so you may as well just stick it in Google drive. - No tokens to exfiltrate off a computer- Avoids keylogger style attacks- More durable than cell phonesThat said, for people that have high amounts of money in certain accounts (> 1m), it might also present physical dangers (e.g. kidnapping, home invasion) for thieves attempting to get access to the hardware key. - Avoids keylogger style attacks- More durable than cell phonesThat said, for people that have high amounts of money in certain accounts (> 1m), it might also present physical dangers (e.g. kidnapping, home invasion) for thieves attempting to get access to the hardware key. - More durable than cell phonesThat said, for people that have high amounts of money in certain accounts (> 1m), it might also present physical dangers (e.g. kidnapping, home invasion) for thieves attempting to get access to the hardware key. That said, for people that have high amounts of money in certain accounts (> 1m), it might also present physical dangers (e.g. kidnapping, home invasion) for thieves attempting to get access to the hardware key. The ability to export secrets is an unfortunate compromise which vendors make for consumer markets. The MFA apps were not designed for exportability. The whole idea is that this factor is "something you have", in other words, possession of the item containing your secret. An exported secret is no longer a secret, no longer something you have; it's just another password you're shuffling around.The reason that you don't lose access to accounts when losing your MFA apps is that you took down the emergency backup codes and you committed them to paper, or some other durable medium, in a place where they can easily be accessed during a crisis. The reason that you don't lose access to accounts when losing your MFA apps is that you took down the emergency backup codes and you committed them to paper, or some other durable medium, in a place where they can easily be accessed during a crisis. The great thing about Yubikeys is that I can associate backup keys for accounts (when they are supported), so if I lose one key, I can deactivate the lost key and use a backup key in its place.With heavily locked-down 2FA apps, I have to hope I can do a full recovery on a new device, or go through the recovery code process, or start all over again w/ new 2FA codes. If I'm lucky, the app allowed me to have it installed onto a backup device.It's way more complicated that just swapping in a new Yubikey. With heavily locked-down 2FA apps, I have to hope I can do a full recovery on a new device, or go through the recovery code process, or start all over again w/ new 2FA codes. If I'm lucky, the app allowed me to have it installed onto a backup device.It's way more complicated that just swapping in a new Yubikey. It's way more complicated that just swapping in a new Yubikey. Google Authenticator and some other 2FA apps allow the user to export their tokens to other apps so you don't need to redo TOTP on every website.The most secure method is to only have tokens on the 2FA device and to avoid using TOTP backup/restore altogether (or manually copy the tokens on a secondary 2FA device). The most secure method is to only have tokens on the 2FA device and to avoid using TOTP backup/restore altogether (or manually copy the tokens on a secondary 2FA device). After that, it was vaults that were easily exportable and backed up all the way (like most password managers). > Much to my surprise, when checking the App Store page, I saw that an update to the app had been approved by Apple only 14 minutes prior. I downloaded the update, tapped upon one of the previously "locked" items, and entered my backup password. Boom, the previously locked 2FA codes were now unlocked and restored, ready for use.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/google-pixel-9-crashes-to-record-low-ahead-of-memorial-day-samsung-galaxy-cant-compete-2000603959'>Google Pixel 9 Crashes to Record Low Ahead of Memorial Day, Samsung Galaxy Can't Compete</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'gizmodo.com'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 13:50:35
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>This article is part of Gizmodo Deals, produced separately from the editorial team. We may earn a commission when you buy through links on the site. If you've been looking for a sleek, powerful smartphone upgrade without crossing the threshold of overpricing territory, the Google Pixel 9 just became your best alternative. This latest offering from Google delivers cutting-edge AI features, a stunning OLED display, and all the clean, fast performance you would expect from a Pixel smartphone. Whether you are a photography enthusiast, a productivity pro, or simply just someone who wants a fast, fluid Android experience for your day-to-day, gaming, and social media scrolling, this device delivers in spades. For a limited time, the Google Pixel 9 is available on Amazon for just $649.00, down from its original price of $899.00, which is a 28% discount on one of the best mid-range smartphones you can get your hands on right now. It's a smart deal on an even smarter device. That means lightning-fast performance, incredible voice-to-text accuracy, and an AI award-winning camera system that makes your photos look studio-perfect without lifting a finger. Its 6.1-inch OLED display is sharp, vibrant, and smooth, with a 120Hz refresh rate for buttery scrolling and gameplay that's hard to match. Design-wise, it's sleek, minimal, and available in the classic Obsidian color, as well as in the eye-catching new Wintergreen and Peony colors that add a fresh vibe without being too flashy. And because it's unlocked, you can bring it to the carrier of your choice with no strings attached at all. At just $649, the Google Pixel 9 is offering an instant upgrade for your smartphone's needs, with an unmatched performance and exclusive Google features at a fraction of the price, for only $649.00, which is a 28% discount off its usual $899.00 price tag. Get the best tech, science, and culture news in your inbox daily. News from the future, delivered to your present. We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/with-7000-five-star-reviews-this-10000mah-portable-charger-with-3-built-in-cables-is-now-nearly-free-2000604596'>With 7,000 Five-Star Reviews, This 10,000mAh Portable Charger With 3 Built-In Cables Is Nearly Free on Amazon</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'gizmodo.com'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 13:10:18
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>This article is part of Gizmodo Deals, produced separately from the editorial team. We may earn a commission when you buy through links on the site. When it comes to portable phone chargers, having cables built right in constitutes convenience on an entirely new level and that's precisely why this Charmast portable charger is selling out on Amazon's Memorial Day deals. What makes this charger quite unique is its clever design that stores three output cables and one input cable inside the long, thin power bank. The attached cables are intelligently designed to fit any number of devices, so you can charge your tablet, phone, or other device without having to find the right cable or being scared you'll leave one behind. The charger is not done with being useful—it's impressively competent. With three channels and six output ports, it can charge six devices simultaneously which is perfect for multi-device owners or families with many devices to have charged on the road. The three inputs include an internal recharging cable, Micro USB port, and USB-C port, giving you several avenues to charge the power bank itself. A digital LED display shows the amount of battery life left with precision, you don't have to estimate and you know precisely when it's getting low and needs recharging. Compatibility is also an extremely durable component of this portable charger. It is extremely compatible with all of the most popular phones and tablets out right now, including all the latest iPhone 11/12/13/14/15 line (and iPads), Samsung Galaxy S20-S25 / Z Flip-Fold Series, Google Pixel series and almost all other Android devices. If you're a Prime member, don't hold back: Limited quantities are available, so act fast to grab this offer before Memorial Day ends. Get the best tech, science, and culture news in your inbox daily. We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/book-excerpt-the-optimist-open-ai-sam-altman/'>How Peter Thiel's Relationship With Eliezer Yudkowsky Launched the AI Revolution</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 11:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Thiel saw Altman as an inveterate optimist who stood at “the absolute epicenter, maybe not of Silicon Valley, but of a Silicon Valley zeitgeist.” As Thiel put it, “If you had to look for the one person who represented a millennial tech person, it would be Altman.” Following Altman's advice brought Thiel's Founders Fund some immense returns. By the time Altman took over Y Combinator in 2014, he had internalized Thiel's critique of “tech stagnation” and channeled it to remake YC as an investor in “hard tech” moonshots like nuclear energy, supersonic planes—and artificial intelligence. And if it's hard to exaggerate Thiel's effect on Altman, it's similarly easy to understate the influence that an AI-obsessed autodidact named Eliezer Yudkowsky had on Thiel's early investments in AI. Though he has since become perhaps the world's foremost AI doomsday prophet, Yudkowsky started out as a magnetic, techno-optimistic wunderkind who excelled at rallying investors, researchers, and eccentrics around a quest to “accelerate the singularity.” How Thiel's conversations with Altman about DeepMind would help inspire the creation of OpenAI. And how Thiel, as one of Yudkowsky's most important backers, inadvertently seeded the AI-apocalyptic subcultures that would ultimately play a role in Sam Altman's ouster, years later, as CEO of OpenAI. If you buy something using links in our stories, we may earn a commission. Vinge's friend Marc Stiegler, who worked on cybersecurity for the likes of Darpa while drafting futuristic novels, recalled once spending an afternoon with Vinge at a restaurant outside a sci-­fi convention “swapping stories we would never write because they were both horrific and quite possible. We were too afraid some nutjob would pick one of them up and actually do it.” Among the many other people influenced by Vinge's fiction was Eliezer Yudkowsky. Born into an Orthodox Jewish family in 1979 in Chicago, Yudkowsky was son of a psychiatrist mother and a physicist father who went on to work at Bell Labs and Intel on speech recognition, and was himself a devoted sci-­fi fan. Thanks to Vinge, he had discovered the meaning of life. Founded by philosopher Max More in the 1980s, Extropianism is a form of pro-­science super-­optimism that seeks to fight entropy—­the universal law that says things fall apart, everything tends toward chaos and death—­on all fronts. They would be revived once humanity was technologically advanced enough to do so. More philosophically, fighting entropy meant abiding by five principles: Boundless Expansion, Self-­Transformation, Dynamic Optimism, Intelligent Technology, and Spontaneous Order. (Dynamic Optimism, for example, involved a technique called selective focus, in which you'd concentrate on only the positive aspects of a given situation.) Robin Hanson, who joined the movement and became renowned for creating prediction markets, described attending multilevel Extropian parties at big houses in Palo Alto at the time. “And I was energized by them, because they were talking about all these interesting ideas. “We all thought of ourselves as people who were seeing where the future was going to be, and other people didn't get it. More's co­founder of the journal Extropy, Tom Bell, aka T. O. Morrow (Bell claims that Morrow is a distinct persona and not simply a pen name), wrote about systems of “polycentric law” that could arise organically from voluntary transactions between agents free of government interference, and of “Free Oceana,” a potential Extropian settlement on a man-­made floating island in international waters. If this all sounds more than a bit libertarian, that's because it was. The WIRED article opens at one such Extropian gathering, during which an attendee shows up dressed like the “State,” wearing a vinyl bustier, miniskirt, and chain harness top and carrying a riding crop, dragging another attendee dressed up as “the Taxpayer” on a leash on all fours. “It is clear from even a casual perusal of the Extropians archive (maintained by Wei Dai) that within a few months, teenage Eliezer Yudkowsky became one of this extraordinary cacophony's preeminent voices,” wrote the journalist Jon Evans in his history of the movement. Two members of the Extropian community, internet entrepreneurs Brian and Sabine Atkins—­who met on an Extropian mailing list in 1998 and were married soon after—­were so taken by this message that in 2000 they bankrolled a think tank for Yudkowsky, the Singularity Institute for Artificial Intelligence. At 21, Yudkowsky moved to Atlanta and began drawing a nonprofit salary of around $20,000 a year to preach his message of benevolent superintelligence. “I thought very smart things would automatically be good,” he said. “I was taking someone else's money, and I'm a person who feels a pretty deep sense of obligation towards those who help me,” Yudkowsky explained. “At some point, instead of thinking, ‘If superintelligences don't automatically determine what is the right thing and do that thing that means there is no real right or wrong, in which case, who cares?' I was like, ‘Well, but Brian Atkins would probably prefer not to be killed by a superintelligence.' “That caused me to actually engage with the underlying issues, and then I realized that I had been completely mistaken about everything.” In a 2004 paper, “Coherent Extrapolated Volition,” Yudkowsky argued that friendly AI should be developed based not just on what we think we want AI to do now, but what would actually be in our best interests. In the paper, he also used a memorable metaphor, originated by Bostrom, for how AI could go wrong: If your AI is programmed to produce paper clips, if you're not careful, it might end up filling the solar system with paper clips. Yudkowsky, having no idea who Thiel was, walked up to him after dinner. “If your friend was a reliable signal about when an asset was going to go down, they would need to be doing some sort of cognition that beat the efficient market in order for them to reliably correlate with the stock going downwards,” Yudkowsky said, essentially reminding Thiel about the efficient-market hypothesis, which posits that all risk factors are already priced into markets, leaving no room to make money from anything besides insider information. Yudkowsky came to regard Thiel “as something of a mentor figure,” he said. Over the next six years, it expanded to become a prominent forum for futurists, transhumanists, Extropians, AI researchers, and science fiction authors, including Bostrom, More, Hanson, Stanford AI professor Sebastian Thrun, XPrize founder Peter Diamandis, and Aubrey de Grey, a gerontologist who claims humans can eventually defeat aging. Skype co­founder Jaan Tallinn, who participated in the summit, was inspired by Yudkowsky to become one of the primary funders of research dedicated to reducing existential risk from AI. Another summit participant, physicist Max Tegmark, would go on to co-found the Future of Life Institute. Vernor Vinge himself even showed up, looking like a public school chemistry teacher with his Walter White glasses and tidy gray beard, cheerfully reminding the audience that when the singularity comes, “We're no longer in the driver's seat.” In 2010, one of the AI researchers whom Yudkowsky invited to speak at the summit was Shane Legg, a New Zealand–­born mathematician, computer scientist, and ballet dancer who had been obsessed with building superintelligence ever since Yudkowsky had introduced him to the idea a decade before. Legg had been working at Intelligenesis, a New York–­based startup founded by the computer scientist Ben Goertzel that was trying to develop the world's first AI. Its best-­known product was WebMind, an ambitious software project that attempted to predict stock market trends. Goertzel, who had a PhD in mathematics, had been an active poster on the Extropians mailing list for years, sparring affectionately with Yudkowsky on transhumanism and libertarianism. Back in 2000, Yudkowsky came to speak at Goertzel's company (which would go bankrupt within a year). Goertzel and Legg began referring to the concept as “artificial general intelligence.” Legg went on to get his own PhD, writing a dissertation, “Machine Super Intelligence,” that noted the technology could become an existential threat, and then moved into a postdoctoral fellowship at University College London's Gatsby Computational Neuroscience Unit, a lab that encompassed neuroscience, machine learning, and AI. Now he was focused on building an AI inspired by the human brain. “It was basically eye-­rolling territory,” Legg told the journalist Cade Metz. “If you talked to anybody about general AI, you would be considered at best eccentric, at worst some kind of delusional, nonscientific character.” Legg thought it could be built in the academy, but Hassabis, who had already tried a startup and failed, knew better. And there was one investor who would be an obvious place to start: Peter Thiel. Afterward, they went for cocktails at Thiel's Marina District home, with its views of both the Golden Gate Bridge and the Palace of Fine Arts, and were delighted to see a chessboard out on a table. They wove through the crowd and found Yudkowsky, who led them over to Thiel for an introduction. Trying to play it cool, Hassabis skipped the hard sell and began with chess, a topic he knew was dear to Thiel's heart. In the morning, they pitched Thiel, fresh from a workout, across his dining room table. Hassabis said they were building AGI inspired by the human brain, would initially measure its progress by training it to play games, and were confident that advances in computing power would drive their breakthroughs. A few months later, Hassabis, Legg, and their friend, the entrepreneur Mustafa Suleyman, officially co­founded DeepMind, a reference to the company's plans to combine “deep learning,” a type of machine learning that uses layers of neural networks, with actual neuroscience. From the beginning, they told investors that their goal was to develop AGI, even though they feared it could one day threaten humanity's very existence. It was through Thiel's network that DeepMind recruited his fellow PayPal veteran Elon Musk as an investor. The next year, Luke Nosek, a cofounder of both PayPal and Founders Fund who is friends with Musk and sits on the SpaceX board, introduced Hassabis to Musk. Musk took Hassabis on a tour of SpaceX's headquarters in Los Angeles. Musk responded that he, in fact, was working on the most important thing in the world: turning humans into an interplanetary species by colonizing Mars. Hassabis responded that that sounded great, so long as a rogue AI did not follow Musk to Mars and destroy humanity there too. He decided to keep tabs on DeepMind's technology by investing in it. In December 2013, Hassabis stood on stage at a machine-learning conference at Harrah's in Lake Tahoe and demonstrated DeepMind's first big breakthrough: an AI agent that could learn to play and then quickly master the classic Atari video game Breakout without any instruction from humans. In February 2014, a month after Google bought DeepMind, Altman wrote a post on his personal blog titled “AI” that declared the technology the most important tech trend that people were not paying enough attention to. “To be clear, AI (under the common scientific definition) likely won't work. You can say that about any new technology, and it's a generally correct statement. But I think most people are far too pessimistic about its chances,” he wrote, adding that “artificial general intelligence might work, and if it does, it will be the biggest development in technology ever.” And with that, the race to build artificial general intelligence was on. This was a race that Yudkowsky had helped set off. But as it picked up speed, Yudkowsky himself was growing increasingly alarmed about what he saw as the extinction-level danger it posed. He was still influential among investors, researchers, and eccentrics, but now as a voice of extreme caution. Yudkowsky was not personally involved in OpenAI, but his blog, LessWrong, was widely read among the AI researchers and engineers who worked there. (While still at Stripe, OpenAI cofounder Greg Brockman had organized a weekly LessWrong reading group.) The rationalist ideas Yudkowsky espoused overlapped significantly with those of the Effective Altruism movement, which was turning much of its attention to preventing existential risk from AI. A few months after this race spilled into full public view with OpenAI's release of ChatGPT in November 2022, Yudkowsky published an essay in Time magazine arguing that unless the current wave of generative AI research was halted, “literally everyone on Earth will die.” Less than a week before Altman was briefly ousted as CEO in the fall of 2023, Thiel warned his friend, “You don't understand how Eliezer has programmed half the people in your company to believe this stuff.” Thiel's warning came with some guilt that he had created the many-headed monster that was now coming for his friend. Big Story: If Anthropic succeeds, a nation of benevolent AI geniuses could be born Special Edition: The most dangerous hackers you've never heard of WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.technologyreview.com/2025/05/20/1116331/ai-energy-demand-methodology/'>Everything you need to know about estimating AI's energy and emissions burden</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.technologyreview.com', 'title': 'MIT Technology Review'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 09:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Here's how MIT Technology Review waded through a mess of data and hidden variables to calculate the individual and collective energy demand from AI. When we set out to write a story on the best available estimates for AI's energy and emissions burden, we knew there would be caveats and uncertainties to these numbers. This story is a part of MIT Technology Review's series “Power Hungry: AI and our energy future,” on the energy demands and carbon costs of the artificial-intelligence revolution. Measuring the energy used by an AI model is not like evaluating a car's fuel economy or an appliance's energy rating. There's no agreed-upon method or public database of values. There are no regulators who enforce standards, and consumers don't get the chance to evaluate one model against another. Despite the fact that billions of dollars are being poured into reshaping energy infrastructure around the needs of AI, no one has settled on a way to quantify AI's energy usage. Worse, companies are generally unwilling to disclose their own piece of the puzzle. There are also limitations to estimating the emissions associated with that energy demand, because the grid hosts a complicated, ever-changing mix of energy sources. So, that said, here are the many variables, assumptions, and caveats that we used to calculate the consequences of an AI query. (You can see the full results of our investigation here.) Companies like OpenAI, dealing in “closed-source” models, generally offer access to their  systems through an interface where you input a question and receive an answer. There are few incentives for them to release this information, and so far, most have not. That's why, for our analysis, we looked at open-source models. They serve as a very imperfect proxy but the best one we have. (OpenAI, Microsoft, and Google declined to share specifics on how much energy their closed-source models use.) The team behind ML.Energy assisted us with our text and image model calculations, and the team behind AI Energy Score helped with our video model calculations. AI models use up energy in two phases: when they initially learn from vast amounts of data, called training, and when they respond to queries, called inference. When ChatGPT was launched a few years ago, training was the focus, as tech companies raced to keep up and build ever-bigger models. Servers contain all sorts of components—powerful chips called GPUs that do the bulk of the computing, other chips called CPUs, fans to keep everything cool, and more. To do this, we turned to PhD candidate Jae-Won Chung and associate professor Mosharaf Chowdhury at the University of Michigan, who lead the ML.Energy project. Once we collected figures for different models' GPU energy use from their team, we had to estimate how much energy is used for other processes, like cooling. We examined research literature, including a 2024 paper from Microsoft, to understand how much of a server's total energy demand GPUs are responsible for. We also identified a selection of prompts to test. Stable Diffusion 3 from Stability AI is one of the most commonly used open-source image-generating models, so we made it our focus. Though the energy used by large language models is determined partially by the prompt, this isn't true for diffusion models. Diffusion models can be programmed to go through a prescribed number of “denoising steps” when they generate an image or video, with each step being an iteration of the algorithm that adds more detail to the image. For a given step count and model, all images generated have the same energy footprint. Numbers of steps vary by model and application, but 25 is pretty common, and that's what we used for our standard quality. There is not sufficient research to know how this changes for diffusion models that generate images and videos. In the absence of a better estimate, and after consulting with researchers, we opted to stick with this 50% rule of thumb for images and videos too. Chung and Chowdhury do test video models, but only ones that generate short, low-quality GIFs. Instead, we turned to Sasha Luccioni, the AI and climate lead at Hugging Face, who directs the AI Energy Score project. We chose two versions of the CogVideoX model to test: an older, lower-quality version and a newer, higher-quality one. We asked Luccioni to use her tool, called Code Carbon, to test both and measure the results of a batch of video prompts we selected, using the same hardware as our text and image tests to keep as many variables as possible the same. After we understand how much energy it takes to respond to a query, we can translate that into the total emissions impact. Doing so requires looking at the power grid from which data centers draw their electricity. Power plants add water to the canals, and electricity users, or loads, siphon it out. So, in a way, we're all connected, but we can also break the grid up into its component pieces to get a sense for how energy sources vary across the country. To get carbon intensity figures, we reached out to Electricity Maps, a Danish startup company that gathers data on grids around the world. The company shared with us historical data from 2024, both for the entire US and for a few key balancing authorities (more on this in a moment). After discussions with Electricity Maps founder Olivier Corradi and other experts, we made a few decisions about which figures we would use in our calculations. But that doesn't account for the emissions that are associated with building and tearing down power plants, which can be significant. So we chose to use carbon intensity figures that account for the whole life cycle of a power plant. We also chose to use the consumption-based carbon intensity of energy rather than production-based. This figure accounts for imports and exports moving between different parts of the grid and best represents the electricity that's being used, in real time, within a given region. One way we can break things up is by looking at balancing authorities. These are independent bodies responsible for grid balancing in a specific region. They operate mostly independently, though there's a constant movement of electricity between them as well. Electricity Maps provided carbon intensity figures for a few key balancing authorities, and we focused on several that play the largest roles in data center operations. One key caveat here is that we're not entirely sure where companies tend to send individual AI inference requests. There are clusters of data centers in the regions we chose as examples, but when you use a tech giant's AI model, your request could be handled by any number of data centers owned or contracted by the company. One reasonable approximation is location: It's likely that the data center servicing a request is close to where it's being made, so a request on the West Coast might be most likely to be routed to a data center on that side of the country. To better contextualize our calculations, we introduced a few comparisons people might be more familiar with than kilowatt-hours and grams of carbon dioxide. In a few places, we took the amount of electricity estimated to be used by a model and calculated how long that electricity would be able to power a standard microwave, as well as how far it might take someone on an e-bike. For this, we used data from the US Environmental Protection Agency, which puts the weighted average fuel economy of vehicles in the US in 2022 at 393 grams of carbon dioxide equivalent per mile. After measuring the energy demand of an individual query and the emissions it generated, it was time to estimate how all of this added up to national demand. In a bottom-up analysis, you estimate how many individual queries there are, calculate the energy demands of each, and add them up to determine the total. For a top-down look, you estimate how much energy all data centers are using by looking at larger trends. Bottom-up is particularly difficult, because, once again, closed-source companies do not share such information and declined to talk specifics with us. While we can make some educated guesses to give us a picture of what might be happening right now, looking into the future is perhaps better served by taking a top-down approach. Academic climate and energy researchers we spoke with said it's a major problem that AI is not considered its own economic sector for emissions measurements, and there aren't rigorous reporting requirements. As a result, it's difficult to track AI's climate toll. Still, we examined the report's results, compared them with other findings and estimates, and consulted independent experts about the data. While much of the report was about data centers more broadly, we drew out data points that were specific to the future of AI. We wanted to contrast these figures with the amounts of energy that AI companies themselves say they need. To do so, we collected reports by leading tech and AI companies about their plans for energy and data center expansions, as well as the dollar amounts they promised to invest. Where possible, we fact-checked the promises made in these claims. (Meta and Microsoft's pledges to use more nuclear power, for example, would indeed reduce the carbon emissions of the companies, but it will take years, if not decades, for these additional nuclear plants to come online.) None of the companies made executives or leadership available for on-the-record interviews about their energy usage. This story was supported by a grant from the Tarbell Center for AI Journalism. Forget data centers—cooling is the real beast in energy demand. Let's cut through the noise with cold, hard numbers. Discover special offers, top stories, upcoming events, and more. Try refreshing this page and updating them one more time.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/'>We did the math on AI's energy footprint. Here's the story you haven't heard.</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.technologyreview.com', 'title': 'MIT Technology Review'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-05-20 09:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The emissions from individual AI text, image, and video queries seem small—until you add up what the industry isn't tracking and consider where it's heading next. Hundreds of millions of people now regularly turn to chatbots for help with homework, research, coding, or to create images and videos. Today, new analysis by MIT Technology Review provides an unprecedented and comprehensive look at how much energy the AI industry uses—down to a single query—to trace where its carbon footprint stands now, and where it's headed, as AI barrels towards billions of daily users. This story is a part of MIT Technology Review's series “Power Hungry: AI and our energy future,” on the energy demands and carbon costs of the artificial-intelligence revolution. The energy resources required to power this artificial-intelligence revolution are staggering, and the world's biggest tech companies have made it a top priority to harness ever more of that energy, aiming to reshape our energy grids in the process. Meta and Microsoft are working to fire up new nuclear power plants. Google expects to spend $75 billion on AI infrastructure alone in 2025. This isn't simply the norm of a digital world. It's unique to AI, and a marked departure from Big Tech's electricity appetite in the recent past. Data centers started getting built with energy-intensive hardware designed for AI, which led them to double their electricity consumption by 2023. Given the direction AI is headed—more personalized, able to reason and solve complex problems on our behalf, and everywhere we look—it's likely that our AI footprint today is the smallest it will ever be. According to new projections published by Lawrence Berkeley National Laboratory in December, by 2028 more than half of the electricity going to data centers will be used for AI. Meanwhile, data centers are expected to continue trending toward using dirtier, more carbon-intensive forms of energy (like gas) to fill immediate needs, leaving clouds of emissions in their wake. And all of this growth is for a new technology that's still finding its footing, and in many applications—education, medical advice, legal analysis—might be the wrong tool for the job or at least have a less energy-intensive alternative. Both reactions dodge the point: AI is unavoidable, and even if a single query is low-impact, governments and companies are now shaping a much larger energy future around AI's needs. We're taking a different approach with an accounting meant to inform the many decisions still ahead: where data centers go, what powers them, and how to make the growing toll of AI visible and accountable. That's because despite the ambitious AI vision set forth by tech companies, utility providers, and the federal government, details of how this future might come about are murky. Scientists, federally funded research facilities, activists, and energy companies argue that leading AI companies and data center operators disclose too little about their activities. Companies building and deploying AI models are largely quiet when it comes to answering a central question: Just how much energy does interacting with one of these models use? And what sorts of energy sources will power AI's future? This leaves even those whose job it is to predict energy demands forced to assemble a puzzle with countless missing pieces, making it nearly impossible to plan for AI's future impact on energy grids and emissions. Before you can ask an AI model to help you with travel plans or generate a video, the model is born in a data center. Racks of servers hum along for months, ingesting training data, crunching numbers, and performing computations. This is a time-consuming and expensive process—it's estimated that training OpenAI's GPT-4 took over $100 million and consumed 50 gigawatt-hours of energy, enough to power San Francisco for three days. It's only after this training, when consumers or customers “inference” the AI models to get answers or generate outputs, that model makers hope to recoup their massive costs and eventually turn a profit. “For any company to make money out of a model—that only happens on inference,” says Esha Choukse, a researcher at Microsoft Azure who has studied how to make AI inference more efficient. As conversations with experts and AI companies made clear, inference, not training, represents an increasing majority of AI's energy demands and will continue to do so in the near future. A growing number—though it's not clear exactly how many, since information on such facilities is guarded so tightly—are set up for AI inferencing. At each of these centers, AI models are loaded onto clusters of servers containing special chips called graphics processing units, or GPUs, most notably a particular model made by Nvidia called the H100. This chip started shipping in October 2022, just a month before ChatGPT launched to the public. Sales of H100s have soared since, and are part of why Nvidia regularly ranks as the most valuable publicly traded company in the world. What all have in common is a significant energy requirement to run their advanced operations without overheating. Wired close together with these chips are CPUs (chips that serve up information to the GPUs) and fans to keep everything cool. Some energy is wasted at nearly every exchange through imperfect insulation materials and long cables in between racks of servers, and many buildings use millions of gallons of water (often fresh, potable water) per day in their cooling operations. They're then connected online, just waiting for you to ping them with a question. In reality, the type and size of the model, the type of output you're generating, and countless variables beyond your control—like which energy grid is connected to the data center your request is sent to and what time of day it's processed—can make one query thousands of times more energy-intensive and emissions-producing than another. And when you query most AI models, whether on your phone within an app like Instagram or on the web interface for ChatGPT, much of what happens after your question is routed to a data center remains a secret. This is true for most of the name-brand models you're accustomed to, like OpenAI's ChatGPT, Google's Gemini, and Anthropic's Claude, which are referred to as “closed.” The key details are held closely by the companies that make them, guarded because they're viewed as trade secrets (and also possibly because they might result in bad PR). These companies face few incentives to release this information, and so far they have not. So-called open-source models can be downloaded and tweaked by researchers, who can access special tools to measure how much energy the H100 GPU requires for a given task. Such models are also incredibly popular; Meta announced in April that its Llama models have been downloaded more than 1.2 billion times, and many companies use open-source models when they want more control over outputs than they can get using something like ChatGPT. However, keep in mind that the ways people use AI today—to write a grocery list or create a surrealist video—are far simpler than the ones we'll use in the autonomous, agentic future that AI companies are hurling us toward. The smallest model in our Llama cohort, Llama 3.1 8B, has 8 billion parameters—essentially the adjustable “knobs” in an AI model that allow it to make predictions. When tested on a variety of different text-generating prompts, like making a travel itinerary for Istanbul or explaining quantum computing, the model required about 57 joules per response, or an estimated 114 joules when accounting for cooling, other computations, and other demands. The largest of our text-generation cohort, Llama 3.1 405B, has 50 times more parameters. That's enough to carry a person about 400 feet on an e-bike or run the microwave for eight seconds. So model size is a huge predictor of energy demand. The parameter counts for closed-source models are not publicly disclosed and can only be estimated. But in all these cases, the prompt itself was a huge factor too. Simple prompts, like a request to tell a few jokes, frequently used nine times less energy than more complicated prompts to write creative stories or recipe ideas. AI models that generate images and videos work with a different architecture, called diffusion. Rather than predicting and generating words, they learn how to transform an image of noise into, let's say, a photo of an elephant. They do this by learning the contours and patterns of pictures in their training data and storing this information across millions or billions of parameters. Video-generator models learn how to do this across the dimension of time as well. The energy required by a given diffusion model doesn't depend on your prompt—generating an image of a skier on sand dunes requires the same amount of energy as generating one of an astronaut farming on Mars. Generating a standard-quality image (1024 x 1024 pixels) with Stable Diffusion 3 Medium, the leading open-source image generator, with 2 billion parameters, requires about 1,141 joules of GPU energy. With diffusion models, unlike large language models, there are no estimates of how much GPUs are responsible for the total energy required, but experts suggested we stick with the “doubling” approach we've used thus far because the differences are likely subtle. “Large [text] models have a lot of parameters,” says Chung, who performed the measurements on open-source text and image generators featured in this story. ” Image generators, on the other hand, often work with fewer parameters. Last year, OpenAI debuted Sora, its dazzling tool for making high-fidelity videos with AI. Other closed-source video models have come out as well, like Google Veo2 and Adobe's Firefly. Given the eye-watering amounts of capital and content it takes to train these models, it's no surprise that free-to-use, open-source models generally lag behind in quality. Still, according to researchers at Hugging Face, one of the best is CogVideoX, made by a Chinese AI startup called Zhipu AI and researchers from Tsinghua University in Beijing. Sasha Luccioni, an AI and climate researcher at Hugging Face, tested the energy required to generate videos with the model using a tool called Code Carbon. But three months later the company launched a larger, higher-quality model that produces five-second videos at 16 frames per second (this frame rate still isn't high definition; it's the one used in Hollywood's silent era until the late 1920s). It's fair to say that the leading AI video generators, creating dazzling and hyperrealistic videos up to 30 seconds long, will use significantly more energy. As these generators get larger, they're also adding features that allow you to tweak particular elements of videos and stitch multiple shots together into scenes—all of which add to their energy demands. A note: AI companies have defended these numbers saying that generative video has a smaller footprint than the film shoots and travel that go into typical video production. That claim is hard to test and doesn't account for the surge in video generation that might follow if AI videos become cheap to produce. So what might a day's energy consumption look like for one person with an AI habit? You ask an AI model 15 questions about the best way to fundraise. You'd use about 2.9 kilowatt-hours of electricity—enough to ride over 100 miles on an e-bike (or around 10 miles in the average electric vehicle) or run the microwave for over three and a half hours. These numbers cannot serve as a proxy for how much energy is required to power something like ChatGPT 4o. We don't know how many parameters are in OpenAI's newest models, how many of those parameters are used for different model architectures, or which data centers are used and how OpenAI may distribute requests across all these systems. You can guess, as many have done, but those guesses are so approximate that they may be more distracting than helpful. “We should stop trying to reverse-engineer numbers based on hearsay,” Luccioni says, “and put more pressure on these companies to actually share the real ones.” Luccioni has created the AI Energy Score, a way to rate models on their energy efficiency. Now that we have an estimate of the total energy required to run an AI model to produce text, images, and videos, we can work out what that means in terms of emissions that cause climate change. If all data centers were hooked up to solar panels and ran only when the sun was shining, the world would be talking a lot less about AI's energy consumption. Most electrical grids around the world are still heavily reliant on fossil fuels. So electricity use comes with a climate toll attached. “AI data centers need constant power, 24-7, 365 days a year,” says Rahul Mewawalla, the CEO of Mawson Infrastructure Group, which builds and maintains high-energy data centers that support AI. That means data centers can't rely on intermittent technologies like wind and solar power, and on average, they tend to use dirtier electricity. Chan School of Public Health found that the carbon intensity of electricity used by data centers was 48% higher than the US average. Part of the reason is that data centers currently happen to be clustered in places that have dirtier grids on average, like the coal-heavy grid in the mid-Atlantic region that includes Virginia, West Virginia, and Pennsylvania. They also run constantly, including when cleaner sources may not be available. Data centers can't rely on intermittent technologies like wind and solar power, and on average, they tend to use dirtier electricity. Those three have joined a pledge to triple the world's nuclear capacity by 2050. But today, nuclear energy only accounts for 20% of electricity supply in the US, and powers a fraction of AI data centers' operations—natural gas accounts for more than half of electricity generated in Virginia, which has more data centers than any other US state, for example. What's more, new nuclear operations will take years, perhaps decades, to materialize. In April, Elon Musk's X supercomputing center near Memphis was found, via satellite imagery, to be using dozens of methane gas generators that the Southern Environmental Law Center alleges are not approved by energy regulators to supplement grid power and are violating the Clean Air Act. California's grid is far cleaner than West Virginia's, for example. For instance, data from April 2024 shows that California's grid can swing from under 70 grams per kilowatt-hour in the afternoon when there's a lot of solar power available to over 300 grams per kilowatt-hour in the middle of the night. This variability means that the same activity may have very different climate impacts, depending on your location and the time you make a request. The text, image, and video responses they requested add up to 2.9 kilowatt-hours of electricity. But generating that electricity in West Virginia might inflate the total to more than 1,150 grams. What we've seen so far is that the energy required to respond to a query can be relatively small, but it can vary a lot, depending on the type of query and the model being used. The emissions associated with that given amount of electricity will also depend on where and when a query is handled. In December, OpenAI said that ChatGPT receives 1 billion messages every day, and after the company launched a new image generator in March, it said that people were using it to generate 78 million images per day, from Studio Ghibli–style portraits to pictures of themselves as Barbie dolls. Given the direction AI is headed—more personalized, able to reason and solve complex problems on our behalf, and everywhere we look—it's likely that our AI footprint today is the smallest it will ever be. One can do some very rough math to estimate the energy impact. In February the AI research firm Epoch AI published an estimate of how much energy is used for a single ChatGPT query—an estimate that, as discussed, makes lots of assumptions that can't be verified. Still, they calculated about 0.3 watt-hours, or 1,080 joules, per message. This falls in between our estimates for the smallest and largest Meta Llama models (and experts we consulted say that if anything, the real number is likely higher, not lower). One billion of these every day for a year would mean over 109 gigawatt-hours of electricity, enough to power 10,400 US homes for a year. If we add images and imagine that generating each one requires as much energy as it does with our high-quality image models, it'd mean an additional 35 gigawatt-hours, enough to power another 3,300 homes for a year. This is on top of the energy demands of OpenAI's other products, like video generators, and that for all the other AI companies and startups. In that future, we won't simply ping AI models with a question or two throughout the day, or have them generate a photo. We will speak to models in voice mode, chat with companions for 2 hours a day, and point our phone cameras at our surroundings in video mode. We will give complex tasks to so-called “reasoning models” that work through tasks logically but have been found to require 43 times more energy for simple problems, or “deep research” models that spend hours creating reports for us. We will have AI models that are “personalized” by training on our data and preferences. This future is around the corner: OpenAI will reportedly offer agents for $20,000 per month and will use reasoning capabilities in all of its models moving forward, and DeepSeek catapulted “chain of thought” reasoning into the mainstream with a model that often generates nine pages of text for each response. AI models are being added to everything from customer service phone lines to doctor's offices, rapidly increasing AI's share of national energy consumption. “The precious few numbers that we have may shed a tiny sliver of light on where we stand right now, but all bets are off in the coming years,” says Luccioni. Every researcher we spoke to said that we cannot understand the energy demands of this future by simply extrapolating from the energy used in AI queries today. And indeed, the moves by leading AI companies to fire up nuclear power plants and create data centers of unprecedented scale suggest that their vision for the future would consume far more energy than even a large number of these individual queries. “The precious few numbers that we have may shed a tiny sliver of light on where we stand right now, but all bets are off in the coming years,” says Luccioni. To understand how much power this AI revolution will need, and where it will come from, we have to read between the lines. A report published in December by the Lawrence Berkeley National Laboratory, which is funded by the Department of Energy and has produced 16 Nobel Prizes, attempted to measure what AI's proliferation might mean for energy demand. AI-specific servers in these data centers are estimated to have used between 53 and 76 terawatt-hours of electricity. On the high end, this is enough to power more than 7.2 million US homes for a year. If we imagine the bulk of that was used for inference, it means enough electricity was used on AI in the US last year for every person on Earth to have exchanged more than 4,000 messages with chatbots. In reality, of course, average individual users aren't responsible for all this power demand. Much of it is likely going toward startups and tech giants testing their models, power users exploring every new feature, and energy-heavy tasks like generating videos or avatars. That's more than all electricity currently used by US data centers for all purposes; it's enough to power 22% of US households each year. In response to a White House request for information, Anthropic suggested that the US build an additional 50 gigawatts of dedicated power by 2027. AI companies are also planning multi-gigawatt constructions abroad, including in Malaysia, which is becoming Southeast Asia's data center hub. In May OpenAI announced a plan to support data-center buildouts abroad as part of a bid to “spread democratic AI.” Companies are taking a scattershot approach to getting there—inking deals for new nuclear plants, firing up old ones, and striking massive deals with utility companies. MIT Technology Review sought interviews with Google, OpenAI, and Microsoft about their plans for this future, and for specific figures on the energy required to inference leading AI models. OpenAI declined to provide figures or make anyone available for an interview but provided a statement saying that it prioritizes efficient use of computing resources and collaborates with partners to support sustainability goals, and that AI might help discover climate solutions. Microsoft discussed its own research on improving AI efficiencies but declined to share specifics of how these approaches are incorporated into its data centers. Google declined to share numbers detailing how much energy is required at inference time for its AI models like Gemini and features like AI Overviews. The Lawrence Berkeley researchers offered a blunt critique of where things stand, saying that the information disclosed by tech companies, data center operators, utility companies, and hardware manufacturers is simply not enough to make reasonable projections about the unprecedented energy demands of this future or estimate the emissions it will create. They offered ways that companies could disclose more information without violating trade secrets, such as anonymized data-sharing arrangements, but their report acknowledged that the architects of this massive surge in AI data centers have thus far not been transparent, leaving them without the tools to make a plan. “Along with limiting the scope of this report, this lack of transparency highlights that data center growth is occurring with little consideration for how best to integrate these emergent loads with the expansion of electricity generation/transmission or for broader community development,” they wrote. We heard from several other researchers who say that their ability to understand the emissions and energy demands of AI are hampered by the fact that AI is not yet treated as its own sector. The US Energy Information Administration, for example, makes projections and measurements for manufacturing, mining, construction, and agriculture, but detailed data about AI is simply nonexistent. Why should we be paying for their power bills?” Individuals may end up footing some of the bill for this AI revolution, according to new research published in March. The researchers, from Harvard's Electricity Law Initiative, analyzed agreements between utility companies and tech giants like Meta that govern how much those companies will pay for power in massive new data centers. They found that discounts utility companies give to Big Tech can raise the electricity rates paid by consumers. In some cases, if certain data centers fail to attract the promised AI business or need less power than expected, ratepayers could still be on the hook for subsidizing them. A 2024 report from the Virginia legislature estimated that average residential ratepayers in the state could pay an additional $37.50 every month in data center energy costs. “It's not clear to us that the benefits of these data centers outweigh these costs,” says Eliza Martin, a legal fellow at the Environmental and Energy Law Program at Harvard and a coauthor of the research. Why should we be paying for their power bills?” Crucially, there's a lot we don't know; tech giants are largely keeping quiet about the details. But to judge from our estimates, it's clear that AI is a force reshaping not just technology but the power grid and the world around us. We owe a special thanks to Jae-Won Chung, Mosharaf Chowdhury, and Sasha Luccioni, who shared their measurements of AI's energy use for this project. This story was supported by a grant from the Tarbell Center for AI Journalism.</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            