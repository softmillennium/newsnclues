
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - TECHNOLOGY Article Summaries - 2025-09-28</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            TECHNOLOGY
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/09/28/dji-loses-lawsuit-over-classification-as-chinese-military-company/'>DJI loses lawsuit over classification as Chinese military company</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 20:57:16
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>A federal judge has rejected drone maker DJI's efforts to get off a Department of Defense list of Chinese military companies. U.S. District Judge Paul Friedman ruled Friday that the DoD had provided “substantial evidence” that DJI contributes “to the Chinese defense industrial base.” Pointing to the use of modified DJI drones in the conflict between Russia and Ukraine, Friedman wrote, “Whether or not DJI's policies prohibit military use is irrelevant. TechCrunch has reached out to DJI for comment. The company told Reuters that it's considering its legal options and said Judge Friedman's decision was “based on a single rationale that applies to many companies that have never been listed.”DJI faces other legal hurdles in the United States, including a potential ban on sales starting in December unless a national security agency determines that its drones do not “pose an unacceptable risk to the national security of the United States.” Register now and save up to $444.Rates increase when doors open Famed roboticist says humanoid robot bubble is doomed to burst OpenAI launches ChatGPT Pulse to proactively write you morning briefs 2 social app on the Apple App Store, pays users to record their phone calls and sells data to AI firms Google isn't kidding around about cost cutting, even slashing its FT subscription</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/fornite-ditches-peacemaker-emote-after-the-shows-big-reveal-2000664740'>‘Fortnite' Ditches ‘Peacemaker' Emote After the Show's Big Reveal</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 16:33:50
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>This week's Peacemaker episode ended with a twist fans have been calling for weeks, and now it's affecting the show's Fortnite presence. Assuming it's not coming back, we'll issue refunds in the next few days.” “As we inquire into our partner's creative intentions in this collab emote. Assuming it's not coming back, we'll issue refunds in the next few days.” pic.twitter.com/hwHqOiid1o The “Hips” emoji references the show's season two intro, which has its cast flap their arms up and down in a way that makes them look like swastikas. That dance may also have been hiding the Nazi twist in plain sight (boy, what a sentence), so Epic's spent two weeks potentially unaware that it was charging people 400 V-bucks (or $3.29) to make their characters dance like Nazis. At time of writing, neither WB or James Gunn have commented on the emote being disabled. Fortnite's no stranger to emote-related controversy, but the apparent secrecy behind the Peacemaker dance's intent makes this all so fascinating from different angles. Is Gunn and WB at fault for not giving Epic a heads up about the meaning, or did the developer not do its job in properly vetting it? Is this just what happens as IP collaborations become so normalized, which Fortnite itself has had a hand in? Check out when to expect the latest Marvel, Star Wars, and Star Trek releases, what's next for the DC Universe on film and TV, and everything you need to know about the future of Doctor Who. The DC Studios head also discussed how it ties into 'Superman' follow-up 'Man of Tomorrow.' Who would've thought an opening dance number was plot essential? Plus, could 'Edge of Tomorrow 2' finally start shooting next year?</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=45405584'>Show HN: Built an MCP server using Cloudflare's Code Mode pattern</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 16:26:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>HN Discussion: https://news.ycombinator.com/item?id=45399204 https://news.ycombinator.com/item?id=45386248Deno provides a great sandbox environment for Typescript code execution because of its permissions system which made it easy to spin up code that only has access to fetch and network calls.Stick an MCP proxy on top of that and you've got "CodeMode" (code intermixed with MCP tool calls) for more advanced workflow orchestration.https://github.com/jx-codes/codemode-mcpThere's a lot of things that can be improved here. Deno provides a great sandbox environment for Typescript code execution because of its permissions system which made it easy to spin up code that only has access to fetch and network calls.Stick an MCP proxy on top of that and you've got "CodeMode" (code intermixed with MCP tool calls) for more advanced workflow orchestration.https://github.com/jx-codes/codemode-mcpThere's a lot of things that can be improved here. Stick an MCP proxy on top of that and you've got "CodeMode" (code intermixed with MCP tool calls) for more advanced workflow orchestration.https://github.com/jx-codes/codemode-mcpThere's a lot of things that can be improved here. https://github.com/jx-codes/codemode-mcpThere's a lot of things that can be improved here. There's a lot of things that can be improved here. A search and a read tool and use regexp as much as possible for passing parameters.You can see an early version of this pattern here: https://github.com/typedef-ai/fenic/blob/main/examples/mcp/d...It has been working well, at least in terms of the model knowing how to invoke and use the tools.I have to say though that each model is different. A search and a read tool and use regexp as much as possible for passing parameters.You can see an early version of this pattern here: https://github.com/typedef-ai/fenic/blob/main/examples/mcp/d...It has been working well, at least in terms of the model knowing how to invoke and use the tools.I have to say though that each model is different. A search and a read tool and use regexp as much as possible for passing parameters.You can see an early version of this pattern here: https://github.com/typedef-ai/fenic/blob/main/examples/mcp/d...It has been working well, at least in terms of the model knowing how to invoke and use the tools.I have to say though that each model is different. A search and a read tool and use regexp as much as possible for passing parameters.You can see an early version of this pattern here: https://github.com/typedef-ai/fenic/blob/main/examples/mcp/d...It has been working well, at least in terms of the model knowing how to invoke and use the tools.I have to say though that each model is different. You can see an early version of this pattern here: https://github.com/typedef-ai/fenic/blob/main/examples/mcp/d...It has been working well, at least in terms of the model knowing how to invoke and use the tools.I have to say though that each model is different. It has been working well, at least in terms of the model knowing how to invoke and use the tools.I have to say though that each model is different. Maybe I should try to run some benchmarking and compare more formally Definitely gotta clean up the code quite a bit. This is harder to get right:``` { "jsonrpc": "2.0", "id": 102, "method": "tools/call", "params": { "name": "book_flight", "arguments": { "origin": "SFO", "destination": "JFK", "departureDate": "2025-10-15", "returnDate": "2025-10-18", "passengers": 2, "cabinClass": "business" } } } ```Than the equivalent... but with `method: "POST"` boilerplate, etc? Or is it literally the chaining of tools that's missing from—and fundamentally faulty in—MCP client implementations? Or is it literally the chaining of tools that's missing from—and fundamentally faulty in—MCP client implementations? Or is it literally the chaining of tools that's missing from—and fundamentally faulty in—MCP client implementations? From what I understand Cloudflare is essentially generating an SDK for the LLM to write code against.Instead of writing that fetch call. From what I understand Cloudflare is essentially generating an SDK for the LLM to write code against.Instead of writing that fetch call. No idea if this is a valuable workflow or not personally. Except it can use Typescript to manipulate the data mid stream.So in reality this is MCP Middleware + MCP Orchestration + Tool Call Efficiency.It will save tokens as well due to only returning what it needs, but more so just think of going from 10 consecutive tool calls, to 1 call that gives you everything you need and nothing you don't, with 1/10th the time taken to accomplish. So in reality this is MCP Middleware + MCP Orchestration + Tool Call Efficiency.It will save tokens as well due to only returning what it needs, but more so just think of going from 10 consecutive tool calls, to 1 call that gives you everything you need and nothing you don't, with 1/10th the time taken to accomplish. It will save tokens as well due to only returning what it needs, but more so just think of going from 10 consecutive tool calls, to 1 call that gives you everything you need and nothing you don't, with 1/10th the time taken to accomplish. Tool calls are intentionally simple; adding a code generation layer introduces needless complexity and failure points.2. Cloudflare already acts as a man-in-the-middle for ~20% of the Internet with limited transparency about government data requests3. This is clearly designed to drive adoption of their Worker platform and create lock-in for AI agent developersSimilar to their x402 payment scheme that reinvents HTTP 402 under their control, the community has already built alternatives (see the Aperture implementation from Lightning) that don't require surrendering more of your stack to Cloudflare.Remember what's happening here: a company with unprecedented visibility into web traffic wants even more control over how AI agents interact with the internet. Cloudflare already acts as a man-in-the-middle for ~20% of the Internet with limited transparency about government data requests3. This is clearly designed to drive adoption of their Worker platform and create lock-in for AI agent developersSimilar to their x402 payment scheme that reinvents HTTP 402 under their control, the community has already built alternatives (see the Aperture implementation from Lightning) that don't require surrendering more of your stack to Cloudflare.Remember what's happening here: a company with unprecedented visibility into web traffic wants even more control over how AI agents interact with the internet. This is clearly designed to drive adoption of their Worker platform and create lock-in for AI agent developersSimilar to their x402 payment scheme that reinvents HTTP 402 under their control, the community has already built alternatives (see the Aperture implementation from Lightning) that don't require surrendering more of your stack to Cloudflare.Remember what's happening here: a company with unprecedented visibility into web traffic wants even more control over how AI agents interact with the internet. Similar to their x402 payment scheme that reinvents HTTP 402 under their control, the community has already built alternatives (see the Aperture implementation from Lightning) that don't require surrendering more of your stack to Cloudflare.Remember what's happening here: a company with unprecedented visibility into web traffic wants even more control over how AI agents interact with the internet. In which case your likely wrong, people do want it, and AI will be very good at orchestrating simple patterns.CF definitely has a vested interest.. The problem for them now that I see is that THEY DIDN"T ACTUALLY LAUNCH IT... but did describe what it is/does in complete detail.Now there are gonna be dozens of non CF locked clones, just like the one OP linked. The problem for them now that I see is that THEY DIDN"T ACTUALLY LAUNCH IT... but did describe what it is/does in complete detail.Now there are gonna be dozens of non CF locked clones, just like the one OP linked. Now there are gonna be dozens of non CF locked clones, just like the one OP linked. If you run `deno check` before executing the code you'd get the type-safety loop (working on this now)Later I want to see what'd happen if you give the LLM a repo of sorts to store useful snippets and functions with comments for later use. So the LLM itself would save workflows, be able to import them into the Deno environment and chain those together.It definitely needs a prompt that tells it to use the MCP server but I can see it being pretty powerful.I only did simple tests like get Reddit posts, their comments, find the weather on those days, stick them in duckdb, and run some social media metric queries.I could see that same test being: "find me leads, filter by keywords, run against some parquet file stored somewhere using duckdb, craft an email for my boss. "I'm kind of ranting but I think this a pretty exciting approach.Edit: GraphQL style codegen layer but for all your APIs seems like a pretty obvious middle layer for this, maybe next weekend. Later I want to see what'd happen if you give the LLM a repo of sorts to store useful snippets and functions with comments for later use. So the LLM itself would save workflows, be able to import them into the Deno environment and chain those together.It definitely needs a prompt that tells it to use the MCP server but I can see it being pretty powerful.I only did simple tests like get Reddit posts, their comments, find the weather on those days, stick them in duckdb, and run some social media metric queries.I could see that same test being: "find me leads, filter by keywords, run against some parquet file stored somewhere using duckdb, craft an email for my boss. "I'm kind of ranting but I think this a pretty exciting approach.Edit: GraphQL style codegen layer but for all your APIs seems like a pretty obvious middle layer for this, maybe next weekend. It definitely needs a prompt that tells it to use the MCP server but I can see it being pretty powerful.I only did simple tests like get Reddit posts, their comments, find the weather on those days, stick them in duckdb, and run some social media metric queries.I could see that same test being: "find me leads, filter by keywords, run against some parquet file stored somewhere using duckdb, craft an email for my boss. "I'm kind of ranting but I think this a pretty exciting approach.Edit: GraphQL style codegen layer but for all your APIs seems like a pretty obvious middle layer for this, maybe next weekend. I only did simple tests like get Reddit posts, their comments, find the weather on those days, stick them in duckdb, and run some social media metric queries.I could see that same test being: "find me leads, filter by keywords, run against some parquet file stored somewhere using duckdb, craft an email for my boss. "I'm kind of ranting but I think this a pretty exciting approach.Edit: GraphQL style codegen layer but for all your APIs seems like a pretty obvious middle layer for this, maybe next weekend. I could see that same test being: "find me leads, filter by keywords, run against some parquet file stored somewhere using duckdb, craft an email for my boss. "I'm kind of ranting but I think this a pretty exciting approach.Edit: GraphQL style codegen layer but for all your APIs seems like a pretty obvious middle layer for this, maybe next weekend. I'm kind of ranting but I think this a pretty exciting approach.Edit: GraphQL style codegen layer but for all your APIs seems like a pretty obvious middle layer for this, maybe next weekend. > Later I want to see what'd happen if you give the LLM a repo of sorts to store useful snippets and functions with comments for later use. Just discussing yesterday how I can't remember it going off the rails since implementing automem last week even.Best thing it does, fully recaps all your daily accomplishments, across all platforms (Claude Code, Claude Desktop, ChatGPT, Cursor).https://i.postimg.cc/Z0tYGKvf/Screenshot-2025-09-28-at-3-15-... https://i.postimg.cc/SQX6bTzV/Screenshot-2025-09-28-at-3-16-...Called Automem by a friend of my (Jack Arturo), currently closed-source, though I'm sure you could reverse engineer it enough.- its a hosted stack of FalkorDB + QDrant - has endpoints for creating/retrieving memories - embeds stuff using ChatGPT models - Uses Graph nodes for relating memories together - Has a dream/sleeping phase which degrades long term memory relevant, finds and tracks patterns and more. - Has an MCP which connects any AI directly to memory - Automated hooks which record memory queues on commit, deploy, learning moments - Automated storing of all queued memories on chat end. To be fair Jack has about a 2 month head start on the rest of us with this idea haha.--The setup were building will be an always running setup, so it also has a scheduling runtime in Node that uses MD files to create automatable workflows, some uses agents, some just run bash. They can call mcps, tools, run commands, log output, use automem etc, all in human readable text.https://i.postimg.cc/Y246Bnmx/Screenshot-2025-09-28-at-3-11-... https://i.postimg.cc/ThM2zY5Z/Screenshot-2025-09-28-at-3-17-... https://i.postimg.cc/vT6H26T7/Screenshot-2025-09-28-at-3-17-...PS Keep up the great work on your codemode service, got some great ideas from yours to incorporate to ours that should resolve the one or 2 issues we had outstanding. Just discussing yesterday how I can't remember it going off the rails since implementing automem last week even.Best thing it does, fully recaps all your daily accomplishments, across all platforms (Claude Code, Claude Desktop, ChatGPT, Cursor).https://i.postimg.cc/Z0tYGKvf/Screenshot-2025-09-28-at-3-15-... https://i.postimg.cc/SQX6bTzV/Screenshot-2025-09-28-at-3-16-...Called Automem by a friend of my (Jack Arturo), currently closed-source, though I'm sure you could reverse engineer it enough.- its a hosted stack of FalkorDB + QDrant - has endpoints for creating/retrieving memories - embeds stuff using ChatGPT models - Uses Graph nodes for relating memories together - Has a dream/sleeping phase which degrades long term memory relevant, finds and tracks patterns and more. - Has an MCP which connects any AI directly to memory - Automated hooks which record memory queues on commit, deploy, learning moments - Automated storing of all queued memories on chat end. To be fair Jack has about a 2 month head start on the rest of us with this idea haha.--The setup were building will be an always running setup, so it also has a scheduling runtime in Node that uses MD files to create automatable workflows, some uses agents, some just run bash. They can call mcps, tools, run commands, log output, use automem etc, all in human readable text.https://i.postimg.cc/Y246Bnmx/Screenshot-2025-09-28-at-3-11-... https://i.postimg.cc/ThM2zY5Z/Screenshot-2025-09-28-at-3-17-... https://i.postimg.cc/vT6H26T7/Screenshot-2025-09-28-at-3-17-...PS Keep up the great work on your codemode service, got some great ideas from yours to incorporate to ours that should resolve the one or 2 issues we had outstanding. Best thing it does, fully recaps all your daily accomplishments, across all platforms (Claude Code, Claude Desktop, ChatGPT, Cursor).https://i.postimg.cc/Z0tYGKvf/Screenshot-2025-09-28-at-3-15-... https://i.postimg.cc/SQX6bTzV/Screenshot-2025-09-28-at-3-16-...Called Automem by a friend of my (Jack Arturo), currently closed-source, though I'm sure you could reverse engineer it enough.- its a hosted stack of FalkorDB + QDrant - has endpoints for creating/retrieving memories - embeds stuff using ChatGPT models - Uses Graph nodes for relating memories together - Has a dream/sleeping phase which degrades long term memory relevant, finds and tracks patterns and more. - Has an MCP which connects any AI directly to memory - Automated hooks which record memory queues on commit, deploy, learning moments - Automated storing of all queued memories on chat end. To be fair Jack has about a 2 month head start on the rest of us with this idea haha.--The setup were building will be an always running setup, so it also has a scheduling runtime in Node that uses MD files to create automatable workflows, some uses agents, some just run bash. They can call mcps, tools, run commands, log output, use automem etc, all in human readable text.https://i.postimg.cc/Y246Bnmx/Screenshot-2025-09-28-at-3-11-... https://i.postimg.cc/ThM2zY5Z/Screenshot-2025-09-28-at-3-17-... https://i.postimg.cc/vT6H26T7/Screenshot-2025-09-28-at-3-17-...PS Keep up the great work on your codemode service, got some great ideas from yours to incorporate to ours that should resolve the one or 2 issues we had outstanding. https://i.postimg.cc/Z0tYGKvf/Screenshot-2025-09-28-at-3-15-... https://i.postimg.cc/SQX6bTzV/Screenshot-2025-09-28-at-3-16-...Called Automem by a friend of my (Jack Arturo), currently closed-source, though I'm sure you could reverse engineer it enough.- its a hosted stack of FalkorDB + QDrant - has endpoints for creating/retrieving memories - embeds stuff using ChatGPT models - Uses Graph nodes for relating memories together - Has a dream/sleeping phase which degrades long term memory relevant, finds and tracks patterns and more. - Has an MCP which connects any AI directly to memory - Automated hooks which record memory queues on commit, deploy, learning moments - Automated storing of all queued memories on chat end. To be fair Jack has about a 2 month head start on the rest of us with this idea haha.--The setup were building will be an always running setup, so it also has a scheduling runtime in Node that uses MD files to create automatable workflows, some uses agents, some just run bash. They can call mcps, tools, run commands, log output, use automem etc, all in human readable text.https://i.postimg.cc/Y246Bnmx/Screenshot-2025-09-28-at-3-11-... https://i.postimg.cc/ThM2zY5Z/Screenshot-2025-09-28-at-3-17-... https://i.postimg.cc/vT6H26T7/Screenshot-2025-09-28-at-3-17-...PS Keep up the great work on your codemode service, got some great ideas from yours to incorporate to ours that should resolve the one or 2 issues we had outstanding. Called Automem by a friend of my (Jack Arturo), currently closed-source, though I'm sure you could reverse engineer it enough.- its a hosted stack of FalkorDB + QDrant - has endpoints for creating/retrieving memories - embeds stuff using ChatGPT models - Uses Graph nodes for relating memories together - Has a dream/sleeping phase which degrades long term memory relevant, finds and tracks patterns and more. - Has an MCP which connects any AI directly to memory - Automated hooks which record memory queues on commit, deploy, learning moments - Automated storing of all queued memories on chat end. To be fair Jack has about a 2 month head start on the rest of us with this idea haha.--The setup were building will be an always running setup, so it also has a scheduling runtime in Node that uses MD files to create automatable workflows, some uses agents, some just run bash. They can call mcps, tools, run commands, log output, use automem etc, all in human readable text.https://i.postimg.cc/Y246Bnmx/Screenshot-2025-09-28-at-3-11-... https://i.postimg.cc/ThM2zY5Z/Screenshot-2025-09-28-at-3-17-... https://i.postimg.cc/vT6H26T7/Screenshot-2025-09-28-at-3-17-...PS Keep up the great work on your codemode service, got some great ideas from yours to incorporate to ours that should resolve the one or 2 issues we had outstanding. - its a hosted stack of FalkorDB + QDrant - has endpoints for creating/retrieving memories - embeds stuff using ChatGPT models - Uses Graph nodes for relating memories together - Has a dream/sleeping phase which degrades long term memory relevant, finds and tracks patterns and more. - Has an MCP which connects any AI directly to memory - Automated hooks which record memory queues on commit, deploy, learning moments - Automated storing of all queued memories on chat end. To be fair Jack has about a 2 month head start on the rest of us with this idea haha.--The setup were building will be an always running setup, so it also has a scheduling runtime in Node that uses MD files to create automatable workflows, some uses agents, some just run bash. They can call mcps, tools, run commands, log output, use automem etc, all in human readable text.https://i.postimg.cc/Y246Bnmx/Screenshot-2025-09-28-at-3-11-... https://i.postimg.cc/ThM2zY5Z/Screenshot-2025-09-28-at-3-17-... https://i.postimg.cc/vT6H26T7/Screenshot-2025-09-28-at-3-17-...PS Keep up the great work on your codemode service, got some great ideas from yours to incorporate to ours that should resolve the one or 2 issues we had outstanding. So in reality you get a near biological memory, useful by any MCP agent. To be fair Jack has about a 2 month head start on the rest of us with this idea haha.--The setup were building will be an always running setup, so it also has a scheduling runtime in Node that uses MD files to create automatable workflows, some uses agents, some just run bash. They can call mcps, tools, run commands, log output, use automem etc, all in human readable text.https://i.postimg.cc/Y246Bnmx/Screenshot-2025-09-28-at-3-11-... https://i.postimg.cc/ThM2zY5Z/Screenshot-2025-09-28-at-3-17-... https://i.postimg.cc/vT6H26T7/Screenshot-2025-09-28-at-3-17-...PS Keep up the great work on your codemode service, got some great ideas from yours to incorporate to ours that should resolve the one or 2 issues we had outstanding. --The setup were building will be an always running setup, so it also has a scheduling runtime in Node that uses MD files to create automatable workflows, some uses agents, some just run bash. They can call mcps, tools, run commands, log output, use automem etc, all in human readable text.https://i.postimg.cc/Y246Bnmx/Screenshot-2025-09-28-at-3-11-... https://i.postimg.cc/ThM2zY5Z/Screenshot-2025-09-28-at-3-17-... https://i.postimg.cc/vT6H26T7/Screenshot-2025-09-28-at-3-17-...PS Keep up the great work on your codemode service, got some great ideas from yours to incorporate to ours that should resolve the one or 2 issues we had outstanding. The setup were building will be an always running setup, so it also has a scheduling runtime in Node that uses MD files to create automatable workflows, some uses agents, some just run bash. They can call mcps, tools, run commands, log output, use automem etc, all in human readable text.https://i.postimg.cc/Y246Bnmx/Screenshot-2025-09-28-at-3-11-... https://i.postimg.cc/ThM2zY5Z/Screenshot-2025-09-28-at-3-17-... https://i.postimg.cc/vT6H26T7/Screenshot-2025-09-28-at-3-17-...PS Keep up the great work on your codemode service, got some great ideas from yours to incorporate to ours that should resolve the one or 2 issues we had outstanding. PS Keep up the great work on your codemode service, got some great ideas from yours to incorporate to ours that should resolve the one or 2 issues we had outstanding. Just because an agent “lives” in the environment, doesn't make it RL. It needs a reward function, or even better something like Gym. So once it has the API shape in memory, it could make dozens of tool calls in a single call.It isn't about token saving, its about time/efficiency of tool usage/response time accumulation.Instead of 20 separate tool calls one after the other, you get one larger, orchestrated one that only returns exactly what it needed.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/jensen-huang-says-china-is-nanoseconds-behind-in-chips'>Jensen Huang says China is ‘nanoseconds behind' the US in chipmaking, calls for reducing US export restrictions on Nvidia's AI chips</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 16:22:42
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>As Chinese firms scale and U.S. export rules tighten, Nvidia is fighting to keep a foothold in China. When you purchase through links on our site, we may earn an affiliate commission. Nvidia CEO Jensen Huang says China is just “nanoseconds behind” the U.S. in chipmaking and that Washington should stop trying to wall off the market. Speaking on the BG2 podcast, Huang argued that allowing companies like Nvidia to sell into China would serve American interests by spreading U.S. technology and extending its geopolitical influence. “We're up against a formidable, innovative, hungry, fast-moving, underregulated [competitor],” Huang said, talking about the pedigree of China's engineers and controversial 9-9-6 working culture. The Commerce Department is understood to have begun issuing licenses for the H20 in August, and Nvidia is already working on a successor chip designed to comply with current restrictions while offering better performance. China, meanwhile, is accelerating its own plans to become self-sufficient. Huawei's new Atlas 900 A3 SuperPoD systems, powered by the company's Ascend 910B chips, are now shipping in volume. The company has laid out an ambitious roadmap through 2027 with next-gen Ascend silicon that aims to match or exceed current-gen performance. These systems are CUDA-free by design and optimized for Chinese-built software stacks, a shift that puts real pressure on Nvidia's dominance, which, according to Huang, previously held a 95% market share in China. Baidu, Alibaba, Tencent, and ByteDance are all investing in custom silicon, either through internal chip teams or by funding startups. Asked what he sees in the near future, Huang said, “They [China] publicly say… they want China to be an open market, they want… companies to come to China and compete in the marketplace… and I believe and I hope that we return to that.” Follow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Although his background is in legal, he has a personal interest in all things tech, especially hardware and microelectronics, and anything regulatory. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/09/28/techcrunch-mobility-self-driving-trucks-startup-kodiak-goes-public-and-a-shake-up-at-hyundais-supernal/'>TechCrunch Mobility: Self-driving trucks startup Kodiak goes public and a shake-up at Hyundai's Supernal</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 16:01:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Welcome back to TechCrunch Mobility — your central hub for news and insights on the future of transportation. To get this in your inbox, sign up here for free — just click TechCrunch Mobility! The autonomous vehicle industry is years — maybe decades — from maturing. And so there's still a Wild West quality to the sector, in spite of the steady stream of announcements that do show marked progress. Two such news items from this week illustrate my point of progress, possibility, and even a bit of peril (at least to the ups and downs a public market can provide). The startup, which I first wrote about in 2019, announced a multi-year and expanded commercial partnership with Canada's largest retailer, Loblaw. This means these third-generation AV trucks will operate autonomously to pick up products from two distribution centers and make deliveries to over 300 retail stores. “These are multiple brands within the Loblaw umbrella,” he said. In other words, this is not some fixed-route pilot program. Next up is Kodiak Robotics, another startup I have reported on since its founding. The company, which is developing self-driving trucks for highway, industrial, and defense uses, began trading on Nasdaq this week under the tickers KDK and KDKRW. The company, which is now called Kodiak AI, went public via a merger with special-purpose acquisition company Ares Acquisition Corporation II, an affiliate of Ares Management. I spoke to founder and CEO Don Burnette the day before Kodiak's big debut about why he took the company public — let alone via a SPAC. It was a big moment for Burnette, whose family was on hand to watch him ring the bell and mark the milestone. “As you can imagine, building and scaling a transformative autonomous driving company is very capital intensive, and we were looking to access the public markets as a path forward for the company. And when choosing between, you know, traditional IPO or a SPAC, we considered all the options,” he said. It should be noted that Burnette is also quite bullish on defense. “I think autonomy is the future of ground transportation broadly,” he said, before noting the benefits within defense for logistics and reconnaissance operations for ground vehicles. “One of the key things is defense requires unstructured autonomy, and this is one of the areas where we become specialists.” A few weeks ago, we wrote about some trouble at Hyundai‘s electric air taxi startup Supernal, including that the company had stopped work on its air taxi program and that its CEO and CTO were out. This week, a little bird told us that a wider reorg of Supernal's C-suite was afoot — something Hyundai Motor Group has now confirmed to us. Chief strategy officer Jaeyong Song and chief safety officer Tracy Lamb are part of a “transition to new leadership,” according to the Korean conglomerate. Song's departure is particularly notable, as he was once the VP of Hyundai's Advanced Air Mobility division, which Supernal was spun out of in 2021. Also gone is Lina Yang, who most recently served as chief of staff to the startup's now-former CEO, but who also served as Supernal's “Head of Intelligent Systems” before that. Remember Moxion Power, the portable battery startup that raised $110 million before going bankrupt? The founders are back with a new startup called Anode Technology Company, which has designed a mobile battery and inverter that can be used for EV charging and supplying remote power to construction sites and live events. The startup just raised $9 million in seed funding in a round led by Eclipse Ventures; its partner, Jiten Behl, who spearheaded the deal, was previously Rivian's chief growth officer. Apparently, Behl's interest was sparked by his experience at Rivian. Side note: Palo Alto-based venture capital firm Eclipse sure has been busy this year. The firm doesn't explicitly focus on transportation, but some of its portfolio companies in this sector include Arc, Bedrock Robotics, Reliable Robotics, Skyryse, and Wayve. Rapido, a popular ride-hailing platform in India that competes with Uber, doubled its valuation to $2.3 billion following a secondary share sale by food delivery giant Swiggy. The share sale comes just weeks after Rapido began piloting food deliveries, edging into Swiggy's core territory. TheTrump administration is seeking up to a 10% stake in Lithium Americas in exchange for renegotiating the repayment period of a $2.26 billion Department of Energy loan. Hackers have had quite an active week in the transportation sector. Stellantis confirmed a data breach involving customers' personal information. The breach is linked to a hack of its Salesforce database. Meanwhile, a hack that began last Friday and targeted check-in systems provided by Collins Aerospace caused delays at Brussels, Berlin, and Dublin airports, as well as London's Heathrow. And finally, Jaguar Land Rover said it will not resume production at its factories for yet another week as it continues to grapple with fallout from a cyberattack. Battery materials startup Sila started operations at its facility in Moses Lake, Washington, a milestone that could pave the way for longer-range, faster-charging EVs. Automakers continue to pull back on EVs and electrified vehicles. Honda is ending U.S. production of its Acura ZDX electric vehicle that was being built by General Motors in Tennessee, CNBC reported. And Stellantis has canceled plans to produce a 4xe plug-in hybrid Jeep Gladiator in North America by the end of 2025. Tesla asked the Environmental Protection Agency not to roll back current vehicle emissions standards, breaking from other major automakers that want to see the rules eased. Waymo launched “Waymo for Business,” a new service designed for companies to set up accounts so their employees can access robotaxis in cities like Los Angeles, Phoenix, and San Francisco. Zoox has asked federal regulators for an exemption that would allow the Amazon-owned autonomous vehicle company to commercially deploy its custom-built robotaxis, which lack traditional controls like pedals and a steering wheel. This week, he reappeared as the co-founder of a new company called Russell AI Labs. Register now and save up to $444.Rates increase when doors open OpenAI launches ChatGPT Pulse to proactively write you morning briefs Tim Chen has quietly become of one the most sought-after solo investors Google isn't kidding around about cost cutting, even slashing its FT subscription</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/ray-ban-meta-gen-2-review-still-the-best-non-display-smart-glasses-2000664295'>Ray-Ban Meta Gen 2 Review: Still the Best Non-Display Smart Glasses</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 15:00:40
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>It's never ideal being the second-most anything in the world, but there are worse places to be, too. The first, if popular opinion is any indication, is Meta's Ray-Ban Display that, as you may already have gathered, has a screen in it. But even if the Ray-Ban Meta Gen 2 (starting at $379) are the second-most exciting pair of smart glasses to come out of Connect, they can still be the first-most something, and in my estimation, they are. These are the best pair of Ray-Ban Meta AI glasses you can buy without a screen. Ray-Ban Meta AI Glasses Gen 2 aren't exciting but they're better then the original. I've already covered this a few times, so I'll keep it brief; the biggest updates in the Ray-Ban Meta Gen 2 are battery life and video. The battery life, though, is now rated for double, which in this case equates to about 8 hours of general use. The battery increase in the smart glasses is thanks to what Meta is calling “ultra-narrow steelcan” batteries—the same ones it's putting in the Meta Ray-Ban Display, its smart glasses with a screen in them. On the video side of things, it's upping the max resolution of recording to 3K and also introducing a 60 fps option, though that will only be available if you're recording in 1080p. It's 12 megapixels with a max resolution of 3,024 x 4,032. That may not sound like a lot, but you can't really understate the importance of battery life and videos in a pair of smart glasses—those are pretty important to any device that would dare encroach on phone territory. I often use my first-gen Ray-Ban Meta to record video while I'm biking, because recording with your phone in one hand while you're on a bike in New York City is kind of a death wish. Here's a side-by-side comparison of a still frame pulled from the Ray-Ban Meta Gen 1's maximum 1080p video versus an image from the Ray-Ban Meta Gen 2. Where some edges used to be blurred and a little too smooth, the videos recorded in 3K feel like a more accurate slice of life. There's another aspect to the video upgrade, 60 fps, that I would have loved to test out for you guys, but unfortunately, it's not available yet. According to a Meta representative, 60 fps will roll out in a software update for Ray-Ban Gen 2 on Oct. 1, coinciding with the release of the Oakley Meta Vanguard smart glasses. As is the case with any gadget, the battery life will largely depend not just on density or size but also on your usage. One thing that I love to do with the first-gen Ray-Ban Meta AI glasses is use them as open-ear headphones, and I think lots of people who own them would agree. The volume was fairly loud, though (a metric that affects battery life), since I was listening in a crowded coffee shop and needed to overpower music and chatter. That's not the 8 hours promised by Meta, but it's also an improvement over the first-gen smart glasses, which usually expire fully after about 3 to 4 hours for audio streaming. That's not gold medal-worthy news, but again, your battery is going to depend on what you're doing with the Ray-Ban Meta Gen 2. My second-favorite use of Ray-Ban Meta AI smart glasses is taking calls with them. I hopped on a call with my mom, which lasted 32 minutes at full volume, and the smart glasses barely took a hit, battery-wise. Again, your mileage here is going to vary based on what you're doing. Well, you can expect the Meta Ray-Ban Gen 2 to die sooner. You might get closer to the advertised 8 hours of battery life. One thing is for sure: the battery definitely gets more juice, which should be welcome for anyone who's sick of having to pop their smart glasses back in the case just so they can listen to some music while they go for a walk. How this battery will hold up under the strain of Meta Ray-Ban Display is anyone's guess, but this is definitely the best battery in a pair of non-display Ray-Ban Meta AI glasses yet. If you're fine with how your smart glasses perform in those areas, though, I can't see a reason to rush out and pick up a new pair. Whether the updates appeal to you or not, though, these are still the best pair of non-display Ray-Ban Meta AI glasses you can buy, even if I would have liked to see substantive improvements to things like Meta AI, which is still finicky at best. As for connectivity to other apps, things are also the same. Meta's voice assistant nails your simple commands the majority of the time (like skip this song or play and pause), but asking it to play specific songs or artists can be hit and miss. There is no direct integration with iOS and Android, so if you want to call or text with your smart glasses via the voice assistant, you'll need to link your Instagram or WhatsApp. For some people, that will be fine, but for others who don't use those platforms, it may be a dealbreaker. And while it works fine for transferring and storing pictures and videos from your smart glasses, I still wish it didn't shoehorn an LLM (large language model) in there. As is the case with any of Meta's products, you're going to have to be okay with knowing that you won't always get the best protections when it comes to personal privacy, too. As I've pointed out previously, Meta has a pretty bad track record on that front, so if the idea of Meta using photos and videos you take by using the “Hey, Meta” function to train its AI skeeves you out, you'd best steer clear of Ray-Ban smart glasses. The second-gen glasses aren't groundbreaking, but they're improved. Subscribe and interact with our community, get up to date with our customised Newsletters and much more. Another impressive use case for VR at a time where interest feels to be waning. There are a couple major differences between generations that could sway your opinion. The Apple Watch Ultra 3 has the most features of any Apple smartwatch, but you may not need to buy it if you want two of its best features. There's one big hurdle between Meta and making a device that actually stands on its own.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/how-to-buy-a-gaming-laptop/'>I've Been Reviewing Gaming Laptops for Over a Decade. Here's What to Look for When Shopping</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 15:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>All products featured on WIRED are independently selected by our editors. There are gaming laptops that prioritize performance at all costs and others that hone in on thinness, cost, or design. That breadth of choices means choosing a gaming laptop in 2025 isn't simple. While picking any option from our Best Gaming Laptops guide is a good place to start, you still might not end up with a gaming laptop perfectly suited for your needs. Having tested many gaming laptops in over a decade of reviewing products, I'll break down each element of these spendy machines to lead you in the right direction, as well as explain what to expect from the major laptop brands. You'll often see three sizes across brands: 14-inch, 16-inch, and 18-inch. Though they are large laptops, they give the powerful gaming hardware enough space for the thermals to breathe. 14-inch laptops are a newer development, tending to be highly portable and compact. These are gaming laptops meant to primarily be left at a desk or workstation. This is especially nice if you aren't playing on an external monitor. A gaming laptop needs a discrete GPU to be ready for 3D gaming, and typically, that means choosing from something in Nvidia's RTX lineup. Nvidia will have you believe that multi-frame generation is the reason to buy a new laptop with one of these GPUs, though in my testing, that hasn't always proven true. Either way, the feature is there to play with regardless of which GPU your laptop has. I won't list out all the specs for these graphics cards, but there are a few important things to know when deciding. It's also important to remember that these laptop GPUs do not correspond with the desktop versions in terms of specs. Some cheaper gaming laptops, such as the Gigabyte Aero X16, run that same RTX 5060 at a max of 85 watts. That severely limits the performance you can expect out of it. This spec is not always clearly labeled on retailer pages, so make sure to check with the manufacturer before buying. Beyond graphics, your CPU matters in performance too. Intel and AMD both have a strong position in gaming laptops, and you'll find options for them spread out across different laptop lineups. The latest generation of chips you'll see in 2025 gaming laptops are the Intel Core Ultra Series 2 H or HX chips, and AMD has its third-gen Ryzen AI chips, such as the Ryzen AI 9 365 or the Ryzen AI 9 HX 375. Although it's a bit rarer, we're also seeing some gaming laptops adopt the Ryzen 9 9955HX3D, which is the absolute king of gaming performance right now. Meanwhile, Intel's latest chips are a bit more commonly used and get you better battery life. Should you buy older gaming laptops that are now on discount? Well, I wouldn't recommend buying anything with a GPU older than the RTX 40-series. Remember: these GPUs have been around since 2023, so you're potentially purchasing something that's a couple of years old. I just haven't found many options that are discounted deep enough to be worth it. You won't find many new gaming laptops with less than 16 GB of RAM anymore, thankfully. In fact, many companies are now moving to 32 GB, largely because of how memory-intensive modern games can be. Unfortunately, some of these gaming laptops no longer let you easily upgrade the memory yourself, as it's soldered to the motherboard. But many still offer it, such as the aforementioned ROG Strix G16, Alienware 16 Aurora, MSI Titan 18 HX, and others. For storage, 512 GB is still the standard, though some higher-end gaming laptops have moved to one terabyte as the base configuration. Razer did that with its Blade gaming laptops a few years back. Remember: modern games are absolutely massive these days, and while you'll no doubt be using external storage at some point for your game collection, having a terabyte of internal storage can be super helpful. Most gaming laptops will allow you to easily upgrade the storage yourself, though, and often offer a second empty M.2 slot. Like with RAM, this is a much cheaper option than configuring it in your laptop purchase up front. Do not underestimate the importance of your gaming laptop's display. Unless you plan on exclusively using it while plugged into an external monitor (in which case you should probably buy or build a desktop PC), the display of your gaming laptop is the window through which you experience the world of your games. Outside of the size, which we already discussed, there are three primary considerations with a gaming laptop's screen: resolution, refresh rate, and panel type. Occasionally, you may run across a 16:9 aspect ratio screen with an old-school 1920 x 1080 resolution, too. The good news is that all modern gaming laptops have a refresh rate of over 60 Hz, which is the standard for non-gaming laptops. Laptop manufacturers tend to do a good job of offering display resolutions and refresh rates appropriate to the amount of performance you can expect from the laptop, but sometimes you'll have a choice of a higher resolution or a higher refresh rate. The last important consideration with a gaming laptop's display is the panel type, which is increasingly a very exciting aspect of these devices. While IPS is still the standard, higher-end gaming laptops have begun to adopt Mini-LED or OLED. Not only are these panels more color accurate and vivid, but they also allow for vastly better HDR performance. Many of these panels, including the OLED ones, can hit over 1,000 nits of peak HDR brightness, really bringing the lighting in games to life. The best part is that, unlike effects like ray tracing, it doesn't cost any extra performance to enjoy the benefits. OLED also offers better response times, offering more responsive gaming. There was a time not so long ago when Lenovo didn't have much of a presence in the world of gaming. That began to change in 2016 with the launch of the Lenovo Legion PC gaming brand, which would, over time, gain a lot of ground. It offers both Intel and AMD versions of these devices, which range from $1,340 up to over $4,500. Legion laptops don't always have the flashiest or thinnest designs, but they often offer great performance for the price. And because Legion laptops don't chase the ultra-thin designs like Asus and Razer, they often have strong thermals. For now, LOQ laptops only feature lower-end GPUs: the RTX 4050, 4060, 5050, and 5060. One quirk with the LOQ gaming laptops is that, unlike most of the competition, they still use a 16:9 aspect ratio display, giving them less screen and a large bottom bezel. Still, they're one of the few gaming laptop brands right now that are offering the latest RTX 50-series GPUs in designs under $1,000. My favorite Lenovo gaming laptop right now is the Lenovo Legion 7i Gen 10, which has a glorious OLED screen and a really clean, all-white design. On the surface, Asus has just two lines for its gaming laptops: ROG (Republic of Gamers) and TUF. ROG Zephyrus is the company's flagship gaming laptop brand. These gaming laptops are some of the thinnest you can buy, while still offering high-end OLED screens and graphics up to an RTX 5090. Perhaps taking inspiration from Razer, ROG Zephyrus laptops feature a clean, minimalist design that makes them great as hybrid devices that can double for work or school just as well as for gaming. This is where the company's thicker, more conventional gaming laptops are found. Pricing can range widely, as it includes affordable options like the ROG Strix G16 with the RTX 5050, which starts at just $1,300. These TUF gaming laptops used to be some of the most affordable gaming laptops you could buy, but they've gone up in price over the past few years. There aren't any Asus gaming laptops under $1,000 that feature the latest RTX 50-series GPUs, though you can find plenty of older models for less on Amazon or Best Buy. Dell's gaming laptop lineup is fairly sparse these days. I like the simplicity of the new lineup, which focuses on what Alienware has always been known for: its brash, gamer style and higher-end performance. HP's Omen gaming brand has been around for over a decade, but it really feels like the company has started to build some momentum around it over the past few years. Interestingly, HP breaks down its options into three categories of thickness and performance. Omen 16 is the middle ground, capping out at an RTX 5070. Omen Transcend, which offers a 14-inch model, still supports up to an RTX 5070, but brings the thickness down to 0.7 inches. There are 16-inch size options available across all three subbrands; however, none of the laptops are as thin as some of the competition. There's also an Omen 16 Slim, which blurs the lines a bit. Beyond these mainstay brands, you also have PC gaming companies that have dipped into gaming laptops, such as Gigabyte, Origin, and Maingear. Just stay away from the no-name brands that have popular listings on Amazon despite lacking discrete graphics cards—like this. While there's an entire ecosystem of laptops marketed toward gamers, that doesn't mean you can't play games on other devices. Laptops with dedicated graphics cards can often play games just as well as gaming laptops, but they're often targeted more at creatives who need better graphics to run creative applications. If you're buying a laptop primarily to play games, though, I wouldn't recommend one of these. They usually don't support the higher-tier GPUs like the RTX 5080 or 5090, and you won't get super-fast refresh rates beyond 120 Hz. If you're more of a casual gamer and just want a high-end laptop that can do it all, these are good options. They're especially good if you despise the “gamer” aesthetic and want something a bit more subtle. I should mention that integrated graphics have improved tremendously in recent years. You'll still need to drop down the settings (and perhaps the resolution) to achieve smoother frame rates, but I've been surprised by how well lighter games like Fortnite or Marvel Rivals play on the best laptops I've tested, like the Dell 14 Plus or Lenovo Yoga 9i, which both use the Core Ultra 7 256V or 258V. Again, I would never recommend someone buy a laptop like this just to play games on, but they can technically play games. Heck, I even happily played Baldur's Gate 3 on a MacBook Pro last year. Buying directly from the manufacturer is always the safest way to go, whether that's Asus, Dell, HP, or Lenovo. Best Buy has the best selection of gaming laptops, and does a good job of weeding out listings from unknown brands, too. Amazon is similar, though I'd advise you to tread a bit more carefully. Searching for “gaming laptops” can lead you to some seemingly cheap gaming laptops that you really shouldn't buy. Stick to the name brands, and you'll be OK. On Amazon, you also need to watch out for the “Renewed” label, which indicates that it's refurbished. Lastly, make sure to check the seller when shopping on Amazon and double-check that you're buying from the manufacturer. Aside from the big two, I'd also recommend checking out Newegg and Walmart, both of which sometimes have decent deals on gaming laptops. Walmart has the same problem as Amazon with junky, super-cheap listings, and even Newegg keeps listings up like this. Calling this a gaming laptop is wildly misleading. If you're lucky, there's a Micro Center near you (or something similar), which is a great place to go and play around with the latest gaming laptops so you can get a proper feel for them before dropping a wad of cash. In your inbox: Our biggest stories, handpicked for you each day Meet the guys betting big on AI gambling agents WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/semiconductors/lutnick-says-taiwan-deal-coming-pretty-soon'>US Commerce head notes China 'isn't even shy' about its goal to 'take' Taiwan, says US-Taiwan tariff deal coming soon — goal is to have 40% of chips made in America</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 14:18:19
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Lutnick claims deal talks with Taiwan are advancing as the Trump administration turns up pressure on chipmakers to onshore advanced fabs. When you purchase through links on our site, we may earn an affiliate commission. Commerce Secretary Howard Lutnick said Saturday that a major semiconductor deal with Taiwan is coming “pretty soon,” signaling a potential breakthrough in U.S. efforts to shore up domestic chip production and reduce reliance on a single, geopolitically vulnerable supplier. The comment came during an interview with NewsNation, where he also set an ambitious target of increasing U.S. chip production to 40% of national needs before he leaves office. “The Chinese have said, ‘we're going to take Taiwan,'” he told NewsNation. “They're not even shy about it.” That threat, he says, is exactly why semiconductor manufacturing cannot remain concentrated on “an island 80 miles from mainland China” that makes “95% of our chips.” These comments echo long-standing concerns about overdependence on Taiwan's advanced foundries, particularly TSMC, which produces around 90% of the world's leading-edge chips below 10nm. While the island is essential for high-performance CPU and GPU silicon, it accounts for around 44% of logic chips and 24% of memory chips that enter the U.S. market, according to a November 2023 working paper published by the U.S. International Trade Commission. Still, the Trump administration is pushing hard to increase domestic manufacturing. A proposed 1:1 chip rule would require companies to match every imported chip with one made domestically or face 100% tariffs, a major pivot from subsidies to leverage as U.S. officials seek lasting supply chain independence. Lutnick's comments concerning a Taiwan deal suggests the administration is now looking to formalize or expand its partnership with TSMC, which is already building two fabs in Arizona and, in March, pledged $100 billion toward U.S. investments over five years. If — and it's a big if — an upcoming deal leads to TSMC bringing state-of-the-art node production to the U.S., it would mark a monumental shift in where leading-edge silicon is fabricated. TSMC is already producing N4 chips at its Arizona facility and plans to support N3 and then N2 by 2028-2029 at Fab 21, but locking in leading nodes will be tricky. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Taiwan's government has already signaled resistance to transferring its most advanced technology abroad, saying that it will ensure TSMC will “keep its most advanced manufacturing processes in Taiwan” under the proposed N-1 policy. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/semiconductors/u-s-govt-mulls-tariffing-devices-based-on-the-number-of-chips-used-and-their-estimated-value-policy-would-impact-nearly-every-type-of-electronic-device'>U.S. gov't mulls tariffing devices based on the number of chips used and their estimated value — policy would impact nearly every type of electronic device</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 14:02:20
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. This plan, which is still under internal review, could impact everything from basic gadgets like the Apple Watch to high-end servers, marking a shift toward chip-specific trade penalties. However, there are obvious difficulties associated with implementing such tariffs. Although still uncertain, the numbers indicate a shift toward creating a tiered tariff system based on origin and chip usage intensity. In addition, the Trump administration is also working on a policy that would require chipmakers to produce one chip in the U.S. for every one they import into the country, or face steep tariffs, potentially as high as 100%. The plan ties tariff exemptions to actual production volumes in terms of unit count. However, the proposed 1:1 import-to-domestic ratio raises serious feasibility concerns due to the wide variation in chip types, from low-cost smartphone system-on-chips to high-end AI processors, making accurate tracking and fair enforcement difficult. Major chipmakers outside the U.S., such as TSMC and Samsung, would be particularly exposed under the current draft of the plan, as while both companies have production capacities in the U.S., their production capacity in Taiwan and South Korea is dramatically bigger, and it hardly makes sense for them to match their American and domestic capacities. chipmakers and chip designers to produce more chips in the U.S. However, such policies may create their own set of problems. Since chips are embedded in all electronic devices (even cheap kettles), a wide range of consumer products could become more expensive. Economists note that even goods assembled domestically might carry higher price tags due to increased costs of foreign components. Apparently, while chip-making lithography tools from ASML are currently exempt from tariffs, the Commerce Department is at least considering tariffs on chip-making equipment, which could increase the costs of fabs in the U.S. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Anton Shilov is a contributing writer at Tom's Hardware. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/china-finds-ingenious-solution-for-its-decommissioned-wind-turbine-blades-2000663951'>China Finds Ingenious Solution for Its Decommissioned Wind Turbine Blades</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 14:00:32
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Many wind turbine blades in China are approaching retirement, and researchers have come up with a creative way to reuse the giant components. The approach could be the solution to two problems: dealing with old blades and finding optimal sand control measures. “Wind turbine blades with high strength and durability can be directly cut and drilled into sand barriers,” the researchers wrote in the paper. While sand barriers such as those made out of reeds and branches are inexpensive, easy to construct, and environmentally friendly, they're short-lived and don't hold up well to extreme environments. More effective artificial sand control materials don't offer perfect solutions, because they also face challenges in extremely windy areas along railways. As such, people sometimes turn to stronger barriers made of materials such as cement, metal, and rocky sand. Ultimately, the materials should be strong, long-lasting, wind-abrasion-resistant, thermally stable, available, reasonably priced, and with optimal porosity. As for the wind power industry, the question of what to do with old wind turbine blades faces high costs and complex traditional recycling processes, in addition to the risk of pollution in the case of improper management. As such, the researchers investigated the efficacy of sand barriers made from decommissioned or damaged wind turbine blades. “Second, through wind tunnel experiments and numerical simulations, we analyzed the shelter and sand stabilization effects of the new sand barriers with different porosities compared with traditional nylon net sand barriers.” The approach revealed that the new barrier's erosion rate can be 56% lower than that of wood composite materials, and its bending strength was 14 times greater. “Therefore, the new porous sand barriers made from decommissioned or damaged wind turbine blades possess excellent UV and erosion resistance, high strength and thermal stability, recyclability, and long service life,” the researchers concluded. “It combines the porous structure of flexible sand barriers with the strength of rigid sand barriers, making it well-suited for regions with strong winds, large temperature variations, and intense UV radiation, which has significant potential for application in sand control practices.” Or, in this case, one industry's trash is another's solution. Subscribe and interact with our community, get up to date with our customised Newsletters and much more. Huawei chipped in on the censorship effort.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/09/28/wiz-chief-technologist-ami-luttwak-on-how-ai-is-transforming-cyberattacks/'>Wiz chief technologist Ami Luttwak on how AI is transforming cyberattacks</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 14:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>“One of the key things to understand about cybersecurity is that it's a mind game,” Ami Luttwak, chief technologist at cybersecurity firm Wiz, told TechCrunch on a recent episode of Equity. As enterprises rush to embed AI into their workflows — whether through vibe coding, AI agent integration, or new tooling — the attack surface is expanding. AI helps developers ship code faster, but that speed often comes with shortcuts and mistakes, creating new openings for attackers. Wiz, which was acquired by Google earlier this year for $32 billion, conducted tests recently, says Luttwak, and found that a common issue in vibe coded applications was insecure implementation of the authentication — the system that verifies a user's identity and ensures they're not an attacker. “Vibe coding agents do what you say, and if you didn't tell them to build it in the most secure way, it won't.” But developers aren't the only ones using AI to move faster. Attackers are now using vibe coding, prompt-based techniques, and even their own AI agents to launch exploits, he said. “You can actually see the attacker is now using prompts to attack,” Luttwak said. Amid this landscape, attackers are also finding entry points in new AI tools that companies roll out internally to boost efficiency. Luttwak says these integrations can lead to “supply chain attacks.” By compromising a third-party service that has broad access to a company's infrastructure, attackers can then pivot deeper into corporate systems. That's what happened last month when Drift — a startup that sells AI chatbots for sales and marketing — was breached, exposing the Salesforce data of hundreds of enterprise customers like Cloudflare, Palo Alto Networks, and Google. The attackers gained access to tokens, or digital keys, and used them to impersonate the chatbot, query Salesforce data, and move laterally inside customer environments. It means that we as an industry need to move faster.” Luttwak pointed to another major supply chain attack, dubbed “s1ingularity,” in August on Nx, a popular build system for JavaScript developers. The attack compromised thousands of developer tokens and keys, giving attackers access to private GitHub repositories. Luttwak says that despite the threats, this has been an exciting time to be a leader in cybersecurity. Over the last year, Wiz has expanded its capabilities to keep up with the speed of AI-related attacks — and to use AI for its own products. Luttwak said that it's vital for Wiz to fully understand the applications of their customers if the startup is going to help with what he calls “horizontal security.” “We need to understand why you're building it … so I can build the security tool that no one has ever had before, the security tool that understands you,” he said. But Luttwak says enterprises shouldn't just send all of their company, employee, and customer data to “every small SaaS company that has five employees just because they say, ‘Give me all your data, and I will give you amazing AI insights. Of course, those startups need that data if their offering is going to have any value. Luttwak says that means it's incumbent upon them to make sure they're operating like a secure organization from the start. “From day one, you need to think about security and compliance,” he said. “From day one, you need to have a CISO (chief information security officer). The next most important step for startups is to think about architecture, he said. Theresa Loconsolo is an audio producer at TechCrunch focusing on Equity, the network's flagship podcast. You can contact or verify outreach from Theresa by emailing theresa.loconsolo@techcrunch.com. You can contact or verify outreach from Theresa by emailing theresa.loconsolo@techcrunch.com. You can contact or verify outreach from Theresa by emailing theresa.loconsolo@techcrunch.com. Register now and save up to $444.Rates increase when doors open OpenAI launches ChatGPT Pulse to proactively write you morning briefs Tim Chen has quietly become of one the most sought-after solo investors Google isn't kidding around about cost cutting, even slashing its FT subscription</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=45404021'>Privacy Badger is a free browser extension made by EFF to stop spying</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 13:39:03
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>But if I'm currently looking at an auto dealers web site, the odds are pretty good that I'm still interested in buying one.What's wrong with advertisers? Without any real proof, they have bought into this vision of advertising that is illogical, ineffective and simply not true in many cases --- the idea that personal browsing history is a good indicator of the future.In the process, they have surrendered their ad budgets to a "black box" process that they have no insight into or control over and can be easily manipulated against them.So why do I care? Because we *all* pay a price for this. But if I'm currently looking at an auto dealers web site, the odds are pretty good that I'm still interested in buying one.What's wrong with advertisers? Without any real proof, they have bought into this vision of advertising that is illogical, ineffective and simply not true in many cases --- the idea that personal browsing history is a good indicator of the future.In the process, they have surrendered their ad budgets to a "black box" process that they have no insight into or control over and can be easily manipulated against them.So why do I care? Because we *all* pay a price for this. Without any real proof, they have bought into this vision of advertising that is illogical, ineffective and simply not true in many cases --- the idea that personal browsing history is a good indicator of the future.In the process, they have surrendered their ad budgets to a "black box" process that they have no insight into or control over and can be easily manipulated against them.So why do I care? Because we *all* pay a price for this. In the process, they have surrendered their ad budgets to a "black box" process that they have no insight into or control over and can be easily manipulated against them.So why do I care? Because we *all* pay a price for this. Because we *all* pay a price for this. Privacy Badger by itself is an OK ad blocker.Also, you can easily tell Privacy Badger to block sites.Privacy Badger warns you that blocking certain domains, such as Google Tag Manager (otherwise known as Google Backdoor Hostile Javascript Injector) will break some sites. In practice, this seems not to be a problem. I've had Google Tag Manager blocked for years. Also, you can easily tell Privacy Badger to block sites.Privacy Badger warns you that blocking certain domains, such as Google Tag Manager (otherwise known as Google Backdoor Hostile Javascript Injector) will break some sites. In practice, this seems not to be a problem. I've had Google Tag Manager blocked for years. Privacy Badger warns you that blocking certain domains, such as Google Tag Manager (otherwise known as Google Backdoor Hostile Javascript Injector) will break some sites. In practice, this seems not to be a problem. I've had Google Tag Manager blocked for years. no app can patch this 'analog hole' of the gig industry. Whenever we hire someone,  a restaurant to cook our meal, a lawyer to help settle our house purchase,  a plumber to fix the leaky pipe,  we almost never know what we are buying into.So e ask people that have previously had someone do those jobs for them.And here's the rub,  they have no idea whatsoever on the quality of the person being hired,  only that they've not NOTICED any poor results.I've highlighted noticed,  because,  unless the person you ask is qualified to assess the work,  they have no idea on is quality.And this affects us all,  because we use references to guide us on people to hire for jobs, and we have no idea on the quality of the person providing the reference.Do we ask for a reference on the person giving the reference? Heck, businesses will sue you if you put bad feedback on glassdoor.I've even been offered 2 months salary by a business to NOT disparage their (toxic) culture on social media. I've even been offered 2 months salary by a business to NOT disparage their (toxic) culture on social media. My "car guy" has a track record of saving me from over-spending on things that don't matter. I don't have a good enough reason to try someone else.There's a infinite regression in your logic that can only be broken by either:1. trust in the person, or somewhere along the chain of referrals or;2. simply possessing the skill and knowledge to assess the work yourself (but lacking the time, energy, or other resources to do it yourself) Before that, there were classified ads in papers. Those were lightly vetted by the local newspaper. (Like house sitters that don't exist, but are instead getting lists of people that will be out of town.) In some sparser places there might also only be a couple contractors working anyway. Yes, and anecdotally I've heard of better experiences using services that do not appear on the top search results. They already have their business and may not need yours. You're right, they'll find whatever incumbent cleaner instead. A marketing ban is something that all incumbents would love, because they don't need to attract more customers whereas marketing is basically the only way that upstarts can get a foothold. Reputation based platforms are pretty much the only way to go around here. The modern web was designed by predatory middlemen who want a cut of transactions they otherwise have no business being involved in. So... this intuition is wrong.Across... well, basically every category of product... the product which you are most likely to purchase next is the same (or a substitute for or a complement to) the last product you purchased. Anyone who has ever worked in retail analytics will tell you this.Advertisers want to minimize their ad spend, so they always try to sell you first on the product which you have the highest propensity to buy. The ROI is astronomically higher than for contextual ads. (That's why the DMA's prohibition on Facebook's pay-or-consent model, and HN's general cheerleading of it, is such a joke... and that's before you even get into the adverse selection problem of people willing to pay to avoid ads)There are plenty of greedy people in business. Rest assured: If cost of personalized grew to the point that ROI dropped below contextual ads, advertisers would switch to contextual ads in a heartbeat. Across... well, basically every category of product... the product which you are most likely to purchase next is the same (or a substitute for or a complement to) the last product you purchased. Anyone who has ever worked in retail analytics will tell you this.Advertisers want to minimize their ad spend, so they always try to sell you first on the product which you have the highest propensity to buy. The ROI is astronomically higher than for contextual ads. (That's why the DMA's prohibition on Facebook's pay-or-consent model, and HN's general cheerleading of it, is such a joke... and that's before you even get into the adverse selection problem of people willing to pay to avoid ads)There are plenty of greedy people in business. Rest assured: If cost of personalized grew to the point that ROI dropped below contextual ads, advertisers would switch to contextual ads in a heartbeat. The ROI is astronomically higher than for contextual ads. (That's why the DMA's prohibition on Facebook's pay-or-consent model, and HN's general cheerleading of it, is such a joke... and that's before you even get into the adverse selection problem of people willing to pay to avoid ads)There are plenty of greedy people in business. Rest assured: If cost of personalized grew to the point that ROI dropped below contextual ads, advertisers would switch to contextual ads in a heartbeat. (That's why the DMA's prohibition on Facebook's pay-or-consent model, and HN's general cheerleading of it, is such a joke... and that's before you even get into the adverse selection problem of people willing to pay to avoid ads)There are plenty of greedy people in business. Rest assured: If cost of personalized grew to the point that ROI dropped below contextual ads, advertisers would switch to contextual ads in a heartbeat. There are plenty of greedy people in business. Rest assured: If cost of personalized grew to the point that ROI dropped below contextual ads, advertisers would switch to contextual ads in a heartbeat. The level of identification and tracking possible today is scary even across devices. Edit: I'm not familiar with data on context based ads but I'm very skeptical they are significantly better in the general case. They are already used in things where it makes sense like when you're searching for something. The key is remembering we are talking about average people, not nerdy techno anarchists with router level ad blocking and a pavolonian vomit reflex to seeing the word "sponsored". Targeted ads are definitely better for the publisher, but hard to automate (the matchmaking between publishers and advertisers is less automated), but the percentage of ad spend that goes to the publisher is much higher, and the quality of each ad impression is higher.There's some win for targeting on the margins, where there's no good place to buy ads.Also, there's an infinite inventory of targeted ad slots (like invisible windows displayed by malware or redirect spam), which could be better than display ads, where you might not be able to spend your marketing budget, at least in theory. There's some win for targeting on the margins, where there's no good place to buy ads.Also, there's an infinite inventory of targeted ad slots (like invisible windows displayed by malware or redirect spam), which could be better than display ads, where you might not be able to spend your marketing budget, at least in theory. Also, there's an infinite inventory of targeted ad slots (like invisible windows displayed by malware or redirect spam), which could be better than display ads, where you might not be able to spend your marketing budget, at least in theory. Havent almost everyone including MKBHD said youtube ads doesnt give them enough to be used as the only revenue.Contextual ads are more effective. It doesnt first need the shoe data and then later show shoe ads after you started searching for socks. Contextual ads would mean you need a worthy product and having to handle your ad folks yourself. You cannot buy a domain and immediately start showing ads.Behavioural ads breakeven because they sell your data. They could've just started doing it old school and it would have made news open and more privacy friendly. It doesnt first need the shoe data and then later show shoe ads after you started searching for socks. Contextual ads would mean you need a worthy product and having to handle your ad folks yourself. You cannot buy a domain and immediately start showing ads.Behavioural ads breakeven because they sell your data. They could've just started doing it old school and it would have made news open and more privacy friendly. Contextual ads would mean you need a worthy product and having to handle your ad folks yourself. You cannot buy a domain and immediately start showing ads.Behavioural ads breakeven because they sell your data. They could've just started doing it old school and it would have made news open and more privacy friendly. Behavioural ads breakeven because they sell your data. They could've just started doing it old school and it would have made news open and more privacy friendly. They could've just started doing it old school and it would have made news open and more privacy friendly. Channels like MKBHD (and LTT) need more revenue than what they get from YouTube ads because their expenses have greatly increased, particularly staff.You can't automate contextual ads in news media, otherwise you get airline ads next to stories about airplane crashes. People pairing ads with stories increases the labor costs and there's already not enough money being paid for actual journalism to increase the cost of having ads. You can't automate contextual ads in news media, otherwise you get airline ads next to stories about airplane crashes. People pairing ads with stories increases the labor costs and there's already not enough money being paid for actual journalism to increase the cost of having ads. They won't say this, the children in their audience will throw a fit, but tech audiences are stacked with content freeloaders. This is theh same going when you use adwords. Who are these folks doing this "scatter-shot" approach? How do we get some insight into their practices?The major company doing context sensitive advertising nowadays is Amazon. When you search on Amazon, they display relevant "sponsored" products that are clearly labeled as such.So how is Amazon's "context sensitive" advertising business doing? Everyone (except Amazon) just accepts "personalized" as the default --- mainly because there is no credible, large scale, organized, generally available alternative to compare it to. The major company doing context sensitive advertising nowadays is Amazon. When you search on Amazon, they display relevant "sponsored" products that are clearly labeled as such.So how is Amazon's "context sensitive" advertising business doing? Everyone (except Amazon) just accepts "personalized" as the default --- mainly because there is no credible, large scale, organized, generally available alternative to compare it to. So how is Amazon's "context sensitive" advertising business doing? Everyone (except Amazon) just accepts "personalized" as the default --- mainly because there is no credible, large scale, organized, generally available alternative to compare it to. Everyone (except Amazon) just accepts "personalized" as the default --- mainly because there is no credible, large scale, organized, generally available alternative to compare it to. Everyone (except Amazon) just accepts "personalized" as the default --- mainly because there is no credible, large scale, organized, generally available alternative to compare it to. You can easily argue that these "context sensitive" ads are actually personalized ads: They're personalized based on the search query you just made! Of course those context ads are going to have high ROI because they're showing an ad relevant to the thing you're shopping for!When people talk about context ads, they mean "Why doesn't Facebook or the local newspaper use context ads?" Of course those context ads are going to have high ROI because they're showing an ad relevant to the thing you're shopping for!When people talk about context ads, they mean "Why doesn't Facebook or the local newspaper use context ads?" When people talk about context ads, they mean "Why doesn't Facebook or the local newspaper use context ads?" And this number is produced even with the edge case you brought up! Targeting is just that good.Advertising is also not just product advertising, as in, "we would like to purchase this exact product". Advertising spaces are also contested, so, if one brand doesn't buy it, maybe a competitor will. Advertising also increases mindshare - you might not buy another new car of course, but people are still influenced by what they see. Brands are also bolstering their image with ads, regardless if you particularly buy or not. They are associating situations, lifestyles, emotions with their brand.What I'm trying to get at is incentive. Advertising spaces are also contested, so, if one brand doesn't buy it, maybe a competitor will. Advertising also increases mindshare - you might not buy another new car of course, but people are still influenced by what they see. Brands are also bolstering their image with ads, regardless if you particularly buy or not. They are associating situations, lifestyles, emotions with their brand.What I'm trying to get at is incentive. What I'm trying to get at is incentive. The marketing side of the business is very data driven with lots of very intelligent statisticians and scientific testing for ad placement and ad content, etc. I cant accept that the same people that are manipulating my thoughts and desires with algorithmically optimized content never once thought to run hypothesis test on performance of targeted ads based on browsing history.I feel like you are making a bold claim, am I misunderstanding? We'll see that and raise you: “It is difficult to get a man to understand something, when his salary depends on his not understanding it.” (Upton Sinclair) If I can cut my company's ad spend by an order of magnitude and still get the same sales... you really expect me to believe I won't get a fat bonus next year? Can you elaborate what you mean about the "system that generates that signal (inside and outside of Google) is designed to defraud the advertiser (and advertising firms)"?Thanks I do not want to see an unskippable 60 second ad for a skincare product I do not care about whatsoever in the middle of a video about replacing the cambelt on a 90s French hot hatch. I especially don't want that ad to bisect a word or sentence.At least try to show me something that might have some passing relevance to what I'm watching, will you, please? At least try to show me something that might have some passing relevance to what I'm watching, will you, please? *I am not convinced that AdSense is really doing this everywhere, in spite of the need to do so for (UK/EU) GDPR reasons etc once I have told it to. Also, don't try to make me feel guilty for having an "ad blocker". at any rate - not only context aware ads would be better privacy-wise but also probably would be way more lightweight… People who just bought a car are generally upside-down, and will not be looking to trade or buy another anytime soon. The actual reason is that they work better.There's an old saying in the ad biz: "I know I'm wasting half my advertising budget. They let low quality sites “steal” audience impressions from higher quality sites by displaying ads to people that happened to visit both sites.I think personalized ads / algorithmic targeting (and even collecting the datasets that enable it) should be banned. Since most of the internet has been low-effort algorithmic slop for the last twenty years, tracking ads are more popular. They let low quality sites “steal” audience impressions from higher quality sites by displaying ads to people that happened to visit both sites.I think personalized ads / algorithmic targeting (and even collecting the datasets that enable it) should be banned. I think personalized ads / algorithmic targeting (and even collecting the datasets that enable it) should be banned. Your browsing history gives a more reliable base to segment you based on buyer profiles (incl age groups, location, interests), figure out your "intent" and target ads based on it. If you were to, say, read a random "Top 10 cars with highest resale value" article, on its own without historical data it won't be of any use for targeting because they don't know if you're actually a potential buyer in the market or just some teenager passing their time. Showing you those ads will waste their $$ if it were the latter.This isn't in any way an endorsement of their intrusive advertising practices, by the way - I personally have been using ad blockers and aggressively taking every step possible to avoid all online advertisements for more than a decade. This isn't in any way an endorsement of their intrusive advertising practices, by the way - I personally have been using ad blockers and aggressively taking every step possible to avoid all online advertisements for more than a decade. Those trackers, such as Facebook and Google, aren't loaded at all, so they are unaware of the request that was not tracked.What you are advocating is loading those libraries, etc., anyway and allowing them to have their way with your browser session. This will always be less private than not doing it. Even Tor Browser has all sorts of protections from these types of things in place, which you would need far less of if you just blocked these tracking libraries to begin with.Yes, theoretically, my blog or The New York Times could start profiling the missing requests and send them over to Facebook through the back-end, which is what is referred to as 'server-side tracking' in the industry, as far as I know. However, the chances of most websites doing this are slim, as it requires at least some effort on the server side. The way these websites usually do this is by passing along the account information they have on you, such as e-mail addresses, phone numbers, etc. Even if you signed in on some site with Tor, they'd still send those things along if they had gone through this trouble.Ironically, even Tor relies on clearing cookies, disabling JavaScript, and blocking specific requests to protect your identity, not just the origin obfuscation. So, the thing you are claiming makes it easier to track you, and suggesting that Tor is the solution is somewhat at odds. What you are advocating is loading those libraries, etc., anyway and allowing them to have their way with your browser session. This will always be less private than not doing it. Even Tor Browser has all sorts of protections from these types of things in place, which you would need far less of if you just blocked these tracking libraries to begin with.Yes, theoretically, my blog or The New York Times could start profiling the missing requests and send them over to Facebook through the back-end, which is what is referred to as 'server-side tracking' in the industry, as far as I know. However, the chances of most websites doing this are slim, as it requires at least some effort on the server side. The way these websites usually do this is by passing along the account information they have on you, such as e-mail addresses, phone numbers, etc. Even if you signed in on some site with Tor, they'd still send those things along if they had gone through this trouble.Ironically, even Tor relies on clearing cookies, disabling JavaScript, and blocking specific requests to protect your identity, not just the origin obfuscation. So, the thing you are claiming makes it easier to track you, and suggesting that Tor is the solution is somewhat at odds. However, the chances of most websites doing this are slim, as it requires at least some effort on the server side. The way these websites usually do this is by passing along the account information they have on you, such as e-mail addresses, phone numbers, etc. Even if you signed in on some site with Tor, they'd still send those things along if they had gone through this trouble.Ironically, even Tor relies on clearing cookies, disabling JavaScript, and blocking specific requests to protect your identity, not just the origin obfuscation. So, the thing you are claiming makes it easier to track you, and suggesting that Tor is the solution is somewhat at odds. Ironically, even Tor relies on clearing cookies, disabling JavaScript, and blocking specific requests to protect your identity, not just the origin obfuscation. So, the thing you are claiming makes it easier to track you, and suggesting that Tor is the solution is somewhat at odds.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/judge-rules-that-drone-maker-dji-is-affiliated-with-chinas-defense-industry-company-to-stay-on-pentagons-list-of-chinese-military-companies'>Judge rules that drone maker DJI is affiliated with China's defense industry — company to stay on Pentagon's list of Chinese military companies</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 13:01:28
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. DJI claims that it's neither owned nor controlled by the Chinese military, and that it has “lost business deals, been stigmatized as a national security threat, and been banned from contracting with multiple federal government agencies.” Despite this loss, it said that it will continue operating in the U.S. and explore other legal remedies. Although being included in the list is not an outright ban, it makes doing business more difficult in the U.S. and could even lead to further, more drastic actions. In fact, the company narrowly escaped a proposed law that would have prohibited its sales within the United States. However, it must still undergo a security review in 2025 to prove that its products aren't a national security risk. Despite not creating military drones, lawmakers are concerned that, due to the ubiquity of its products in the American market, Beijing could force it to insert a backdoor in its products. China-based DJI isn't the only company that has challenged the U.S. government over its designation as a Chinese military company. It has since appealed the decision and is waiting for word from a higher court. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Jowi Morales is a tech enthusiast with years of experience working in the industry. He's been writing with several tech publications since 2021, where he's been interested in tech hardware and consumer electronics. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York,</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/review/proton-pass-2025/'>Proton Pass Finally Has the Goods to Compete With Other Password Managers</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 12:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>All products featured on WIRED are independently selected by our editors. However, when you buy something through our retail links, we may earn an affiliate commission. It's remarkable how quickly Proton Pass has evolved. The app is a little over two years old, and Proton has quickly moved to transform Pass from a bare-bones browser extension into one of the best password managers on the market. Major updates seem to show up every month or two. Even as I write this review, Proton launched an emergency access feature less than two weeks ago. It has a clear, consistent commitment to updates, combined with the best free password manager plan I've seen and a robust system of apps you can get for a single price. It's a company with a long history when it comes to security and privacy, and those same principles are at play with Pass, from end-to-end encryption to open source applications. Proton Pass gives you a lot of flexibility in what you store in your vault, due in no small part to the fact that Proton gives you a ton of storage space. Every entry supports text fields, two-factor authentication codes, notes, and attachments. You get 10 GB of storage with a paid plan, but Proton shares your storage space across your Proton account. With the Unlimited plan, you have 500 GB of storage. Broadly, there are five categories of entries: logins (including passkeys), aliases, credit cards, notes, and identities. Regardless of whether you choose one of Proton's starting points or start an entry from scratch, everything that falls outside of those five main categories is considered a “custom item," which can make organization a little tricky. I resorted to using vaults as my main method of organization. Proton caps the number of vaults you can create at 50, but I can't imagine a situation where you'd need more than that. Unfortunately, free users have access to just two vaults. With unlimited logins and cross-device sync, there had to be a catch somewhere on the free plan. All products featured on WIRED are independently selected by our editors. You can rename your vaults, but you can also assign them one of a few dozen icons, as well as choose from a handful of color presets. Beyond logins, you can also generate and store email aliases, similar to NordPass. It's a standard feature, even if you don't subscribe. You can set up aliases like that, but Proton allows you to forward emails to multiple addresses, create catch-all addresses, and even reply directly from the web app. Proton automatically creates contacts for everyone who interacts with your alias, and you can block spammy addresses without ever opening your email client. Proton Pass was originally available only as a browser extension, but it now has apps for Windows, macOS, and even Linux, as long as you're on a Fedora- or Debian-based distribution. I mainly used Pass in the browser, not only because it's convenient but also because the extension is available on just about everything—Chromium-based browsers have access, and there are separate extensions for Firefox, Safari, and Brave. The browser app has everything you need, and it works a treat when it comes to password capture and autofill. But outside of that small hiccup, I never encountered an issue with autofill for forms, logins, or credit cards. It'll show you weak passwords, accounts where you can enable 2FA, and critically, accounts that have been victims of a data breach. Pass Monitor is great, but breach notifications have a problem. If you're importing passwords from another app, as I did, and you have different emails, those aren't a part of the monitoring by default. You have to click into breach details and manually add addresses. All products featured on WIRED are independently selected by our editors. Proton includes a short setup process when you first open the app, and dark-web monitoring should be part of it. You can easily overlook manually adding your email and miss breach notifications. The app didn't show any breaches when I first started using it, but after manually adding a burner email for some logins in my account, I found it was involved in seven breaches. This really isn't the type of feature that should be left to chance. That's my only issue with the desktop and web applications, thankfully. There are some useful upsides to these apps. You can unlock your account with a PIN instead of your account password, for example, which makes the 10-minute auto-lock less annoying to deal with. And Proton maintains a history of passwords it generates for two weeks, so you can look back in the event the capture fails and a new login isn't saved to your account. Password managers are always a little spotty on mobile if that's not the primary place you create and store logins. Logins get associated with desktop URLs, and apps often redirect you elsewhere to log in. Proton Pass doesn't solve that problem—it can't—but it nails association. As I logged into apps with autofill, Pass silently associated whatever redirect I got on mobile to the proper login. But even after a week of using Proton Pass, I was no longer stumbling upon pesky login fields. By default, your vault locks on mobile after two minutes, but you can adjust the lock time from immediately up to four hours. Any password manager worth its salt uses end-to-end encryption, and if there's any company that knows a thing about end-to-end encryption, it's Proton. The company has received thousands of court orders over the years and has been unable to hand over data, and it has won challenges to such orders in a Swiss court. Its email service, Proton Mail, has been blocked in Russia for years, and India recently started cracking down on its use, as emails can't be decrypted or tracked. If Proton wants to store user data, lie about its encryption, and cooperate with the government, it's doing a pretty terrible job. All products featured on WIRED are independently selected by our editors. That's important in the context of password managers. It means that data is only ever encrypted or decrypted at rest. And to ensure a data breach wouldn't expose your passwords, Proton has, miraculously, not suffered a major data breach yet. In short, Proton stores your data, but it doesn't have the means to decrypt that data, and that data can't be intercepted and decrypted while it's in transit. Proton Pass doesn't go as far as 1Password with its unique Two Secret Key Derivation, but it's still a secure, zero-knowledge model. Proton also has a stellar track record when it comes to user security and privacy, which is shocking considering how big a cybersecurity target is painted on its back. At first glance, there's one weak point in Proton's security when it comes to Pass: it's tied to your Proton account. It's a hassle, but even in the unlikely event of a breach, and in the even more unlikely event that your Proton password is exposed, you'll still have a layer of security. Thankfully, you don't need to enter two passwords constantly. All products featured on WIRED are independently selected by our editors. On the plus side, Proton Pass is open source. Surprisingly few password managers open source their applications, but Proton is among them. Even with a secure foundation, application bugs can expose user data. Most major password managers have some sort of bug bounty program—as does Proton, offering up to $100,000 for critical flaws—but open source applications make finding those bugs much easier, and they allow security researchers to find bugs before they become a bigger issue. Once again, a public-private key pair is at work when you share items or full vaults with Proton Pass. Unique to Pass, however, is Proton's Key Transparency system. As battle-tested as public-key cryptography is, it's still susceptible to man-in-the-middle attacks if an attacker can spoof a public key. The Key Transparency system stores address keys connected to Proton users before they're hashed and anonymized, and stored on a private blockchain. When sharing with Proton Pass, the public key is checked against this ledger to ensure it's a legitimate user. It couldn't hope to match other password managers two years ago, and now, in some areas, it exceeds even the old guard. It has also taken up the mantle left in the wake of disastrous breaches with LastPass, offering a free, bare-bones password manager with unlimited login storage and cross-device sync. As a paid password manager, Proton Pass still holds up. Between a VPN, encrypted email, 500 GB of storage, and one of the top password managers on the market, it's hard to beat. All products featured on WIRED are independently selected by our editors. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/this-wireless-tech-could-fix-the-most-annoying-thing-about-using-wireless-earbuds-at-home-2000664306'>This Wireless Tech Could Fix the Most Annoying Thing About Using Wireless Earbuds at Home</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-09-28 10:00:04
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Your phone is usually attached to your hip (in terms of the recent iPhone 17's Crossbody Strap, I mean that literally). But in the comfort of your own home when you're trying to unwind and escape your phone with your favorite music, needing to stay in Bluetooth range for your headphones and wireless earbuds can be a little annoying. Qualcomm's audio engineers are trying to solve that issue by seamlessly switching to Wi-Fi if you travel away from your audio source. Sure, that sounds neat, but the tech implies a future where you won't even need any other device nearby to listen to your favorite tunes on your AirPods. The problem this feature hopes to fix is a very niche use case, but it's one that could end up in many next-gen wireless earbuds in the near future. I tested out this feature at Snapdragon Summer in Hawaii (full disclosure: travel and lodging were paid by Qualcomm, and Gizmodo did not guarantee any coverage as a condition of accepting the trip), dubbed XPAN for “Expanded Personal Area Network,” with a pair of nonspecific reference wireless earbuds used by Qualcomm. If you start walking away, they will automatically switch over to Wi-Fi. I walked 30 feet away from the phone and back, and I didn't notice any interruptions in the song playing. A Bluetooth 5.3 connection range is technically close to 33 feet. While that means you won't lose connection walking from one end of the room to the other, intervening walls or—in my case—a crowd of bodies could interrupt that signal. XPAN merely expands the range to encompass everywhere there's a Wi-Fi signal. Although wireless earbuds with the technology will be limited to local Wi-Fi, the technology could potentially allow you to listen to your device from “anywhere in the world” through a Wi-Fi access point. Modern wireless earbuds are already so damn good at cutting down on latency even when streaming high-bitrate lossless audio. Wi-Fi networks should be able to handle the 96kHz speeds necessary for lossless. Qualcomm has talked up Wi-Fi audio connections for the past two years with its previous-gen S7 and S7 Pro platforms. The first wireless earbuds with XPAN built in were the Xiaomi Buds 5 Pro released earlier this year. They support the 96kHz standard, though Bekis promised we should see more wireless earbuds soon enough with current or future S7 chips. Audiophiles would still extol the benefits of lossless and minimum latency. Still, the feature may end up being more useful for taking calls with your wireless earbuds than for listening to music. What that means for music listeners is a future where we connect to Spotify or Apple Music right from our wireless earbuds' or headphones' case, rather than needing to go through a phone. Hell, if you were longing for a device as dedicated to music as your old iPod, a Wi-Fi-enabled pair of wireless earbuds could fit the bill. Subscribe and interact with our community, get up to date with our customised Newsletters and much more. The Pulse Elevate sound like a cash grab, but Sony actually knows how to make solid audio and gaming products. Google and Qualcomm seem to be mixing it up for an option beyond Mac, Windows, and Linux. Qualcomm's Snapdragon 8 Elite Gen 5 will be powering many flagship Android phones next year, and it has a few surprises beyond its silly name. Maybe, but Qualcomm's dealing more blows to Intel while its down.</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            