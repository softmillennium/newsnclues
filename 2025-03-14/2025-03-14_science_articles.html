
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - SCIENCE Article Summaries - 2025-03-14</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
          <a href='2025-03-14_science_articles.csv' title="Download CSV file">SCIENCE <i class="fa fa-download"></i></a>
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/saudi-arabias-role-as-ukraine-war-mediator-advances-gulf-nations-diplomatic-rehabilitation-and-boosts-its-chances-of-a-seat-at-the-table-should-iran-us-talks-resume-252035'>Saudi Arabia’s role as Ukraine war mediator advances Gulf nation’s diplomatic rehabilitation − and boosts its chances of a seat at the table should Iran-US talks resume</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 17:52:42
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Saudi Arabia is 2,000 miles from Ukraine and even more politically distant, so at first glance it might seem like it has nothing to do with the ongoing war there. But the Gulf state has emerged as a key intermediary in the most serious ceasefire negotiations since Russia invaded its neighbor three years ago.

While it is U.S. officials who are undoubtedly leading the efforts for an agreement, it is the Saudi capital of Riyadh that has been staging the crucial talks.

In a flurry of diplomatic activity on March 10, 2025, Saudi Crown Prince Mohammed bin Salman, the country’s top political authority, hosted separate meetings with Ukrainian President Volodymyr Zelenskyy and a U.S. delegation led by Secretary of State Marco Rubio and national security adviser Mike Waltz.

The following day, senior Saudi officials facilitated face-to-face meetings between U.S. and Ukrainian delegations.

The resulting agreement, which is now being mulled in Moscow, is all the more notable given that it followed a diplomatic breakdown just weeks before at the Oval Office between Zelenskyy, President Donald Trump and Vice President JD Vance.

Whether the proposed interim 30-day ceasefire materializes is still uncertain. On March 14, Russian President Vladimir Putin said he agreed with the proposal in principle, but he added that a lot of the details needed to be sorted out.

Should a deal be reached, there is every reason to believe it will be inked in Saudi Arabia, which has hosted not only the latest U.S.-Ukrainian talks but earlier rounds of high-level Russian-U.S. meetings.

But why is a Gulf nation playing mediator in a conflict in Eastern Europe? As an expert on Saudi politics, I believe the answer to that lies in the kingdom’s diplomatic ambitions and its desire to present a more positive image to the world. And in the background is the goal of better positioning the nation in the event of diplomatic maneuvers in its own region, notably in regards to any talks between U.S. and Iran.

The diplomatic convertion of MBS

Saudi Arabia’s growing diplomatic role has been a feature of the kingdom’s foreign policy since 2022.

Crown Prince Mohammed, who that year succeeded his father as prime minister, views Saudi Arabia as the convening power in the Arab and Islamic world.

Accordingly, officials in the kingdom have been directed to lead regional diplomacy over a number of pressing issues, including the conflicts in Gaza and Sudan.

At the same time, Saudis have started the process of reconciliation with Iran, which has long been perceived as the chief regional rival to Saudi influence.

This turn to diplomacy marks a shift away from the confrontational policies adopted by the crown prince during his rise to power in Saudi Arabia between 2015 and 2018. Policies such as Saudi Arabia’s military intervention in Yemen, its blockade of Qatar, the detention of Lebanon’s Prime Minister Saad Hariri and the conversion of the Ritz-Carlton hotel in Riyadh into a makeshift prison all fed an image of the young prince as an impulsive decision-maker. Then in 2018 came the murder of journalist Jamal Khashoggi in the Saudi Consulate in Istanbul.

This approach brought little in the way of stability. Rather, it left the country ensnared in an unwinnable war in Yemen, a fruitless row with Qatar, and diplomatic isolation by Western officials.

A friend to Ukraine and Russia

In regards to the war in Ukraine, Saudi Arabia’s intermediary role is helped by a perception of the kingdom as a neutral nation on the conflict.

Saudi officials, in common with their counterparts in the other Gulf states, have long sought to avoid taking sides in the emerging era of great power competition and strategic rivalry. As such, the kingdom has maintained working relations with both Russia and pro-Western Ukraine since the outbreak of war in Europe.

In 2022, for example, Saudi Arabia and Russia – both leaders of OPEC+ – coordinated oil production cuts to cushion Moscow from the effects of global sanctions the West imposed after it invaded Ukraine. Yet just months later, Saudi Arabia invited Zelenskyy to address an Arab League summit in the Saudi city of Jeddah.

It was a prelude to a 2023 international summit, also in Jeddah, which brought together representatives from 40 countries to discuss the ongoing war.

Despite failing to produce a breakthrough, the meeting illustrated the convening reach of the crown prince and his intention to act as a diplomatic go-between in the Ukraine-Russia war.

Saudi Arabia and neighboring United Arab Emirates later facilitated occasional prisoner exchanges between the two countries – rare diplomatic successes in three years of conflict.

Staging ground for diplomacy

Direct engagement in high-stakes international diplomacy over the largest war in Europe since 1945 is undoubtedly a step up in Saudi ambitions. But the country’s efforts aren’t purely altruistic. Riyadh believes there’s mileage to be gained in such diplomatic endeavors.

The advent of a Trump presidency has fit Saudi desires. Trump has made his desire to be seen as a dealmaker and peacemaker clear, but he needs a neutral venue in which the hard work of diplomacy can flourish.

Just weeks into the new U.S. administration, the Saudi capital hosted the first meeting between a U.S. secretary of state and Russian foreign minister since Russia invaded in 2022.

It yielded an agreement to “re-establish the bilateral relationship” and establish a consultation mechanism to “address irritants” in ties.

The two rounds of dialogue in Riyadh – first with Russia, then Ukraine – have positioned the Saudi leadership firmly in the diplomatic process. It has also gone some way to rehabilitate Mohammed bin Salman’s image.

The sight of the crown prince warmly greeting Zelenskyy contrasted sharply with the images from a fractious White House meeting that went around the world, presenting the crown prince as a statesmanlike figure.

Turning to Tehran

Such positive optics would have seemed inconceivable as recently as 2019, when the crown prince was shunned and then presidential candidate Joe Biden labeled the country a “pariah” state.

Changing this negative global perception of Saudi Arabia is crucial if the kingdom is to attract the tens of millions of visitors that are pivotal to the success of the “giga-projects” – sports, culture and tourism events that the Saudis hope will drive its economy and allow the kingdom to be less economically dependent on fossil fuel exports.

Whereas easing tensions with Iran and supporting Yemen’s fragile truce are about derisking the kingdom’s vulnerability to regional volatility, facilitating diplomacy over Ukraine is a relatively cost-free way to reinforce the changing narratives about Saudi Arabia.

After all, any breakdown in the Russia-U.S.-Ukraine negotiations is unlikely to be blamed on the Saudis.

Indeed, Saudi officials may view their engagement with U.S. officials over Ukraine as the prelude to further diplomatic cooperation. And this will be especially true if Crown Prince Mohammed is able to establish himself as an indispensable partner in the eyes of Trump.

Saudi officials were excluded from the last major talks between Iran and the U.S., which also involved several other major world powers and led to the 2016 Iran nuclear deal. Trump withdrew from the deal shortly after assuming office for the first time in 2017, and U.S.-Iranian relations have been moribund since then.

The U.S. administration has already mooted the idea of a resumption of negotiations with Tehran over its nuclear capabilities.

Placing Saudi Arabia in the middle of any attempts to secure a new nuclear agreement that would replace or supersede that earlier deal would be a high-risk move, given the intensity of feeling on both the U.S. and Iranian sides and the uneasy coexistence between Tehran and Riyadh.

But doing so would give the kingdom what it most desires: a seat at the table.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.livescience.com/technology/artificial-intelligence/chinas-manus-ai-agent-could-be-our-1st-glimpse-at-artificial-general-intelligence'>China's Manus AI 'agent' could be our 1st glimpse at artificial general intelligence</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> livescience&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 17:45:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Introducing Manus: The General AI Agent - YouTube Watch On

Chinese scientists have unveiled an artificial intelligence (AI) "agent" that makes its own decisions without requiring specific instructions from a human operator.

The AI agent, Manus , was developed by Chinese startup Butterfly Effect. Its representatives claim it is the world's first general AI agent — meaning it demonstrates a level of autonomy that current AI models lack. The scientists who created Manus say it shows a potential glimpse of what artificial general intelligence (AGI) may one day be capable of.

This emerging type of AI responds to text prompts, similar to chatbots such as ChatGPT or DeepSeek. However, unlike chatbots, they work on different tasks, without the need for frequent, step-by-step instructions.

Manus isn't available to the general public yet, but a limited distribution of invite codes has given a select few access, sparking a flurry of interest online. Some users appear to have created playable video games from simple prompts, while others have used Manus to design and launch websites.

Related: New AI model converts your thought into full written speech by harnessing your brain's magnetic signals

It's still early days for Manus, however, with some users reporting crashes and other issues such as a tendency to get stuck in an infinite feedback loop. The company is also aware of relatively high failure rates in Manus versus ChatGPT. Chief scientist Peak Ji acknowledged these as part of the teething issues in launching a new tool on the social media platform X .

Reporter Caiwei Chen , who had access to Manus for MIT Technology Review , wrote that the experience was "like collaborating with a highly intelligent and efficient intern." However, Chen also noted that Manus sometimes lacked understanding of what it was supposed to do, made incorrect assumptions and cut corners. "Ultimately, it’s promising but not perfect," Chen wrote.

Sign up for the Live Science daily newsletter now Get the world’s most fascinating discoveries delivered straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors

Is this the dawn of AI agents?

Manus AI is the second Chinese AI tool to send shock waves through the tech industry this year. In January, DeepSeek changed the landscape of AI by achieving similar or better chatbot results than its American competitors for reportedly a fraction of the cost . Manus, on the other hand, could represent the first of an entirely new generation of AI.

Chatbots usually run on a single large language model (LLM), while Manus uses multiple LLMs and other independently operating software to work autonomously on a variety of tasks, MIT Technology Review reported. This is also known as a multi-agent architecture , in which multiple components communicate and collaborate to process tasks.

General AI agents promise to be more human-like than previous AI. (Image credit: Yuichiro Chino via Getty Images)

In a head-to-head between Manus and ChatGPT, the agent will often provide more detailed responses than the chatbot — a claim which the company has reinforced with testing data from the GAIA benchmark . However, Manus also takes a lot longer to provide those responses as it does deeper research, Tom's Guide reported.

In other words, Manus will effectively go its own way and figure out what to do in response to a prompt, rather than relying on step-by-step instructions like a chatbot does. It's designed to start tasks on its own and dynamically adjust its approach along the way, Forbes reported .

Give Manus a single prompt, and it will navigate the web, write code and analyze data for its reply, without requiring further intervention as a conventional LLM-powered chatbot would.

Some examples Manus AI has demonstrated on its website include planning a detailed holiday itinerary, analyzing the stock market and screening job resumes. The difference between this and a tool like ChatGPT is that Manus can break down and complete complex tasks without continuous input. The system works from the cloud, too, so users can close their computers at any time, and Manus will keep working in the background.

The arrival of a general AI agent brings a new wave of ethical questions and considerations surrounding the use of AI. Agents behave more like humans, but unlike humans, they can work fast and continuously — provided they don't crash — and never get tired.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.livescience.com/space/cosmology/could-the-universe-ever-stop-expanding-new-theory-proposes-a-cosmic-off-switch'>Could the universe ever stop expanding? New theory proposes a cosmic 'off switch'</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> livescience&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 16:40:45
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>An illustration of galaxies curving the fabric of space-time in an expanding universe. A new theoretical paper proposes that cosmic expansion may not be a given — it can abruptly reverse and change strength.

Dark energy may have switched directions sometime in the distant past — and this violent transition may explain why cosmological observations aren't adding up, researchers propose in a new paper.

The modern picture of the evolution of the universe is known as ΛCDM (or lambda-CDM), for dark energy (represented by the Greek letter Λ) and cold dark matter. Dark energy is the mysterious force driving the accelerating expansion of the universe, and cold dark matter refers to the mysterious, invisible substance that provides most of the mass of almost every single galaxy.

This model has explained a wide variety of observations, such as the behavior of galaxies and clusters, the growth of large-scale structures , and the appearance of the cosmic microwave background. But in recent years, two troubling tensions have popped up.

One such problem, known as the Hubble tension , is a difference in measuring the present-day expansion rate of the universe, a number known as the Hubble constant. Probes of the distant, early universe seem to be giving estimates significantly lower than probes of the nearby, late universe do.

Related: After 2 years in space, the James Webb telescope has broken cosmology. Can it be fixed?

Related to this issue is the second problem, known as the sigma-8 tension. This is a measure of how clumpy matter is in the universe, and once again, different probes are yielding different results.

A cosmic slowdown

Something in the ΛCDM model has to be wrong, but we're not sure what. One hypothesis is that dark energy might be more dynamic than we originally thought. In the usual ΛCDM picture, dark energy is a cosmological constant. It stays the same through cosmic history.

Sign up for the Live Science daily newsletter now Get the world’s most fascinating discoveries delivered straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors

But in a recent model that's been gaining interest, dark energy changes. And not by a little; it undergoes a complete phase transition, from decelerating the universe to accelerating the universe.

Now, adding a twist to that theory, a research team has explored the possibility that the phase change is even more dramatic. In a paper posted to the preprint server arXiv in February but not yet peer-reviewed, dark energy doesn't just switch signs; it also changes strength, so that it powers an acceleration differently than it powers a deceleration.

Then, the researchers tested their model against a wide variety of observations and datasets. These included the Planck space observatory's measurements of the cosmic microwave background, the oldest light we can see in the universe; a measurement of a phenomenon called the baryon acoustic oscillation, a pattern in the arrangement of galaxies at very large scales; the Pantheon dataset of supernova distance measures; and a weak lensing map that provides details accounting for the effects of dark matter.

They found that the new model alleviated some of the Hubble and sigma-8 tensions, and thus they contend that this approach might be a promising way forward.

That said, the researchers noted that this model isn't exactly grounded in known physics. It's just a toy, a way to explore the physical consequences of a model without knowing the underlying physics. But because it seems like a promising direction, this approach could motivate theorists to come up with mechanisms to explain how dark energy might switch like this.

No matter what, it appears that the universe — especially dark energy — is more complicated than we assumed.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/waiting-lists-crumbling-buildings-staff-burnout-five-years-on-covid-is-still-hurting-the-financial-health-of-the-nhs-251637'>Waiting lists, crumbling buildings, staff burnout: five years on, COVID is still hurting the financial health of the NHS</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 16:10:54
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The NHS was hit hard by COVID. And no amount of appreciative clapping or painted rainbows could distract from the vulnerabilities which were exposed by the pandemic – or the challenges it created.

Some of those challenges – like the staggering backlog in patient care, or the huge mental and physical toll experienced by staff – will take years to overcome.

And anyone compelled to attend a hospital in the UK at the moment can see the evidence at first hand. Wards are very busy and staff are overstretched.

This is part of the legacy of a fast-spreading virus which killed 232,112 people in the UK and left an estimated 2 million suffering from the effects of long-COVID. It demanded urgent action from hospitals and health workers and brought immediate and widespread disruption to routine care, with appointments for elective surgery, cancer screenings and chronic disease management all delayed.

One 2024 study I worked on analysed appointment cancellations for cancer patients during the pandemic, and found that they waited an average of 19 days longer than before for rescheduled appointments. (Mortality rates remained stable though, indicating that the NHS effectively prioritised the most urgent cases.)

This kind of disruption has left the healthcare system facing a monumental backlog, with treatment waiting lists soaring to record levels. According to the British Medical Association, there are over 7.5 million people now on waiting lists (compared to 4.5 million before the pandemic) – and those waiting times are longer.

Cutting this waiting list is apparently one of the prime ministers’s priorities. But there is no easy fix.

The basic infrastructure of the NHS – the buildings, IT equipment, offices – is creaking, with outdated facilities, insufficient beds and a lack of specialised equipment. And one study suggests that capital funding – investment in assets that will be used for more than a year – for NHS trusts in England is down by 21% over the past five years.

This is primarily because the Department of Health and Social Care has been diverting long-term investment funds to cover day-to-day operational costs such as staff salaries and medicines.

Since 2019, £500 million of capital investment has been cancelled or postponed. And while overall NHS budgets have been growing, the increased spending has often been absorbed by inflation, rising demand and the need to address immediate pressures. This leaves little for infrastructure upgrades, new equipment or technological advancements.

The Health Foundation has warned that the lack of a long-term capital funding strategy could further jeopardise patient care in the future. Many NHS facilities no longer meet the needs of a modern health service, with some hospitals requiring complete refurbishment or replacement rather than just repairs.

And of course, treating patients is not just about equipment and buildings. Nurses and doctors are under extreme pressure, facing unprecedented levels of stress, burnout and trauma. A recent survey revealed that one in three NHS doctors are experiencing extreme tiredness, impairing their ability to treat patients effectively.

A similar number said their ability to practice medicine may have been negatively affected by fatigue, with some even reporting cases of patient harm or a near-miss incident.

Stressed NHS

And although the NHS workforce has actually grown over the past five years, it has not been sufficient to reduce waiting lists, deal with growing demand, or improve staff morale. Anxiety, stress and depression accounted for for over 624,300 working days lost in one month last year.

Without a healthy and motivated workforce, the NHS’s recovery efforts will remain severely hampered. Other contributing factors include increased demand for healthcare services, partly due to an ageing population and the growing prevalence of chronic conditions.

To address these challenges, the NHS needs a modernised approach to patient care. Research suggests that technology including telemedicine (online consultations) and AI-driven diagnostics, could streamline services and reduce waiting times.

Other possible steps include the expansion of community diagnostic centres, to ease access to tests, and screenings, to improve efficiency.

Overall, the pandemic has underscored the critical importance of a robust and resilient healthcare system. As the NHS navigates its own path to recovery, it must prioritise both immediate solutions to the backlog crisis and long-term strategies. This will require significant investment, but also a commitment to innovation and the wellbeing of healthcare workers.

The road ahead for the NHS will be tricky, but with the right measures in place, it could emerge stronger and more resilient than ever. The lessons learned from COVID should serve as a catalyst for transformative change, ensuring that the UK’s healthcare system is better prepared to face whatever the future may hold.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/abolishing-nhs-england-could-shift-power-from-the-centre-but-health-service-overhauls-rarely-go-well-252240'>Abolishing NHS England could shift power from the centre – but health service overhauls rarely go well</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 16:10:53
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The UK prime minister, Keir Starmer, has announced plans to abolish NHS England, the organisation that oversees and manages the NHS in England, employing 19,000 people.

He declared he was bringing the NHS back under “democratic control” and cutting unnecessary bureaucracy by moving oversight of the NHS back into the Department of Health and Social Care (DHSC). This will reverse plans put in place by the Conservative-led coalition government in 2013 when it tried to “take the politics out of the NHS” by having NHS England as an independent body.

The NHS is the largest public sector organisation in England, seeing 1.7 million people each day including in patients’ own homes, local GP surgeries, pharmacies and hospitals. It employs 1.7 million people, is funded largely out of general taxation, and has an annual budget of about £190 billion.

The NHS is, however, one of the most centrally organised health systems in the world. This contrasts with many European and other countries where there is typically a national ministry of health to set strategy, with the detail of how this is implemented being left to regional and local councils, health authorities and hospitals.

Some analysts have suggested that the NHS has become even more centrally managed in recent years, but the truth is it has always been held very close by its political masters.

Colin McPherson / Alamy Stock Photo

On the face of it, there are advantages to abolishing NHS England, allowing DHSC to focus on clarifying politicians’ priorities for how and on what NHS funding will be spent. These will include reducing waiting lists for operations, making it easier to get an appointment with a GP, and ensuring that emergency departments can deal quickly with patients without resorting to “corridor care”.

In turn, local NHS organisations such as integrated care boards (who among other things organise GP, dental, pharmacy and optometry services) and NHS trusts (who run hospitals, community, mental health and ambulance services) can concentrate on making sure these policy priorities are put into practice in ways that work best for local communities.

NHS England has a range of other important roles that will need to be reallocated, whether to an expanded DHSC or elsewhere. These include planning the training of healthcare staff, organising vaccination and screening programmes, purchasing medicines, and collating huge amounts of data about NHS activity and performance.

The government has also announced plans to halve staffing in the 42 local integrated care boards, so any move of former NHS England roles to this level will probably only happen if these local boards merge, which now seems likely.

The government appears therefore to have signalled another NHS management “redisorganisation” – something the NHS has suffered on a periodic basis, a consequence of its highly centralised and political nature. Research evidence is clear that management reorganisations struggle to achieve their objectives, causing instead significant distraction away from work to improve services for patients.

In his major review of the NHS for the new Labour government in September 2024, Lord Ara Darzi – a former Labour health minister – highlighted the urgent need for more skilled and effective managers to support NHS staff in restoring and improving the service after years of economic austerity and the challenges of the pandemic. This seems to run counter to recent announcements about “cutting bureaucracy”.

With careful planning, there is, however, potential for the abolition of NHS England to lead to a slimmer DHSC (more akin to some of its European counterparts) with a smaller number of well-resourced and managed integrated care boards who could effectively steer, support and monitor local NHS trusts and primary care services.

In 2002, Alan Milburn, then secretary of state for health in Tony Blair’s government, issued a white paper called Shifting the Balance of Power Within the NHS. Milburn is now a leading figure in the Starmer government’s health team, so it is perhaps not surprising that we have these new plans to slim the policy centre, shift power and decision-making more locally, and enable stronger accountability to politicians and the public.

What is likely to happen?

What will matter as much as what is done is how these changes are made. The government has Lord Darzi’s clear and comprehensive diagnosis of the NHS’s problems. It now needs to prioritise what should be done first and what can wait, and has made a good start on this with its recent planning guidance to the NHS.

What will be much more difficult will be to decide exactly how to reduce and then abolish NHS England – doing this in a way that ensures important roles are moved smoothly to DHSC, integrated care boards and NHS trusts.

History is not encouraging. There is a big risk that NHS managers will find themselves focusing too much attention on handling a major reorganisation when they (and patients) would rather they concentrate on improving services.

The government clearly wants to hold on to setting policy direction for the NHS while letting go of the detail of implementation to local level. But ultimately, it will be held to account by a population impatient for improvements to NHS services.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/keir-starmer-promises-more-democratic-control-of-the-nhs-how-do-other-european-countries-do-it-252313'>Keir Starmer promises more ‘democratic control’ of the NHS – how do other European countries do it?</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 16:10:52
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Sir Keir Starmer, the UK prime minister, announced on March 13 that the government will move to abolish NHS England in the next two years. During this period, the government plans to bring its functions under the UK’s health ministry, with the aim of bringing the health service “into democratic control”. What does this mean, and what difference will it make?

When the NHS was established in 1948, part of the aim was to make the local health problems of patients across the country the concern of the national government. The plan succeeded. Today, the NHS is politically highly important – it matters enormously to patients and the public, and has one of the largest spending budgets in the UK.

At the same time, it is technically difficult to manage, with local needs and opportunities and complex organisation that are hard and sometimes inefficient to manage centrally.

Striking the balance between delivering high-quality patient care and addressing the technical complexity of doing so is a continual challenge for governments. The solution chosen as part of the 2012 health and welfare reforms was to establish NHS England as an organisationally independent government body to provide technical and operational leadership for the NHS – leaving ministers insulated from those day-to-day issues and free to set an overall strategy.

The government’s decision to abolish NHS England marks a change back to direct ministerial grip on the system. This may reflect high public concern about the NHS and pressure on its services, as well as a desire by the recently elected government to exercise more direct control over the health service.

How does this compare to other health systems?

The NHS has long been an unusually centralised system. Although the English NHS covers more than 55 million people, it has historically been run by central government, which this change reinforces.

In contrast, although Spain has a similar NHS-style system, the Spanish health system is run by the 17 regional governments through their departments of health, with the largest covering 8.6 million people.

Europe’s other large national health system, in Italy, now also has a decentralised system. The national government sets the overall principles and benefits, but the actual services are under the control of regional governments.

These decentralised systems strike a different balance between political control and operational management, by bringing them together at a more local level.

If the UK government was to extend its aim of bringing the NHS into democratic control by taking a similar decentralisation approach to other NHS-style systems in Europe, what would this look like?

The NHS already has 42 integrated care systems at the local level. These already work with upper-tier local authorities, such as county councils, and are mostly aligned with their boundaries, but are under the control of central government.

Other countries already decentralise their health systems to similar levels. In Sweden, for example, the 21 counties are responsible for financing, purchasing and providing their health services, under the democratic control of the county councillors. While there might be questions about the capacity of local government in England to take on such a role, experience from elsewhere shows that it should be possible.

Compared with those decentralised systems, the abolition of NHS England is a relatively minor change. It puts ministers more directly in charge of the English NHS, but does not change the basic structure of the service nor its control by central government.

Examples from other countries suggest that if the ambition is to bring the health service more into democratic control, there are options for much more profound change. This would strike a whole new balance between political control and local management.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.livescience.com/planet-earth/rivers-oceans/oceans-heart-is-slowing-down-and-it-will-affect-the-entire-planets-circulation'>Ocean's 'heart' is slowing down — and it will affect the entire planet's circulation</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> livescience&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 16:07:04
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Melting Antarctic ice is slowing Earth's strongest ocean current, according to a new study.

The influx of cold meltwater could slow the Antarctic Circumpolar Current by up to 20% by 2050, researchers reported March 3 in the journal Environmental Research Letters . The slowdown could affect ocean temperatures, sea level rise and Antarctica's ecosystem, the team said.

The Antarctic Circumpolar Current, which swirls clockwise around Antarctica, transports around a billion liters (264 million gallons) of water per second. It keeps warmer water away from the Antarctic Ice Sheet and connects the Atlantic, Pacific, Indian and Southern oceans, providing a pathway for heat exchange between these bodies of water.

Climate change has caused Antarctic ice to melt rapidly in recent years, adding an influx of fresh, cold water to the Southern Ocean. To explore how this influx will affect the Antarctic Circumpolar Current's strength and circulation, Bishakhdatta Gayen , a fluid mechanist at the University of Melbourne in Australia, and his colleagues used Australia's fastest supercomputer and climate simulator to model interactions between the ocean and the ice sheet.

Related: Are Atlantic Ocean currents weakening? A new study finds no, but other experts aren't so sure.

Fresh, cold meltwater likely weakens the current, the team found. The meltwater dilutes the surrounding seawater and slows convection between surface water and deep water near the ice sheet. Over time, the deep Southern Ocean will warm as convection brings less cold water from the surface. Meltwater also makes its way farther north before sinking. Together, these changes affect the density profile of the world's oceans, which drives the slowdown.

Such a slowdown could allow more warm water to reach the Antarctic Ice Sheet, thereby exacerbating the melting that's already been observed. In addition to contributing to sea level rise, this could add even more meltwater to the Southern Ocean and weaken the Antarctic Circumpolar Current further.

Sign up for the Live Science daily newsletter now Get the world’s most fascinating discoveries delivered straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors

The Antarctic Circumpolar Current also acts as a barrier against invasive species by directing non-native plants — and any animals hitching a ride on them — away from the continent. If the current slows or weakens, this barrier could become less effective.

"It's like a merry-go-round. It keeps on moving around and around, so it takes a longer time to come back to Antarctica," Gayen said. "If it slows down, what will happen is, things can migrate very quickly to the Antarctic coastline."

It's difficult to say when we'll start to feel the effects — if we haven't started feeling them already. The Antarctic Circumpolar Current hasn't been monitored very long because it's in such a remote location, Gayen told Live Science. To better differentiate warming-induced changes from baseline conditions, "we need a long-term record," he said.

The effects of the slowdown will be felt even in other oceans. "This is where the ocean heart sits," Gayen said. "If something stops there, or something different is happening, it's going to impact each and every ocean circulation."

Antarctica quiz: Test your knowledge on Earth's frozen continent</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.livescience.com/space/the-moon/blood-moon-total-lunar-eclipse-stunning-photos-of-our-celestial-neighbor-turning-red-over-the-americas'>'Blood moon' total lunar eclipse: Stunning photos of our celestial neighbor turning red over the Americas</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> livescience&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 15:52:44
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The "blood moon" appears during a total lunar eclipse. The photo was taken from Austin, Texas on March 14.

A "blood moon" was visible from Earth last night, marking the first total lunar eclipse since 2022.

A total lunar eclipse occurs when a full moon passes directly through Earth 's shadow, casting our planet's natural satellite in a reddish, blood-like hue — often called a blood moon .

Skywatchers across the Americas snapped photographs of this unusual phenomenon as the moon completed its lunar phase on Thursday night and into Friday morning (March 13 to 14).

The 'blood moon' hovering above the Statue of Liberty in New York. (Image credit: Gary Hershorn via Getty Images)

In North America, one photographer captured the "blood moon" rising over the Statue of Liberty in New York, while another caught it peaking out of the clouds above the Golden Gate Bridge in San Francisco.

Related: Full moons of 2025: When is the next full moon?

The 'blood moon' hovering above San Francisco. (Image credit: Tayfun Coskun/Anadolu via Getty Images)

Further south, photos revealed the moon passing by the Little Prince monument in El Salvador and the Young Woman of Amajac statue in Mexico City.

The 'blood moon' passing over the Little Prince monument in San Salvador, El Salvador. (Image credit: MARVIN RECINOS/AFP via Getty Images)

A lunar eclipse is the opposite of a solar eclipse , when the moon slides between Earth and the sun. During a lunar eclipse, the moon travels behind Earth relative to the position of the sun, meaning the satellite is cast in shadow.

Sign up for the Live Science daily newsletter now Get the world’s most fascinating discoveries delivered straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors

The 'blood moon' over the "Young Woman of Amajac" monument in Mexico City. (Image credit: YURI CORTEZ/AFP via Getty Images)

The moon is still visible during this lunar phase because some light from the sun refracts through Earth's atmosphere and hits the satellite before reflecting back to the surface of our planet facing the moon. The sun projects a spectrum of different colors in its light — the seven colors of the rainbow, plus infrared and ultraviolet light. However, particles in Earth's atmosphere scatter blues and other short-wavelength light, while allowing the longer-wavelength oranges and reds to pass through — similar to a sunset or sunrise — and then splash onto the moon.

Not every full moon results in a lunar eclipse. The event only happens when the moon is perfectly aligned behind our planet. If that alignment is slightly off, then the sun's light can still directly reach some of the moon — meaning it's a partial eclipse.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.livescience.com/planet-earth/fossils/refuge-from-the-worst-mass-extinction-in-earths-history-discovered-fossilized-in-china'>Refuge from the worst mass extinction in Earth's history discovered fossilized in China</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> livescience&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 14:49:41
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The mass extinction that killed 80% of life on Earth 250 million years ago may not have been quite so disastrous for plants, new fossils hint. Scientists have identified a refuge in China where it seems that plants weathered the planet's worst die-off.

The end-Permian mass extinction, also known as the "Great Dying," took place 251.9 million years ago. At that time, the supercontinent Pangea was in the process of breaking up, but all land on Earth was still largely clustered together, with the newly formed continents separated by shallow seas. An enormous eruption from a volcanic system called the Siberian Traps seem to have pushed carbon dioxide levels to extremes: A 2021 study estimated that atmospheric CO2 got as high as 2,500 parts per million (ppm) in this period, compared with current levels of 425 ppm. This caused global warming and ocean acidification, leading to a massive collapse of the ocean ecosystem.

The situation on land is far hazier. Only a handful of places around the world have rock layers containing fossils from land ecosystems at the end of the Permian and beginning of the Triassic.

A new study of one of these spots — located in what is now northeastern China —revealed a refuge where the ecosystem remained relatively healthy despite the Great Dying. In this place, seed-producing gymnosperm forests continued to grow, complemented by spore-producing ferns.

"At least in this place, we don't see mass extinction of plants," study co-author Wan Yang , a professor of geology and geophysics at the Missouri University of Science and Technology, told Live Science.

The finding, published Wednesday (March 12) in the journal Science Advances , adds weight to the idea that the Great Dying was more complicated on land than in the seas, Yang said.

A fossilized conifer trunk from the end-Permian mass extinction uncovered in what is now northeastern China. (Image credit: NIGPAS)

The great changover?

Yang and his colleagues looked at rock layers in Xinjiang that span the mass extinction event.

Sign up for the Live Science daily newsletter now Get the world’s most fascinating discoveries delivered straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors

A major advantage of this now-desert site is that the rocks include layers of ash that hold tiny crystals called zircons. The zircons include radioactive elements — lead and uranium — that gradually decay, which enables researchers to determine how long it has been since the crystals formed. This means the researchers can more accurately date the rock layers here than they can at other sites.

Some of these layers also hold fossil spores and pollen. These fossils reveal that there wasn't a massive die-off and repopulation but a slow changeover of species, Yang said.

This is consistent with other evidence from Africa and Argentina, where plant populations seemed to have shifted gradually rather than dying off dramatically and then repopulating, said Josefina Bodnar , a paleobotanist at the National University of La Plata in Argentina who was not involved in the research.

Land plants "have a lot of adaptations that allow them to survive this extinction," Bodnar told Live Science. "For example, [they have] subterranean structures, roots or stems, that can survive perhaps hundreds of years." Seeds can also persist a long time, she added.

Tetrapod skeletal fossils dating to approximately 150,000 years before the end-Permian mass extinction (Image credit: NIGPAS)

This survival may have been particularly possible at humid, high-latitude regions. The site in Xinjiang was once dotted with lakes and rivers, a few hundred miles from the coast. Other places where plant refuges have been found, such as Argentina, were also high-latitude in the Permian, far from the equator where temperatures were the hottest.

Yang and his colleagues found that during the late Permian and early Triassic, the climate became a bit drier in what is now Xinjiang — but not enough to cause deforestation.

This may have been a consequence of location, said Devin Hoffman , a researcher in paleontology at University College London who was not involved in the new study. Marine animals had no escape from global ocean acidification. But climate change on land wasn't uniform. The impact would have been most pronounced in the center of Pangea, which was a vast desert.

This means that in more temperate regions on land, survival could have been possible, Hoffman told Live Science. "You essentially have everything being pushed toward the poles and towards the coast, but on land you're able to escape some of the effects," he said.

Now an arid desert, the region the fossils were found would've been a humid forest 250 million years ago. (Image credit: NIGPAS)

The planet's memory

These findings have led to some debate over whether the greatest mass extinction ever deserves the moniker on land. "I will call it a crisis on land. I will not call it an extinction," said Robert Gastaldo , an emeritus professor of Geology at Colby College who was not involved in the new study, but who has collaborated with Yang in the past.

The end-Permian extinction is particularly interesting to scientists because it was driven by greenhouse gases, much like climate change today. The situation was far more extreme then: The polar ice caps melted completely — a situation that would cause sea levels to rise a staggering 230 feet (70 meters) today.

But humans may be nearly as deadly as giant volcanoes. A 2020 study , for example, found that a smaller extinction event at the end of the Triassic (201 million years ago) was driven by greenhouse gas pulses from volcanoes that were on a similar scale to what humans are expected to emit by the end of this century. Studying these ancient catastrophes can give us a sense of what to expect under atmospheric carbon dioxide levels people have never experienced, Gastaldo said.

"The planet has experienced it," he said. "The planet's memory is in the rock record. And we can learn from the rock record what happens to our planet under these extreme conditions."</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.livescience.com/health/heart-circulation/how-do-fitness-trackers-measure-your-heart-rate'>How do fitness trackers measure your heart rate?</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> livescience&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 14:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Heart rate tracking is increasingly common among fitness enthusiasts, and understandably so. Whether it is a rugged outdoor smartwatch or a discreet smart ring, smart wearables can help you determine if you exercised hard enough, rested well during sleep or stressed too much during the day — simply by listening to your heartbeat.

Some of the best fitness trackers can even use machine learning to give you detailed exercise recommendations based on how your health metrics change over time — not to mention that smart wearables can be invaluable tools for endurance athletes. But how do fitness trackers measure your heart rate, exactly? And how accurate are these measurements? We asked the experts.

Most fitness watches and smart rings depend on a technique called photoplethysmography (PPG). While its name may sound scarily complex, this technology is based on a relatively simple concept — light absorption by the body tissues.

How does photoplethysmography work?

PPG uses optical sensors that detect heart rate by measuring changes in the volume of blood flowing through tiny blood vessels in the skin and underlying connective tissue, Dr. Peter Sogaard , professor of cardiology at Aalborg University in Denmark and chief medical officer at VentriJect , a company which has developed a novel device for measuring cardiorespiratory fitness, told Live Science by email.

With each heartbeat, the heart muscle contracts and relaxes, to force the next portion of blood into circulation. Contracting causes a temporary spike in blood volume and increased pressure on the artery walls, and it is often referred to as the systolic phase of the cardiac cycle. When the heart relaxes between beats, the blood flow decreases — this is known as the diastolic phase. PPG sensors measure these changes in blood volume and pulse pressure (the difference between systolic and diastolic pressure), and then convert these metrics into heart rate measurements, Sogaard said.

Fitness trackers detect heart rate by measuring changes in blood volume, which is exactly what we do when we check our pulse. (Image credit: Getty Images)

PPG sensors detect these changes in blood movement by emitting light at specific wavelengths into the skin. Blood components like hemoglobin, the protein in red blood cells, absorb some of that light. The tracker's photodetector then measures the amount of light reflected back. The more light absorbed by the blood, the higher its volume in the blood vessels — and this is what fitness trackers interpret as a heartbeat, Sogaard said.

"The most commonly used light sources are infrared and green LED," Sogaard said. That is because these wavelengths of light tend to be the most effective at penetrating the skin tissue, according to a 2022 review published in the Frontiers of Physiology . Generally, the accuracy of PPG increases with the light wavelength, the review authors noted. Some optical sensors even combine several wavelengths to improve accuracy .

That is the theory. But how accurate are optical sensors in practice? The answer is less clear.

How accurate is photoplethysmography?

"Multiple factors can affect the accuracy of PPG, from tracker placement and body temperature to skin thickness, motion artifact [distortions caused by movement] and cardiovascular disorders like arrhythmia and peripheral vascular disease [a condition in which the arteries outside of the brain and the heart become blocked or narrowed]," Dr. Masaki Nakamura , a cardiothoracic surgeon at Baptist Health Miami Cardiac & Vascular Institute, told Live Science by email.

For example, optical sensors tend to provide more reliable heart rate measurements during rest and sleep than they do during exercise, according to a 2020 meta-analysis in the Journal of Sports Sciences . Scientists compiled 44 studies that compared the accuracy of PPG fitness to more precise ECG (electrocardiogram) and chest-strap heart rate monitors and found that the biggest discrepancies could be observed with weightlifting, cycling and other high-intensity sports. While most modern fitness trackers use accelerometer-based algorithms to account for rapid movements, motion artifacts can still affect their tracking accuracy.

Rapid movements can decrease the accuracy of optical sensors. (Image credit: Getty Images)

Skin contact is another factor that can have an impact on PPG measurements, Sogaard said. For example, a device that is too loose or too tight will not allow the optical sensors to get a good reading. Skin temperature can also interfere with PPG. "If the patient has a low temperature, vessels are contracted and measurements become inaccurate," Sogaard said.

Moreover, optical sensors may struggle with detecting heart rate in people with darker skin tones or tattoos. That is because both melanin, the dark pigment in the skin, and tattoo ink can absorb light and reduce the amount of light reflected back to the tracker, according to a 2023 review published in the Journal of Racial and Ethnic Health Disparities .

People with obesity may also struggle with obtaining accurate heart rate measurements. Excess body fat can lead to changes in skin thickness and blood ﬂow, which is why it may affect the accuracy of optical sensors, according to a 2021 review published in the journal Biosensors . The good news is that scientists are working on developing new technologies that would make PPG more accessible for these population groups.

Darker skin tones and tattoos may interfere with optical sensors and lead to inaccurate heart rate measurements. (Image credit: Getty Images)

While not without limitations, PPG fitness trackers can be useful for monitoring heart rate in people with certain cardiovascular conditions, according to Nakamura. "Continuous heart rate and blood pressure monitoring can be crucial for cardiac patients to prevent future events like a heart attack, stroke or acute heart failure. The current industry gold standards of blood pressure and heart rate assessment are the manual sphygmomanometer (BP cuff) and the electrocardiogram. However, both these exams can only be measured intermittently and can be affected by factors such as white coat syndrome [a condition when a person's blood pressure is high only when measured in a health care setting], caffeine or stress," Nakamura said.

That said, experts agree that PPG-based heart rate readings should never be regarded as a substitute for clinically validated tests conducted by healthcare professionals.

This article is for informational purposes only and is not meant to offer medical advice.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/the-government-has-revealed-its-plans-to-get-britain-building-again-some-of-them-might-just-work-252231'>The government has revealed its plans to get Britain building again. Some of them might just work</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 13:58:13
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The UK government has published its planning and infrastructure bill, a cornerstone of its strategy for growth. The bill aims to “get Britain building again and deliver economic growth” and includes the hugely ambitious target of building 1.5 million homes in England over this parliament.

The bill is ambitious in scope – 160 pages long and very technical. But what does it promise exactly?

On infrastructure, it outlines reforms to limit vexatious repeat use of judicial review to block development. There are also some measures for a stronger electricity grid to ease the move towards renewable energy. While the plan to reward people living near new pylons with £250 off their bills grabbed headlines, just as important are measures for energy storage to level out peaks in demand and supply.

On the planning side, planning departments will be allowed to charge more to those making applications. This should speed up decisions by funding more planning officer roles. But there are no measures to increase funding for drawing up local plans. This is important because councils often fall behind schedule in producing these. And where there is no up-to-date plan, there is a danger that developers will push through controversial proposals.

The bill also provides for more decisions to be delegated to planning officials rather than planning committees – this means council staff rather than elected representatives. This already happens for smaller planning applications, so is not entirely new. But it does raise concerns about democratic scrutiny.

The government argues that local democracy will not be undermined, as planning officers will be making their decisions in the context of democratically approved local plans as well as national legislation. But this could be misleading, unless planning authorities have the funds to update local plans regularly.

There are also changes to existing development corporation legislation, to support the building of new towns. Particularly welcome is the responsibility on development corporations – government organisations dealing with urban development – to consider climate change and design quality. This is in order to hit net-zero targets and avoid cookie-cutter housing estates.

Other measures are aimed at ensuring appropriate infrastructure is built to serve these new towns.

Read more: Why building new towns isn't the answer to the UK's housing crisis

There are changes planned too on when compulsory purchase orders can be used to buy sites that are broadly to be used for the public good. This could be for affordable homes, health or education facilities, for instance. It would work by reducing payments to the actual value of the land rather than its “hope value” (when landholders hold out for price rises once planning permission is granted).

There is also a commitment to creating a nature restoration fund, which the government hopes will overcome some of the delays to approving new housing caused by potential threats to wildlife.

The fund will aim to unblock development in general rather than specific sites, as happens at the moment, and will pool contributions from developers to fund nature recovery. Where there are concerns for wildlife, experts will develop a long-term mitigation plan that will be paid for by the fund while allowing the development to go ahead in the meantime.

Will it work?

As a professor of urban and environmental planning, the question for me is will the bill encourage development to progress more speedily? Almost certainly – probably mostly in terms of bringing forward improvements to critical national infrastructure schemes such as the electric grid. For residential development, some incremental speeding up is likely as developers crave certainty in planning decisions.

But on their own, these measures are unlikely to be enough to provide the 1.5 million new homes set out in the government’s target. They offer nothing to tackle critical bottlenecks in terms of both labour and materials. It is also difficult to see the target being met without much more government involvement – by building social housing in particular.

Will the bill result in better quality development? There is surprisingly little in the plans about improving design quality, other than in development corporation areas. This is disappointing, and a missed opportunity to ensure that developers raise their game in residential building and neighbourhood quality.

And might it override local democracy? Arguably yes, but in practice not as much as some critics might argue. Most of the reforms are finessing existing practices, such as delegated powers to planning officers. Much depends on what the national government guidance turns out to be.

The biggest concern is that it might increase invisible political pressures on planning officers by councillors and senior officials. It would have been good to have seen more measures to protect their independence and professional judgement.

Hopefully the bill will speed up delivery of nationally important schemes for critical infrastructure. This means things like modernising the electricity grid and removing repeated use of judicial review to block a development. These elements should create jobs sooner and support economic growth.

Where the bill will make absolutely no difference is in improving living standards for people with older homes. This bill is focused on new builds and has little to offer those hoping for support in retrofitting ageing housing stock with more energy-efficient features or creating green spaces in areas where new development is increasingly in demand.

Despite some of the ministerial bluster about removing red tape, much of the content of this bill is not about removing planning regulations. It is much more about improving them. Some measures will work better than others, but overall, given the government’s electoral mandate to deliver growth and protect the environment, this is a reasonable balancing act.

It’s unlikely to deliver much growth in its own right, but as an enabler of growth, it is promising. More worrying is whether it will lead to poor-quality housing built at pace and massive scale to inadequate energy-efficiency and design standards. This would fail to deliver on net-zero and biodiversity ambitions. It is very much a minor win for facilitating growth, but for nature it is nothing more than maintaining the status quo.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/cuts-and-caps-to-benefits-have-always-harmed-people-not-helped-them-into-work-252110'>Cuts and caps to benefits have always harmed people, not helped them into work</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 13:37:18
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Keir Starmer’s government is expected to announce a host of cuts to sickness and disability support in the coming days. The UK’s ageing and increasingly unwell population has led to what has been described as “unsustainable” and “indefensible” spending on benefits.

As researchers of poverty and welfare reform, we find it both shocking and sadly unsurprising that, after more than a decade of cuts to social security, the government seems to have once again decided that austerity is the answer to the economic pressures they are facing.

We have spent many years documenting the real harms created by reforms to social security. It was disappointing to hear Starmer describe Britain’s social security system as an expensive way to “trap” people on welfare, rather than helping them find work.

The expected proposals are intended to incentivise people into work, by reducing the generosity of support offered to people claiming disability-related benefits. But in reality, many of the measures already implemented to reduce spending by cutting or capping benefits have pushed people further away from the labour market.

The relationship between welfare and work is more complex than it first appears. Around 37% of people on universal credit are currently in work.

Approximately 23% of those out of work are engaging with advisers whose job is to support them back into the labour market. The majority of the rest of universal credit claimants are people who are not expected to be in work – often people who have health challenges that make it difficult for them to work most jobs.

The UK’s social security payments cover a much smaller proportion of the average wage than most other countries in Europe.

A single person’s allowance on universal credit is £393.45 per month if they are 25 or over, while under-25s receive £311.68. This averages out at less than £100 a week to meet all essential living costs, bar support with housing.

Disabled people received additional support in the form of personal independence payments (Pip) or disability living allowance if you live in England, Wales or Northern Ireland, and adult or child disability payments in Scotland.

This support is designed to help people meet the additional costs that come with disabilities and long-term health conditions. It is not means-tested, and is available to people in employment as well as those not currently working.

Ministers are expected to make it more difficult to access Pip, freezing its value so this does not rise with inflation, and to reduce the amount of universal credit received by those judged unable to work. These proposals are likely to face strong opposition from many Labour MPs.

Want more politics coverage from academic experts? Every week, we bring you informed analysis of developments in government and fact check the claims being made.



Sign up for our weekly politics newsletter, delivered every Friday.

Currently, if people are not able to engage in paid work for long periods, they are entitled to an additional payment through universal credit. This amount – equivalent to approximately £400 a month – could go down. The problem is that this is already not enough to live on, and often necessitates going without essentials, such as food or electricity.

Families with dependent children receive additional support through child elements of universal credit, and through child benefit. But this support is subject to caps – the controversial and poverty-producing two-child limit, and the benefit cap, which restricts the support any household can receive where no one is working or claiming disability benefits.

Our research has shown that these restrictions do not work. The two-child limit is not helping families get into work, and nor is it affecting whether families have more children.

The benefit cap harms mental health, pushes people deep into poverty, and increases economic inactivity. Both policies are punitive and, in our view, need to be removed.

Other reforms to disability-related social security have left people hungry, pushed people into economic inactivity, increased depression, and may have even raised the suicide rate.

Getting Britain working?

The government is trying to solve the wrong problem. They are focusing on those who are out of work, when it is increasingly clear that one big reason people with disabilities are not in employment is because work environments have fewer roles they can fill.

While spending on disability-related support has gone up in recent years, the overall welfare bill has not. On top of that, the proportion of people who are not in work and who are claiming disability-related social security is actually about the same as it has been for the last 40 years. Indeed, the fact it is so low, given population ageing, could be read as good news.

There have also been wider changes in the labour market. There has been a rapid decline in “light work”, like lift attendants, cinema ushers, or low-physical exertion roles in factories. As work environments have become more intense, people with disabilities have found it increasingly difficult to stay in work.

So, what would work to entice more people into work? The truth is we know far more about what does not work than what does.

The best evidence we have right now suggests that making it more difficult to claim social security and placing more strenuous work-search requirements on claimants will simply push people with poor health (particularly mental ill-health) further away from the labour market.

The welfare narrative

Behind the cuts currently being trailed is a popular but ill-founded logic which views social security as the cause of the country’s economic woes. Welfare itself is seen as the problem, with whole generations supposedly left parked on what is depicted as too-easy-to-claim and too-generous support.

But this narrative grossly misrepresents what it’s actually like to try and claim social security. It is, in fact, notoriously complex. Often, this complexity is intentional.

Making accessing social security difficult is not necessarily (or always) about meanness, but this “nasty strategy” is a product of a system that assumes that many people are not eligible for the support they claim.

The system has always assessed eligibility for benefits, but the way these assessments have been done in recent years has often been experienced as degrading and dehumanising. On the flip side, some have claimed that people are not being assessed regularly enough, and suggest that some people who have claimed benefits in the past may now be fit to work.

Where this is true is unclear, but the failure to reassess is also a product of cuts to this system – so taking more money out will not address this problem either.

Britain’s social security system has been stripped to the bones: it provides neither security nor enough support to those who receive it, and is ripe for reform. But the reform required is not of the type Labour is proposing, which will succeed only in further decimating what little remains of our social security safety net.

This article was co-published with LSE Blogs at the London School of Economics.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.livescience.com/archaeology/the-most-shameful-form-of-execution-han-warriors-found-dismembered-in-2-100-year-old-mass-grave-in-mongolia'>'The most shameful form of execution': Han warriors found dismembered in 2,100-year-old mass grave in Mongolia</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> livescience&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 13:28:34
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>An ancient mass grave excavated in southern Mongolia contains the bodies of dismembered Han warriors who fought the nomadic Xiongnu people in the second century B.C., a chemical analysis reveals.

The discovery adds new information about soldiers' lives and their gruesome deaths to a significant period in Chinese history .

"Execution by dismemberment was the most shameful form of execution," study co-author Alexey Kovalev , a researcher at the Institute of Archaeology of the Russian Academy of Sciences, told Live Science in an email. "It was done by enemies so that the souls of these people could never be reborn."

Kovalev and a team of researchers studied more than two dozen complete and partial skeletons recovered from a mass grave at the archaeological site of Bayanbulag, a fortress built by the Han Empire in 104 B.C. just north of the Great Wall of China to protect against the encroaching Xiongnu Empire.

In a study published online last month in the Journal of Archaeological Science , the researchers used genomic and isotope analyses to figure out who was buried in the grave and where they came from.

Most of the bodies were piled up in a layer in the middle of a pit, the researchers found, which was initially the result of clay mining before it was turned into a makeshift mass grave. They identified a total of 17 skulls, all of which were from adult men. Most of the skeletons also showed signs of dismemberment, decapitation or amputation by sword, and at least two men were buried in a kneeling position.

Related: Ancient DNA reveals mysterious origins of the Huns who sacked Rome

Sign up for the Live Science daily newsletter now Get the world’s most fascinating discoveries delivered straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors

Aerial view of the excavation at the Bayanbulag archaeological site in Mongolia. (Image credit: Ma et al. / Journal of Archaeological Science / CC BY-NC 4.0

Ancient DNA analysis of 14 of the skeletons revealed that the people were more genetically similar to present-day Han and northern Chinese people rather than to the Xiongnu and other ancient Siberians. Similarly, strontium isotope analysis — which measures variations in the element to reveal where a person grew up — of the skeletons showed that the men came to Bayanbulug from elsewhere, presumably as soldiers who directly participated in a battle.

The Han-Xiongnu Wars were fought over the course of two centuries (133 B.C. to A.D. 89). Battles between the Chinese civilization and the nomadic Xiongnu erupted on the Mongolian Plateau, and the northern Chinese built fortifications against the Xiongnu incursion, some of which were eventually incorporated into the Great Wall. But this is the first study to examine a grave of Han soldiers killed by the enemy and buried by their comrades, the researchers wrote.

"It is significant that all the small pieces of severed arms and legs, severed heads and other pieces of human bodies were collected for burial," Kovalev said. "According to the beliefs of the Chinese, it is necessary to bury the body of the deceased in full integrity. Those who buried these soldiers tried to make them feel good in the afterlife."

But not everyone could be buried intact. One man was decapitated, but his head was never found; presumably, it was taken away by the Xiongnu as proof of victory over the Han. "Who exactly killed the Han soldiers buried in the mass grave, we can only guess based on the context," Kovalev said.

Michael Rivera , a bioarchaeologist at the University of Hong Kong who was not involved in the study, told Live Science by email that the research impressively combines historical context with genetic, archaeological and isotopic analyses.

"The individuals in this burial were a diverse group of men from across Northeast Asia fighting in this conflict," Rivera said, and "we can see which side of the battle these individuals represented."

Further work needs to be done to fully understand the Bayanbulag mass grave, Kovalev said, particularly in the absence of information about funeral customs for ordinary people in this time period. "Now we are studying such a grave for the first time, and for the first time, we can reconstruct this ritual," he said.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.livescience.com/planet-earth/weather/mount-washington-home-to-the-worlds-worst-weather-with-record-wind-speeds-of-231-mph'>Mount Washington: Home to 'the world's worst weather' with record wind speeds of 231 mph</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> livescience&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 13:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>QUICK FACTS Name: Mount Washington Location: New Hampshire Coordinates: 44.270631129317565, -71.30324713195401 Why it's incredible: The mountain has some of the wildest weather on Earth.

Mount Washington is the tallest peak in the Northeast. The mountain is famous for attracting extreme weather, with winds that exceed the force of a hurricane more than 100 days per year.

The mountain is home to "the world's worst weather" for three main reasons. Firstly, at 6,288 feet (1,917 meters) tall, it is the highest mountain in New England. Winds pick up speed when they can blow unobstructed, and the mountain is directly exposed to winds from the west that travel for hundreds of miles without obstruction. The closest mountains of a similar height to Mount Washington along this westerly windpath are the Black Hills of South Dakota about 1,600 miles (2,500 kilometers) away, according to the Mount Washington Observatory .

Not only do these winds hit Mount Washington at full speed but they are also siphoned toward the peak by the surrounding landscape. The mountains to the west of Mount Washington form a 75-mile-wide (120 km) funnel that channels westerly winds toward the mountain, accelerating already-fast winds until they reach breakneck speeds, according to the observatory.

Finally, Mount Washington sits on the confluence of three major storm tracks. Storms hit the summit every three days on average in the winter, bringing high winds and huge amounts of precipitation, according to the observatory. Record levels of precipitation for Mount Washington were measured in 1969, when 4.1 feet (1.3 m) of snow fell within 24 hours.

Related: Record spike in earthquakes at Washington's 'high threat' volcano sends researchers scrambling for answers

As a result of its unique position, Mount Washington is a contender for the world's fastest recorded wind speed . On "calm" summer days, instruments on Mount Washington's summit record wind speeds of 40 mph (65 km/h). But when storms roll in, these winds can whip up gusts exceeding 100 mph (160 km/h).

In the midst of making sure instruments were working well, the summit crew took some time to show us (safely) what 100mph winds looked like... and had some fun doing it. Tune in tonight at 5pm for the weekend's Higher Summits Forecast on Facebook Live. pic.twitter.com/6TSShijLgkMarch 7, 2025

On April 12, 1934, instruments at the summit measured a record wind speed of 231 mph (372 km/h), which is equivalent to wind speeds inside a level-5 tornado on the Enhanced Fujita Scale . Such winds have the power to level well-constructed buildings, blow away structures with weak foundations and throw cars over large distances. The record still stands today as the second-fastest natural wind gust ever recorded, with the fastest occurring on Barrow Island in Australia on April 10, 1996 and reaching speeds of 253 mph (407 km/h) .

Sign up for the Live Science daily newsletter now Get the world’s most fascinating discoveries delivered straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors

Even wind speeds of 100 mph can rip huge chunks of ice off the mountain and the Mount Washington Observatory building at the summit, which poses a severe risk for hikers and climbers in the winter. The observatory has bulletproof windows to mitigate the risk of one of these chunks smashing into the building, according to its website.

As well as flying ice, people climbing Mount Washington in the winter are faced with the risk of avalanches, hypothermia and frostbite. Temperatures on the mountain average 27.1 degrees Fahrenheit (minus 2.7 degrees Celsius), which can create extreme wind chill conditions, according to New Hampshire State Parks .</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.livescience.com/technology/artificial-intelligence/people-find-ai-more-compassionate-than-mental-health-experts-study-finds-what-could-this-mean-for-future-counseling'>People find AI more compassionate than mental health experts, study finds. What could this mean for future counseling?</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> livescience&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 13:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The tests revealed that AI responses were considered more compassionate than those from professional crisis responders, even when the author of the responses was revealed to the participants.

People find responses from artificial intelligence (AI) to be more compassionate and understanding than those from human mental health experts, a new study shows. The finding again demonstrates that AI can outperform humans in fields in which we've long assumed only people with shared experience are good at.

In the study, published Jan. 10 in the journal Communications Psychology , scientists conducted a series of four experiments to find out how 550 participants rated empathetic responses for compassion and responsiveness generated by AI versus those from professionals. Specifically, the participants gave information about personal experiences and then assessed the answers for compassion, responsiveness and overall preference.

The tests revealed that AI responses were considered more compassionate than those from professional crisis responders, even when the author of the responses was revealed to the participants.

The results suggest AI has uses in "contexts requiring empathetic interaction, with the potential to address the increasing need for empathy in supportive communication contexts," the researchers wrote in the study.

On average, AI-generated responses were rated 16% more compassionate than human responses and were preferred 68% of the time, even when compared to trained crisis responders.

Related: AI faces are 'more real' than human faces — but only if they're white

Study lead author Dariya Ovsyannikova , a lab manager at the University of Toronto's psychology department, attributed the AI's success to its ability to identify fine details and stay objective as crisis experiences were described. This made the AI better able to generate attentive communication that gave the user the illusion of empathy. At the same time, the humans may have performed worse because human responders are susceptible to fatigue and burnout, she added.

Sign up for the Live Science daily newsletter now Get the world’s most fascinating discoveries delivered straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors

Live Science asked Eleanor Watson , IEEE member, AI ethics engineer and AI faculty at Singularity University, what the finding means, not just for the future of AI-human interactions but the ongoing debate about which jobs AI can't or shouldn't do when human understanding and input seems critical.

Watson called the finding "fascinating" but wasn't altogether surprised. "[AI] can certainly model supportive responses with a remarkable consistency and apparent empathy, something that humans struggle to maintain due to fatigue and cognitive biases," she told Live Science.

"Human practitioners are constrained by their direct clinical experience and cognitive limitations. The scale of data AI can process fundamentally changes the equation of therapeutic support. It can also potentially enable patients to gain perspectives or approaches their therapist has not been trained in," she said.

Accessible mental health care

Globally, mental health care is in crisis, and the study raises the possibility of AI filling the gaps. According to the World Health Organization , more than two-thirds of people with mental health conditions don't get the care they need. In low and middle income countries that figure rises to 85%.

Watson said the ease in accessing AI versus human therapists could make it a useful tool to help with mental health provision. "The availability of machines is a welcome factor, especially compared with expensive practitioners whose time is limited," Watson said.

"Also, people often find dealing with a machine less daunting, particularly with more sensitive topics. There's less fear of judgment or gossip."

But finding AI-generated responses more empathetic doesn't come without risks. Watson warned of the specter of supernormal stimulus, which is the tendency to respond more strongly to an exaggerated version of a stimulus.

"AI is so enticing we become entranced by it," Watson said. "AI can be flirty, insightful, enlightening, fun, provocative, forbearing and accessible to the point where it's impossible for any human being to measure up."

Content about mental health also exacerbates the privacy issues associated with AI. "The privacy implications are stark," Watson noted. "Having access to people's deepest vulnerabilities and struggles makes them vulnerable to various forms of attack and demoralization. Scrupulous governance of systems and the organizations behind them must be upheld to defend against exploitation by bad actors."</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.sciencenews.org/article/measles-spreading-questions-answered'>Measles is spreading. Here’s what experts say you should know</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> sciencenews&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 13:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>As measles cases surge in the United States, leading to the country’s first two measles-related deaths in a decade, questions, worries and misinformation about the infectious disease are swirling. More than 300 confirmed measles cases have been reported this year as of March 13, largely associated with an outbreak at the border between Texas and New Mexico, according to the U.S. Centers for Disease Control and Prevention. Unvaccinated children make up the majority of confirmed cases.

Still, the number of deaths “suggests that the outbreak is much bigger than the official number,” says infectious diseases physician Peter Chin-Hong of the University of California, San Francisco. Based on the expected fatality rate of 1 to 2 people per 1,000 infections, he says, the real number of cases may be closer to the high hundreds if not over 1,000.

Known for its blotchy red rash that usually starts on the face, measles can lead to high fever, pneumonia, ear infection and brain swelling. The virus that causes measles is highly contagious. The airborne virus spreads when an individual comes in contact with someone who’s sick or with virus-contaminated surfaces. It can linger in the air for hours even after an infected person has left the room. After exposure, up to 90 percent of people without immunity to measles will catch it.

Vaccination is the best way to gain protection, health experts say. But measles vaccination rates among kindergarteners have dropped from 95.2 percent in the 2019–2020 school year to 92.7 percent in 2023–2024, leaving around 280,000 kindergarteners vulnerable that academic year, according to CDC. The decline preceded new scrutiny of the childhood vaccine schedule by U.S. Health and Human Services Secretary Robert F. Kennedy Jr., a known vaccine skeptic.

The measles vaccine “not only prevents serious disease, it also prevents infection,” Chin-Hong says. “It’s a fantastic vaccine.”

Since the United States first declared measles eliminated in 2000, the country has rarely exceeded 300 cases within a year. Most outbreaks and isolated cases are sparked by travelers bringing the virus from places where it circulates more widely.

But the early uptick in 2025 now has left many people wondering whether they need a booster shot, what the early warning signs of measles are and how to treat it. To learn more, Science News spoke with several physicians and researchers well-versed in infectious diseases.

What are the early signs and symptoms of measles?

Generally, it starts with a fever, cough, runny nose and red eyes, Chin-Hong says. But the early symptoms resemble those associated with plenty of other illnesses, leaving measles to be dismissed as something like a simple cold.

“Nobody really knows it’s measles in the beginning,” Chin-Hong says. “That’s why it’s so insidious and could be so transmissible.”

Around three to five days later, however, a telltale rash usually appears. It typically starts on the face and works its way down the body. But people are infectious up to four days before the rash appears, and four days after, Chin-Hong notes. An infected person may not show symptoms until up to three weeks after picking up the virus.

Can good nutrition protect you from getting measles or having a bad outcome after contracting it?

Sponsor Message

No.

“Nutrition is no substitute for vaccination,” says Scott Weaver, who directs the Institute for Human Infections and Immunity at the University of Texas Medical Branch in Galveston. “There’s no evidence anywhere in the world that it prevents infection or that it prevents the spread from infected people to others.… The main way to stop this outbreak is through vaccination. There’s no reason to think that improving nutrition is going to have any impact on the trajectory of this outbreak.”

“Nutrition is no substitute for vaccination.” Scott Weaver, University of Texas Medical Branch in Galveston



Measles doesn’t pass over the well-nourished, agrees Larry Kociolek, an infectious diseases pediatrician at Ann & Robert H. Lurie Children’s Hospital of Chicago and Northwestern University Feinberg School of Medicine. “The frightening thing about measles is how contagious it is in the air. If you enter the room of somebody with measles — even if that person left that room an hour or two prior — if you’re not immune to measles, you can catch measles.

“Your risk of acquiring measles is not going to go down if you’re not immune just because you’ve otherwise lived a healthy lifestyle.”

But children who are malnourished have a greater chance of catching diseases and may develop more severe disease than kids with adequate nutrition.Severe malnutrition is not usually involved in measles outbreaks in high-income countries like the United States.

Do antibiotics, vitamin A or cod liver oil help treat measles?

Not directly, Weaver says. “A lot of the severe infections progress to [pneumonia, which] can be caused by bacteria, and in this case, they certainly need antibiotics.”

As for supplements, “the reason that this is in the news is that there were studies in Africa and Asia that showed one of them, vitamin A supplements, actually increased survival among children,” he says.

That may be because children in those parts of the world have a greater likelihood of being vitamin A deficient, Kociolek says. “If you’re vitamin A deficient and you get measles, it is very important that you get vitamin A as a treatment to reduce the severity of disease. But there’s no evidence that if you’re not vitamin A deficient, that vitamin A provides any benefit.”

In fact, taking too much vitamin A can be dangerous, he says. Symptoms of vitamin A toxicity include nausea, vomiting, liver damage, hair loss and brittle bones that can lead to fractures.

Unfortunately, “there’s no treatment for measles,” Chin-Hong says. When someone is hospitalized with severe disease — usually an infant — doctors may give them a general antiviral drug called ribavirin that’s sometimes used to treat hepatitis C and RSV. “There’s no great data” for ribavirin helping with measles, he says, but it’s used occasionally because there are no measles-specific drugs.

How vaccines protect communities When few people in a community are vaccinated, measles can spread easily. Measles is one of the most contagious diseases, with each infected person (red) able to pass the virus to 12 to 18 susceptible people (yellow). People who have gotten a measles vaccine (green) act as a shield against contagion. They rarely get infected and usually don’t pass the virus on to others on the rare occasions when they do get infected. When 95 percent of people in a community are vaccinated, the community is protected with herd immunity. Click the arrows to see how disease spreads with and without herd immunity.

C. Chang

Does getting measles strengthen your immune system in the long run?

No. In fact, the opposite, Weaver says. “It actually interferes with your immune system in the short run. If you’re infected by a [measles] virus without being vaccinated, the infection suppresses your immune response for typically a few months to a few years, and that can lead to you being more vulnerable to secondary infections.”

Measles can also cause long-term damage to the immune system. After an infection or vaccination, immune cells known as T cells, B cells and plasma cells maintain the memory of those invaders, says Stephen Elledge, an immunologist at Brigham and Women’s Hospital in Boston. “B cells are involved in making antibodies. They actually don’t secrete antibodies. They differentiate into these plasma cells, and the plasma cells become the antibody factories. They go to your bone marrow, and that’s where they stay for the rest of your life.They can live for 30 [to] 40 years, the whole time just pumping out the memory of your infections,” he says. “It turns out that measles can kill those cells.… It kills the T cells and kills the B cells. It kills the plasma cells.”

So 10 to 20 percent of people infected with measles have the immune memory of other infections or vaccinations wiped out, Elledge says. That may leave them vulnerable to illnesses in the future even if they were previously infected or vaccinated against bacteria and viruses.

“We showed it happens in people and in controlled experiments with macaques, so it’s undeniably true. And the epidemiology backs it up 100 percent,” Elledge says.

The vaccine is a weakened virus that does not kill the immune memory cells so it can’t cause immune amnesia. Instead it guards against measles and other infectious diseases by shielding the immune system’s memory.

“Natural immunity” from infections also carries risks far beyond those associated with vaccination. “This natural immunity theory is dangerous,” Kociolek says. “The natural infection for measles can be severe. [About] 20 percent of children will require hospitalization for measles, a small percentage will get life threatening brain swelling. There’s a small proportion of people who will recover and be seemingly fine, and then several years later, sometimes 10 to 20 years later, will get lethal inflammation of the brain from their prior infection.” By contrast, “the measles vaccine is incredibly safe.”

What’s the recommended age for babies and children to get the measles vaccine?

Usually infants get a measles vaccine when they are about a year old and a second shot when they are 4 to 6 years old. But in the Texas outbreak area, the state health department is advising parents to get babies vaccinated when they are as young as 6 months old. That early shot should be followed with the regular schedule of measles vaccines.

The reason doctors typically hold the first measles shot until a child turns 1 year old is that antibodies from the mother protect the baby and may interfere with the vaccine. “Those antibodies prevent the vaccine from replicating well,” Weaver says. “But if the mother was not vaccinated or infected and that baby has no immunity, then it’s a good idea to give them the vaccine earlier.”

Can you get measles as an adult if you’ve had it before or were vaccinated as a child?

“Very unlikely,” Weaver says. “The vaccine with two doses protects about 97 percent of people from getting measles again, and natural infection is probably a similar level of protection.”

Even if you do get it, you’ll probably have a milder disease, Chin-Hong says.

Does immunity from the measles vaccine wane over time?

Probably somewhat, says Elledge. “Antibodies [against the measles virus] stick around a long time … but they do go down. They’re really good when you’re young, and then they start dropping off.”

Older people who were vaccinated many decades ago may have lost some protection, he says.

“The idea that it gives you lifelong protection may be true, but it probably would be more true if you were in an environment where you occasionally got reinfected.” Occasional exposure to the virus or vaccine booster shots may help build stronger immunity, he says.

But, Weaver says, “the majority of people don’t need to worry about it. There’s very little evidence of people with older age losing the protection against the infection. So unless they have some particular circumstance [such as] their immunity might wane because of some general immune deficiency, then they can get tested for their antibody levels. The vast majority of people [who] receive two doses as a child, they should be protected for life.”

Should adults get a booster shot?

Some should, Kociolek says. “In general, if you’ve had one dose of vaccine you’re protected, probably with 93 percent effectiveness. If you’ve had two doses of vaccine you’re about 97 percent protected as well. So that’s considered adequate immunity.

“Those who have had a prior measles infection are protected lifelong,” he adds. “Individuals who were born in the United States before the year 1957 are also considered immune. That was before vaccination, [but measles is] so transmissible that everyone born in the U.S. before 1957 is thought to have had measles. If those criteria don’t apply to you, you may need to be vaccinated.”

Is there a way to find out if you should get a measles shot?

Ideally, Weaver says, people “would go to their health care provider who would have complete records of their vaccination and find out if they received two doses as a child. [If so] they really don’t need to be vaccinated again. If those records are not available and they’re relying on their own memory or what they were told by their parents and they’re not certain about that, it’s certainly a good idea to get a booster, even if they likely were vaccinated as a child. It really can’t hurt to get that booster.”

Health care workers may “get boosted if their antibodies have dropped below a certain threshold. But for the vast majority of people, they don’t really need to worry about that if they’re pretty certain they’ve been vaccinated as a child.”</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/see-you-in-the-funny-papers-how-superhero-comics-tell-the-story-of-jewish-america-248218'>See you in the funny papers: How superhero comics tell the story of Jewish America</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 12:52:52
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Nearly a hundred years ago, a hastily crafted spaceship crash-landed in Smallville, Kansas. Inside was an infant – the sole survivor of a planet destroyed by old age. Discovering he possessed superhuman strength and abilities, the boy committed to channeling his power to benefit humankind and champion the oppressed.

This is the story of Superman: one of the most recognizable characters in history, who first reached audiences in the pages of Action Comics in 1938 – what many fans consider the most important single comic in history.

As a historian of American immigration and ethnicity – and a lifelong comics fan – I read this well-known bit of fiction as an allegory about immigration and the American dream. It is, at its core, the ultimate story of an immigrant in the early 20th century, when many people saw the United States as a land with open gates, providing such orphans of the world an opportunity to reach their fullest potential.

Taken in and raised by a rural family under the name Clark Kent, the baby was imbued with the best qualities of America. But, like all immigrant stories, Kent’s is a two-parter. There is also the emigrant story: the story of how Kal-El – Superman’s name at birth – was driven from his home on Planet Krypton to embrace a new land.

That origin story reflects the heritage of Superman’s creators: two of the many Jewish American writers and artists who ushered in the Golden Age of comic books.

Jewish history…

The American comics industry was largely started by the children of Jewish immigrants. Like most publishing in the early 20th century, it was centered in New York City, home to the country’s largest Jewish population. Though they were still a very small minority, immigration had swelled the United States’ Jewish population more than a thousandfold: from roughly 3,000 in 1820 to roughly 3,500,000 in 1920.

Comic books had not yet been devised, but strip comics in newspapers were a regular feature. They began in the late 19th century with popular stories featuring recurring characters, such as Richard F. Outcault’s “Yellow Kid” and “the Little Bears” by Jimmy Swinnerton.

A few Jewish creators were able to break into the industry, such as Harry Hershfield and his comic “Abie the Agent.” Hershfield’s success was exceptional in three ways: He broke into mainstream newspaper comics, his titular character was also Jewish, and he never adopted an anglicized pen name – as many other Jewish creators felt they must.

Generally, however, Jews were barred from the more prestigious jobs in newspaper cartooning. A more accessible alternative was the cheaper, second-tier business of reprinting previously published works.

In 1933, second-generation Jewish New Yorker Max Gaines – born Maxwell Ginzburg – began a new publication, “Funnies on Parade.” “Funnies” pulled together preexisting comic strips, reproducing them in saddle-stitched pamphlets that became the standard for the American comics industry. He went on to found All-American Comics and Educational Comics.

Another publisher, Malcolm Wheeler-Nicholson, founded National Allied Publications in 1934 and published the first comic book to feature entirely new material, rather than reprints of newspaper strips. He joined forces with two Jewish immigrants, Harry Donenfeld and Jack Leibowitz. At National, they created and distributed Detective and Action Comics – the precursors to DC, which would become one of the two largest comics distributors in history.

It was at Action Comics that Jerry Siegel and Joe Shuster, two second-generation immigrants from a Jewish neighborhood in Cleveland, found a home for Superman. It would also be where two Jewish kids from the Bronx, Bob Kane and Bill Finger – born Robert Kahn and Milton Finger – found a home for their character, Batman, in 1939.

The success of these characters inspired another prominent second-generation Jewish New Yorker, pulp magazine publisher Moses “Martin” Goodman, to enter comics production with his line, “Timely Comics.” The 1939 debut featured what would become two of the early industry’s most well-known superheroes: the Sub-Mariner and the Human Torch. These characters would be mainstays of Goodman’s company, even when it became better known as Marvel Comics.

Thus were born the “big two,” Marvel and DC, from humble Jewish origins.

…and Jewish stories

The creation and popularization of superhero comics isn’t Jewish just because of its history. The content was, too, reflecting the values and priorities of Jewish America at the time: a community influenced by its origins and traditions, as well as the American mainstream.

Some of the most foundational early comics echo Jewish history and texts, such as Superman’s story, which parallels the Jewish hero Moses. The biblical prophet was born in Egypt, where the Israelites were enslaved, and soon after Pharaoh ordered the murder of all their newborn sons. Similarly, Superman’s people, the Kryptonians, faced an existential threat: the destruction of their planet.

Moses’ life is saved when his mother floats him down the Nile in a hastily constructed and tarred basket. Kal-El, too, is sent away to safety in a hastily constructed craft. Both boys are raised by strangers in a strange land and destined to become heroes to their people.

Comics also reflected the feelings and fears of Jews in a moment in time. For example, in the wake of Kristallnacht – the 1938 night of widespread organized attacks on German Jews and their property, which many historians see as a turning point toward the Holocaust – Finger and Kane debuted Batman’s Gotham City. The city is a dark contrast to Superman’s shining metropolis, a place where villains lurked around every corner and reflected the darkest sides of modern humanity.

Some comic artists and writers used their platform to make political statements. Jack Kirby – born Kurtzberg – and Hymie “Joe” Simon, creators of Captain America, explained that they “knew what was going on over in Europe. World events gave us the perfect comic-book villain, Adolf Hitler, with his ranting, goose-stepping and ridiculous moustache. So we decided to create the perfect hero who would be his foil.” The comic debut of Captain America in 1941 featured a brightly colored cover with the brand-new hero punching Adolf Hitler in the face.

In later generations, characters penned by Jewish authors continued to grapple with issues of outsider status, hiding aspects of their identity, and maintaining their determination to better the world in spite of rejection from it. Think of Spider-Man, the Fantastic Four and X-Men. All of these were created by Stan Lee – another Jewish creator, born Stanley Martin Lieber – who was hired into Timely Comics at just 17 years old.

With so many of the most popular comics written by New York Jews, and centered in the city, much of New York’s Yiddish-tinged, recognizably Jewish language made its way onto the pages. Lee’s Spider-Man, for example, frequently exclaims “oy!” or calls bad guys “putz” or “shmuck.”

In later years, Jewish authors such as Chris Claremont and Brian Michael Bendis introduced or took over mainstream characters who were overtly Jewish – reflecting an emerging comfort with a more public Jewish ethnic identity in America. In X-Men, for example, Kitty Pryde recounts her encounters with contemporary antisemitism. Magneto, who is at times friend but often foe of the X-Men, developed a backstory as a Holocaust survivor.

History is never solely about retelling; it’s about gaining a better understanding of complex narratives. Trends in comics history, particularly in the superhero genre, offer insight into the ways that Jewish American anxieties, ambitions, patriotism and sense of place in the U.S. continually changed over the 20th century. To me, this understanding makes the retelling of these classic stories even more meaningful and entertaining.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/the-psychology-behind-anti-trans-legislation-how-cognitive-biases-shape-thoughts-and-policy-251691'>The psychology behind anti-trans legislation: How cognitive biases shape thoughts and policy</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 12:52:37
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>A state law signed Feb. 28, 2025, removes gender identity as a protected status from the Iowa Civil Rights Act, leaving transgender people vulnerable to discrimination. The rights of transgender people – those who present gender characteristics that differ from what has historically been expected of someone based on their biological sex traits – are under political attack across the United States. There are now hundreds of anti-trans bills at various points in the legislative process.

But why?

Reasons given usually center on protecting children, protecting cisgender women’s rights in bathrooms and sports competitions, and on removing funding for gender-affirming care. Some efforts appear to stem from fear-driven motives that are not supported by evidence.

Bias against trans people may not always feel like bias. For someone who believes it to be true, saying there can only be biological men who identify as men and biological women who identify as women may feel like a statement of fact. But research shows that gender is a spectrum, separate from biological sex, which is also more complex than the common male-female binary.

We are social psychologists who study and teach about the basic social, cognitive and emotion-based processes people use to make sense of themselves and the world. Research reveals psychological processes that bias people in ways they usually aren’t aware of. These common human tendencies can influence what we think about a particular group, influence how we act toward them, and prompt legislators to pass biased laws.

Root of negative views of transgender people

Social psychology theory and research point to several possible sources of negative views of transgender people.

Part of forming your own identity is defining yourself by the traits that make you unique. To do this, you categorize others as belonging to your group – based on characteristics that matter to you, such as race, age, culture or gender – or not. Psychologists call these categories in-groups and out-groups.

There is a natural human tendency to have inherent negative feelings toward people who aren’t part of your in-group. The bias you might feel against fans of a rival sports team is an example. This tendency may be rooted deep in evolutionary history, when favoring your own safe group over unknown outsiders would have been a survival advantage.

A trans person’s status as transgender may be the most salient thing about them to an observer, overshadowing other characteristics such as their height, race, profession, parental status and so on. As a small minority, transgender people are an out-group from the mainstream – making it likely out-group bias will be directed their way.

Anti-trans feeling may also result from fear that transgender people pose threats to one’s personal or group identity. Gender is part of everyone’s identity. If someone perceives their own gender to be determined by their biological sex, they may perceive other people who violate that “rule” as a threat to their own gender identity. Part of identity formation is not just out-group derogation but in-group favoritism. A cisgender person may engage in “in-group boundary protection” by making sure the parameters of “gender” are well defined and match their own beliefs.

Once you hold negative feelings about someone in an out-group, there are other social psychological processes that may solidify and amplify them in your mind.

The illusion of a causal connection

People tend to form illusory correlations between objects, people, occurrences or behaviors, particularly when those things are infrequently encountered. Two distinctive things happening at the same time makes people believe that one is causing the other.

Some superstitions result from this phenomenon. For example, you might attribute an unusual success such as winning money to wearing a particular shirt, which you now think of as your lucky shirt.

If a person only ever hears about negative events when they see or hear about a transgender person, an immigrant or a member of some other minority group, then an illusory correlation can form between the negative events and the minority group. That connection is the starting point for prejudice: automatic, negative feelings toward a group of people without justification.

Of course, it is possible that individuals from the group in question have committed some offense. But to take one individual’s bad deed and attribute it to an entire group of people isn’t justified. This kind of extrapolation is the natural human tendency of stereotyping, which can bias people’s actions.

‘That’s exactly what I thought’

Human minds are biased to confirm the beliefs they already hold, including stereotypes about trans people. A few interconnected processes are at play in what psychologists call confirmation bias.

First, there’s a natural tendency to seek out information that fits with what you already believe. If you think a shirt is lucky, then you’re more likely to look for positive things that happen when you wear it than you are to look for negative events that would seem to disconfirm its luckiness.

If you think transgender people are dangerous, you are more likely to conduct an internet search for “transgender people who are dangerous” than “transgender people are victims of crime.”

There’s a second, more passive process in play as well. Rather than actively seeking out confirming information, people also simply pay attention to information that confirms what they thought in the first place and ignore contradictory information. This can happen without you even realizing.

People also tend to interpret ambiguous events in line with their beliefs – “I must be having a good day, despite some setbacks, because I’m wearing my lucky shirt.” That confirmation bias could explain someone with anti-trans attitudes thinking “that transgender person holding hands with a child must be a pedophile” instead of “that transgender mother is showing love and care for her kid.”

Finally, people tend to remember things that confirm their beliefs better than things that challenge them.

Confirmation bias can strengthen an illusory correlation, making it even more likely to influence subsequent actions – whether compulsively wearing a lucky shirt to an anxiety-inducing appointment or not hiring someone because of discriminatory thoughts about the group they belong to.

Moving past biases

Awareness of biases is the first step in avoiding them. Setting bias aside allows people to make fair decisions, based on accurate information, and in line with their values.

However, this is not an easy task in the face of another social psychological process called group polarization. This phenomenon occurs when individuals’ beliefs become more extreme as they talk and listen only to people who hold the same beliefs they do. Think of the social media bubbles that result from interacting only with people who share your perspective.

Efforts to stifle or prohibit educators’ and librarians’ ability to teach and discuss gender and sexuality topics, openly and fairly, add another challenge. Education through access to impartial, evidence-based information can be one way to help neutralize inherent bias.

As a final, hopeful point, social psychological research has identified one strategy for overcoming intergroup conflict: forming close contacts with individuals from the “other” group. Having a friend, loved one or trusted and valued colleague who belongs to the out-group can help you recognize their humanity and overcome the biases you hold against that out-group as a whole.

A relevant and recent example of this scenario came when two transgender state representatives convinced their fellow lawmakers to vote against two extreme anti-trans bills in Montana by making the issue personal.

All of these decision-making biases influence everyone, not just the lawmakers currently in power. And they can be quite complex, with particular in-group and out-group memberships being hard to define – for instance, factions within religious groups who disagree on particular political issues.

But understanding and overcoming the biases everyone falls prey to means that optimal decisions can be made for everyone’s well-being and economic vitality. After all, psychology research has repeatedly demonstrated that diversity is good for the bottom line while it simultaneously promotes an equitable and inclusive society. Even from a solely financial perspective, discrimination is bad for all Americans.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/radioisotope-generators-inside-the-nuclear-batteries-that-power-faraway-spacecraft-248504'>Radioisotope generators − inside the ‘nuclear batteries’ that power faraway spacecraft</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 12:52:03
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Powering spacecraft with solar energy may not seem like a challenge, given how intense the Sun’s light can feel on Earth. Spacecraft near the Earth use large solar panels to harness the Sun for the electricity needed to run their communications systems and science instruments.

However, the farther into space you go, the weaker the Sun’s light becomes and the less useful it is for powering systems with solar panels. Even in the inner solar system, spacecraft such as lunar or Mars rovers need alternative power sources.

As an astrophysicist and professor of physics, I teach a senior-level aerospace engineering course on the space environment. One of the key lessons I emphasize to my students is just how unforgiving space can be. In this extreme environment where spacecraft must withstand intense solar flares, radiation and temperature swings from hundreds of degrees below zero to hundreds of degrees above zero, engineers have developed innovative solutions to power some of the most remote and isolated space missions.

So how do engineers power missions in the outer reaches of our solar system and beyond? The solution is technology developed in the 1960s based on scientific principles discovered two centuries ago: radioisotope thermoelectric generators, or RTGs.

RTGs are essentially nuclear-powered batteries. But unlike the AAA batteries in your TV remote, RTGs can provide power for decades while hundreds of millions to billions of miles from Earth.

Nuclear power

Radioisotope thermoelectric generators do not rely on chemical reactions like the batteries in your phone. Instead, they rely on the radioactive decay of elements to produce heat and eventually electricity. While this concept sounds similar to that of a nuclear power plant, RTGs work on a different principle.

Most RTGs are built using plutonium-238 as their source of energy, which is not usable for nuclear power plants since it does not sustain fission reactions. Instead, plutonium-238 is an unstable element that will undergo radioactive decay.

Radioactive decay, or nuclear decay, happens when an unstable atomic nucleus spontaneously and randomly emits particles and energy to reach a more stable configuration. This process often causes the element to change into another element, since the nucleus can lose protons.

When plutonium-238 decays, it emits alpha particles, which consist of two protons and two neutrons. When the plutonium-238, which starts with 94 protons, releases an alpha particle, it loses two protons and turns into uranium-234, which has 92 protons.

These alpha particles interact with and transfer energy into the material surrounding the plutonium, which heats up that material. The radioactive decay of plutonium-238 releases enough energy that it can glow red from its own heat, and it is this powerful heat that is the energy source to power an RTG.

Heat as power

Radioisotope thermoelectric generators can turn heat into electricity using a principle called the Seebeck effect, discovered by German scientist Thomas Seebeck in 1821. As an added benefit, the heat from some types of RTGs can help keep electronics and the other components of a deep-space mission warm and working well.

In its basic form, the Seebeck effect describes how two wires of different conducting materials joined in a loop produce a current in that loop when exposed to a temperature difference.

Devices that use this principle are called thermoelectric couples, or thermocouples. These thermocouples allow RTGs to produce electricity from the difference in temperature created by the heat of plutonium-238 decay and the frigid cold of space.

Radioisotope thermoelectric generator design

In a basic radioisotope thermoelectric generator, you have a container of plutonium-238, stored in the form of plutonium-dioxide, often in a solid ceramic state that provides extra safety in the event of an accident. The plutonium material is surrounded by a protective layer of foil insulation to which a large array of thermocouples is attached. The whole assembly is inside a protective aluminum casing.

The interior of the RTG and one side of the thermocouples is kept hot – close to 1,000 degrees Fahrenheit (538 degrees Celsius) – while the outside of the RTG and the other side of the thermocouples are exposed to space. This outside, space-facing layer can be as cold as a few hundred degrees Fahrenheit below zero.

This strong temperature difference allows an RTG to turn the heat from radioactive decay into electricity. That electricity powers all kinds of spacecraft, from communications systems to science instruments to rovers on Mars, including five current NASA missions.

But don’t get too excited about buying an RTG for your house. With the current technology, they can produce only a few hundred watts of power. That may be enough to power a standard laptop, but not enough to play video games with a powerful GPU.

For deep-space missions, however, those couple hundred watts are more than enough.

The real benefit of RTGs is their ability to provide predictable, consistent power. The radioactive decay of plutonium is constant – every second of every day for decades. Over the course of about 90 years, only half the plutonium in an RTG will have decayed away. An RTG requires no moving parts to generate electricity, which makes them much less likely to break down or stop working.

Additionally, they have an excellent safety record, and they’re designed to survive their normal use and also be safe in the event of an accident.

RTGs in action

RTGs have been key to the success of many of NASA’s solar system and deep-space missions. The Mars Curiosity and Perseverance rovers and the New Horizons spacecraft that visited Pluto in 2015 have all used RTGs. New Horizons is traveling out of the solar system, where its RTGs will provide power where solar panels could not.

However, no missions capture the power of RTGs quite like the Voyager missions. NASA launched the twin spacecraft Voyager 1 and Voyager 2 in 1977 to take a tour of the outer solar system and then journey beyond it.

Each craft was equipped with three RTGs, providing a total of 470 watts of power at launch. It has been almost 50 years since the launch of the Voyager probes, and both are still active science missions, collecting and sending data back to Earth.

Voyager 1 and Voyager 2 are about 15.5 billion miles and 13 billion miles (nearly 25 billion kilometers and 21 billion kilometers) from the Earth, respectively, making them the most distant human-made objects ever. Even at these extreme distances, their RTGs are still providing them consistent power.

These spacecraft are a testament to the ingenuity of the engineers who first designed RTGs in the early 1960s.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/when-humans-use-ai-to-earn-patents-who-is-doing-the-inventing-248216'>When humans use AI to earn patents, who is doing the inventing?</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 12:51:51
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The advent of generative artificial intelligence has sent shock waves across industries, from the technical to the creative. AI systems that can generate viable computer code, write news stories and spin up professional-looking graphics have inspired countless headlines asking whether they will take away jobs in technology, journalism and design, among many other fields.

And these new ways of doing work and making things raise another question: In the era of AI, what does it mean to be an inventor?

Among technologists who build digital tools or programs, it is increasingly common to use AI as part of design and development processes. But as deep learning models flex their technical muscles more and more, even highly skilled researchers who are using AI in their work have begun to express concerns about becoming obsolete.

There is much debate about whether AI can augment human creativity, but emerging data suggests that the technology can boost research and development where creativity typically plays an important role. A recent study by MIT economics doctoral student Aidan Toner-Rodgers found that scientists using AI tools increased their patent filings by 39% and created 17% more prototypes than when they worked without such tools.

While this study indicates that AI seemed to help humans be more productive, it also showed there was a downside: 82% of the surveyed researchers felt less satisfied with their jobs since implementing AI in their workflows. “I couldn’t help feeling that much of my education is now worthless,” one researcher said.

This emerging dynamic leads to a related question: If a scientist uses AI in order to build something new, does the output still qualify as an invention? As a legal scholar who studies technology and intellectual property law, I see the growing power of AI shifting the legal landscape.

Natural persons

In 2020, the United States Patent and Trademark Office refused to list the AI system DABUS, which purportedly designed a food container and a flashing emergency beacon, as an inventor on patent applications. Subsequent court rulings clarified that under current U.S. law, only humans can be listed as inventors, but they left open the question of whether inventions developed by scientists with the help of AI qualify for patent protection.

The concept of inventorship and legal protections for inventions have deep roots in the U.S. The Constitution explicitly protects the “exclusive rights” of authors and inventors “to their respective writings and discoveries,” reflecting the framers’ strong conviction that the state should protect and encourage original ideas.

U.S. law today defines an inventor as a natural person who has conceived of a complete and operative invention that can be used without extensive research or experimentation. An inventor must do more than follow routine instructions – they must make an intellectual contribution in producing something novel.

That contribution can be a key idea that sparks the invention or a crucial insight that turns the concept into a working product. If a person’s input is routine or just explains what’s already known, they are not an inventor.

Role of AI

To what extent can or should AI become part of the invention process? The release of AI applications such as ChatGPT in 2022 introduced the public to large language models and sparked renewed debate about whether and how AI should be used in the inventive process. That same year, the U.S. Court of Appeals for the Federal Circuit heard a case that tested whether AI could be named as an inventor on a patent application.

The court concluded that under U.S. law, inventors must be human beings. The ruling reaffirmed the idea that Congress intended to encourage human beings, not machines, to invent. This idea remains foundational to current patent policy.

In light of the court’s decision, in 2024 the United States Patent and Trademark Office updated its guidance to clarify the role of AI in the inventive process. The guidance reaffirms that an inventor must be human. However, the Patent and Trademark Office explained that the policy did not preclude inventors from using AI tools to assist in the research and development of inventions. This approach acknowledges how the rapid development of AI technologies has allowed researchers to make exciting breakthroughs.

Policymakers seem to understand that if the U.S. is to continue to lead the world in innovation, the mythology of a sole inventor toiling away in a garage and relying on pure intellect must evolve to account for the value of AI tools that research has proven make humans more productive.

Nevertheless, since only human beings can be named as inventors on a patent, current policy does not quite answer the question of who or what should get credit for doing the work. Despite a growing trend where researchers are expected to disclose whether they’ve used AI tools, for example in academic papers, the U.S. patent system makes no such demand.

Regardless of AI’s role in the research and development process, a U.S. patent will list only the names of human inventors so long as those humans made a significant contribution to the invention. As a result, current policy is not concerned with how to recognize the contributions of AI. AI is considered a tool like a microscope or a Bunsen burner.

Personal ingenuity in the age of AI

Given this shifting legal landscape, I see that U.S. innovation policy is at a crossroads. The Patent and Trademark Office’s guidance reaffirming human inventorship and simultaneously embracing AI as an innovation tool is only a year old. It is unclear how the Trump administration’s forthcoming action plan to “enhance America’s global AI dominance” will affect this guidance.

Some observers expect the rate of scientific discovery to increase dramatically with the assistance of AI tools. But if the majority of those same productive researchers enjoy their jobs less, is the act of inventing being encouraged as the framers envisioned?

Current U.S. policy attempts to strike a balance and recognize the concept of personal ingenuity, stemming from the principle that for an invention to be patented in the U.S., a human must have led the way. Yet the guidance also implicitly acknowledges that AI can lend a helping hand in modern research and development. Whether and how policymakers maintain this balance – and how leaders in industry and science respond – will help shape the next chapter of American innovation.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/the-push-to-restore-semiconductor-manufacturing-faces-a-labor-crisis-can-the-us-train-enough-workers-in-time-245516'>The push to restore semiconductor manufacturing faces a labor crisis − can the US train enough workers in time?</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 12:51:38
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Semiconductors power nearly every aspect of modern life – cars, smartphones, medical devices and even national defense systems. These tiny but essential components make the information age possible, whether they’re supporting lifesaving hospital equipment or facilitating the latest advances in artificial intelligence.

It’s easy to take them for granted, until something goes wrong. That’s exactly what happened when the COVID-19 pandemic exposed major weaknesses in the global semiconductor supply chain. Suddenly, to name just one consequence, new vehicles couldn’t be finished because chips produced abroad weren’t being delivered. The semiconductor supply crunch disrupted entire industries and cost hundreds of billions of dollars.

The crisis underscored a hard reality: The U.S. depends heavily on foreign countries – including China, a geopolitical rival – to manufacture semiconductors. This isn’t just an economic concern; it’s widely recognized as a national security risk.

That’s why the U.S. government has taken steps to invest in semiconductor production through initiatives such as the CHIPS and Science Act, which aims to revitalize American manufacturing and was passed with bipartisan support in 2022. While President Donald Trump has criticized the CHIPS and Science Act recently, both he and his predecessor, Joe Biden, have touted their efforts to expand domestic chip manufacturing in recent years.

Yet, even with bipartisan support for new chip plants, a major challenge remains: Who will operate them?

Minding the workforce gap

The push to bring semiconductor manufacturing back to the U.S. faces a significant hurdle: a shortage of skilled workers. The semiconductor industry is expected to need 300,000 engineers by 2030 as new plants are built. Without a well-trained workforce, these efforts will fall short, and the U.S. will remain dependent on foreign suppliers.

This isn’t just a problem for the tech sector – it affects every industry that relies on semiconductors, from auto manufacturing to defense contractors. Virtually every military communication, monitoring and advanced weapon system relies on microchips. It’s not sustainable or safe for the U.S. to rely on foreign nations – especially adversaries – for the technology that powers its military.

For the U.S. to secure supply chains and maintain technological leadership, I believe it would be wise to invest in education and workforce development alongside manufacturing expansion.

Building the next generation of semiconductor engineers

Filling this labor gap will require a nationwide effort to train engineers and technicians in semiconductor research, design and fabrication. Engineering programs across the country are taking up this challenge by introducing specialized curricula that combine hands-on training with industry-focused coursework.

Future semiconductor workers will need expertise in chip design and microelectronics, materials science and process engineering, and advanced manufacturing and clean room operations. To meet this demand, it will be important for universities and colleges to work alongside industry leaders to ensure students graduate with the skills employers need. Offering hands-on experience in semiconductor fabrication, clean-room-based labs and advanced process design will be essential for preparing a workforce that’s ready to contribute from Day 1.

At Missouri University of Science of Technology, where I am the chair of the materials science and engineering department, we’re launching a multidisciplinary bachelor’s degree in semiconductor engineering this fall. Other universities across the U.S. are also expanding their semiconductor engineering options amid strong demand from both industry and students.

A historic opportunity for economic growth

Rebuilding domestic semiconductor manufacturing isn’t just about national security – it’s an economic opportunity that could benefit millions of Americans. By expanding training programs and workforce pipelines, the U.S. can create tens of thousands of high-paying jobs, strengthening the economy and reducing reliance on foreign supply chains.

And the race to secure semiconductor supply chains isn’t just about stability – it’s about innovation. The U.S. has long been a global leader in semiconductor research and development, but recent supply chain disruptions have shown the risks of allowing manufacturing to move overseas.

If the U.S. wants to remain at the forefront of technological advancement in artificial intelligence, quantum computing and next-generation communication systems, it seems clear to me it will need new workers – not just new factories – to gain control of its semiconductor production.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/institutions/missouri-university-of-science-and-technology-1927'>Missouri University of Science and Technology on The Conversation</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 12:51:38
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Founded in 1870 as Missouri School of Mines, Missouri University of Science and Technology primarily educated mining engineers and surveyors. The campus really started to grow right after World War II. As the need for engineers and scientists grew, so did the university. The campus evolved into a world-class technological research university, one that was making an impact beyond the state and nation.

In 1964, the institution’s name was changed to the University of Missouri-Rolla. UMR was the technology flagship of the four-campus University of Missouri System.

Then, in 2008, the name officially became Missouri University of Science and Technology. As a technological research university, Missouri S&T is a member of a small but elite group of American institutions that distinguish themselves by having a mission-based commitment to improving the world through the study and application of advanced sciences and technology.

There are 16 technological research universities in the nation, including MIT, Caltech, Missouri S&T, Rensselaer, Georgia Tech and the Colorado School of Mines. Many of these institutions complement their technological strengths by offering good programs in humanities, liberal arts and social sciences. Missouri S&T is admired around the world for preparing students and creating research that solves the problems of a technological society.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/simple-strategies-can-boost-vaccination-rates-for-adults-over-65-new-study-250246'>Simple strategies can boost vaccination rates for adults over 65 − new study</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 12:51:25
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Knowing which vaccines older adults should get and hearing a clear recommendation from their health care provider about why a particular vaccine is important strongly motivated them to get vaccinated. That’s a key finding in a recent study I co-authored in the journal Open Forum Infectious Diseases.

Adults over 65 have a higher risk of severe infections, but they receive routine vaccinations at lower rates than do other groups. My colleagues and I collaborated with six primary care clinics across the U.S. to test two approaches for increasing vaccination rates for older adults.

In all, 249 patients who were visiting their primary care providers participated in the study. Of these, 116 patients received a two-page vaccine discussion guide to read in the waiting room before their visit. Another 133 patients received invitations to attend a one-hour education session after their visit.

The guide, which we created for the study, was designed to help people start a conversation about vaccines with their providers. It included checkboxes for marking what made it hard for them to get vaccinated and which vaccines they want to know more about, as well as space to write down any questions they have. The guide also featured a chart listing recommended vaccines for older adults, with boxes where people could check off ones they had already received.

In the sessions, providers shared in-depth information about vaccines and vaccine-preventable diseases and facilitated a discussion to address vaccine hesitancy.

In a follow-up survey two months later, patients reported that the most significant barriers they faced were knowing when they should receive a particular vaccine, having concerns about side effects and securing transportation to a vaccination appointment.

The percentage of patients who said they wanted to get a vaccine increased from 68% to 79% after using the vaccine guide. Following each intervention, 80% of patients reported they discussed vaccines more in that visit than they had in prior visits.

Of the 14 health care providers who completed the follow-up survey, 57% reported increased vaccination rates following each approach. Half of the providers felt that the use of the vaccine guide was an effective strategy in guiding conversations with their patients.

Why it matters

Only about 15% of adults ages 60-64 and 26% of adults 65 and older are up to date on all the vaccines recommended for their age, according to CDC data from 2022. These include vaccines for COVID 19, influenza, tetanus, pneumococcal disease and shingles.

Yet studies consistently show that getting vaccinated reduces the risk of complications from these conditions in this age group.

My research shows that strategies that equip older adults with personalized information about vaccines empower them to start the conversation about vaccines with their clinicians and enable them to be active participants in their health care.

What’s next

In the future, we will explore whether engaging patients on this topic earlier is even more helpful than doing so in the waiting room before their visit.

This might involve having clinical team members or care coordinators connect with patients ahead of their visit, either by phone or through telemedicine that is designed specifically for older adults.

My research team plans to conduct a pilot study that tests this approach. We hope to learn whether reaching out to these patients before their clinic visits and helping them think through their vaccination status, which vaccines their provider recommends and what barriers they face in getting vaccinated will improve vaccination rates for this population.

The Research Brief is a short take on interesting academic work.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/when-algorithms-take-the-field-inside-mlbs-robo-umping-experiment-251094'>When algorithms take the field – inside MLB’s robo-umping experiment</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 12:51:14
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Baseball fans tuning into spring training games may have noticed another new wrinkle in a sport that’s experienced a host of changes in recent years.

Batters, pitchers and catchers can challenge a home plate umpire’s ball or strike call. Powered by Hawk-Eye ball-tracking technology, the automated ball-strike system replays the pitch trajectory to determine whether the umpire’s call was correct.

To minimize disruptions, Major League Baseball permits each team a maximum of two failed challenges per game but allows unlimited challenges as long as they’re successful. For now, the technology will be limited to the spring exhibition games. But it could be implemented in the regular season as soon as 2026.

Count future Hall of Famer Max Scherzer among the skeptics.

“We’re humans,” the Toronto Blue Jays hurler said after a spring training game in which he challenged two calls and lost both to the robo umps. “Can we just be judged by humans?”

Technological advances that lead to fairer, more accurate calls are often seen as triumphs. But as co-editors of the recently published volume “Inventing for Sports,” which includes case studies of over 20 sports inventions, we find that new technology doesn’t mean perfect precision – nor does it necessarily lead to better competition from the fan perspective.

Cue the cameras

While playing in a cricket match in the 1990s, British computer scientist Paul Hawkins fumed over a bad call. He decided to make sure the same mistake wouldn’t happen again.

Drawing on his doctoral training in artificial intelligence, he designed an array of high-speed cameras to capture a ball’s flight path and velocity, and a software algorithm that used the data to predict the ball’s likely future path.

He founded Hawk-Eye Innovations Ltd. in 2001, and his first clients were cricket broadcasters who used the technology’s trajectory graphics to enhance their telecasts.

By 2006, professional tennis leagues began deploying Hawk-Eye to help officials adjudicate line calls. Cricket leagues followed in 2009, incorporating it to help umpires make what are known as “leg before wicket” calls, among others. And professional soccer leagues started using the technology in 2012 to determine whether balls cross the goal line.

Reaction to Hawk-Eye has been mixed. In tennis, players, fans and broadcasters have generally embraced the technology. During a challenge, spectators often clap rhythmically in anticipation as the Hawk-Eye official cues up the replayed trajectory.

“As a player, and now as a TV commentator,” tennis legend Pam Shriver said in 2006, “I dreamed of the day when technology would take the accuracy of line calling to the next level. That day has now arrived.”

But Hawk-Eye isn’t perfect. In 2020 and 2022, the firm publicly apologized to fans of professional soccer clubs after its goal-line technology made errant calls after players congregated in the goal box and obstructed key camera sight lines.

Perfection isn’t possible

Critics have also raised more fundamental concerns.

In their 2016 book “Bad Call,” researchers Harry Collins, Robert Evans and Christopher Higgins reminded readers that Hawk-Eye is not a replay of the ball’s actual position; rather, it produces a prediction of a trajectory, based on the ball’s prior velocity, rotation and position.

The authors lament that Hawk-Eye and what they term “decision aids” have undermined the authority of referees and umpires, which they consider bad for the games.

Ultimately, there are no purely objective standards for fairness and accuracy in technological officiating. They are always negotiated. Even the most precise officiating innovations require human consensus to define and validate their role. Technologies like photo-finish cameras, instant replay and ball-tracking systems have improved the precision of officiating, but their deployment is shaped – and often limited – by human judgment and institutional decisions.

For example, today’s best race timing systems are accurate to 0.0001 seconds, yet Olympic sports such as swimming, track and field, and alpine skiing report results in increments of only 0.01 seconds. This can lead to situations – such as Dominique Gisin and Tina Maze’s gold medal tie in the women’s downhill ski race at the 2014 Sochi Olympics – in which the timing officials admitted that their equipment could have revealed the actual winner. But they were forced to report a dead heat under the rules established by the ski federation.

With slow-motion instant replays, determining a catch or a player’s intention for a personal foul can actually be distorted by low-speed replay, since humans aren’t adept at adjusting to shifting replay speeds.

One of the big issues with baseball’s automated ball-strike system has to do with the strike zone itself.

MLB’s rule book defines the strike zone as the depth and width of home plate and the vertical distance between the midpoint of a player’s torso to the point just below his knees. The interpretation of the strike zone is notoriously subjective and varies with each umpire. For example, human umpires often call a strike if the ball crosses the plate in the rear corner. However the automated ball-strike system uses an imaginary plane that bisects the middle – not the front or the rear – of home plate.

There are more complications. Since every player has a unique height, each has a unique strike zone. At the outset of spring training, each player’s height was measured – standing up without cleats – and then confirmed through a biomechanical analysis.

But what if a player changes their batting stance and decides to crouch? What if they change their cleats and raise their strike zone by an extra quarter-inch?

Of course, as has been the case in tennis, soccer and other sports, Hawk-Eye can help rectify genuinely bad calls. By allowing teams to correct the most disputed calls without eliminating the human element of umpiring, MLB hopes to strike a balance between tradition and change.

Fans have the final say

Finding a balance between machine precision and the human element of baseball is crucial.

Players’ and managers’ efforts to work the umpires to contract or expand the strike zone have long been a part of the game. And fans eagerly cheer or jeer players and managers who argue with the umpires. When ejections take place, more yelling and taunting ensues.

Though often unacknowledged in negotiations between leagues and athletes, fan enthusiasm is a key component of whether to adopt new technology.

For example, innovative “full-body” swimsuits contributed to a wave of record-breaking finishes in the sport between 2000 and 2009. But uneven access to the newest gear raised the specter of what some called “technological doping.” World Aquatics worried that as records fell simply due to equipment innovations, spectators would stop watching and broadcast and sponsorship revenue would dry up. The swimming federation ended up banning full-body swimsuits.

Of course, algorithmic officiating differs from technologies that enhance performance and speed. But it runs a similar risk of turning off fans. So MLB, like other sports leagues, is being thrust into the role of managing technological change.

Assessing technologies for their immediate and long-term impact is difficult enough for large government agencies. Sports leagues lack those resources, yet are nonetheless being forced to carefully consider how they introduce and regulate various innovations.

MLB, to its credit, is proceeding incrementally. While the logical conclusion to the current automated ball-strike experiment would be fully electronic officiating, we think fans and players will resist going that far.

The league’s challenge system is a test. But the real umpires will ultimately be the fans.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/big-cuts-at-the-education-departments-civil-rights-office-will-affect-vulnerable-students-for-years-to-come-249716'>Big cuts at the Education Department’s civil rights office will affect vulnerable students for years to come</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 12:51:02
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The U.S. Department of Education cut its workforce by nearly 50% on March 11, 2025, when it laid off about 1,315 employees. The move follows several recent directives targeting the Cabinet-level agency.

Within the department, the Office for Civil Rights – which already experienced layoffs in February – was especially hard hit by cuts.

The details remain unclear, but reports suggest that staffs at six of the 12 regional OCR offices were laid off. Because of the office’s role in enforcing civil rights laws in schools and universities, the cuts will affect students across the country.

As education policy scholars who study how laws and policies shape educational inequities, we believe the Office for Civil Rights has played an important role in facilitating equitable education for all students.

The latest cuts further compound funding and staffing shortages that have plagued the office. The full effects of these changes on the most vulnerable public school students will likely be felt for many years.

Few staff members

The Education Department, already the smallest Cabinet-level agency before the recent layoffs, distributed roughly US$242 billion to students, K-12 schools and universities in the 2024 fiscal year.

About $160 billion of that money went to student aid for higher education. The department’s discretionary budget was just under $80 billion, a sliver compared with other agencies.

By comparison, the Department of Health and Human Services received nearly $2.9 trillion in fiscal year 2024.

Within the Education Department, the Office for Civil Rights had a $140 million budget for fiscal year 2024, less than 0.2% of discretionary funding, which requires annual congressional approval.

It has lacked financial support to effectively carry out its duties. For example, amid complaints filed by students and their families, the OCR has not had an increase in staff. That leaves thousands of complaints unresolved.

The office’s appropriated budget in fiscal year 2017 was one-third of the budget of the Equal Employment Opportunity Commission – a federal agency responsible for civil rights protection in the workplace – despite the high number of discrimination complaints that OCR handles.

Support for OCR

Despite this underfunding, the office has traditionally received bipartisan support.

Former Secretary of Education Betsy DeVos, for example, requested a funding decrease for the office during the first Trump administration. Congress, however, overrode her budget request and increased appropriations.

Likewise, regardless of changing administrations, the office’s budget has remained fairly unchanged since 2001.

It garners attention for investigating and resolving discrimination-related complaints in K-12 and higher education. And while administrations have different priorities in how to investigate these complaints, they have remained an important resource for students for decades.

But a key function that often goes unnoticed is its collection and release of data through the Civil Rights Data Collection.

The CRDC is a national database that collects information on various indicators of student access and barriers to educational opportunity. Historically, only 5% of the OCR’s budget appropriations has been allocated for the CRDC.

Yet, there are concerns among academic scholars that the continued collection and dissemination of the CRDC might be affected by staff cuts and contract cancellations worth $900 million at the Department of Education’s research arm, the Institute of Education Science.

That’s because the CRDC often relies on data infrastructure that is shared with the institute.

The history of the CRDC

The CRDC originated in the late 1960s as required by the Civil Rights Act of 1964. The data questionnaire, which poses questions about civil rights concerns, is usually administered to U.S. public school districts every two years.

It provides indicators on student experiences in public preschools and K-12 schools. That includes participation rates in curricular opportunities like Advanced Placement courses and extracurricular activities. It also provides data on 504 plans for students with disabilities and English-learner instruction.

Although there have been some changes to questions over the years, others have been consistent for 50 years to allow for examining changes over time. Some examples are counts of students disciplined by schools’ use of corporal punishment or out-of-school suspension.

During the Obama administration, the Office for Civil Rights prioritized making the CRDC more accessible to the public. The administration created a website that allows the public to view information for particular schools or districts, or to download data to analyze.

Why the CRDC matters

Our research focuses on how the CRDC has been used and how it could be improved. In an ongoing research project, we identified 221 peer-reviewed publications that have analyzed the CRDC.

Articles focusing on school discipline – out-of-school suspensions, for example – are the most common. But there are many other topics that would be difficult to study without the CRDC.

That’s especially true when making comparisons between districts and states, such as whether students have access to advanced coursework or participation in gifted and talented programs.

The data has also inspired policy changes.

The Obama administration, informed by the data on the use of seclusion and restraint to discipline students, issued a policy guidance document in 2016 regarding its overuse for students with disabilities.

Additionally, the data helps examine the effects of judicial decisions and laws – desegregation laws in the South, for example – that have improved educational opportunities for many vulnerable students.

Amid the Education Department’s continued cancellation of contracts of federally funded equity assistance centers, we believe research partnerships with policymakers and practitioners drawing on CRDC data will be more important than ever.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/why-parents-of-twice-exceptional-children-choose-homeschooling-over-public-school-244385'>Why parents of ‘twice-exceptional’ children choose homeschooling over public school</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 12:50:49
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Homeschooling has exploded in popularity in recent years, particularly since the pandemic. But researchers are still exploring why parents choose to homeschool their children.

While the decision to homeschool is often associated with religion, a 2023 survey found that the two top reasons people cited as most important were a concern about the school environment, such as safety and drugs, and a dissatisfaction with academic instruction.

I studied giftedness, creativity and talent as part of my Ph.D. program focusing on students who are “twice exceptional” – that is, they have both learning challenges such autism or attention-deficit/hyperactivity disorder as well as advanced skills. A better understanding of why parents choose homeschooling can help identify ways to improve the public education system. I believe focusing on twice-exceptional students can offer insights beyond this subset of the homeschooled population.

What we know about homeschooling

The truth is researchers don’t know much about homeschooling and homeschoolers.

One problem is regulations involving homeschooling differ dramatically among states, so it is often hard to determine who is being instructed at home. And many families are unwilling to talk about their experiences homeschooling and their reasons for doing so.

But here’s what we do know.

The share of children being homeschooled has surged since 2020, rising from 3.7% in the 2018-2019 school year to 5.2% in 2022-2023 – the latest data available from the National Center for Education Statistics. Over 3 million students were homeschooled in 2021-22, according to the National Home Education Research Institute.

And the population of homeschoolers is becoming increasingly diverse, with about half of families reporting as nonwhite in a 2023 Washington Post-Schar School poll. In addition, homeschooling families are just as likely to be Democrat as Republican, according to that same Post-Schar survey, a sharp shift from previous surveys that suggested Republicans were much more likely to homeschool.

As for why parents homeschool, 28% of those surveyed in 2023 by the Institute of Education Sciences said the school environment was their biggest reason, followed by 17% that cited concerns about academic instruction. Another 17% said providing their kids with moral or religious instruction was most important.

But not far behind at 12% was a group of parents who prioritized homeschooling for a different reason: They have a child with physical or mental health problems or other special needs.

This group would include parents of twice-exceptional children, who may be especially interested in pursuing homeschooling as an alternative method of education for three reasons in particular.

1. The ‘masking’ problem

These parents may notice that their child’s needs are being overlooked in the public education system and may view homeschooling as a way to provide better individualized instruction.

Students who are twice exceptional often experience what researchers call the “masking” phenomenon. This can occur when a child’s disabilities hide their giftedness. When this occurs, teachers tend to provide academic support but hesitate to give these children the challenging material they may require.

Masking can also occur in reverse, when a student’s gifts tend to hide disabilities. In these cases, teachers provide challenging material, but they do not provide the needed accommodations that allow the gifted child to access the materials. Either way, masking can be a problem for students and parents who must advocate for teachers to address their unique range of academic needs.

While either type of masking is challenging for the student, it may be particularly frustrating for parents of twice-exceptional students to watch classroom teachers focus only on their child’s weaknesses rather than helping them develop their advanced abilities.

2. Individualized instruction

By the time a child enters school, parents have spent years observing their child’s development, comparing their progress with that of others their age. They’re also likely to be aware of their child’s unique interests.

While this may not be true for all parents, those who choose to homeschool may do so because they feel they have more of an ability and interest in catering to their child’s unique needs than a classroom teacher who is tasked with teaching many students simultaneously. Parents of students who demonstrate exceptional ability have expressed concerns about their child’s future educational opportunities in a public school setting.

Additionally, parents may become exhausted by their efforts to advocate for their child’s unique needs in the school system. Parents of students who demonstrate advanced abilities often pull their children out of public school after repeated efforts to improve communication between home and school.

3. Behavioral and emotional needs

Gifted students who have emotional or behavioral disabilities may find it difficult to demonstrate their abilities in the classroom.

All too often, teachers may be more focused on disciplining these students rather than addressing their academic needs. For example, a child who is bored with the class material may be loud and attempt to distract others as well.

Rather than recognizing this as signaling a need for more advanced material, the teacher might send the child to a separate area in the classroom or in the school to refocus or as punishment. Parents may feel better equipped than teachers to address both their child’s challenging behaviors and their gifted abilities, given the knowledge they have about their child’s history, interests, strengths and areas needing improvement.

Supporting students’ needs

Gaining a better understanding of the motivations driving parents to take their children out of the public school system is an important step toward improving schools so that fewer will feel the need to take this path.

Additionally, strengthening educators’ and policymakers’ understanding about twice-exceptional homeschooled students may help communities provide more support to their families – who then may not feel homeschooling is the only or best option. My research shows that many schools can do a better job providing these types of students and their parents with the support they need to thrive.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/keir-starmer-to-abolish-nhs-england-the-pros-and-cons-252237'>Keir Starmer to abolish NHS England – the pros and cons</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 12:30:37
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The UK government has announced the abolition of NHS England, phased over two years. In practice, this will involve merging some functions and staff from NHS England into the Department for Health and Social Care (DHSC). As part of the change, the government has stated that it expects to reduce duplication and save hundreds of millions of pounds.

NHS England was established under the Health and Social Care Act of 2012 (the Lansley reforms) and is responsible for commissioning care and overseeing the day-to-day running of the NHS. This involves negotiating budgets for local care provision with bodies like integrated care boards and hospitals; performance management such as monitoring waiting times and quality measures; and implementing national initiatives across NHS organisations.

NHS England was established to provide operational autonomy, shielding the health service from daily political interference. It is an “arm’s-length body”, meaning it operates independently from the government but remains accountable to it. The DHSC sets strategic goals and oversees NHS England activities.

In practice, NHS England and DHSC have distinct roles, although they overlap in some areas. DHSC staff typically have broader policy expertise – for example, many have worked in other areas of the civil service, whereas NHS England staff often have more detailed knowledge of how the NHS works on the ground.

Risks

The loss of expertise within NHS England is probably the largest risk of the abolition. Alongside very experienced NHS managers and analysts, NHS England employs senior doctors and other health care workers who contribute valuable practical knowledge from the NHS frontline into policy roles.

A major risk of this move is the potential loss of this clinical expertise and operational insight into policymaking. Lord Darzi’s report on the NHS specifically cited the loss in management talent that occurred as a result of the 2012 reforms, and cautioned against further reorganisation that might repeat that disruption.

Another risk is that bringing NHS England functions directly under ministerial control risks increased politicisation of day-to-day NHS management.

The government will argue that other policy areas like defence, education and policing do not have such a large arm’s-length body between the department and the frontline. However, health and social care is a uniquely large (11% of GDP) and highly political organisation, with a fast-growing budget and faster-growing challenges.

PA Images / Alamy Stock Photo

NHS policy is already highly politicised, but abolishing NHS England risks the DHSC and the ministers being on the hook for every operational decision. This could lead to operational decisions being made to appease public opinion rather than promoting public health.

The government faces significant practical challenges in merging two organisations with different cultures, working practices and pay structures. Currently, NHS England (about 16,000 staff) is much larger than DHSC (about 3,000 staff). Many NHS England roles will have to move into the much smaller DHSC.

The transition itself will require investment, so the promised savings are unlikely to be achieved in the short term.

Opportunities

The main opportunity of the abolition is the removal of duplication between DHSC and NHS England.

Currently, both organisations maintain separate policy teams covering similar areas – for example, elective surgery waiting times or cancer care. And sometimes, it is unclear how well they work together or why both are necessary.

By consolidating within the DHSC, there is an opportunity to strengthen policy analysis. With one strong policy team in the DHSC, policy advice to ministers (DHSC) and policy implementation on the ground (previously NHS England) could be better coordinated and aligned with the government’s objectives.

Lord Darzi’s report on the NHS highlighted the growth of regulatory roles within NHS England, questioning whether too much accountability could be counterproductive.

The abolition of NHS England is also an opportunity to streamline regulation while strengthening local management roles and valuable policy analysis.

Another opportunity from the abolition of the organisation would be the strengthening of local NHS bodies like integrated care boards. These local bodies, designed to tailor healthcare to local area needs, may sometimes have been stymied by excessive central control.

The health secretary, Wes Streeting, has already expressed his desire to see more devolution of power and responsibility within the NHS. This process provides the opportunity to enact that promise.

What will happen next?

The abolition of NHS England and the transfer of some responsibilities back to the DHSC will take time and incur significant costs and disruption. Any benefits are likely to emerge only in the long term.

Before the introduction of NHS England, there were larger regional organisations (strategic health authorities) that were responsible for implementing policy at a regional level. Perhaps the re-emergence of similar regional bodies could smooth the transition from a central NHS England to a more decentralised health service.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/two-charts-that-explain-why-reform-isnt-being-dented-by-its-scandals-252201'>Two charts that explain why Reform isn’t being dented by its scandals</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 12:30:34
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The spat between Nigel Farage, the leader of the Reform party, and Rupert Lowe, the MP for Great Yarmouth, burst into the open when Lowe was suspended from the party. The allegation was that he had threatened violence to the party leadership, which he denies. The matter is currently being investigated by the police.

The row does not appear to have affected support for Reform in the polls. A YouGov poll completed on March 10, after Lowe’s suspension, shows Reform on 23% in vote intentions, compared with 24% for Labour and 22% for the Conservatives. It is still a three-party race at the top of British party politics.

In the 2024 general election a good deal of Reform’s support came from protest voters. These are voters who dislike all the mainstream parties and so see a vote for the party as a way of choosing “none of the above”. They are not attached to any party and can easily switch support when circumstances change. So why has support for the party not been affected by this row?

Protest politics and support for Reform

The answer to this question is that while Reform attracted a lot of discontented protest voters in the election, it has since acquired a more stable niche in British party politics. It is primarily a party of English nationalism, equivalent to the SNP in Scotland and Plaid Cymru in Wales. These three parties differ greatly in outlook and politics, but they occupy a similar place in the public’s minds.

Want more politics coverage from academic experts? Every week, we bring you informed analysis of developments in government and fact check the claims being made.



Sign up for our weekly politics newsletter, delivered every Friday.

To examine Reform’s support from protest voters we can look at the relationship between spoilt ballots in the 2024 general election and support for the party in the 632 constituencies in England, Scotland and Wales. Normally, observers of British elections pay little attention to spoilt ballots (or “invalid votes” as they are described in official statistics). However, it turns out that they played an important role in the 2024 election which has a bearing on support for Reform.

Research shows that voters who spoil their ballots can be classified into two categories: those who simply make a mistake when filling in the ballot and those who are protesting about the current system.

Mistakes are easy to make in countries with complex electoral systems. However, in Britain, the first-past-the-post system in which everyone has just one vote, ensures that this is not a significant factor because ballot papers are so simple. The bulk of spoilt ballots are protests of various kinds, taking the form of blank ballots, write-in candidates, or abusive messages about parties and candidates.

This is illustrated in the Lancashire seat of Chorley, which is held by the speaker of the House of Commons, Lindsay Hoyle. By tradition none of the major parties challenge the Speaker by campaigning in his constituency. In the election there were no less than 1,198 spoilt ballots in his constituency. It is fairly clear that these were a result of some voters feeling disenfranchised by the absence of their preferred party on the ballot paper.

The relationship between the Reform vote share and the number of spoilt ballots in constituencies in the 2024 election

There is a strong negative relationship (a correlation of -0.46) between the share of a constituency vote that went to Reform in 2024 and the number of ballots spoiled in that constituency. Where people were voting Reform, in other words, fewer people were spoiling their ballots. The implication is that the party picked up votes from people who would normally spoil their ballots or would not have voted at all if Reform had not stood in their constituency. These are the protest voters.

Identity politics and support for Reform

Not all support for Reform came from protest voters, however. The chart below compares the percentage of Reform voters with those who identified as English in the 2021 census in England. There is a strong relationship between the two measures (a correlation of 0.66). The more English identifiers there are in a constituency, the greater support for Reform. In effect, Reform has become an English national party.

The relationship between Reform voting and English identity in 2024

National identities can change over time, but the process of change is slow. There has been a growth in “Englishness” at the expense of “Britishness” over time and this is undoubtedly reinforcing support for Reform.

It means the party has a relatively solid base of supporters to rely on in future elections. While the row between the party’s leader and one of his MPs could play out in any number of different directions at this early stage, it would be wrong to suggest that Reform isn’t thinking big picture and long term.

Farage has clearly learnt from his past and will not let his current party disintegrate into chaos like UKIP or the Brexit party before it.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.sciencenews.org/article/therapy-dog-kids-anxiety-emergency-room'>Therapy dogs can ease young patients’ anxiety in the emergency room</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> sciencenews&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 11:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>About 10 minutes with a therapy dog soothed kids who felt anxious about being emergency room patients.

A clinical trial found that after spending time with a dog, young patients reported a significantly larger decrease in their anxiety than kids who didn’t have dog time. The patients’ parents also perceived significantly reduced anxiety in their kids, researchers report March 14 in JAMA Network Open.

Managing kids’ anxiety and pain while receiving emergency medical care is a key part of the treatment plan, according to the American Academy of Pediatrics. Many pediatric emergency departments have child life specialists, who explain procedures in developmentally appropriate ways and help young patients cope with stress through play therapy and other methods.

The new clinical trial, which took place at Riley Children’s Hospital in Indianapolis from early 2023 to mid-2024, investigated whether adding a dog therapy visit would calm young patients even further. Riley Children’s Hospital has a dog therapy program in place. The dogs are vaccinated, have yearly vet checks and are certified as therapy animals.

All 80 participants in the trial, admitted patients 5 to 17 years old, worked with child life specialists. Forty of the patients also spent around 10 minutes with a therapy dog and the dog’s handler. Kids who were fearful of dogs or had allergies to the animals were excluded from the trial.

The research team evaluated the kids’ anxiety, and parents’ perception of their kids’ anxiety, with the FACES scale, which shows a series of faces in different amounts of distress. The scale ranges from zero, or no anxiety, to 10, or very severe anxiety.

The baseline, self-reported score for all 80 patients was 5.4 on average. Forty-five minutes after time with the child life specialists and, for those receiving it, the dog therapy visit, the research team assessed anxiety again. The kids getting the usual care saw an average drop in their score of 1.5, while the kids who hung out with therapy dogs had an average drop of 2.7 points. The pattern held true when the parents of the kids assessed their kids’ anxiety over time.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.livescience.com/animals/dinosaurs/dinosaurs-facts-about-the-reptiles-that-roamed-earth-more-than-66-million-years-ago'>Dinosaurs: Facts about the reptiles that roamed Earth more than 66 million years ago</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> livescience&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 10:27:15
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Dinosaurs were once thought to look like modern lizards, covered in green scales. However, some dinosaur species were actually covered in feathers , just like birds today.

We know this because some fossils from creatures such as Archaeopteryx and Sinosauropteryx — both theropod dinosaurs — have preserved feather imprints. And some Velociraptor fossils have tiny bumps on their arm bones where feathers were attached, just like in modern birds.

At first, paleontologists thought only theropod dinosaurs had feathers. However, scientists have found traces of downy feathers on fossils of a plant-eating dinosaur, suggesting that feathers may have been more common in dinosaurs than we thought.

Some dinosaurs may have used feathers to stay warm, court mates or even fly. For instance, paleontologists think a tiny chicken-size dinosaur named Microraptor had feathers on all four limbs to help it glide or even fly .</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.livescience.com/physics-mathematics/mathematics/how-do-we-know-pi-is-an-irrational-number'>How do we know pi is an irrational number?</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> livescience&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 09:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Irrational numbers go on and on. How do we know that pi has no ending?

Originally defined as the ratio between the circumference of a circle and its diameter, pi — written as the Greek letter π — appears throughout mathematics, including in areas that are completely unconnected to circles such as chemistry, physical sciences and medicine.

Pi belongs to a huge mathematical group called irrational numbers, which go on forever and cannot be written as fractions. Scientists have calculated pi to 105 trillion digits , although most of us are more familiar with the approximation 3.14. But how do we know that pi is an irrational number?

Rational numbers, which make up the majority of numbers we use in day-to-day life (although less than half of all possible numbers), can be written in the form of one whole number divided by another. Pi, with its complicated string of decimals, certainly doesn't appear to be part of this group at first glance.

"Rationality is the practical property of having access to the number explicitly, i.e. without any approximation … so being able to write the number in a finite amount of symbols," Wadim Zudilin , a mathematician at Radboud University in the Netherlands, told Live Science.

Related: What is the largest known prime number?

However, actually proving that you can't write pi as a fraction is a surprisingly knotty issue. Mathematicians don't have a universal method to show that a particular number is irrational, so they must develop a different proof for each case, explained Keith Conrad , a mathematician at the University of Connecticut. "How do you know a number is not a fraction?" he said. "You're trying to verify a negative property."

Despite this difficulty, over the past 300 years, mathematicians have established different proofs of pi's irrationality, using techniques from across mathematics. Each of these arguments begins with the assumption that pi is rational, written in the form of an equation. Through a series of manipulations and deductions about the properties of the unknown values in this equation, it subsequently becomes clear that the math contradicts this original assertion, leading to the conclusion that pi must be irrational.

Sign up for the Live Science daily newsletter now Get the world’s most fascinating discoveries delivered straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors

The specific math involved is often incredibly complex, typically requiring a university-level understanding of calculus, trigonometry and infinite series. However, each approach relies on this central idea of proof by contradiction.

" There are proofs using calculus and trigonometric functions ," Conrad said. "In some of them, π is singled out as the first positive solution to sin(x) = 0. The first proof by Lambert in the 1760s used a piece of mathematics called infinite continued fractions — it's a kind of infinitely nested fraction."

However, rather than proving pi is irrational directly, it's also possible to confirm irrationality using a different property of the number. Pi belongs to another numerical group called transcendental numbers, which are not algebraic and, importantly, cannot be written as the root of a polynomial equation. Because every transcendental number is irrational, any proof showing that pi is transcendental also proves that pi is irrational.

"Using calculus with complex numbers, you can prove π is transcendental," Conrad said. "The proof uses the very famous equation called Euler's identity: eiπ +1 = 0."

Although pi's universal importance may arise from this intangible irrationality, seven or eight decimal places is usually more than sufficient for any real-world applications. Even NASA uses only 16 digits of pi for its calculations.

"We approximate the value for practical purposes, 3.1415926 — that's already a lot of information!" Zudilin said. "But of course in mathematics, it's not satisfactory. We care about the nature of the numbers."

Pi Day quiz: How much do you know about this irrational number?</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.sciencenews.org/article/narwhals-arctic-whales-horns-tusks-play'>Narwhals may use their iconic tusks to play</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> sciencenews&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 09:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Narwhals wield their iconic tusks in surprising ways — possibly even to play with newfound toys.

Aerial videos showed the Arctic whales swinging their “horns” to thwack fish prior to eating them, and in one case, gingerly prodding and flipping a fish. The gentler movements may have been part of a narwhal play session, researchers report February 28 in Frontiers in Marine Science. It’s the first reported evidence of narwhals (Monodon monoceros) likely amusing themselves for fun.

Few scientists have seen the apparent unicorns of the sea brandishing their tusks in the wild. The elongated, spiraled tooth protrudes from the top lip of males and some females, and can grow to around half the body length of the roughly 4.5-meter-long whales. Scientists suspect the tusk evolved in males to show off to or compete (even literally) for mates. But past research has found it has other benefits, like sensing changes in water temperature and salinity.

Although newer technologies involving genetics, satellite tagging and aerial counts and mapping have led to breakthroughs in whale research, they provide only snapshots of what the animals do, says behavioral ecologist and geneticist Greg O’Corry-Crowe of Florida Atlantic University in Fort Pierce. He wanted to try what he calls an “old-style natural history and behavioral observation.”

Using a remotely operated flying drone, O’Corry-Crowe and colleagues spent hours filming narwhals swimming in an island bay in the Canadian High Arctic in the summer of 2022. One recording captured three narwhals among several Arctic char (Salvelinus alpinus), chasing fish and occasionally swinging their tusks like baseball bats to stun fish before chowing down. Another video showed three narwhals following a large char, with one whale taking the lead in lightly nudging and flipping the fish with the tip or side of its tusk, altering the fish’s path.

An aerial drone captures footage of narwhals following an Arctic char. The whales prod, flip and guide the fish with their tusks, possibly investigating and playing with it.

The second recording may have shown two species that don’t regularly interact investigating one another, as little evidence implies that narwhals normally eat char, and they do most of the year’s hunting and dining in the winter, O’Corry-Crowe says. “There’s this tentativeness,” he explains. “The fish makes a dramatic movement, and even the big animal just recoils and goes whoa!” Aspects of the scene, such as the narwhals’ low-stress environment, their repeated actions with their tusks and the fact that they didn’t try to eat the fish, suggested the whales were playing.

Because of the Arctic’s harsh environment, people often think creatures residing there are constantly fighting to survive, O’Corry-Crowe says. But the new study hints that sometimes these animals have time to explore — and possibly play — during their “summer vacation.”</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.livescience.com/physics-mathematics/albert-einstein-quiz-what-do-you-know-about-the-life-of-the-famous-theoretical-physicist'>Albert Einstein quiz: What do you know about the life of the famous theoretical physicist?</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> livescience&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 08:24:26
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>As one of the most famous scientists of the 20th century, Albert Einstein has become synonymous with genius. He taught himself geometry and calculus while living in Germany in his teens before training in Switzerland to become a math teacher. Unable to find a teaching position, Einstein bounced around until he completed a doctorate in physics in 1905 and began publishing groundbreaking scientific papers that ultimately changed the world .

But Einstein had other interests that are less well known — he was a staunch pacifist, invented an early refrigerator and called himself a "deeply religious non-believer." What do you know about the man, the myth, the genius Einstein? Time to take a quantum leap, because this quiz will test what you know about the famous physicist!

Related: 32 fun and random facts about Albert Einstein

Remember to log in to put your name on the leaderboard; hints are available if you click the yellow button. Consider the gravity of the situation and be sure to ace this quiz at the speed of light!

More science quizzes

— Black hole quiz: How supermassive is your knowledge of the universe?

— James Webb Space Telescope quiz: How well do you know the world's most powerful telescope?</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.sciencenews.org/article/lunar-eclipse-moon-lander-blue-ghost'>The Blue Ghost lander just witnessed a lunar eclipse — from the moon</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> sciencenews&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 07:29:02
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The privately-owned Blue Ghost moon lander, built by Texas-based company Firefly Aerospace, has captured rare views of a lunar eclipse from the moon’s surface.

The lander, which touched down March 2 in a volcanic plain on the moon’s nearside, has spent its time deploying instruments and collecting data. On the night of March 13, as Earth’s shadow covered the moon in a total lunar eclipse, Blue Ghost turned its cameras back toward Earth.

Around 4:30 a.m. EDT, the lander captured the “diamond ring effect,” as a single point of sunlight emerged from behind our planet at the end of totality. Earth itself, appearing as a dark disk in the black lunar sky, is encircled by glowing ring of light.

In the Firefly lander’s first photo of the eclipse, taken on March 14 at 1:30 am EDT, a ring of light encircling Earth is visible in the reflection in the solar panel (bottom). Firefly Aerospace

The first image from the eclipse, captured about three hours earlier, was deceptive — the sun appeared to still be shining brightly. But a reflection in the lander’s solar panels revealed an otherwise hidden detail: an arc of light wreathing Earth with just a spot of sunlight sneaking through.

Since landing, the spacecraft has put eight of its 10 science instruments to work. These include a device that uses a blast of pressurized nitrogen gas to collect and sort lunar soil; a dust shield demonstration, using electrical forces to lift lunar dirt from glass surfaces, which could help keep future spacecraft clean of famously sticky moondust; another experiment to measure the stickiness of that dust; a drill to measure heat flow from the moon’s interior; and an experiment to test a form of lunar GPS.

Cameras on the lander’s underside also took a video of the lander’s engine plumes interacting with the lunar surface, which could provide insights for making future landings smoother and cleaner.

This is not the first time a spacecraft has observed an eclipse from the lunar vicinity. In 2009, the Japanese Aerospace Exploration Agency’s Kaguya orbiter saw a penumbral eclipse, in which the Earth mostly blocked the sun. And NASA’s Surveyor 3 moon lander saw an eclipse way back in 1967.

Associate news editor Christopher Crockett contributed to this story.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://theconversation.com/jangan-tanya-kapan-menikah-dan-punya-anak-hindari-pertanyaan-tak-berempati-saat-kumpul-keluarga-251966'>Jangan tanya kapan menikah dan punya anak–hindari pertanyaan tak berempati saat kumpul keluarga</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> theconversation&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 02:16:29
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Disclosure statement

The study, that has inspired this part of the article, has received the Royal Society Te Aparangi Marsden Funds, with Sharyn Graham Davies as the Principle Investigator, and Nelly Martin-Anatias as the Lead researcher for the Asian and Muslim communities in Aotearoa New Zealand. Nelly Martin-Anatias does not work for, consult, own shares in or receive funding from any company or organisation that would benefit from this article, and has disclosed no relevant affiliations beyond their academic appointment.

Sharyn Graham Davies does not work for, consult, own shares in or receive funding from any company or organization that would benefit from this article, and has disclosed no relevant affiliations beyond their academic appointment.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://scientificamerican.com/game/spellements-2025-03-14/'>Spellements: Friday, March 14, 2025</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> scientificamerican&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 00:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>How to Play

Click the timer at the top of the game page to pause and see a clue to the science-related word in this puzzle!

The objective of the game is to find words that can be made with the given letters such that all the words include the letter in the center. You can enter letters by clicking on them or typing them in. Press Enter to submit a word. Letters can be used multiple times in a single word, and words must contain four letters or more for this size layout. Select the Play Together icon in the navigation bar to invite a friend to work together on this puzzle. Pangrams, words which incorporate all the letters available, appear in bold and receive bonus points. One such word is always drawn from a recent Scientific American article—look out for a popup when you find it! You can view hints for words in the puzzle by hitting the life preserver icon in the game display.

The dictionary we use for this game misses a lot of science words, such as apatite and coati. Let us know at games@sciam.com any extra science terms you found, along with your name and place of residence, and we might give you a shout out in our daily newsletter!</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://scientificamerican.com/game/classic-sudoku-hard-2025-03-14/'>Hard Sudoku: March 14, 2025</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> scientificamerican&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 00:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Solve the grid in this hard Sudoku puzzle!

The objective of Sudoku is to fill each row, column and sub-grid with exactly one of each number from 1-9. A conflict arises if you repeat any entry in the same row, column or sub-grid. For more, select "How to Play" in the game's dropdown menu. Use the "Play Together" option in the navigation bar to invite a friend to play this puzzle with you and enter numbers at the same time.

We’d love to hear from you! E-mail us at games@sciam.com to share your experience.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://scientificamerican.com/game/spellements-2025-03-14/'>Spellements: Friday, March 14, 2025</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> scientificamerican&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 00:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>How to Play

Click the timer at the top of the game page to pause and see a clue to the science-related word in this puzzle!

The objective of the game is to find words that can be made with the given letters such that all the words include the letter in the center. You can enter letters by clicking on them or typing them in. Press Enter to submit a word. Letters can be used multiple times in a single word, and words must contain four letters or more for this size layout. Select the Play Together icon in the navigation bar to invite a friend to work together on this puzzle. Pangrams, words which incorporate all the letters available, appear in bold and receive bonus points. One such word is always drawn from a recent Scientific American article—look out for a popup when you find it! You can view hints for words in the puzzle by hitting the life preserver icon in the game display.

The dictionary we use for this game misses a lot of science words, such as apatite and coati. Let us know at games@sciam.com any extra science terms you found, along with your name and place of residence, and we might give you a shout out in our daily newsletter!</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://scientificamerican.com/game/classic-sudoku-hard-2025-03-14/'>Hard Sudoku: March 14, 2025</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> scientificamerican&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 00:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Solve the grid in this hard Sudoku puzzle!

The objective of Sudoku is to fill each row, column and sub-grid with exactly one of each number from 1-9. A conflict arises if you repeat any entry in the same row, column or sub-grid. For more, select "How to Play" in the game's dropdown menu. Use the "Play Together" option in the navigation bar to invite a friend to play this puzzle with you and enter numbers at the same time.

We’d love to hear from you! E-mail us at games@sciam.com to share your experience.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.quantamagazine.org/once-in-a-century-proof-settles-maths-kakeya-conjecture-20250314/'>‘Once in a Century’ Proof Settles Math’s Kakeya Conjecture</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> quantamagazine&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 00:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Even the Kakeya set that overlaps the most has to take up some space, Fefferman found. That minimum volume depends on how thick the tubes are. Mathematicians quantify the relationship between the tubes’ thickness and the volume of the set using a number called the Minkowski dimension. The smaller the Minkowski dimension, the more you can reduce the set’s volume by thinning the tubes slightly.

The three-dimensional Kakeya conjecture says that a set’s Minkowski dimension must be three. This constitutes a very weak relationship — if you halve the tubes’ thickness, for instance, you will only remove a sliver of the volume at most.

Yet even that mild constraint turned out to be nearly impossible to prove.

Baby Steps

In 2022, five decades after the modern Kakeya conjecture was formulated, Wang and Zahl took a significant step forward. Following a program that Katz and Terence Tao had laid out back in 2014, they examined a pesky class of Kakeya sets. Their proof showed that every set in that particular class had a dimension of three. (The proof applies to both the Minkowski dimension and a closely related concept called the Hausdorff dimension.) With that annoying group set aside, they now had to show that the dimension was three for all the other Kakeya sets.

Sōichi Kakeya posed the problem that would bear his name in 1917, when he was 31. Courtesy of University of Tokyo

Their approach was to go step-by-step. They would first examine a narrow range of Minkowski dimensions — say, 2.5 to 2.6 — and try to show that no Kakeya set could be in that range. If they could prove this for every interval up to three, they’d prove the Kakeya conjecture.

Fortunately, Wang and Zahl didn’t have to start from zero. Tom Wolff proved in 1995 that no three-dimensional Kakeya set has a Hausdorff or Minkowski dimension below 2.5. But they needed a way to prove that a dimension between 2.5 and, say, 2.500001, was also impossible. Then they could repeat that argument to get a bound of 2.500002, and so on. Each time, they would essentially be showing that no Kakeya sets exist within that tiny increment.

In practice, they didn’t actually have to tediously prove each of these millions of increments one by one. They just needed to prove the first increment, so long as they could show that one bound implies the next, slightly larger one. Then they had to show that their argument worked no matter where they began. That would be enough to show that the bound can be walked up all the way to three.

But unlike in 2022, when they used Katz and Tao’s strategy, they had no road map to follow. They turned to a special property called graininess.

In 2014, Larry Guth, a mathematician at the Massachusetts Institute of Technology, had proved that any counterexample to the Kakeya conjecture needed to be “grainy.” In a grainy set, there are many small 3D sections where lots of tubes overlap. Each of these “grains” is about one tube thick and a few times wider, but not nearly as long, with many tubes passing through it lengthwise.

Wang and Zahl realized they could eschew the tubes entirely and deal with these simpler grains. They found that it was easier to enumerate and calculate the various ways the grains could overlap.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://undark.org/2025/03/14/book-review-superbloom/'>Book Review: How Our Digital Infatuation Undermines Discourse</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> undark&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-03-14 00:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>It was all Mother Nature’s fault, you could say. After winter rains in Lake Elsinore, California, reawakened countless dormant poppy seeds in early 2019, spring blossoms crowded in thickly enough to turn the hillsides bright orange — a fleeting “superbloom.” Recognizing an Instagrammable backdrop when she saw one, influencer Jaci Marie Smith reclined across the floral carpet in orange overalls and hit post. “You’ll never influence the world by trying to be like it,” her photo caption read.

In March, posts like Smith’s and #superbloom hashtags fueled a global frenzy. So many sightseers and influencers crowded into Lake Elsinore, snarling traffic and pulling up blooms by the handfuls, that officials declared a public safety emergency. As residents and others ripped into influencers for unleashing viral havoc on the small town, some took down their poppy posts, while others offered excuses and mea culpas. A meme that had begun in innocent enthusiasm curdled in an internet minute, setting people against each other and leaving a wake of real-world destruction.

BOOK REVIEW — “Superbloom: How Technologies of Connection Tear Us Apart,” by Nicholas Carr (W. W. Norton & Company, 272 pages).

We’re living in a perpetual digital superbloom, contends technology writer Nicholas Carr — a state of sensory and communication overload we can no longer control, one that’s sowing division and damage on a global scale. And like the poppy field that hypnotized Dorothy’s “Wizard of Oz” crew, this social media-fueled superbloom lures us in with enticements that are nearly impossible to resist. “Poppies are lush, vibrant, and entrancing,” Carr writes in “Superbloom: How Technologies of Connection Tear Us Apart.” “They’re also garish, invasive, and narcotic.”

This is familiar ground for Carr — at least, as familiar as any fast-morphing digital terrain can be. Carr’s stance as a techno-skeptic has been consistent for decades, though it’s evolved as digital communication modes have bloomed and receded. His 2010 book “The Shallows”, a finalist for the Pulitzer Prize, argued that the online world is distracting and prevents deeper engagement with texts, and he followed that up in 2014 with “The Glass Cage,” a reflection on how interacting with our computers changes us.

In “Superbloom,” Carr expands on a central theme of “The Glass Cage”: While we view our digital devices as helpers serving up knowledge and entertainment, they exact an unacknowledged toll in the process, altering how we think, act, and communicate. We are far different humans in an era of texting, posting, and like-seeking, Carr argues, than we were when limited to letters and phone calls — and not for the better.

“Poppies are lush, vibrant, and entrancing. They’re also garish, invasive, and narcotic.”

He contends that when we communicate mostly in one-line messages and hot takes, the kind that titillate and propagate from one human node to the next, our capacity to engage more intently and thoughtfully withers. “What we sacrifice are depth and rigor,” he writes. Thus, “we rely on quick and often emotional judgments while eschewing slower, reflective ones.”

This is a fair point, if only true in some online contexts: Masters of the 140-character social media quip win plenty of fans elsewhere with their books and long essays. What’s more convincing is Carr’s analysis of why our instant access to one another online, which we often assume is an advantage, has led to more social breakdown rather than less. In fact, he presents research showing that when people have high levels of close contact — something the internet allows on a colossal scale — they tend to turn against each other.

In real-world studies of community dynamics, neighbors seem more likely to be enemies than friends because they see each other’s flaws close up. And once we recognize that someone else is different from us, other research shows, we focus on further ways they’re not the same, a so-called “dissimilarity cascade” that can lead us to dislike them.

Likewise, in virtual space, “we’re all in one another’s business all the time,” Carr writes, later adding, “With an almost microscopic view of what everybody else is saying and doing — the screen turns us all into peeping Toms — we have no end of opportunities to take offense.”

Social media, in other words, packs us into a virtual hole-in-the-wall dorm room, dodging other people’s laundry piles and half-eaten noodles. In this agitated, overwhelmed state, it’s little wonder we’re prone to unload on anyone in the vicinity. Carr also raises more familiar points about how social media breeds anger and division by serving up upsetting yet engaging content, territory that books like Gaia Bernstein’s “Unwired: Gaining Control over Addictive Technologies” cover in depth.

We are far different humans in an era of texting, posting, and like-seeking, Carr argues, than we were when limited to letters and phone calls — and not for the better.

Yet as digital technologies extend ever deeper into our lives, it’s more critical than ever for us all to understand how online exchanges foment social breakdown — and “Superbloom” stands out for its appeal to a broad swath of readers. Where so many technology books seem like sealed capsules, accessible only to those who know the lingo, Carr’s vivid, jargon-free prose hits right in the solar plexus. “We’re not hostages with Stockholm syndrome,” he writes of our relationship with social media. “We’re being given what we want, in quantities so generous we can’t resist gorging ourselves.”

Carr likens artificial intelligence chatbots to the poet William Butler Yeats’ “rough beast” slouching toward us with a “gaze blank and pitiless as the sun,” and mocks tech magnates’ promises that AI will make the world a better place. “The rough beast,” he sarcastically observes, “turns out to be Mary Poppins.”

However hard-hitting and sound its claims, “Superbloom” might feel too apocalyptic were it not for Carr’s closing plea to hold the line. He says it’s too late to change the online systems we’re embedded in — a judgment that seems a tad dour, given how rapidly those same systems have themselves changed over time. But he rightly notes that to peel away from a virtual world that’s more image than substance, users must deliberately resist its empty charms, much as the rebels of Aldous Huxley’s “Brave New World” rejected the happiness drug soma.

SIGN UP FOR NEWSLETTER JOURNEYS: Dive deeper into pressing issues with Undark’s limited run newsletters. Each week for four weeks, you’ll receive a hand-picked excerpt from our archive related to your subject area of interest. Pick your journeys here.

The human brain is far better evolved to function in the real world, and the impact we can make in it is much likelier to fulfill us. “Salvation, if that’s not too strong a word,” Carr writes, “lies in personal, willful acts of excommunication.”

Still, he calls for judicious online withdrawal rather than Luddite-style divestment, for staking out a position “not beyond the reach of the informational flow, but beyond the reach of its liquefying force.”

While digital pessimists can come across as Cassandra-like, their warnings have never been more resonant. For Carr, the rough online beast is no longer merely slouching in our direction. It’s already devouring us. “Superbloom” frames the choice ahead in the starkest possible terms: Do we consent to being swallowed, or find a way — however quixotic and improbable — to escape the maw?</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            