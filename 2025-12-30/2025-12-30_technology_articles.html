
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - TECHNOLOGY Article Summaries - 2025-12-30</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            TECHNOLOGY
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/meta-buys-ai-agent-startup-for-2-billion-says-it-will-cut-all-ties-with-china-2000704284'>Meta Buys AI Agent Startup for $2 Billion, Says It Will Cut All Ties With China</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-30 16:50:42
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The social media giant just bought another AI startup. This time, it's the Singapore-based AI agent company Manus. Meta is buying the AI company in a deal worth more than $2 billion, according to the Wall Street Journal. It's the latest move in Meta's increasingly aggressive push into AI. The company already has plans to invest billions into AI infrastructure. Additionally, Meta has snapped up or invested in AI startups like Scale AI and Limitless, a sign that its in-house efforts may not be moving fast enough. Manus made a splash when it debuted this spring as a general AI agent that could handle a wide range of tasks, including deep research, vacation planning, coding, and stock analysis. Earlier this month, Manus announced that it had reached $100 million in annual recurring revenue just eight months after launching. “Joining Meta allows us to build on a stronger, more sustainable foundation without changing how Manus works or how decisions are made,” Manus CEO Xiao Hong said in a statement. The startup was founded by its parent company, Butterfly Effect, which previously held offices in Beijing and Wuhan. Shortly after launching Manus, the company moved its headquarters to Singapore. Earlier this year, Silicon Valley venture capital firm Benchmark faced backlash from U.S. lawmakers after investing in Manus. “Who thinks it is a good idea for American investors to subsidize our biggest adversary in AI, only to have the CCP use that technology to challenge us economically and militarily? Not me,” Sen. John Cornyn wrote in a post on X at the time. In what appears to be an effort to get ahead of similar accusations, Meta said that after the deal closes, Manus will be required to sever all remaining ties with China. There will be no continuing Chinese ownership interests in Manus AI following the transaction, and Manus AI will discontinue its services and operations in China. According to Nikkei Asia, Manus has laid off most of its Chinese employees and now has 105 staffers based in Singapore, Tokyo, and San Francisco. Subscribe and interact with our community, get up to date with our customised Newsletters and much more. Fake images, videos, and audio files crossed the “indistinguishable threshold" this year. Delayed AI infrastructure projects, rising debt, and weaker-than-expected earnings are reviving dot-com-era fears on Wall Street.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/how-microsoft-is-betting-on-ai-agents-in-windows-dusting-off-a-winning-playbook-from-the-past/'>How Microsoft is betting on AI agents in Windows, dusting off a winning playbook from the past</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-30 16:32:30
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>[Editor's Note: Agents of Transformation is an independent GeekWire series and 2026 event, underwritten by Accenture, exploring the people, companies, and ideas behind the rise of AI agents.] That's what Microsoft said in its 1990 annual report about the shift from MS-DOS to Windows. It was Windows' ability to serve as a platform for applications made by others. Windows 3.0, released that year, made third-party software easier to find and launch, and offered developers a clear bargain: build to Microsoft's specs, and your software would become a first-class citizen on the computers that were arriving “on every desk and in every home,” as the company's original mission statement put it. But Microsoft is hoping that Windows can once again serve as the platform where it all takes off. A new framework called Agent Launchers, introduced earlier this month as a preview in the latest Windows Insider build, lets developers register agents directly with the operating system. They can describe an agent through what's known as a manifest, which then lets the agent show up in the Windows taskbar, inside Microsoft Copilot, and across other apps. Beyond routine tasks like assembling a PDF or organizing files, agents could monitor email and calendars to resolve scheduling conflicts, or scan documents across multiple apps to pull together a briefing for an upcoming meeting. Achieving that level of autonomy requires more than just a clever interface. It will take deep, persistent memory that operates more like the human brain. “We are now entering a phase where we build rich scaffolds that orchestrate multiple models and agents; account for memory and entitlements; enable rich and safe tools use,” Microsoft CEO Satya Nadella wrote in a blog post this week looking ahead to 2026. But Microsoft's Windows team is betting that agents tightly linked to the operating system will win out over ones that merely run on top of it, just as a new class of Windows apps replaced a patchwork of DOS programs in the early days of the graphical operating system. Microsoft 365 Copilot is using the Agent Launchers framework for first-party agents like Analyst, which helps users dig into data, and Researcher, which builds detailed reports. Software developers will be able to register their own agents when an app is installed, or on the fly based on things like whether a user is signed in or paying for a subscription. Agents are meant to maintain this context across apps, ask follow-up questions, and take actions on a user's behalf. That requires a different level of trust than Windows has ever had to manage, which is already raising difficult questions for the company. In a support document, the company warned that malicious content embedded in files or interface elements could override an agent's instructions — potentially leading to stolen data or malware installation. To address this, Microsoft says it has built a security framework that runs agents in their own contained workspace, with a dedicated user account that has limited access to user folders. The agentic features are off by default, and Microsoft is advising users to “understand the security implications of enabling an agent on your computer” before turning them on. Even if Microsoft executes perfectly, the landscape is different now. Smartphones, browsers, and cloud platforms have fragmented the landscape in ways that didn't exist back then. Agent Launchers is a different bet — an attempt to make Windows the home for agents that serve individual users on their own machines. That's a harder sell when the PC is competing with phones, browsers, and cloud apps for people's attention. And unlike in the 1990s, Microsoft can't count on users to embrace what it's building. There's a growing sentiment that these AI capabilities are being pushed into Windows not because users want them, but because Microsoft needs to justify its massive AI investments. “They're thinking about revenue first and foremost,” longtime tech journalist and Microsoft observer Ed Bott said on the GeekWire Podcast at the time. Windows is unlikely to play that kind of outsized role again. Whether that ultimately looks like a restored Porsche or a rocket ship on the launchpad probably doesn't matter as much as keeping it out of the junkyard. Accenture proudly supports GeekWire in its latest series highlighting how companies are using agentic AI to reinvent. We're driving change across every industry with technology and human ingenuity. Contact us to learn more about how AI agents can help transform your organization. Click for more about underwritten and sponsored content on GeekWire. AI is coming for your shopping cart: How agentic commerce could disrupt online retail Microsoft adds Anthropic's Claude AI models to 365 Copilot as OpenAI relationship evolves Microsoft unveils AI agents for sales, striking back at Salesforce Microsoft unveils new autonomous AI agents in advance of competing Salesforce rollout</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/ex-amazon-ai-engineer-bets-six-figures-of-his-own-money-to-disrupt-drug-discovery/'>Ex-Amazon AI engineer bets six figures of his own money to disrupt drug discovery</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-30 15:16:58
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>After four years of working on AI projects at Amazon, Brace left the tech giant to self-fund his vision. After launching last year, the five-employee startup recently came out of stealth. Rather than working from existing molecule-building tools, Rhizome has built its own fine-tuned foundational model, named r1. The technology is a “graph neural network” and was trained on more than 800 million small drug-like molecules. They will ensure each drug candidate can be synthesized efficiently in the lab and is suitable for patent protection. Rhizome last week released ADAMS, an open-source, automated AI tool that uses natural language instructions for simulating the binding between biological molecules. It also plans to share MolSim, which is a physics-based simulation that uses advanced, free-energy calculations that predict how strongly a small molecule will bind to its target. Brace is operating out of Foundations, the Seattle-based startup community launched by entrepreneur and investor Aviel Ginzburg. “I really want to make Seattle kind of a hub for small molecule drug discovery,” Brace said. The region is also home to a slate of related drug design startups that include Pauling.AI, Synthesize Bio and Xaira Therapeutics, which is based in San Francisco and has labs in Seattle. Brace said he's energized by the opportunity to work on a project that could have a meaningful impact on humanity and has no regrets in ponying up his own money for the effort. “This is the most interesting problem space to be in,” Brace said. ‘Scientist-as-a-Service': Seattle startup Pauling.AI aims to shrink drug discovery timelines by months Seattle biotech startup Curi Bio lands $10M to expand its R&D support for drug discovery Tech Moves: GE healthcare exec joins startup; Nautilus taps new CMO; WRF investor steps down Fred Hutch leaders raise $10M for new AI startup aiming to expedite drug discovery</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/12/30/the-top-26-consumer-edtech-companies-from-disrupt-startup-battlefield/'>The top 26 consumer/edtech companies from Disrupt Startup Battlefield</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-30 15:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Every year, TechCrunch's Startup Battlefield pitch contest draws thousands of applicants. What it does: Helps people find places that are accessible to those with limited mobility. What it does: Uses nanophotonic technology to create lenses that enhance visual clarity. Why it's noteworthy: The company says that it has created breakthrough technology that helps people, especially those with conditions like headaches and dizziness, to withstand prolonged extended reality experiences. What it does: This Gen Z dating app is bringing back the way people used to meet — via mutual friends. Why it's noteworthy: It's the latest spin on a dating app during this time of romance app fatigue, trying to prove that digital love is still alive. Why it's noteworthy: The platform is using AI to offer insight into some of the most pressing questions founders always have — how to run and scale a business. It's an easier solution than trying to source information from various places by oneself. What it does: A platform where luxury hotels can give customers vouchers for services like spas and dining. What it does: A platform that lets users create AI videos. Why it's noteworthy: It's an AI tour guide, letting consumers guide themselves through a tour and personalize the experience to ways they see fit. What it does: Prickly Pear provides a voice AI companion for women that monitors brain health. Why it's noteworthy: This isn't a chatbot, but an AI is trained to decipher changes in language and context that could indicate cognitive issues, especially those arising from hormonal changes that women in their 30s to 50s experience. What it does: Rax is a peer-to-peer clothing rental platform. What it does: Helps people find friends within their professions over the internet. Why it's noteworthy: Unlike a social network, this app helps people identify potential friends and includes options like video calls and chats to help friendships sprout. What it does: Renude offers an AI-powered skin care recommendation engine for beauty brands. What it does: Offers a brain-computer interface intended to be used for hands-free everyday interaction. Why it's noteworthy: Snap interacts with game development platform Unity and is intended for a range of uses, from games to stress management. What it does: Tasteit is an app that helps people meet to dine together. Why it's noteworthy: Tasteit calls itself the anti-dating app, as its mission is to use food and dining out as a way for people to match and meet. What it does: Tattd is an AI-powered app that helps people find and book tattoo artists. Why it's noteworthy: It has created a tech called Micro Gimbal Stabilizer, small enough to be embedded in most mobile devices, that works well even in low-light conditions. What it does: A parental control app that watches over and prevents kids from engaging in unsafe online behavior. Why it's noteworthy: The app rewards kids' smart online choices and offers a distraction-blocking feature for study time. What it does: ZoraSafe identifies and protects consumers against scams. What it does: AI-powered training to improve an employee's workplace communications. What it does: CampusAI offers a flexible platform to train people on AI. What it does: The NeuroLingo headset helps people learn a foreign language. What it does: A story-time app for parents and kids. Why it's noteworthy: The app follows along with the words as they are being read aloud, automatically adding sounds and music at certain text sections, making stories more interactive. What it does: Super Teacher offers an AI-powered tutor for elementary schools. What it does: Zezedu is an AI-powered platform, developed in South Korea, that offers personalized math learning. Dominic-Madori Davis is a senior venture capital and startup reporter at TechCrunch. Meta just bought Manus, an AI startup everyone has been talking about Sauron, the high-end home security startup for ‘super premium' customers, plucks a new CEO out of Sonos NY Governor Hochul signs bill requiring warning labels on ‘addictive' social media How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming Nvidia to license AI chip challenger Groq's tech and hire its CEO Waymo explains why its robotaxis got stuck during the SF blackout</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=46433649'>The 70% AI productivity myth: why most companies aren't seeing the gains</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-30 14:31:03
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>"In the METR study, developers predicted AI would make them 24% faster before starting. Seems like it's been mentioned on HN before but not got much traction. Seems like it's been mentioned on HN before but not got much traction. Most people who cite it clearly didn't read as far as the table where METR themselves say:> We do not provide evidence that:> 1) AI systems do not currently speed up many or most software developers. Clarification: We do not claim that our developers or repositories represent a majority or plurality of software development work> 2) AI systems do not speed up individuals or groups in domains other than software development. Clarification: We only study software development> 3) AI systems in the near future will not speed up developers in our exact setting. Clarification: Progress is difficult to predict, and there has been substantial AI progress over the past five years [3]> 4) There are not ways of using existing AI systems more effectively to achieve positive speedup in our exact setting. Clarification: Cursor does not sample many tokens from LLMs, it may not use optimal prompting/scaffolding, and domain/repository-specific training/finetuning/few-shot learning could yield positive speeduphttps://metr.org/blog/2025-07-10-early-2025-ai-experienced-o... Clarification: We do not claim that our developers or repositories represent a majority or plurality of software development work> 2) AI systems do not speed up individuals or groups in domains other than software development. Clarification: We only study software development> 3) AI systems in the near future will not speed up developers in our exact setting. Clarification: Progress is difficult to predict, and there has been substantial AI progress over the past five years [3]> 4) There are not ways of using existing AI systems more effectively to achieve positive speedup in our exact setting. Clarification: Cursor does not sample many tokens from LLMs, it may not use optimal prompting/scaffolding, and domain/repository-specific training/finetuning/few-shot learning could yield positive speeduphttps://metr.org/blog/2025-07-10-early-2025-ai-experienced-o... > 1) AI systems do not currently speed up many or most software developers. Clarification: We do not claim that our developers or repositories represent a majority or plurality of software development work> 2) AI systems do not speed up individuals or groups in domains other than software development. Clarification: We only study software development> 3) AI systems in the near future will not speed up developers in our exact setting. Clarification: Progress is difficult to predict, and there has been substantial AI progress over the past five years [3]> 4) There are not ways of using existing AI systems more effectively to achieve positive speedup in our exact setting. Clarification: Cursor does not sample many tokens from LLMs, it may not use optimal prompting/scaffolding, and domain/repository-specific training/finetuning/few-shot learning could yield positive speeduphttps://metr.org/blog/2025-07-10-early-2025-ai-experienced-o... > 2) AI systems do not speed up individuals or groups in domains other than software development. Clarification: We only study software development> 3) AI systems in the near future will not speed up developers in our exact setting. Clarification: Progress is difficult to predict, and there has been substantial AI progress over the past five years [3]> 4) There are not ways of using existing AI systems more effectively to achieve positive speedup in our exact setting. Clarification: Cursor does not sample many tokens from LLMs, it may not use optimal prompting/scaffolding, and domain/repository-specific training/finetuning/few-shot learning could yield positive speeduphttps://metr.org/blog/2025-07-10-early-2025-ai-experienced-o... Clarification: Progress is difficult to predict, and there has been substantial AI progress over the past five years [3]> 4) There are not ways of using existing AI systems more effectively to achieve positive speedup in our exact setting. Clarification: Cursor does not sample many tokens from LLMs, it may not use optimal prompting/scaffolding, and domain/repository-specific training/finetuning/few-shot learning could yield positive speeduphttps://metr.org/blog/2025-07-10-early-2025-ai-experienced-o... > 4) There are not ways of using existing AI systems more effectively to achieve positive speedup in our exact setting. Clarification: Cursor does not sample many tokens from LLMs, it may not use optimal prompting/scaffolding, and domain/repository-specific training/finetuning/few-shot learning could yield positive speeduphttps://metr.org/blog/2025-07-10-early-2025-ai-experienced-o... Their study still shows something interesting, and quite surprising. But if you choose to extrapolate from this specific setting and say coding assistants don't work in general then that's not scientific and you need to be careful.I think the studyshould probably decrease your prior that AI assistants actually speed up development, even if developers using AI tell you otherwise. I think the studyshould probably decrease your prior that AI assistants actually speed up development, even if developers using AI tell you otherwise. Being armed with that knowledge is useful when thinking about my own productivity, as I know that there's a risk of me over-estimating the impact of this stuff.But then I look at https://github.com/simonw which currently lists 530 commits over 46 repositories for the month of December, which is the month I started using Opus 4.5 in Claude Code. But then I look at https://github.com/simonw which currently lists 530 commits over 46 repositories for the month of December, which is the month I started using Opus 4.5 in Claude Code. I liked the way they did that study and I would be interested to see an updated version with new tools.I'm not particularly sceptical myself and my guess is that using Opus 4.5 would probably have produced a different result to the one in the original study. I'm not particularly sceptical myself and my guess is that using Opus 4.5 would probably have produced a different result to the one in the original study. It (along with the hundreds of billions in investments hinging on it), explains the legions of people online who passionately defend their "system". blogs about playing slots machines where they share their tips and tricks. blogs about playing slots machines where they share their tips and tricks. It reminds me of global warming where on one side of the debate there some scientists with very little money running experiments and on the other side there were some ridiculously wealthy corporations publicly poking holes in those experiments but who secretly knew they were valid since the 1960s. I ran a three month experiment with two of our projects, one Django and the other embedded C and ARM assembler. and not too long after that you end up in hell. I used both ChatGPT and Cursor for this.The only way to use LLMs effectively was to carefully select small chunks of code to work on, have it write the code and then manually integrate into the codebase after carefully checking it and ensuring it didn't want to destroy 10 other files. The only way to use LLMs effectively was to carefully select small chunks of code to work on, have it write the code and then manually integrate into the codebase after carefully checking it and ensuring it didn't want to destroy 10 other files. The first time i almost lost my cool at work and said a negative thing to a coworker.This would be my advice to juniors (and i mean basically: devs who don't yet understand the underlying business/architecture): use the AI to explain how stuff work, generate basic functions maybe, but write code logic/algorithm yourself until you are sure you understand what you're doing and why. Work and reflect on the data structures by yourself, even if generated by the AI, and ask for alternatives. This would be my advice to juniors (and i mean basically: devs who don't yet understand the underlying business/architecture): use the AI to explain how stuff work, generate basic functions maybe, but write code logic/algorithm yourself until you are sure you understand what you're doing and why. Work and reflect on the data structures by yourself, even if generated by the AI, and ask for alternatives. Losing your cool is never a good idea, but this is absolutely a time when you should give negative feedback to that coworker. Now question is..is AI providing solutions smarter than the developer using it might have produced?And perhaps more importantly, How much time it takes AI to write code and human to debug it, even if both are producing equally smart solutions. is AI providing solutions smarter than the developer using it might have produced?And perhaps more importantly, How much time it takes AI to write code and human to debug it, even if both are producing equally smart solutions. And perhaps more importantly, How much time it takes AI to write code and human to debug it, even if both are producing equally smart solutions. * Force the AI to write tests for everything. There's no excuse for a code regression making it's way into a PR because you actually ran the tests before you did the commit, right? * Force the AI to write documentation and properly comment code, then (this is the tricky part) you actually read what it said it was doing and ensure that this is what you wanted it to do before you commit.Just doing these two things will vastly improve the quality and prevent most of the dumb regressions that are common with AI generated code. * Force the AI to write documentation and properly comment code, then (this is the tricky part) you actually read what it said it was doing and ensure that this is what you wanted it to do before you commit.Just doing these two things will vastly improve the quality and prevent most of the dumb regressions that are common with AI generated code. Just doing these two things will vastly improve the quality and prevent most of the dumb regressions that are common with AI generated code. I've had this happen to me on one or two tests every time For some reason Gemini seems to be worse at it than Claude lately. Since mostly moving to 3 I've had it go back and change the tests rather than fixing the bug on what seems to be a regular basis. You really do still have to pay attention that the tests are valid. I don't think this is a coincidence.Writing useful tests is just as important as writing app code, and should be reviewed with equal scrutiny. Code review the AI generated code line by line to ensure it's exactly what you'd have produced yourself when it is generated or2. Pay an unknown amount of tech tebt down the road when it inevitably wasn't what you'd have done yourself and it isn't extensible, scalable, well written code. Code review the AI generated code line by line to ensure it's exactly what you'd have produced yourself when it is generated or2. Pay an unknown amount of tech tebt down the road when it inevitably wasn't what you'd have done yourself and it isn't extensible, scalable, well written code. Pay an unknown amount of tech tebt down the road when it inevitably wasn't what you'd have done yourself and it isn't extensible, scalable, well written code. I've been experimenting with having claude work on some code and commit it, and then having codex review the changes in the most recent git commit, then eyeballing the recommendations and either having codex work the changes, or giving them back to claude. That has seemed to be quite effective so far.Maybe it's turtles all the way down? Garage Duo can out-compete corporate because there is less overhead. But Garage Duo can't possibly output the sheer amount of work matching with corporate. I think that the reason LLMs don't work as well in a corporate environment with large codebases and complex business logic, but do work well in greenfield projects, is linked to the amount of context the agents can maintain.Many types of corporate overhead can be reduced using an LLM. Especially following "well meant but inefficient" process around JIRA tickets, testing evidence, code review, documentation etc. Many types of corporate overhead can be reduced using an LLM. Especially following "well meant but inefficient" process around JIRA tickets, testing evidence, code review, documentation etc. There have been methods to reduce overhead available over the history of our industry. Unfortunately almost all the times it involves using productive tools that would in some way reduce the head counts required to do large projects.The way this works is you eventually have to work with languages like Lisp, Perl, Prolog, and then some one comes up with a theory that programming must be optimised for the mostly beginners and power tooling must be avoided. Now you are forced to use verbose languages, writing, maintaining and troubleshooting take a lot of people.The thing is this time around, we have a way to make code by asking an AI tool questions. So you get the same effect but now with languages like JS and Python. The way this works is you eventually have to work with languages like Lisp, Perl, Prolog, and then some one comes up with a theory that programming must be optimised for the mostly beginners and power tooling must be avoided. Now you are forced to use verbose languages, writing, maintaining and troubleshooting take a lot of people.The thing is this time around, we have a way to make code by asking an AI tool questions. So you get the same effect but now with languages like JS and Python. The thing is this time around, we have a way to make code by asking an AI tool questions. So you get the same effect but now with languages like JS and Python. I think for users this _feels_ incredibly powerful, however this also has its own pitfalls: Any topic which you're incompetent at is one which you're also unequipped to successfully review.I think there are some other productivity pitfalls for LLMs:- Employees use it to give their boss emails / summaries / etc in the language and style their boss wants. This makes their boss happy, but doesn't actually modify productivity whatsoever since the exercise was a waste of time in the first place.- Employees send more emails, and summarize more emails. The email volume has increased, however the emails themselves were probably a waste of time in the first place.- There is more work to review all around and much of it is of poor quality.I think these issues play a smaller part than some of the general issues raised (eg: poor quality code / lack of code reviews / etc.) I think there are some other productivity pitfalls for LLMs:- Employees use it to give their boss emails / summaries / etc in the language and style their boss wants. This makes their boss happy, but doesn't actually modify productivity whatsoever since the exercise was a waste of time in the first place.- Employees send more emails, and summarize more emails. The email volume has increased, however the emails themselves were probably a waste of time in the first place.- There is more work to review all around and much of it is of poor quality.I think these issues play a smaller part than some of the general issues raised (eg: poor quality code / lack of code reviews / etc.) This makes their boss happy, but doesn't actually modify productivity whatsoever since the exercise was a waste of time in the first place.- Employees send more emails, and summarize more emails. The email volume has increased, however the emails themselves were probably a waste of time in the first place.- There is more work to review all around and much of it is of poor quality.I think these issues play a smaller part than some of the general issues raised (eg: poor quality code / lack of code reviews / etc.) The email volume has increased, however the emails themselves were probably a waste of time in the first place.- There is more work to review all around and much of it is of poor quality.I think these issues play a smaller part than some of the general issues raised (eg: poor quality code / lack of code reviews / etc.) I think these issues play a smaller part than some of the general issues raised (eg: poor quality code / lack of code reviews / etc.) This is the average software developer's experience of LLMs This is completely orthogonal to productivity gains for full time professional developers. The job of anyone developing an application framework, whether that's off the shelf or in-house, is to reduce the amount of boilerplate any individual developer needs to write to an absolute bare minimum. Complex legacy refactoring + Systems with poor documentation or unusual patterns + Architectural decisions requiring deep context: These go hand in hand. LLMs are really good at pulling these older systems apart, documenting, then refactoring them, tests and all. You'll get to 80% system comprehension in a matter of months.Novel problem-solving with high stakes: This is the true bottleneck, and where engineers can shine. Risk assessment and recombination of ideas, with rapid prototyping. Novel problem-solving with high stakes: This is the true bottleneck, and where engineers can shine. Risk assessment and recombination of ideas, with rapid prototyping. Force the LLM to follow a workflow, have it do TDD, use task lists, have it write implementation plans.LLMs are great coders, but subpar developers, help them be a good developer and you will see massive returns. LLMs are great coders, but subpar developers, help them be a good developer and you will see massive returns. I did not get the impression from this that LLMs were great coders. They would frequently miss stuff, make mistakes and often just ignore the instructions i gave them.Sometimes they would get it right but not enough. The agentic coding loop still slowed me down overall. Perhaps if i were more junior it would have been a net boost. Sometimes they would get it right but not enough. The agentic coding loop still slowed me down overall. Perhaps if i were more junior it would have been a net boost. If you go the pure subjective route, I've found that people conflate “speed” or “productivity” with “ease.” We have a lot of useless work being done, and AI is absolutely going to be a 10x speed up for this kind of work. In programming we've often embraced spending time to learn new tools. The AI tools are just another set of tools, and they're rapidly changing as well.I've been experimenting seriously with the tools for ~3 years now, and I'm still learning a lot about their use. Just this past weekend I started using a whole new workflow, and it one-shotted building a PWA that implements a fully-featured calorie tracking app (with social features, pre-populating foods from online databases, weight tracking and graphing, avatars, it's on par with many I've used in the past that cost $30+/year).Someone just starting out at chat.openai.com isn't going to get close to this. Just this past weekend I started using a whole new workflow, and it one-shotted building a PWA that implements a fully-featured calorie tracking app (with social features, pre-populating foods from online databases, weight tracking and graphing, avatars, it's on par with many I've used in the past that cost $30+/year).Someone just starting out at chat.openai.com isn't going to get close to this. This is bad for people who used to leverage the difficulty of the task to their own advantage, but good for everyone else.Also, keep in mind that todays LLM's are the worst they'll ever be. They will continue to improve, and you will stagnate if you don't learn to use the new tools effectively. We can now use English as that language, which allows more people than ever to program. This is bad for people who used to leverage the difficulty of the task to their own advantage, but good for everyone else.Also, keep in mind that todays LLM's are the worst they'll ever be. They will continue to improve, and you will stagnate if you don't learn to use the new tools effectively. Also, keep in mind that todays LLM's are the worst they'll ever be. They will continue to improve, and you will stagnate if you don't learn to use the new tools effectively. Specifically teaching myself graphics and mastering the C language. Understanding a "deeper" abstraction layer is almost always to your advantage, even if you seldom use it in your career. You'll find that employers don't want esoteric knowledge or all-knowing wizards who can see the matrix. Mostly, they just want a team member who can cooperate with other folks to get things done in whatever tool they can find enough skilled folks to use. You'll find that employers don't want esoteric knowledge or all-knowing wizards who can see the matrix. Mostly, they just want a team member who can cooperate with other folks to get things done in whatever tool they can find enough skilled folks to use. this hostile marketing scheme is the reason for my hostile opposition to LLMs and LLM idiots.LLMs do not make you smarter or a more effective developer.You are a sucker if you buy into the hype. Their technology moves at a much slower rate and does not require you to learn new things. There's a debate to be had about what any given new technology is good for and how to use it because they all market themselves as the best thing since sliced bread. I use Sonnet all the time as a research tool, it's kind of great. I've also tried lots of stuff that doesn't work.But the attitude towards everyone who isn't an AI MAXIMALIST does not persuade anyone or contribute to this debate in any useful way.Anyway if I get kicked out of the industry for being a heretic I think I'll go open an Italian restaurant. But the attitude towards everyone who isn't an AI MAXIMALIST does not persuade anyone or contribute to this debate in any useful way.Anyway if I get kicked out of the industry for being a heretic I think I'll go open an Italian restaurant. Here's where our opinions differ - I think replacing that Figma person with AI prompts will negatively affect product in a way that is noticeable to the end-user and effects their experience.It does of course depend what kind of product you're making, but I'd say most of the time this holds. If they can't, did they really do it in the first place?Could people write code without use after free bugs without using a GC'd language? If they can't, did they really do it in the first place?Could people make a website without WYSIWYG editor? If they can't, did they really do it in the first place?Could people make a website without WYSIWYG editor? I think graduates of these programs are far, far worse software developers than they were in the recent past.edit: i think you mean "irrelevant", not "irreverent". But this subthread is about interns who did not study CS, and are able to create advanced UIs using LLMs in the short time they had left to finish their project. Based on what I've seen, the "illiterate" are those who would have otherwise dropped out or done a poor job previously. Now instead of exiting the field, or slowly shipping code they didn't understand (because that has always been a thing) they are shovelling more slop.That's a problem, but it's at most gotten worse rather than come out of thin air.But, there are still competent software engineers and I have seen with my own eyes how AI usage makes them more productive.Similarly, some of those "illiterate" are those who now have the ability to make small apps for themselves to solve a problem they would not be able to before, and I argue that's a good thing.Ultimately, people care about the solution to their problems, not the code. If (following the original anecdote) someone with an LLM can build a UI for their project I frankly don't think it matters whether they understood the code. That's a problem, but it's at most gotten worse rather than come out of thin air.But, there are still competent software engineers and I have seen with my own eyes how AI usage makes them more productive.Similarly, some of those "illiterate" are those who now have the ability to make small apps for themselves to solve a problem they would not be able to before, and I argue that's a good thing.Ultimately, people care about the solution to their problems, not the code. If (following the original anecdote) someone with an LLM can build a UI for their project I frankly don't think it matters whether they understood the code. But, there are still competent software engineers and I have seen with my own eyes how AI usage makes them more productive.Similarly, some of those "illiterate" are those who now have the ability to make small apps for themselves to solve a problem they would not be able to before, and I argue that's a good thing.Ultimately, people care about the solution to their problems, not the code. If (following the original anecdote) someone with an LLM can build a UI for their project I frankly don't think it matters whether they understood the code. Similarly, some of those "illiterate" are those who now have the ability to make small apps for themselves to solve a problem they would not be able to before, and I argue that's a good thing.Ultimately, people care about the solution to their problems, not the code. If (following the original anecdote) someone with an LLM can build a UI for their project I frankly don't think it matters whether they understood the code. If (following the original anecdote) someone with an LLM can build a UI for their project I frankly don't think it matters whether they understood the code. would you agree that LLMs make developer stupider?edit: answer my question Looking at the brief history of their account, I don't think anything they are saying or asking is in remotely good faith. As a comment reader this exchange with Simon translates directly to "no, but you have forced me to try and misdirect because I can't reply in good faith to an expert who has forgotten more about LLMs than I'll ever know". developers can exist in a small team, solo, large enterprise all with their mandates and cultures so just saying LLMs increase/decrease is reductive.have a feeling i'm being trolled tho. I think LLM addicts are particularly susceptible to flattery.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/100kw-iron-beam-laser-becomes-worlds-first-drone-defense-zapper-to-be-operationally-deployed-it-can-also-shoot-down-rockets-mortars-and-other-aerial-threats'>100,000-Watt Iron Beam laser becomes world's first drone defense zapper to be operationally deployed — it can also shoot down rockets, mortars, and other aerial threats</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-30 14:19:25
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. The first Iron Beam laser defense system was deployed by Israel on Sunday. This 100kW laser weapon thus became the world's first high-power drone defense zapper to be operationally deployed. The Iron Beam is a short-range line-of-sight laser interceptor that is extremely cheap to run and, therefore, perfectly suited for intercepting low-cost, high-volume threats. According to the official Israeli announcement, Iron Beam systems have “successfully intercepted rockets, mortars, and UAVs.” A complex mix of government, military, scientific, and commercial interests were responsible for the research and development of the Iron Beam laser system. Central to the Iron Beam are “an advanced laser source and a unique electro-optical targeting system, enabling the interception of a wide range of targets at an enhanced operational range, with maximum precision and superior efficiency,” boasted the press release by Israel's MoD. Moreover, it works “at a negligible marginal cost, which constitutes the laser system's primary advantage.” We don't get much more by way of technical details, perhaps understandably. We have seen low-energy laser defense systems deployed earlier this year, with Japan's NTT using relatively puny lasers to scare birds away from poultry farms and prevent the spread of avian flu. With the brutal war between Ukraine and Russia ongoing, where drones have grown to be a pivotal feature of the conflict, laser-drone defenses similar to the Iron Beam are going to be in strong demand. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/networking/start-up-proposes-scaled-up-ai-data-center-active-radio-cable-connectivity-radio-based-interconnections-operating-at-millimeter-wave-and-terahertz-frequencies-offer-1-6-tb-s-using-half-the-volume-of-copper'>Start-up plans to use terahertz radio frequencies for communication between servers instead of copper or optical connections — radio-based interconnections offer 1.6 TB/s using half the volume of copper</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-30 13:59:51
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. Scale-up connectivity is crucial for the performance of rack-scale AI systems, but achieving high bandwidth and low latency for such interconnections using copper wires is becoming increasingly complicated with each generation. Using optical interconnections for scale-up connectivity is a possibility, but it may be an overkill, so start-ups Point2 and AttoTude propose to use radio-based interconnections operating at millimeter-wave and terahertz frequencies over waveguides that connect to systems using standard pluggable connectors, reports IEEE Spectrum. Point2's implementation uses what it calls an 'active radio cable' built from eight 'e-Tube' waveguides. A full cable delivers 1.6 Tb/s, occupies 8.1mm, or about a half the volume of a comparable active copper cable, and can reach up to seven meters, more than enough for scale-up connectivity. The radio transceivers can be fabricated at standard semiconductor production facilities using well-known fabrication processes — the company has already demonstrated this approach using a 28nm chip with the Korea Advanced Institute of Science and Technology (KAIST). Also, its partners Molex and Foxconn Interconnect Technology have shown that the specialized cables can be produced on existing lines without major retooling. AttoTude is pursuing a similar concept, but at even higher frequencies. Early versions used hollow copper tubes, while later generations rely on fibers measuring approximately 200 micrometers across with losses as low as 0.3 dB per meter (considerably lower than copper). While at very high data rates copper cables can pass signals, they do so by becoming thicker, shorter, and more power-hungry. Furthermore, their losses and jitter rise so fast that the link budget collapses and breaks, so cables cannot be used for such applications. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Anton Shilov is a contributing writer at Tom's Hardware. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York,</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=46433117'>MH370 vanished in 2014.New search aims to find answers families desperately want</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-30 13:29:12
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Then there's Helios that crashed near Athens. By the time a cabin crew member with portable oxygen figured out how to get through the door, the fuel was about to run out. I'm sure there has been a lot of thought put into this locking mechanism so that hijackers can't access the cockpit, but how about the rogue pilot scenario like this one? IIRC, pilots outside can enter a code to unlock the door but it can be rejected by the person inside (so it really only applies if they're incapacitated)EDIT: it appears some airlines mandate at least two people in the cockpit at all times after the 2015 Germanwings incident. EDIT: it appears some airlines mandate at least two people in the cockpit at all times after the 2015 Germanwings incident. > New York has obtained a confidential document from the Malaysian police investigation into the disappearance of Malaysia Airlines Flight 370 that shows that the plane's captain, Zaharie Ahmad Shah, conducted a simulated flight deep into the remote southern Indian Ocean less than a month before the plane vanished under uncannily similar circumstances. I've lived in the region...But since we're not citing links, this is all gossip... But since we're not citing links, this is all gossip... Whether this happened before or after the course change is unknown.Given the minimal wreckage, it was likely a soft landing in the ocean rather than the pilot succumbing to a medical event. It's likely the pilot depressurized the cabin as hypoxia would've rendered the crew and passengers so they were unliikely conscious for any of this. I am curious, did changes take place due to this event ? Like real-time telemetry for airliners where their location is always available and saved on systems not on the plane.I remember during the search the commentators said that was not done because Airlines did not want spend for that. I remember during the search the commentators said that was not done because Airlines did not want spend for that. Edited to add: There are also discussions underway on how to better handle pilots suffering from depression, since pilots are currently incentivized to never disclose mental health problems for fear of losing their livelihoods. Mentour Pilot talks about this too at the end of his Germanwings video: https://www.youtube.com/watch?v=lotcRYD42e0 Put a flight attendant in there?</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/review/commodore-64-ultimate/'>The Commodore 64 Ultimate Is an Authentic Re-Creation for Die-Hard Fans</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-30 12:30:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>It's hard to overstate just how seismic an impact the Commodore 64 had on home computing. Launched in 1982, the 8-bit machine—iconic in its beige plastic shell with integrated keyboard—went on to become the best-selling personal computer of all time. Then, retro gaming YouTuber Christian “Peri Fractic” Simpson got the bright idea to buy the company wholesale and re-create its most important piece of hardware. If it weren't for the distinctly un-yellowed plastic shell, it could be mistaken at a glance for the real thing, leftover stock straight from 1982. At its core, this is a field programmable gate array (FPGA) device, an approach most often seen to re-create classic game consoles (as with the recent Analogue3D “remake” of the Nintendo 64). To strip the idea right back, FPGAs tell one chipset to pretend it's another and, ideally, allow for performance near-identical to the original machine at a hardware level, rather than through emulation. This goes a step further, boasting a heap of physical connectors and ports that allow you to use authentic peripherals from the '80s. If you still have your original joysticks or datasette to hand, they should all work as they did back in the day. For fans, collectors, or anyone who has their original Commodore gadgets stashed in a garage somewhere, that's a fantastic proposition. The revived Commodore International hasn't quite put the classic hardware back into production, but this comes damned close. There are a pair of USB-A ports at the rear, where you'll connect the cassette-shaped USB stick that comes with each unit, pre-loaded with games, software demos, music that makes use of the C64's still legendary audio capabilities, and GEOS, a graphical user interface—more on that later. Even there, though, there's still the option for connecting to a CRT monitor, making the additions feel more like a tweak than an overhaul. And, despite the presence of those USB ports, you can't use a modern mouse with the C64U—you'll either need a period piece or set the WASD keys to act as a virtual joystick whenever you might need to manipulate an onscreen cursor. There's almost a sense of resentment here, as if anything too modern would be a desecration of the holy hardware, and any concessions made to ensure the C64U is even halfway usable with present-day displays or add-ons were made reluctantly. The Commodore International of 2025, leaning into its deliberately dated approach, is another fascinating aspect of the Commodore 64 Ultimate. That actually appeals—I'm particularly sick of Windows cramming adverts into every corner of the OS and foisting unwanted AI features where they don't belong (and then warning people not to use them anyway), so maybe a trip back to how computing used to be done would be a virtual balm. Unfortunately, that means travelling back to a time before I was actually born, and the temporal whiplash is brutal. Be forewarned: If you do not have first-hand experience of the original Commodore 64, a deep and abiding love for its genuinely ground-breaking era of home computing, or a burning curiosity for retro technology, the C64 Ultimate is far from welcoming, and probably not for you. Yet even then, getting used to the C64 environment is a steep learning curve. Here, you can type in operation commands just as you would back in the day, using the BASIC programming language. Problem: I don't have the first clue about BASIC. Equal parts history book and instruction manual, it starts out teaching you some simple commands and builds up to teaching you how to code. I'm still very much working my way through it, but that tactile approach—referring to the book, trying something out on the computer, back and forth—is a great touch. If you don't fancy having to do homework, the C64U's own default menu, accessed at any time with a flick of the multifunction power button on the right-hand side of the unit, is a simple list of options and settings. Hit RETURN to go into any section—say, “Video Setup” to adjust whether the C64U outputs in original resolution, in PAL or NTSC modes (surprisingly important, given some games will only work with one display standard or the other), or a crystal clear 1080p with scanlines removed—and back out to save any changes to the system's flash memory. It's still a minimalist approach, but feels fairly intuitive. This is also where you can start playing around with some of the other modern touches of the C64U, like how to leverage its far greater power. Spec-wise, this isn't going to threaten any more modern machine, but running on an AMD Xilinx Artix-7 FPGA chip and packing 128-MB DDR2 RAM—compared to the 64 KB of the C64—it blows its inspiration out of the water. While at baseline it replicates the performance of the 1982 hardware, meaning it operates as if there's only the original 64 KB were there, you can menu-dive to activate a virtualized RAM Expansion Unit, or activate a “Turbo Boost” to accelerate the clock speed to a lightning-fast (in this particular context) 64 MHz. Then there's GEOS, loaded on that cassette-shaped USB. This is the closest to a Windows or macOS type experience on the Commodore, a “regular” desktop environment. However, while GEOS is clearer than BASIC, it's still not as smooth as more modern graphical user interface (GUI) operating systems. I've found it a little confusing switching between programs, for instance, as they seem to need to be mounted and then loaded into the OS before opening them. Even writing that back from my notes, preparing this review, I'm honestly not sure if I've been doing it correctly. Plus, when something doesn't work—failing to create a new document in GEOS apps like its word processor or paint suite was a low point—there's rarely an explanation of why it hasn't. Away from “proper” computing, the C64 was a pioneer for home gaming, and that's one area where the C64U does feel extremely accessible. The USB drive includes a host of classic and modern retro-style games, and more can be added in the form of disk images if you have them. Once you've chosen what you want to play, an internal speaker mimics the sounds of the original tape or disk drive as it loads up, which is a nice—and extremely nerdy—touch. Maybe it's part of that digital detox approach, an attempt to teach us whippersnappers younger than the C64 itself some patience, but I wouldn't have minded losing that particular aspect of the traditional Commodore experience. Yes, it's tremendously accurate to the experience of using a Commodore 64 four decades ago, but who does that serve in 2025? Its proposition of a return to distraction-free computing could be a distinctive selling point, but I'm not sure that this much of a throwback, with its ponderous nature and leisurely pace of doing anything, is going to win many converts. Even for those with the necessary levels of nostalgia, if that hankering is mainly for the C64's games, this is probably too much—emulation or those earlier C64 hardware re-creations that focused more on gaming are probably better options. Despite all that, the Commodore 64 Ultimate really is an exceptional piece of kit. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/desktops/gaming-pcs/grab-this-4k-gaming-pc-with-an-rtx-5080-and-9800x3d-for-just-usd2-499-before-prices-skyrocket-usd200-saving-on-powerful-skytech-rig-with-32gb-of-ddr5-ram-and-1tb-ssd'>Grab this 4K gaming PC with an RTX 5080 and 9800X3D for just $2,499 before prices skyrocket — $200 saving on powerful Skytech rig with 32GB of DDR5 RAM and 1TB SSD</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-30 12:01:28
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>This Skytech PC has epic specs for 4K and VR gaming When you purchase through links on our site, we may earn an affiliate commission. That isn't the case with this Skytech gaming PC, on sale at Newegg ahead of the new year with a very respectable $200 discount that pushes it under $2,500. For the $2,499.99 sale price, you're getting a Skytech Gaming Azure 3 Plus gaming PC that's packed with a serious spec sheet for gamers. Front and center is the AMD Ryzen 7 9800X3D, one of the best CPUs you can buy right now, along with an Nvidia GeForce RTX 5080, an elite-level GPU with 16GB of VRAM. It has 32GB of DDR5-6000 RAM and a 1TB M.2 NVMe SSD with Gen 4 speeds. Our 9800X3D review explains in depth why this eight-core CPU is a powerhouse for gamers, fitted with its game-changing 3D V-Cache, which boosts the available L3 cache to 96MB, reducing the dependency on your system RAM and vastly reducing latency as a result. If you want an all-out rig that can push the limits of your hardware at 4K, with ray tracing and other goodies enabled, this is the CPU you'll want in your machine. These two components alone set the tone for this Skytech gaming PC. This is a rig ready for 4K gaming, able to utilize the full power offered by Nvidia's Blackwell GPU, including DLSS 4 with ray tracing enabled in the games that support it. As long as you have a gaming monitor that can match it, this $2,499 machine offers performance that few other pre-build PCs can offer at this price point. You're also getting 32GB of DDR5 memory, rated for 6,000 MT/s, with RGB lighting. This rig also uses a 360mm AIO cooler with ARGB fans to keep your expensive CPU cool. This $2,499.99 Skytech gaming PC isn't one you should easily dismiss in the current climate, especially with these specs. With PC prices expected to rise by around 8% next year due to the skyrocketing cost of flash memory, not to mention the risk of global economic crises, this might be one of the last chances to score a pre-built PC with these specs at a reasonable price. Don't expect this deal to be around for long. Ben Stockton is a deals writer at Tom's Hardware. He's been writing about technology since 2018, with bylines at PCGamesN, How-To Geek, and Tom's Guide, among others. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/departing-nyc-mayor-adams-next-wants-to-fix-education-violence-and-antisemitism-with-crypto-2000704160'>Departing NYC Mayor Adams Next Wants to Fix Education, Violence, and Antisemitism with Crypto</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-30 10:30:08
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Outgoing New York City Mayor Eric Adams loves crypto. He created a mayoral “Office of Digital Assets and Blockchain,” and supposedly had his first three paychecks converted to bitcoin so the city could even pay him in crypto. And in remarks made Monday at what was probably his final press conference as mayor, he indicated that his love affair with crypto is only intensifying. In fact, Adams is somehow going to fix violence, education, and antisemitism with crypto, he says. I cannot tell you … I've said over and over again, anyone would like to finish a job that you started.” And then he uttered three or four partial sentences I truly could not parse. Then he got his answer back on track with the following: But I also want to use cryptocurrency to go after violence, educate our children, and really deal with antisemitism that we're seeing globally. Is he turning his time machine back to 2021 and starting a DAO to tackle violence, education, and antisemitism? For now, I think it's best to assume he was just expressing himself artistically at this press conference, and that the statement was a sort of Etsy-style mood board in spoken word form. Incidentally, 2025 was an absolutely massive year for lobbying in the crypto industry. According to the Hill, by July of this year no fewer than 27 crypto companies had filed their initial lobbying disclosures. Also in July, Politico reported that Coinbase erected branded vending machines on the National Mall and distributed 5,000 Coinbase chocolate bars, with a representative explaining that they were trying to “create a sugar rush for crypto across the Capitol.” If they're looking for more ideas like that one—and I truly mean this—they'd be fools to hire anyone other than the inventor of the phrase “All my haters become my waiters when I sit down at the table of success.” And they don't even have to pay him in real money. Subscribe and interact with our community, get up to date with our customised Newsletters and much more. It doesn't sound fun being a crypto juror. "Mention markets" are the new cash grab. Fed chair Jerome Powell made some on Wall Street uneasy when he signaled that another rate cut was no guarantee when the Fed meets again.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/12/29/meta-just-bought-manus-an-ai-startup-everyone-has-been-talking-about/'>Meta just bought Manus, an AI startup everyone has been talking about</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-30 05:39:08
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Meta Platforms is acquiring Manus, a Singapore-based AI startup that's become the talk of Silicon Valley since it debuted last spring with a demo video that showed an AI agent doing things like screening job candidates, planning vacations, and analyzing stock portfolios. In April, just weeks after launch, venture capital firm Benchmark led a $75 million funding round that assigned Manus a post-money valuation of $500 million and saw Benchmark general partner Chetan Puttagunta joining the startup's board. Per Chinese media outlets, some other big-name backers had already invested in Manus at that point, including Tencent, ZhenFund, and HSG (formerly known as Sequoia China) via a $10 million round. The company announced in mid December that it has since signed up millions of users and is generating annual recurring revenue of more than $100 million from monthly and year subscribers to its membership service. This is especially pertinent given that investors have grown increasingly twitchy about Meta's $60 billion infrastructure spending spree, and the broader tech industry's debt-backed expenditures on data center construction. Cornyn, a Texas Republican and senior member of the Senate Intelligence Committee, has long been one of Congress' most vocal hawks on China and technology competition, but he's hardly alone. Being tough on China has become one of the genuinely bipartisan issues in Congress. Unsurprisingly, Meta has already told Nikkei Asia that after the acquisition, Manus won't have any ties to Chinese investors and will no longer operate in China. “There will be no continuing Chinese ownership interests in Manus AI following the transaction, and Manus AI will discontinue its services and operations in China,” a Meta spokesperson told the outlet. Meta just bought Manus, an AI startup everyone has been talking about Sauron, the high-end home security startup for ‘super premium' customers, plucks a new CEO out of Sonos NY Governor Hochul signs bill requiring warning labels on ‘addictive' social media How reality crushed Ÿnsect, the French startup that had raised over $600M for insect farming</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            