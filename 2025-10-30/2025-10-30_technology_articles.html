
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - TECHNOLOGY Article Summaries - 2025-10-30</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            TECHNOLOGY
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=45762837'>Some People Can't See Mental Images. The Consequences Are Profound</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 17:47:08
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Not that there isn't a difference in ability, just that it's not as dramatic/binary as we seem to think. Then I started interrogating all of the people who claimed to “visualise” things and it turned out we were all doing the same thing This is the quintessential aphantasic experience. I still struggle to believe that other people "see" things in their heads. What you consider to be "seeing" things in one's head may be not what's happening in that person's mind. What they call "seeing" may be something else.The best way I can describe it is essentially generating a memory. If I were instructed to picture an apple in my mind, I could imagine a hand holding up an bog standard Red Delicious. And it would be much like when I remember what happened yesterday for instance. Of course, we get into whether or not we "see" the memory or not.So, if you are saying you do not consider yourself to have mental images, what, to your best ability to describe it, do you do when you remember an event? The best way I can describe it is essentially generating a memory. If I were instructed to picture an apple in my mind, I could imagine a hand holding up an bog standard Red Delicious. And it would be much like when I remember what happened yesterday for instance. Of course, we get into whether or not we "see" the memory or not.So, if you are saying you do not consider yourself to have mental images, what, to your best ability to describe it, do you do when you remember an event? https://lianamscott.com/wp-content/uploads/2022/10/f4c55-1_b...As in: if you look at this image, can you place yourself on a scale of 1 - 5 of as to the fidelity with which you can picture an apple if you try to imagine it?I'm a 5 for example, and in asking many people this question I've gotten a solid spectrum of answers from 1 - 5. Generally in a single group of a handful of people I'll get several different numbers. As in: if you look at this image, can you place yourself on a scale of 1 - 5 of as to the fidelity with which you can picture an apple if you try to imagine it?I'm a 5 for example, and in asking many people this question I've gotten a solid spectrum of answers from 1 - 5. Generally in a single group of a handful of people I'll get several different numbers. I'm a 5 for example, and in asking many people this question I've gotten a solid spectrum of answers from 1 - 5. Generally in a single group of a handful of people I'll get several different numbers. An old post by Scott Alexander (16+ years, mind blown) discusses this, long before the term "aphantasia" became a thing [1]. There was a debate about what "imagination" actually means already in the late 1800s; some people were absolutely certain that it was just a metaphor and nobody actually "sees" things in their mind; others were vehement that mental images are just as real as those perceived with our eyes. The controversy was resolved by Francis Galton, who did some rigorous interviewing and showed that it really does vary a lot from person to person. ——“So you can really see things in your head when your eyes are closed?”Yeah!“And it's as though you're seeing the object in front of you?”Yeah, you don't have that?“So it's like you're really seeing it? I can recite the qualities of an object, and this generates impressions of the object in my head, but it's not really seeing. “So you can really see things in your head when your eyes are closed?”Yeah!“And it's as though you're seeing the object in front of you?”Yeah, you don't have that?“So it's like you're really seeing it? I can recite the qualities of an object, and this generates impressions of the object in my head, but it's not really seeing. I can recite the qualities of an object, and this generates impressions of the object in my head, but it's not really seeing. I can recite the qualities of an object, and this generates impressions of the object in my head, but it's not really seeing. I can recite the qualities of an object, and this generates impressions of the object in my head, but it's not really seeing. I can recite the qualities of an object, and this generates impressions of the object in my head, but it's not really seeing. I can recite the qualities of an object, and this generates impressions of the object in my head, but it's not really seeing. I can recite the qualities of an object, and this generates impressions of the object in my head, but it's not really seeing. I can recite the qualities of an object, and this generates impressions of the object in my head, but it's not really seeing. I can recite the qualities of an object, and this generates impressions of the object in my head, but it's not really seeing. You're seeing it, but you know it's just a memory of the thing, not a live view. Pull up the image on your phone and look at it. Now close your eyes and imagine the image as accurately as you can.Is it as though you didn't close your eyes at all? Do you see it the same way as when your eyes are open? Is it as though you didn't close your eyes at all? Do you see it the same way as when your eyes are open? If you do not somehow "see" the shape of the candle, how do you remember its physical characteristics? Is it like a list of physical properties in abstract form?I can see, in front of me, a lit candle if I wish it. I can see its yellow flame flickering. I can see drops of wax along the candle. I can see the yellow light it casts. I can see its yellow flame flickering. I can see drops of wax along the candle. I can see the yellow light it casts. Close your eyes and try to visualize an apple. Do this for 30 seconds or so. Try to hold a stable mental picture of that apple.After the 30 seconds, rate your ability to picture the apple from 1 to 5, where 1 is complete inability and 5 is as if you were looking at a picture of an apple for those 30 seconds. I think most people would describe it as being part of a movie or reality. While awake, are you able to recreate scenes in vivid detail as if you were dreaming? After the 30 seconds, rate your ability to picture the apple from 1 to 5, where 1 is complete inability and 5 is as if you were looking at a picture of an apple for those 30 seconds. I think most people would describe it as being part of a movie or reality. While awake, are you able to recreate scenes in vivid detail as if you were dreaming? Another idea is to recall a vivid dream you had. I think most people would describe it as being part of a movie or reality. While awake, are you able to recreate scenes in vivid detail as if you were dreaming? For the most part, I can't “think” about things except maybe mental math. When I do calculus problems, I have to write down in full every intermediate step because I can't visualize how the equations change more than one or two steps in the future.Those kinds of things seem to me like more objective measures of someone's ability to visualize, although I have nothing other than anecdotal evidence to back that up. Those kinds of things seem to me like more objective measures of someone's ability to visualize, although I have nothing other than anecdotal evidence to back that up. I have aphantasia and it always astounds me when I see an article like this, or hear a friend talking about it (about not having it) and realize that their experience of the world is so fundamentally different than my own. https://lianamscott.com/wp-content/uploads/2022/10/f4c55-1_b...As in: if you look at this image, can you place yourself on a scale of 1 - 5 of with what kind of fidelity you can picture an apple if you try to imagine it?I'm a 5 for example, and in asking many people this question I've gotten a solid spectrum of answers from 1 - 5. Generally in a single group of a handful of people I'll get several different numbers. As in: if you look at this image, can you place yourself on a scale of 1 - 5 of with what kind of fidelity you can picture an apple if you try to imagine it?I'm a 5 for example, and in asking many people this question I've gotten a solid spectrum of answers from 1 - 5. Generally in a single group of a handful of people I'll get several different numbers. I'm a 5 for example, and in asking many people this question I've gotten a solid spectrum of answers from 1 - 5. Generally in a single group of a handful of people I'll get several different numbers. Edit: I also have trouble recognising the faces of people I've only met once or twice, and I'm assuming the two things are related. Evaluating qualia in others is extremely difficult/philosophically impossible, I have pre/post expierence with both states of being.I can still somewhat conjure up imagery from prior to the procedure series,  it almost feels like I can see them, my mother's face, my father face, kinda of, it did not effect my dreams or ability to have imagery in my edge of dreaming state, not immediately at least.I went from being very imaginative to trying to surf that half awake state in the mornings because it was such a loss.At this point it's all mostly gone. My memory is entirely text strings now. I can still somewhat conjure up imagery from prior to the procedure series,  it almost feels like I can see them, my mother's face, my father face, kinda of, it did not effect my dreams or ability to have imagery in my edge of dreaming state, not immediately at least.I went from being very imaginative to trying to surf that half awake state in the mornings because it was such a loss.At this point it's all mostly gone. My memory is entirely text strings now. I went from being very imaginative to trying to surf that half awake state in the mornings because it was such a loss.At this point it's all mostly gone. My memory is entirely text strings now. At this point it's all mostly gone. My memory is entirely text strings now. So, for you at least, there is/was a significant difference between "seeing things in your mind" and not being able to. Have you ever gone under any studies or tests to compare your brain activity to others? Anecdotally I know someone with aphantasia and they report having an internal monologue. No sensation of it being the original artist or the actual instruments, it's 100% my own voice in my own head.I have a friend who says she does not have any inner monologue at all, and thinks entirely visually. We're on the pretty extreme opposite ends of the spectrum of how we think, apparently. I have a friend who says she does not have any inner monologue at all, and thinks entirely visually. We're on the pretty extreme opposite ends of the spectrum of how we think, apparently. You can think of it like a bunch of different subsystems responsible for different kinds of tasks and some of them can be broken so the connections between them don't work.Read Hallucinations by Oliver Sacks for a lot of case studies. Read Hallucinations by Oliver Sacks for a lot of case studies.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/10/30/canva-launches-its-own-design-model-adds-new-ai-features-to-the-platform/'>Canva launches its own design model, adds new AI features to the platform</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 17:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Canva said that it is launching its own foundational model, trained on its elements, that would generate designs with editable layers and objects as compared to a flat image. It said the model works across different formats, including social media posts, presentations, whiteboards, and websites. “We started by creating flat images with diffusion models. Omni models have taken that a step further, where you're able to edit those flat images with a lot of sophistication through prompting. But the tools have made you prompt your way to the final result, which, for a visual medium, is challenging,” Canva's global head of product, Robert Kawalsky, told TechCrunch over a call. The company unveiled an AI assistant called Canva AI with a chat-like interface for generating new media items using prompts earlier this year. Users can also mention the bot in comments to get text or media suggestions while working on a project with others. Now, it's connecting these two products, allowing users to make use of data stored in the spreadsheet and create widgets from that. Canva also acquired an ad analytics company called MagicBrief earlier this year. Using its own platform for creation along with the new measurement tool, Canva is launching a full-stack marketing platform called Canva Grow, which uses AI for both asset creation and analytics. It also allows marketers to publish their ads directly on platforms like Meta. Users can now create forms with Canva to get different kinds of input from their clients or people instead of using Google Forms. Canva acquired the pro design tool Affinity last year to better compete with Adobe. And it's tightly integrating Affinity to Canva so designers can create objects in the pro tool and move them to the latter. Users can also take advantage of Canva AI to generate images or designs within Affinity, the company said. OpenAI offers free ChatGPT Go for one year to all users in India OpenAI says over a million people talk to ChatGPT about suicide weekly India, the market BlaBlaCar once walked away from, is now its biggest Rivian will pay $250M to settle lawsuit over R1 price hike</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/inside-the-uw-allen-school-six-grand-challenges-shaping-the-future-of-computer-science/'>Inside the UW Allen School: Six ‘grand challenges' shaping the future of computer science</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 16:42:06
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>In unveiling six “Grand Challenges” at its annual Research Showcase and Open House in Seattle on Wednesday, the Allen School's leaders described a blueprint for technology that protects privacy, supports mental health, broadens accessibility, earns public trust, and sustains people and the planet. The idea is to “organize ourselves into some more specific grand challenges that we can tackle together to have an even greater impact,” said Magdalena Balazinska, director of the Allen School and a UW computer science professor, opening the school's annual Research Showcase and Open House. The Allen School has grown so large that subfields like systems and NLP (natural language processing) risk becoming isolated “mini departments,” said Shwetak Patel, a University of Washington computer science professor. The Grand Challenges initiative emerged as a bottom-up effort to reconnect these groups around shared, human-centered problems. The grand challenges initiative is “music to my ears,” Patel said. In tackling these challenges, the Allen School has a unique advantage against many other computer science schools. These arrangements, he explained, give faculty and students access to data, computing resources, and real-world challenges by working directly with companies developing the most advanced AI systems. “A lot of the problems we're trying to solve, you cannot solve them just at the university,” Patel said, pointing to examples such as open-source foundation models and AI for mental-health research that depend on large-scale resources unavailable in academia alone. “When somebody's split, there's only so much mental energy you can put into the university,” Patel said. At the evening poster session, graduate students filled the rooms to showcase their latest projects — including new advances in artificial intelligence for speech, language, and accessibility. It then processes the audio recordings to estimate fetal heart rate. “The major impact would be in the rural, remote and low-resource settings where access to such maternity care is less — also called maternity care deserts,” said Poojita Garg, a second-year PhD student. This custom-built chatbot is designed to help students stay focused and build real understanding rather than relying on quick shortcuts. Running locally on school devices, the chatbot helps protect student data and ensures access even without Wi-Fi. “We're focused on making sure students have access to technology, and know how to use it properly and safely,” said Marquiese Garrett, a sophomore at the UW. Its key innovation is a custom scheduling algorithm that optimizes performance depending on the use case. “I thought it would be beneficial if we can provide this sort of open-source system that people can use,” said Keisuke Kamahori, third-year Ph.D. student at the Allen School. ConvFill is a lightweight conversational model designed to reduce the delay in voice-based large language models. The system responds quickly with short, initial answers, then fills in more detailed information as larger models complete their processing. By combining small and large models in this way, ConvFill delivers faster responses while conserving tokens and improving efficiency — an important step toward more natural, low-latency conversational AI. “This is an exciting way to think about how we can combine systems together to get the best of both worlds,” said Zachary Englhardt, a third-year Ph.D. student. Running generative AI locally — on laptops, phones, or other personal hardware — introduces new system-level challenges in fairness, efficiency, and scheduling. ConsumerBench is a benchmarking framework that tests how well generative AI applications perform on consumer hardware when multiple AI models run at the same time. The open-source tool helps researchers identify bottlenecks and improve performance on consumer devices. There are a number of benefits to running models locally: “There are privacy purposes — a user can ask for questions related to email or private content, and they can do it efficiently and accurately,” said Yile Gu, a third-year Ph.D. student at the Allen School. Designing Chatbots for Sensitive Health Contexts: Lessons from Contraceptive Care in Kenyan Pharmacies The goal is to understand how chatbots can support private, informed conversations and work effectively within pharmacies. “The fuel behind this whole project is that my team is really interested in improving health outcomes for vulnerable populations,” said Lisa Orii, a fifth-year Ph.D. student. How AI is reshaping the University of Washington computer science school UW computer science leaders push back on AI job fears: ‘The sky is not falling' Coding is dead: UW computer science program rethinks curriculum for the AI era</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/made-in-china-i-deliver-parcels-in-beijing-author-interview/'>“I Sweated So Much I Never Needed to Pee”: Life in China's Relentless Gig Economy</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 16:15:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>“Often, sweat was dripping down my back within the first two hours of a shift and would not stop dripping until the next morning,” writes Hu Anyan in the new English translation of his bestselling book I Deliver Parcels in Beijing. “I sweated so much I never once needed to pee.” This passage was on my mind as I read his book in Tianjin during one hot, Labubu brainrot summer, during which yet another unprecedented annual heat wave had forced almost everyone inside—except for the tireless couriers and delivery workers, whose services are in higher demand when temperatures soar. While his other books, like Living in Low Places, are more about his internal life, I Deliver Parcels in Beijing is a focused, refreshing, on-the-ground account of nearly a decade of work, set against the slow simmering background of China's economic rise. Hu's minimal, hypnotic prose reveals the perverse beauty of tireless endurance in an increasingly precarious economy. When people outside China read about it, it can be easy to imbue the place with a foreign otherness, as if only Chinese people are capable of working around the clock in mind-numbing conditions. Hu's direct writing style lays bare how toiling in a logistics warehouse, whether in Luoheng or Emeryville, are similar: the night shifts, a drink after work, petty arguments and factions, stuffing items into polypropylene bags. Hu Anyan: My writing and logistics work didn't happen simultaneously. For example, when I was delivering packages in Beijing or doing the night shift sorting parcels in Guangdong, I wasn't writing. In my book, when I talked about the period when I read James Joyce's Ulysses and Robert Musil's The Man Without Qualities, that was actually a special circumstance. For courier work, you have to clock in at 7 am. Between 70 and 80 percent of food delivery workers in China are part-time. In recent years, I've seen a lot of news about robot delivery. Do you think people are anxious that robots will replace them? In reality, there isn't much anxiety about robots replacing delivery people. My colleagues at the time didn't worry their work would be replaced by robots. Certainly other jobs, like video editing, advertising, and design might be, but for this kind of physical work, there's less of that anxiety. From what I observed, I think that the Chinese government will have more regulation than the US government to make sure automation serves people. If its development makes more people live unhappily or only makes 10 percent of people live better, it actually has no value for advancement. You have a college degree, which I thought was interesting and unexpected for someone doing courier work. For night-shift logistics sorting, probably no one had attended university, and probably only people who don't have better choices would take a job like that under those circumstances. As for couriers, there are actually people who received higher education. At my last job, our station had eight people. Besides me, one other colleague had a junior college degree, and the person who I replaced also had a junior college degree. From my personal experience—I'm not an expert who studies social issues—I've seen that many college students in China can't find good jobs. In my last courier job, the other college graduate was actually our station manager's high school classmate. Our station manager graduated from high school, didn't attend college, and eventually found a courier job in Beijing and became the station manager. This might not be an isolated case—many college students after graduation can't directly go into professional positions. If they look for a basic entry-level position, their income is very low, definitely lower than couriers and delivery workers. What do you think of tangping, or lying flat culture, the social trend in China where young people reject overwork in favor of minimalist lifestyles? Your book is so eloquent in how it understands work culture. I was born in the 1970s, so maybe my seriousness is mostly because of my generation's education at the time, which made us afraid to be criticized or reprimanded by company leadership or bosses. During my generation, China was still a planned economy, all state owned, no private sector, so many people didn't need to do career planning. People from that time were relatively conservative, with a closed, traditional mindset. Many people in this new generation have ideas about planning for their future. China has changed so rapidly over the past three or four decades, and much of what I say to them is already outdated, doesn't fit with their current circumstances, and has no reference value. Lying flat culture has only appeared in China recently, why? Like I said, previously China wasn't a market economy. Many young people feel that for making money, forming this kind of neijuan [intense competition] is a waste of life, and that you end up just living meaninglessly. The rewards you end up obtaining aren't that big. In a lot of Chinese-language interviews, the interviewer mentions how simply you live. If this is the highest-income job you can find, and you might have to work in this job for the next 10, 20, 30 years to support your parents and family, you'll definitely feel despair. Under these circumstances, the freedom I talk about is pursuing this kind of personal value you can't pursue in work. For example, creative pursuits are so bound to your personal uniqueness. Even if two people jointly experienced the exact same event, if you let them reflect or retell it in writing, their retelling won't be completely the same. So the freedom I mention in my book, it's not a general freedom, it's specific: not being bound by work that is uncreative or makes you just a tool. But I dared not work anymore and decided to write for a while. If you have higher material pursuits, it's harder to be free, because you'll constantly invest more energy and time into making money. This is an edition of Zeyi Yang and Louise Matsakis' Made in China newsletter. In your inbox: Our biggest stories, handpicked for you each day ICE wants to build out a 24/7 social media surveillance team Big Story: What it's like to own a Cybertruck Event: Join some of the most influential voices in tech and beyond WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/semiconductors/police-bust-chip-relabeling-ring-in-shenzen'>Police bust chip counterfeiting outfit in China, fakes may have made it into PC hardware — GPUs, motherboards, and power supplies potentially impacted by fake Infineon and TI power chips</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 16:04:22
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Authorities busted a counterfeiting ring that resurfaced and relabeled discarded ICs. When you purchase through links on our site, we may earn an affiliate commission. Shenzhen authorities have dismantled a counterfeit chip operation that allegedly sold reclaimed and rebranded integrated circuits as premium imports from Infineon, Texas Instruments, and other Western semiconductor firms. According to reporting by the South China Morning Post, police spent four months investigating the ring, which resurfaced discarded chips, laser-polished their markings, and re-labeled them with high-spec part numbers before distributing them through shell companies posing as foreign agents. At least one arrest has been made, and officials say they've begun coordinating with international suppliers to trace affected batches. In other words, precisely the kind of devices where a subtle defect is unlikely to surface until the system is under thermal or electrical stress. The danger is that they work just well enough to pass inspection, only to cause intermittent reboots under GPU boost, erratic fan curves, or coil whine that starts weeks after build. A swapped TI buck regulator or mislabelled Infineon MOSFET could explain failures that otherwise defy diagnosis. In a previous sting operation, Chinese authorities seized over 40,000 fake Nvidia GPUs relabeled and sold as newer models. But while GPU scams tend to target uninformed consumers, this case is more structurally dangerous. The chips were allegedly sold B2B to downstream suppliers, meaning legitimate brands could unknowingly integrate counterfeits into otherwise reputable components. China's tightening grip on chip imports under ongoing US export controls is part of the backdrop, with some domestic buyers having to turn to counterfeit imports after finding it difficult to source parts from Europe and the US, creating an artificial premium for “genuine” branded ICs. In September, China's Ministry of Commerce began an anti-dumping investigation into imported American analog chips, claiming that US chip suppliers had lowered and suppressed the sale prices of Chinese products over several years. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/doctor-who-disney-bbc-deal-budget-diversity-backlash-2000679399'>Report: The 'Doctor Who' Disney Deal Was Doomed by Bad Ratings, Big Budgets, and Backlash Fears</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 15:30:16
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>It's been an odd few years for Doctor Who, from riding on the high of its 60th anniversary heralding a splashy new partnership with Disney to bring the series around the world (and with a much bigger budget) to this week's news that said deal had undramatically fizzled out after just two seasons, with the show not making a return until a 2026 Christmas special. An extensive new report from Deadline alleges that the BBC/Disney partnership on Doctor Who was never expected to last long-term. It claims that Disney's plans for its streaming platform, Disney+, were never an ideal fit to sustain a show as expensive as Doctor Who had become with the new partnership—and especially with the loftier expectations being put on the show's declining viewership. According to Deadline, under the Disney deal, Doctor Who‘s per-episode budget had increased to anywhere between $8 million and $10 million. But the report further claims that while the combination of the show's ballooning budget and its diminished ratings were primary factors behind the decision to terminate the deal, there was another lingering issue: that Disney perceived a potential growing backlash against Doctor Who‘s so-called “woke” storytelling. Disney has increasingly moved towards downplaying diverse casting or storytelling in recent years as part of the company's broader capitulation to the second Trump administration, including cutting back on diversity initiatives and regularly pressuring its own studios to cut storylines that focus on LGBTQ+ topics, especially ones putting transgender characters in the spotlight. Doctor Who has consistently faced accusations of a supposed liberal agenda for years before such criticisms became culturally de rigueur, although the show has consistently centered values around diversity in the face of oppression over its entire 60-plus-year history. But while the latest era of the show has put those values forward on a surface level in recent years—beyond Gatwa's casting as the first Black, openly queer man to play the Doctor, the BBC has consistently defended the series' casting of trans actors such as Heartstopper‘s Yasmin Finney and drag queen Jinx Monsoon, and storylines which included queer elements such as a kiss between Gatwa and guest star Jonathan Groff—the broader storytelling of recent seasons has faced persistent criticism of its failure to consistently back those values up in meaningful ways, with stories questionably handling of allegories to topics such as Israel's genocidal invasion of Gaza and white supremacy, as well as further criticism of how the series treated the arcs of its primary female protagonists in the Doctor's companions. Publicly, Disney has stayed quiet over this week's official disintegration of the deal, only pivoting towards the BBC's own statement about Doctor Who‘s future rather than providing their own. It's been widely rumored since the climax of the 2025 season of Doctor Who—which saw Ncuti Gatwa make a shock exit as the 15th Doctor, regenerating into returning series star Billie Piper—came from significant reshoots to the previously planned series finale, and that Gatwa's exit was in part due to a frustration that potential work on a third season (Gatwa had stated in an October 2024 appearance on the Graham Norton Show that work was set to commence some time in 2025; however, the comments were cut from the final broadcast) was being stalled by Disney's indecision. io9 has reached out to Disney for comment on the veracity of the details included in Deadline's report but has yet to hear back by time of publication. Check out when to expect the latest Marvel, Star Wars, and Star Trek releases, what's next for the DC Universe on film and TV, and everything you need to know about the future of Doctor Who. Subscribe and interact with our community, get up to date with our customised Newsletters and much more. The bizarre ending to the 2025 season of 'Doctor Who' gave us more than a mystery in whether or not the show would survive to actually tell us who Billie Piper was meant to be playing. The BBC has announced that Russell T Davies will pen a 2026 Christmas special for the series after Disney has confirmed it will not renew its partnership. Adam Driver and Steven Soderbergh's 'Star Wars' movie was allegedly much further along than we thought before it met the same fate Ben did in 'Rise of Skywalker.' The actress was the subject of a series of reports in 2023 accusing her of being dismissed from the show before she'd even debuted, despite her eventually returning.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/slowly-but-surely-high-speed-rail-backers-believe-cascadia-mega-project-will-become-a-reality/'>Slowly but surely, high-speed rail backers believe Cascadia mega-project will become a reality</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 15:30:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Ten years into a dream to connect Vancouver, B.C., Seattle and Portland via a high-speed rail line, stakeholders and backers of the mega-project said Wednesday that they're still very much onboard — and to prepare for a long trip. With a lengthy and uncertain timeline ahead, former U.S. Secretary of Transportation Ray LaHood, a speaker at the Cascadia Innovation Corridor conference in Seattle, cautioned many of those in attendance that they likely won't live long enough to see high-speed rail in the Pacific Northwest. “It took us 50 years to build the interstate system.” At Cascadia Innovation Corridor's annual event this week, much of the focus was on how to strengthen the cross-border partnership between three growing cities and numerous locales in between. Leaders discussed ideas around innovation, housing affordability, sustainability, and economic development. Chris Gregoire, Cascadia Innovation Corridor's chair, said that a decade ago, high-speed rail was just an idea. “You would have thought we were thinking of doing something in outer space by the reaction,” she said. “Today, it is much more than an idea, and we are actually moving forward. While we do have a long way to go, as you well know, we're funding the first phase of planning built on one of the most unique coalitions in North America.” Envisioning a mega-region akin to Silicon Valley, in which Vancouver, Seattle and Portland are each only an hour apart, Gregoire highlighted the possibilities that could come with high-speed mobility. “It's a new way of living, working and connecting, one that expands what's possible for everyone who calls Cascadia home.” In 2017, Microsoft — which has an office in downtown Vancouver — gave $50,000 to a $300,000 effort led by Washington state to study a high-speed train proposal. Last year, the Federal Railroad Administration awarded the Washington State Department of Transportation $49.7 million to develop a service development plan for Cascadia High-Speed Rail. A timeline on WSDOT's website points to 2028 for estimated completion of that plan, and for 2029 and beyond it simply says, “future phases to be determined.” Cascadia is not alone in its quest for high-speed rail. He said the Trump administration “clawing back” $4 billion in funding for California's high-speed rail project between San Francisco and Los Angeles should not be considered a “death knell,” despite challenges in that state. Another plan in Texas would connect Houston and Dallas. All are evidence, he said, that this mode of transportation is what Americans want in order to avoid clogged highways and airports. Here are highlights from other speakers at the conference on Wednesday: Microsoft's Brad Smith makes nuanced AI pitch: Huge potential, real concerns, and a Jon Stewart clip</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/pc-components/gpu-drivers/new-amd-driver-snubs-radeon-rx-5000-6000-gpus-with-latest-updates-also-disables-usb-c-functionality-on-rx-7900-series'>New AMD driver snubs Radeon RX 5000, 6000 GPUs with latest updates — also disables USB-C functionality on RX 7900 series</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 15:04:41
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>It also disables USB functionality on RX 7900 series Type-C ports. When you purchase through links on our site, we may earn an affiliate commission. AMD has confirmed that its latest driver update involves sunsetting its Radeon RX 5000 Series and 6000 Series graphics cards, placing them in maintenance mode to allow delivery of new tech for its more recent offerings. "In order to focus on optimizing and delivering new and improved technologies for the latest GPUs, AMD Software Adrenalin Edition 25.10.2 places Radeon RX 5000 series and RX 6000 series graphics cards (RDNA 1 and RDNA 2) in maintenance mode," the company confirmed to Tom's Hardware in a statement. While the company says that its RDNA 1 and RDNA 2 graphics cards will continue to receive critical security updates and bug fixes, new features, like the latest Battlefield 6 update, are reserved for the Radeon RX 7000 and RX 9000 series in the latest AMD Software: Adrenalin Edition 25.10.2. It's not even all good news for Radeon RX 7000 series owners. Folks who have a Radeon RX 7900 series card—that's the XT or XTX—that includes a USB Type-C port on the back may be dismayed to know that the new driver disables that port's ability to power external devices. Instead, it is simply an oddly-shaped DisplayPort connection now. It could certainly be down to the fact that AMD's graphics driver package is now too large to fit on two CD-ROMs. In the era of ubiquitous broadband internet, a 1.6GB driver package is arguably no big deal, but many people around the world still labor under the limitation of metered internet connections with limited transfer allowances. Work Graphs are a little-used feature that essentially allows the GPU to act fully independently of the CPU by dispatching its own work. It's currently supported by Radeon RX 7000, GeForce RTX 30 series, and newer non-Intel GPUs; it's surprising to learn that Work Graphs were not supported on Radeon RX 9000 series parts until now. Also, AMD seems to have resolved a problem where running VR headsets at 80 or 90 Hz could cause stuttering. Finally, no less than ten separate security issues have apparently been resolved in this driver. In AMD's defense, Battlefield 6 already runs pretty well on Radeon RX 6000 GPUs, so there's not exactly a pressing need for that update on those cards. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Zak is a freelance contributor to Tom's Hardware with decades of PC benchmarking experience who has also written for HotHardware and The Tech Report. A modern-day Renaissance man, he may not be an expert on anything, but he knows just a little about nearly everything. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=45760328'>US declines to join more than 70 countries in signing UN cybercrime treaty</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 14:25:21
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Plus it has too many implications for surveillance and security; poor idea in any case. Ok, so it's basically a "five eyes" style agreement for sharing intel on citizens. Why would anyone want their government to support this? It would be a lot fairer to display tons of CO2 per inhabitant I think.And that's before taking into account imported CO2. It doesn't really make much of a difference. Take your position to something of an extreme -- the Vatican could open up 200 coal power plants for its holy Bitcoin operations and still be sufficiently less impactful to CO2 than the US that nobody would target them during climate talks. Rephrased from the other direction, each US citizen would blow their CO2 budget by buying a shirt per decade to get down to the Vatican's levels.That's a common mental failure mode, analogous to the sorites paradox. That's a common mental failure mode, analogous to the sorites paradox. Which is just too hard, and too open to change assumptions to fit a desired result.Because in reality, much of the globe's economy is waaayyyyy too interconnected, and the arrows don't just point one way. Feedback loops without end.That whole "this/that country..." just does not work, except to fill comment sections. Because in reality, much of the globe's economy is waaayyyyy too interconnected, and the arrows don't just point one way. Feedback loops without end.That whole "this/that country..." just does not work, except to fill comment sections. That whole "this/that country..." just does not work, except to fill comment sections. I actually prefer regimes like NATO where everyone is happy to leave the US in charge and doesn't arm themselves. IMO this is all by design, and there are a non-zero number of NGO operatives on this very site who are frustrated that anything is impeding that plan. Depending on local law, even regional parliaments have to approve it (Belgium is such a state). The final implementation of Mercosur is not expected before 2028. But, then again, in the Angloamerican culture, its always 'others' who are evil. > surrenders power to a regime with partial control by objectively bad actors...do you think we are a regime with good actors? What signals of morality or competency do you look for? ...do you think we are a regime with good actors? What signals of morality or competency do you look for? This was a very proportional response to Putin[1] the other day, so it's still technically game theory. Opting out doesn't preclude the US from cooperating with international cybercrime investigations, but it does avoid more data collection, surveillance, and sharing. Opting out of the treaty was probably a good choice. Opting out doesn't preclude the US from cooperating with international cybercrime investigations, but it does avoid more data collection, surveillance, and sharing. Maybe there is some more complexity to this argument, that I'm missing. But, it's not one that has merit without justification. For example, here's what the EFF had to say about it:https://www.eff.org/deeplinks/2024/07/effs-concerns-about-un... https://news.ycombinator.com/item?id=39129274 ("Proposed UN cybercrime treaty has evolved into an expansive surveillance tool (eff.org)", 64 comments)https://news.ycombinator.com/item?id=41210110 ("New U.N. Cybercrime Treaty Unanimously Approved, Could Threaten Human Rights (scientificamerican.com)", 53 comments)https://news.ycombinator.com/item?id=41221403 ("UN Cybercrime Convention to Overrule Bank Secrecy (therage.co)", 42 comments) https://news.ycombinator.com/item?id=41210110 ("New U.N. Cybercrime Treaty Unanimously Approved, Could Threaten Human Rights (scientificamerican.com)", 53 comments)https://news.ycombinator.com/item?id=41221403 ("UN Cybercrime Convention to Overrule Bank Secrecy (therage.co)", 42 comments) https://news.ycombinator.com/item?id=41221403 ("UN Cybercrime Convention to Overrule Bank Secrecy (therage.co)", 42 comments) Algeria,Angola,Australia,Austria,Azerbaijan,Belarus,Belgium,Brazil,Brunei Darussalam,Burkina Faso,Cambodia,Chile,China,Costa Rica,Côte d'Ivoire,Cuba,Czech Republic,Democratic People's Republic of Korea,Democratic Republic of the Congo,Djibouti,Dominican Republic,Ecuador,Egypt,European Union,France,Ghana,Greece,Guinea-Bissau,Iran (Islamic Republic of),Ireland,Jamaica,Mozambique,Namibia,Nauru,Nicaragua,Nigeria,Palau,Papua New Guinea,Peru,Philippines,Poland,Portugal,Qatar,Russian Federation,Rwanda,Saudi Arabia,Slovakia,Slovenia,South Africa,Spain,Sri Lanka,State of Palestine,Sweden,Thailand,Togo,Türkiye,Uganda,United Kingdom of Great Britain and Northern Ireland,United Republic of Tanzania,Uruguay,Uzbekistan,Venezuela (Bolivarian Republic of),Viet Nam,Zimbabwe I wonder what countries you do associate with data privacy. The difference is our federal structure and--until recently--independent courts provided a bit more oversight than other countries' citizens had access to. And we've had--until recently--respect for privacy held deeply enough by enough people that it turns into a stink at the federal level in at least some respect.Most countries have national logging requirements, disclosure requirements and domestic police with the powers of the NSA. This is absolutely not something that should be murky. This is absolutely not something that should be murky. I wouldn't get excited about the US "not signing". With the government shutdown, they might just be waiting for the document to be in New York before they bother. It's the EU's "any program for committing cybercrime is a crime" law, and makes programmers culpable. Sure, there's a clause in there that looks like it's supposed to protect security research (11s2) but this is the thinnest of loincloths.It also seems to apply to "crime where there was a computer somewhere around". As for what constitutes "crime":Article 2:(h) “Serious crime” shall mean conduct constituting an offence punishable by a maximum deprivation of liberty of at least four years or a more serious penalty;...that seems to mean that if publishing information against the state regime is punishable by 4+ years and you used a computer to do it, there is now a basis for seizing your data and extraditing you.I'm not even going to get into the implications this has for damaging privacy in general. It's the EU's "any program for committing cybercrime is a crime" law, and makes programmers culpable. Sure, there's a clause in there that looks like it's supposed to protect security research (11s2) but this is the thinnest of loincloths.It also seems to apply to "crime where there was a computer somewhere around". As for what constitutes "crime":Article 2:(h) “Serious crime” shall mean conduct constituting an offence punishable by a maximum deprivation of liberty of at least four years or a more serious penalty;...that seems to mean that if publishing information against the state regime is punishable by 4+ years and you used a computer to do it, there is now a basis for seizing your data and extraditing you.I'm not even going to get into the implications this has for damaging privacy in general. It's the EU's "any program for committing cybercrime is a crime" law, and makes programmers culpable. Sure, there's a clause in there that looks like it's supposed to protect security research (11s2) but this is the thinnest of loincloths.It also seems to apply to "crime where there was a computer somewhere around". As for what constitutes "crime":Article 2:(h) “Serious crime” shall mean conduct constituting an offence punishable by a maximum deprivation of liberty of at least four years or a more serious penalty;...that seems to mean that if publishing information against the state regime is punishable by 4+ years and you used a computer to do it, there is now a basis for seizing your data and extraditing you.I'm not even going to get into the implications this has for damaging privacy in general. It's the EU's "any program for committing cybercrime is a crime" law, and makes programmers culpable. Sure, there's a clause in there that looks like it's supposed to protect security research (11s2) but this is the thinnest of loincloths.It also seems to apply to "crime where there was a computer somewhere around". As for what constitutes "crime":Article 2:(h) “Serious crime” shall mean conduct constituting an offence punishable by a maximum deprivation of liberty of at least four years or a more serious penalty;...that seems to mean that if publishing information against the state regime is punishable by 4+ years and you used a computer to do it, there is now a basis for seizing your data and extraditing you.I'm not even going to get into the implications this has for damaging privacy in general. As for what constitutes "crime":Article 2:(h) “Serious crime” shall mean conduct constituting an offence punishable by a maximum deprivation of liberty of at least four years or a more serious penalty;...that seems to mean that if publishing information against the state regime is punishable by 4+ years and you used a computer to do it, there is now a basis for seizing your data and extraditing you.I'm not even going to get into the implications this has for damaging privacy in general. Article 2:(h) “Serious crime” shall mean conduct constituting an offence punishable by a maximum deprivation of liberty of at least four years or a more serious penalty;...that seems to mean that if publishing information against the state regime is punishable by 4+ years and you used a computer to do it, there is now a basis for seizing your data and extraditing you.I'm not even going to get into the implications this has for damaging privacy in general. ...that seems to mean that if publishing information against the state regime is punishable by 4+ years and you used a computer to do it, there is now a basis for seizing your data and extraditing you.I'm not even going to get into the implications this has for damaging privacy in general. I'm not even going to get into the implications this has for damaging privacy in general. - (ii) To cooperate and assist the competent authorities in the collection or recording of; traffic data, in real time, associated with specified communications in its territory transmitted by means of an information and communications technology system. Will the authorities of state X simply ask the authorities of state Y to collect/intercept data, and will the authorities of state Y be required to cooperate even without a legal basis in their local legislation? Because this treaty become sufficient legislation?And more so:   3. Each State Party shall adopt such legislative and other measures as may be necessary to oblige a service provider to keep confidential the fact of the execution of any power provided for in this article and any information relating to it. I cannot imagine anyone with a functioning brain signing this at the UN level. Each State Party shall adopt such legislative and other measures as may be necessary to oblige a service provider to keep confidential the fact of the execution of any power provided for in this article and any information relating to it. I cannot imagine anyone with a functioning brain signing this at the UN level. Each State Party shall adopt such legislative and other measures as may be necessary to oblige a service provider to keep confidential the fact of the execution of any power provided for in this article and any information relating to it. I cannot imagine anyone with a functioning brain signing this at the UN level. But given OFCOM's recent stunts of sending british compliance letters to US firms with no british presence, I'd rather not have other countries manufacturing shit laws and exporting to us as a "treaty". Sure it could be argued thats not a real example. But given OFCOM's recent stunts of sending british compliance letters to US firms with no british presence, I'd rather not have other countries manufacturing shit laws and exporting to us as a "treaty". The President isn't shut down, and only the President is needed to sign a treaty; it is submitted for ratification later and that, absent a deadline in the treaty, can take as long as it takes.Also, even if the Senate was required to sign a treaty, the Senate isn't shutdown, and is in session and doing business. Also, even if the Senate was required to sign a treaty, the Senate isn't shutdown, and is in session and doing business. Per the article: “Illicit flows of money, concealed through cryptocurrencies and digital transactions, finance the trafficking of drugs, arms, and terror. And businesses, hospitals, and airports are brought to a standstill by ransomware attacks.”Then there's this: Inside the Trump family's global crypto cash machine https://www.reuters.com/investigations/inside-trump-familys-... Then there's this: Inside the Trump family's global crypto cash machine https://www.reuters.com/investigations/inside-trump-familys-... China especially actively fabricates crimes for Chinese dissidents living outside its borders, and this is a perfect vehicle to allow them to track and monitor those people with ease. > "Russia, however, Rodriguez said, has objected to the convention for infringing state sovereignty by allowing other nations to investigate cybercrimes in its jurisdiction. So in 2017, Russia proposed negotiating a new treaty, and in 2019 the UN adopted a resolution to do so, backed by Russia, Cambodia, Belarus, China, Iran, Myanmar, Nicaragua, Syria and Venezuela. "https://www.theregister.com/2023/04/14/un_cybercrime_treaty/ ("Russia-pushed UN Cybercrime Treaty may rewrite global law. It's ... not great")> "It was proposed by Russia in 2017 and adopted by the General Assembly in December 2024 amid resistance from human rights organizations"https://en.wikipedia.org/wiki/United_Nations_Convention_agai... https://www.theregister.com/2023/04/14/un_cybercrime_treaty/ ("Russia-pushed UN Cybercrime Treaty may rewrite global law. It's ... not great")> "It was proposed by Russia in 2017 and adopted by the General Assembly in December 2024 amid resistance from human rights organizations"https://en.wikipedia.org/wiki/United_Nations_Convention_agai... > "It was proposed by Russia in 2017 and adopted by the General Assembly in December 2024 amid resistance from human rights organizations"https://en.wikipedia.org/wiki/United_Nations_Convention_agai... Countries like Nigeria, Morocco, North Korea and Russia signing a "cybercrime" treaty is just hilarious to me.I don't believe for a second that these countries want to crack down on cybercrime, considering their citizens are the main perpetrators and beneficiaries of it, and they've taken zero actions to prevent it before today. Lagos is essentially the Silicon Valley of internet fraud, and it happens with permission from the highest levels of their government.This obviously is just an excuse to create a global dragnet for governments looking to crack down on dissent. I don't believe for a second that these countries want to crack down on cybercrime, considering their citizens are the main perpetrators and beneficiaries of it, and they've taken zero actions to prevent it before today. Lagos is essentially the Silicon Valley of internet fraud, and it happens with permission from the highest levels of their government.This obviously is just an excuse to create a global dragnet for governments looking to crack down on dissent. Just seems very distracting when actual abuses and interesting political topics are hidden away in /active (like ICEs use of facial recognition)</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/if-you-hated-a-house-of-dynamite-watch-fail-safe-instead/'>If You Hated ‘A House of Dynamite,' Watch This Classic Nuclear Thriller Instead</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 13:10:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>This is the premise of Sidney Lumet's 1964 masterpiece Fail Safe—a movie that asked Cold War audiences to question unbridled nuclear weapons proliferation at a time when, to many, building up a massive arsenal seemed like an imperative. I watched Fail Safe recently to remind myself just how good it is after I was left disappointed by A House of Dynamite, Kathryn Bigelow's portrayal of a nuclear crisis, which arrived on Netflix on October 24. Some political analysts argue that nuclear war has never been more likely than it is today. And yet, despite that ongoing threat to humanity's very existence, few films or TV shows seem to agonize about the prospect anymore. Analysis of the missile's trajectory soon reveals its likely target: Chicago. A weapon like that, government officials tell each other, could kill 10 million people on impact. Many more will likely die due to radioactive fallout created by the nuclear blast. The missile will hit in just 19 minutes, meaning there's no time to evacuate Chicago. All America can do is try to shoot down the ICBM, while contemplating catastrophe. Olivia Walker (Rebecca Ferguson), a senior officer in the White House Situation Room, quickly recognizes the magnitude of what is unfolding on the big board in front of her and her colleagues. We feel the urgency of each desperate action, order, and argument that follows. But A House of Dynamite is nearly two hours long. Those 19 minutes till impact are both elongated and played out no fewer than three times, from three slightly different perspectives. In the second act, we join generals and government officials on a bizarre Zoom call as they try to work out what, if anything, they can do. In short, the tension gradually dries up, the script falls flat, and we never even find out what comes of it all. The ending, or lack thereof, has enraged some viewers. In Fail Safe, by contrast, the tension never eases. The drama gradually builds to a climax that involves personal sacrifice and other dreadful choices. In A House of Dynamite, the crisis blasts into view from outside. Some unidentified other has sent the ICBM, leaving everyone scrambling. In Fail Safe, though, there are hotheads and war-mongers, too. Other films released in 1964, including Seven Days in May and the better-remembered Dr. Strangelove also deal with questions around nuclear posturing and the inherent risks of nuclear proliferation. The only thing everyone can agree on is that no one's responsible.” In 2025, automation seems ubiquitous—we regularly grasp for an answer to the question “Who is accountable?” when AI, or automated vehicles, go wrong. But Fail Safe also serves up a heady cocktail of human personalities and interests. There's the general who is unexpectedly horrified by nuclear weapons; the political scientist determined to eliminate any and all threats to America; and the president (Henry Fonda) who finds that, when it really matters, his supposed authority actually means nothing. The bomber crew's orders are to ignore any commands once their attack run begins. Voices on their radios, training has told them, could be imitated by the enemy. And so as lead pilot Colonel Jack Grady (Edward Binns) nears his target, Fonda insists that he return to base, bellowing: “Damn it, Grady, this is the president!” All to no avail. It's a situation that has been called “the human button,” in which military personnel are trained to carry out the procedures for launching a nuclear attack without hesitation or deviation. These procedures may be repeatedly rehearsed in order to induce a kind of unthinking muscle memory. Soldiers in silos and submarines would carry out the last rites like automatons. Many have questioned whether this chain of events would really unfold so neatly. In 1983, for instance, one real-life Russian duty officer did famously deviate from the doomsday script. Stanislav Petrov received a computer warning that several nuclear missiles had been fired toward the Soviet Union from the US. In principle, this ought to have triggered an immediate retaliatory strike against the US. But Petrov had a hunch it was a false alarm and, against protocol, chose not to alert his superiors, potentially averting Armageddon. Yes, this is arguably the fault of all those who have supported nuclear posturing, that's what the film's title is about. But Fail Safe is much more successful at showing how and why the worst risks come from within. Early in Fail Safe, before the chilling alarms and frantic phone calls, there's a scene in which two old-school Air Force pilots hang out and play pool. Ironically, the pilot who utters these words is none other than Colonel Grady, the human button who goes on to fly unwaveringly toward Moscow. In your inbox: WIRED's most ambitious, future-defining stories Big Interview: We spoke to Zohran Mamdani, New York's mayoral front-runner Watch: Following your stolen data through the dark web WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/10/30/the-prompting-company-snags-6-5m-to-help-products-get-mentioned-in-chatgpt-and-other-ai-apps/'>The Prompting Company snags $6.5M to help products get mentioned in ChatGPT and other AI apps</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 13:10:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>People are increasingly asking AI, not Google, to help them discover products. A recent shopping report says Americans, this holiday season, will likely turn to large language models this season to find gifts, deals, and sales instead of traditional search. For brands, that means figuring out how to show up in AI-generated recommendations, and fast. “We're already seeing developers ask AI tools for product recommendations inside their workflows, and we think people, over time, will be less involved in parts of the purchasing funnel.” What that means, according to Chandra, is that brands will need an AI-facing website, a version of their site made for agents without navigation bars, pop-ups, or marketing fluff. “Most businesses still design websites only for humans,” Chandra told TechCrunch. It then creates structured content that answers those questions and automatically routes AI agents to “AI-optimized pages.” The Y Combinator-backed startup helps companies publish thousands of AI-friendly pages so LLMs can cite their answers even when they don't rank in traditional SEO. While SEO still matters, Chandra argues that GEO is quickly becoming the priority for brands. In GEO, product results surface organically based on relevance to the conversation, not paid keywords or search rankings. Emerging protocols, including Google's Agent-to-Agent framework and OpenAI's partnership with Stripe, could further accelerate adoption by allowing AI agents to browse and complete purchases on behalf of users, moving them from discovery to transaction. Users can buy items, make returns, compare products, or search for promotions. Right now, these agents aren't yet clicking those options or accessing APIs directly, but we expect that to change in the coming months,” said Chandra. “Once that becomes widespread and attribution improves, we see a path toward more advertising- or conversion-driven models. For now, we're focused on helping companies get discovered and recommended by AI.” So far, The Prompting Company serves mostly fintech, developer tools, and enterprise SaaS customers. Overall, traffic driven to client sites is in the double-digit millions per month. The company's founders, Indonesian immigrants who met as freshmen, previously built YC-backed Typedream (YC W20), a startup that allowed users to build and launch websites in minutes with AI, before Lovable and newer entrants took off (beehiiv acquired Typedream last June). The founders also built Cotter, a passwordless authentication SDK that was acquired by Stytch. The startup is also collaborating with NVIDIA on next-generation AI search. “If your product isn't discovered or cited in ChatGPT, you're ngmi,” said Arnav Sahu, partner at Peak XV Partners. OpenAI offers free ChatGPT Go for one year to all users in India OpenAI says over a million people talk to ChatGPT about suicide weekly India, the market BlaBlaCar once walked away from, is now its biggest</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.technologyreview.com/2025/10/30/1127057/agi-conspiracy-theory-artifcial-general-intelligence/'>How AGI became the most consequential conspiracy theory of our time</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.technologyreview.com', 'title': 'MIT Technology Review'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 10:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The idea that machines will be as smart as—or smarter than—humans has hijacked an entire industry. I hear it's close: two years, five years—maybe next year! And I hear it's going to change everything: it will cure disease, save the planet, and usher in an age of abundance. It will solve our biggest problems in ways we cannot yet imagine. Because I also hear it will bring on the apocalypse and kill us all … Either way, and whatever your timeline, something big is about to happen. Or the day when Heaven's Gaters imagined they'd be picked up by a UFO and transformed into enlightened aliens. We're of course talking about artificial general intelligence, or AGI—that hypothetical near-future technology that (I hear) will be able to do pretty much whatever a human brain can do. This story is part of MIT Technology Review's series “The New Conspiracy Age,” on how the present boom in conspiracy theories is reshaping science and technology. For many, AGI is more than just a technology. Ilya Sutskever, cofounder and former chief scientist at OpenAI, is said to have led chants of “Feel the AGI!” at team meetings. Superintelligence is the hot new flavor—AGI but better!—introduced as talk of AGI becomes commonplace. Sutskever also exemplifies the mixed-up motivations at play among many self-anointed AGI evangelists. “It's going to be monumental, earth-shattering—there will be a before and an after,” he told me a few months before he quit OpenAI. When I asked him why he had redirected his efforts into reining that technology in, he said: “I'm doing it for my own self-interest. It's obviously important that any superintelligence anyone builds does not go rogue. He's far from alone in his grandiose, even apocalyptic, thinking. Every age has its believers, people with an unshakeable faith that something huge is about to happen—a before and an after that they are privileged (or doomed) to live through. What's different, of course, is that in contrast to computers and the internet, AGI doesn't exist.” Here's what I think: AGI is a lot like a conspiracy theory, and it may be the most consequential one of our time. It justifies dizzying down payments on the new power plants and data centers that we're told are needed to make the dream come true. Fixated on this hypothetical technology, AI firms are selling us hard. AGI will be as smart as an entire “country of geniuses” (Dario Amodei, CEO of Anthropic); it will kick-start “an era of maximum human flourishing, where we travel to the stars and colonize the galaxy” (Demis Hassabis, CEO of Google DeepMind); it will “massively increase abundance and prosperity,” even encourage people to enjoy life more and have more children (Sam Altman, CEO of OpenAI). When those people are not shilling for utopia, they're saving us from hell. In 2023, Amodei, Hassabis, and Altman all put their names to a 22-word statement that read: “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.” Elon Musk says AI has a 20% chance of annihilating humans. “I've noticed recently that superintelligence, which I thought was a concept you definitely shouldn't mention if you want to be taken seriously in public, is being thrown around by tech CEOs who are apparently planning to build it,” says Katja Grace, lead researcher at AI Impacts, an organization that surveys AI researchers about their field. “I think it's easy to feel like this is fine. You have to admit it all sounds a bit tinfoil hat. And I'm not drawing this parallel to dismiss the very real, often jaw-dropping results achieved by many people in this field, including (or especially) the AGI believers. But by zooming in on things that AGI has in common with genuine conspiracies, I think we can bring the whole concept into better focus and reveal it for what it is: a techno-utopian (or techno-dystopian—pick your pill) fever dream that got its hooks into some pretty deep-seated beliefs that have made it hard to shake. It's important to question what we're told about AGI because buying into the idea isn't harmless. We can't make sense of what's going on in AI without understanding where the idea of AGI came from, why it is so compelling, and how it shapes the way we think about technology overall. It will also piss a lot of people off. A typical conspiracy theory usually starts out on the fringes. Maybe it's just a couple of people posting on a message board, gathering “evidence.” Maybe it's a few people out in the desert with binoculars waiting to spot some bright lights in the sky. Maybe it's the UFOs (ahem, sorry, “unidentified aerial phenomena”) that are now formally and openly discussed in government hearings. Maybe it's vaccine skepticism (yes, a much more dangerous example) that becomes official policy. And it's impossible to ignore that artificial general intelligence has followed a pretty similar trajectory to its more overtly conspiratorial brethren. But Goertzel was an influential figure in a fringe community of researchers who had dreamed for years of building humanlike artificial intelligence, an all-purpose computer program that could do many of the things people can do (and do them better). Goertzel wanted to put out a book promoting that vision, and he needed a name that would set it apart from the humdrum AI of the time. A former Webmind employee named Shane Legg suggested Artificial General Intelligence. A few years later, Legg cofounded DeepMind with Demis Hassabis and Mustafa Suleyman. But to most serious researchers at the time, the claim that AI would one day mimic human abilities was a bit of a joke. AGI used to be a dirty word, Sutskever told me. Andrew Ng, founder of Google Brain and former chief scientist at the Chinese tech giant Baidu, told me he thought it was loony. Goertzel reckons a few things took the idea mainstream. Next is Legg, who took the term with him to DeepMind. “I think they were the first mainstream corporate entity to talk about AGI,” says Goertzel. “It wasn't the main thing they were harping on, but Shane and Demis would talk about it now and then. When I first talked to Legg about AGI five years ago, he said: “Talking about AGI in the early 2000s put you on the lunatic fringe … Even when we started DeepMind in 2010, we got an astonishing amount of eye-rolling at conferences.” But by 2020 the wind had changed. In the years between shutting down Webmind and publishing that AGI book, Goertzel did some work with Peter Thiel at Thiel's hedge fund Clarium Capital. He recalls spending a day with Thiel at the Four Seasons in San Francisco. “I was trying to drum AGI into his head,” says Goertzel. “But then he was also hearing from Eliezer how AGI is going to kill everybody.” That's Eliezer Yudkowsky, another influential figure who has done at least as much as Goertzel, if not more, to push the idea of AGI. But unlike Goertzel, Yudkowsky thinks there's a very high chance—99.5% is one number he throws out—that the development of AGI will be a catastrophe. In 2000, Yudkowsky cofounded a nonprofit research outfit called the Singularity Institute for Artificial Intelligence (later renamed the Machine Intelligence Research Institute), which pretty quickly dedicated itself to preventing doomer scenarios. At first, Yudkowsky's ideas didn't get much pickup. Recall that back then the idea of an all-powerful AI—let alone a dangerous one—was pure sci-fi. “It put the AGI thing out there,” says Goertzel. “I mean, Bill Gates, Elon Musk—lots of tech-industry AI people—read that book, and whether or not they agreed with his doomer perspective, Nick took Eliezer's concepts and wrapped them up in a very acceptable way.” “Rather than it being pure crackpot stuff from mavericks howling out in the wilderness.” Yudkowsky has been banging the same drum for 25 years; many engineers at today's top AI companies grew up reading and discussing his views online, especially on LessWrong, a popular hub for the tech industry's fervent community of rationalists and effective altruists. Today, those views are more popular than ever, capturing the imagination of a younger generation of doomers like David Krueger, a researcher at the University of Montreal who previously served as research director at the UK's AI Security Institute. “I think we are definitely on track to build superhuman AI systems that will kill everybody,” Krueger tells me. Yudkowsky gets profiled by the likes of the New York Times, which bills him as “Silicon Valley's version of a doomsday preacher.” His new book, If Anyone Builds It, Everyone Dies, written with Nate Soares, president of the Machine Intelligence Research Institute, lays out wild claims, with little evidence, that unless we pull the plug on development, near-future AGI will lead to global Armageddon. The pair's position is extreme: They argue that an international ban should be enforced at all costs, up to and including the point of nuclear retaliation. After all, “datacenters can kill more people than nuclear weapons,” Yudkowsky and Soares write. The book is an NYT bestseller and comes with endorsements from national security experts such as Suzanne Spaulding, a former US Department of Homeland Security official, and Fiona Hill, former senior director of the White House National Security Council, who now advises the UK government; celebrity scientists such as Max Tegmark and George Church; and other household names, including Stephen Fry, Mark Ruffalo, and Grimes. Still, it is those early quiet words in certain ears that may prove most consequential. Yudkowsky is credited with introducing Thiel to DeepMind's founders, after which Thiel became one of the first big investors in the company. Alongside Musk, Thiel was also instrumental in setting up OpenAI in 2015, sinking millions into a startup founded on the singular ambition to build AGI—and make it safe. In 2023, OpenAI CEO Sam Altman posted on X: “eliezer has IMO done more to accelerate AGI than anyone else. certainly he got many of us interested in AGI.” Yudkowsky might one day deserve the Nobel Peace Prize for that, Altman added. Alan Turing asked if machines could think only five years after the first electronic computer, ENIAC, was built in 1945. And here's Turing a little later, in a 1951 radio broadcast: “It seems probable that once the machine thinking method had started, it would not take long to outstrip our feeble powers. There would be no question of the machines dying, and they would be able to converse with each other to sharpen their wits. Then, in 1955, the computer scientist John McCarthy and his colleagues applied for US government funding to create what they fatefully chose to call “artificial intelligence”—a canny spin, given that computers at the time were the size of a room and as dumb as a thermostat. Even so, as McCarthy wrote in that funding application: “An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves.” Once you see that, other parallels with conspiracy thinking start to leap out. Talking about AGI can sometimes feel like arguing with an enthusiastic Redditor about what drugs (or particles in the sky) are controlling your mind. Each point has a counterpoint that tries to chip away at your own sense of what's true. More than that: Most people don't even agree on what AGI really is—which helps explain how people can get away with telling us it can both save the world and end it. (And remember, superintelligence is AGI's shiny new upgrade: a machine that can outmatch us.) But even that's easy to pull apart: What humans are we talking about? “There's no real definition of it,” says Christopher Symons, chief artificial intelligence scientist at the AI health-care startup Lirio and former head of the computer science and math division at Oak Ridge National Laboratory. And so, says Symons, we're in this weird race to build … what, exactly? In 2023, a team of researchers at Google DeepMind, including Legg, had a go at categorizing various definitions that people had proposed for AGI. I didn't really feel it was necessary,” he said at the time. The problem is that some people think they've seen it already. It was a moment when a lot of researchers were blown away and trying to come to terms with what they were seeing. “Shit was working better than they had expected it to,” says Goertzel. “The concept of AGI genuinely started to seem more plausible.” And yet for all of LLMs' remarkable wordplay, Goertzel doesn't think that they do in fact contain sparks of AGI. “It's a little surprising to me that some people with a deep technical understanding of how these tools work under the hood still think that they could become human-level AGI,” he says. “On the other hand, you can't prove it's not true.” “But we really don't have any evidence for it.” But instead of seeing that as evidence that AGI wasn't attainable—or attainable with an LLM, at least—believers pushed out their predictions for how soon AGI would come. Jeremy Cohen, who studies conspiracy thinking in technology circles at McMaster University in Canada, calls this imperfect evidence gathering—a hallmark of conspiracy thinking. Cohen started his research career in the Arizona desert, studying a community called People Unlimited that believed its members were immortal. When its members died of natural causes (including two of its founders), the thinking was that they must have deserved it. Cohen has since been focused on transhumanism (the idea that technology can help humans push past their natural limitations) and AGI. “It connects really well to the kinds of religious imaginaries that you see in conspiracy thinking today.” When I talk to researchers or engineers who are happy to drop AGI into the conversation as a given, it's like they know something I don't. But nobody's ever been able to tell me what that something is. The truth is out there, if you know where to look. Conspiracy theories are primarily concerned about revealing a hidden truth, Cohen tells me: “It's a really fundamental part of conspiracy thinking, and that's absolutely something that you see in the way people talk about AGI,” he says. Last year, a 23-year-old former OpenAI staffer turned investor, Leopold Aschenbrenner, published a much-dissected 165-page manifesto titled “Situational Awareness.” You don't need to read it to get the idea: You either see the truth of what's coming or you don't. And you don't need cold, hard facts, either—it's enough to feel it. This idea stalked the periphery of my conversation with Goertzel, too. When I pushed him on why people are skeptical of AGI, for instance, he said: “Before every major technical achievement, from human flight to electrical power, loads of wise pundits would tell you why it was never going to happen. The fact is, most people only believe what they see in front of their faces.” That makes AGI sound like an article of faith. I put that to Krueger, who believes AGI's arrival is maybe five years out. (Even so, he hedges: No one knows for sure, he says, but there's no obvious reason that AGI won't come.) Hidden truths bring truth seekers, bent on revealing what they've been able to see all along. With AGI, though, it's not enough to uncover something hidden. If you believe AGI is achievable, then you believe that those making it are midwives to machines that will match or surpass human intelligence. Krueger, who is based in Berkeley, says he knows people working on AI who see the technology as our natural successor. “They view it as akin to having children or something,” he says. Cohen sees parallels between many modern conspiracy theories and the New Age movement, which reached its peak of influence in the 1970s and '80s. Adherents believed humanity was on the cusp of unlocking an era of spiritual well-being and expanded consciousness that would usher in a more peaceful and prosperous world. In a nutshell, the idea was that by engaging in a set of pseudo-religious practices, including astrology and the careful curation of crystals, humans would transcend their limitations and enter a kind of hippie utopia. Today's tech industry is built on compute, not crystals, but its sense of what's at stake is no less transcendent: “You know, this idea that there is going to be this fundamental shift, there's going to be this millenarian turn where we end up in a techno-utopian future,” says Cohen. In many people's telling, AGI will arrive all at once. At which point—FOOM—it will advance so rapidly that AGI will arrive in what's often called an intelligence explosion, leading to a point of no return known as the Singularity, a goofy term that's been popular in AGI circles for years. Call it the AI Big Bang—which, again, gives us a before and an after, a transcendent moment when humanity as we know it changes forever (for good or bad). “People imagine it as an event,” says Grace from AI Impacts. For Vallor, this belief system is notable for the way that a faith in technology has replaced a faith in humans. With the pursuit of AGI, we've left that self-belief behind and bought into the idea that only technology can save us, she says. “We're in an era where other paths to material improvement of human lives and our societies seem to have been exhausted,” Vallor says. “I think the one thing that gives many people hope and a return to that kind of optimism about the future is AGI.” Push this idea to its conclusion and, again, AGI becomes a kind of god—one that can offer relief from earthly suffering, says Vallor. Kelly Joyce, a sociologist at the University of North Carolina who studies how cultural, political, and economic beliefs shape the way we think about and use technology, sees all these wild predictions about AGI as something more banal: part of a long-term pattern of overpromising from the tech industry. “What's interesting to me is that we get sucked in every time,” she says. Joyce thinks that's why, when the hype kicks in, people are predisposed to believe it. But like many pervasive conspiracy theories, it has very real consequences. More than anything else, it gives us a free pass to be lazy. It fools us into thinking we might be able to avoid the actual hard work needed to solve intractable, world-spanning problems—problems that will require international cooperation and compromise and expensive aid. Why bother with that when we'll soon have machines to figure it all out for us? Consider the resources being sunk into this grand project. Just last month, OpenAI and Nvidia announced an up-to-$100 billion partnership that would see the chip giant supply at least 10 gigawatts of ChatGPT's insatiable demand. A bolt of lightning might release that much energy. And then, only two weeks later, OpenAI announced a second partnership with chipmaker AMD for another six gigawatts of power. Promoting the Nvidia deal on CNBC, Altman, straight-faced, claimed that without this kind of data center buildout, people would have to choose between a cure for cancer and free education. “No one wants to make that choice,” he said. (Just a few weeks later, he announced that erotic chats would be coming to ChatGPT.) Add to those costs the loss of investment in more immediate technology that could change lives today and tomorrow and the next day. “To me it's a huge missed opportunity,” says Lirio's Symons, “to put all these resources into solving something nebulous when we already know there's real problems that we could solve.” But that's not how the likes of OpenAI needs to operate. Despite his steadfast belief that AGI is coming, Krueger also thinks the industry's single-minded pursuit of it means that potential solutions to real problems, such as better health care, are being ignored. Tina Law, who studies technology policy at the University of California–Davis, worries that policymakers are getting lobbied about the ways AI will one day kill us all, instead of addressing real concerns about the ways AI could impact people's lives in immediate and material ways today. “Hype is a lucrative strategy for tech firms,” says Law. A big part of that hype is the idea that what's happening is inevitable: If we don't build it, someone else will. “When something is framed as inevitable,” Law says, “people doubt not only whether they should resist but also whether they have the capacity to do so.” Everyone gets locked in. The AGI distortion field isn't limited to tech policy, says Milton Mueller at the Georgia Institute of Technology, who works on technology policy and regulation. “So whoever gets it first is going to have ultimate power over everybody else. There's a business incentive for companies (and governments) to push the myth of AGI, says Mueller, because they can then claim that they will be the first to get there. But because they're running a race in which nobody has agreed on the finish line, the myth can be spun as long as it's useful. It's not hard to see how this plays out. It's not utopia or hell—it's OpenAI and its peers making a whole lot more money. And maybe that brings us back to the whole conspiracy thing—and a late-game twist in this tale. So far we've ignored one popular feature of conspiracy thinking: that there's a group of powerful figures pulling the levers behind the scenes and that, by seeking the truth, believers can expose this elite cabal. But what if there are, in fact, shadowy puppet masters here—and they're the very people who have pushed the AGI conspiracy hardest all along? The kings of Silicon Valley are throwing everything they can get at building AGI for profit. The myth of AGI serves their interests more than anybody else's. As Vallor puts it: “If OpenAI says they're building a machine that's going to make corporations even more powerful than they are today, that isn't going to get the kind of public buy-in that they need.” Krueger says there's a line of thinking running through Silicon Valley in which building AI is a way to seize huge amounts of power. “They're putting so much effort into selling their vision of a future with AGI in it, and they're having a pretty good amount of success because they have so much power,” he adds. Goertzel, for one, is almost lamenting how successful the maybe-cabal has been. He's actually starting to miss life on the fringes. “Now it's almost, like, what your grandma tells you to do to get a job instead of being a business major.” “It's disorienting that this stuff is so broadly accepted,” he says. “It almost gives me the desire to go work on something else that not so many people are doing.” He's half joking (I think): “Obviously, putting the finishing touches to AGI is more important than gratifying my preference to be out on the frontier.” In a lot of ways, I think the whole idea of AGI is built on a warped view of what we should expect technology to do, and even what intelligence is in the first place. Stripped back to its essentials, the argument for AGI rests on the premise that one technology, AI, has gotten very good, very fast, and will continue to get better. But set aside the technical objections—what if it doesn't continue to get better?—and you're left with the claim that intelligence is a commodity you can get more of if you have the right data or compute or neural network. Some Nobel Prize winners are really bad at playing the piano or caring for their kids. Some very smart people insist that AGI is coming next year. It's hard not to wonder what will get its hooks into us next. Before we ended our call, Goertzel told me about an event he'd just been to in San Francisco on AI consciousness and parapsychology: “ESP, precognition, and whatnot.” They're risking their clients' trust and privacy in the process. Machine translators have made it easier than ever to create error-plagued Wikipedia articles in obscure languages. What happens when AI models get trained on junk pages? India is OpenAI's second-largest market, but ChatGPT and Sora reproduce caste stereotypes that harm millions of people. Discover special offers, top stories, upcoming events, and more. Try refreshing this page and updating them one more time.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.technologyreview.com/2025/10/30/1126471/chatbots-are-surprisingly-effective-at-debunking-conspiracy-theories/'>Chatbots are surprisingly effective at debunking conspiracy theories</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.technologyreview.com', 'title': 'MIT Technology Review'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 10:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Turns out many believers do respond positively when presented with the right evidence and arguments. It's become a truism that facts alone don't change people's minds. Perhaps nowhere is this more clear than when it comes to conspiracy theories: Many people believe that you can't talk conspiracists out of their beliefs. It turns out that many conspiracy believers do respond to evidence and arguments—information that is now easy to deliver in the form of a tailored conversation with an AI chatbot. In research we published in the journal Science this year, we had over 2,000 conspiracy believers engage in a roughly eight-minute conversation with DebunkBot, a model we built on top of OpenAI's GPT-4 Turbo (the most up-to-date GPT model at that time). Participants began by writing out, in their own words, a conspiracy theory that they believed and the evidence that made the theory compelling to them. This story is part of MIT Technology Review's series “The New Conspiracy Age,” on how the present boom in conspiracy theories is reshaping science and technology. This is good news, given the outsize role that unfounded conspiracy theories play in today's political landscape. So while there are widespread and legitimate concerns that generative AI is a potent tool for spreading disinformation, our work shows that it can also be part of the solution. Even people who began the conversation absolutely certain that their conspiracy was true, or who indicated that it was highly important to their personal worldview, showed marked decreases in belief. Remarkably, the effects were very durable; we followed up with participants two months later and saw just as big a reduction in conspiracy belief as we did immediately after the conversations. Our experiments indicate that many believers are relatively rational but misinformed, and getting them timely, accurate facts can have a big impact. Conspiracy theories can make sense to reasonable people who have simply never heard clear, non-conspiratorial explanations for the events they're fixated on. For example, 9/11 deniers often point to the claim that jet fuel doesn't burn hot enough to melt steel as evidence that airplanes were not responsible for bringing down the Twin Towers—but the chatbot responds by pointing out that although this is true, the American Institute of Steel Construction says jet fuel does burn hot enough to reduce the strength of steel by over 50%, which is more than enough to cause such towers to collapse. Although we have greater access to factual information than ever before, it is extremely difficult to search that vast corpus of knowledge efficiently. There are large time and skill barriers to conducting such a search every time we hear a new claim, and so it's easy to take conspiratorial content you stumble upon at face value. And most would-be debunkers at the Thanksgiving table make elementary mistakes that AI avoids: Do you know the melting point and tensile strength of steel offhand? With enough effort, humans would almost certainly be able to research and deliver facts like the AI in our experiments. And in a follow-up experiment, we found that the AI debunking was just as effective if we told participants they were talking to an expert rather than an AI. So it's not that the debunking effect is AI-specific. Generally speaking, facts and evidence delivered by humans would also work. Generative AI can do the cognitive labor of fact-checking and rebutting conspiracy claims much more efficiently. When we hired a professional fact-checker to evaluate GPT-4's claims, they found that over 99% of the claims were rated as true (and not politically biased). Now, thanks to advances in generative AI, we have a tool that can change conspiracists' minds using evidence. Bots prompted to debunk conspiracy theories could be deployed on social media platforms to engage with those who share conspiratorial content—including other AI chatbots that spread conspiracies. And instead of arguing with your conspiratorial uncle over the dinner table, you could just pass him your phone and have him talk to AI. By that account, our passions trump truth, logic-based reasoning is passé, and the only way to effectively change people's minds is via psychological tactics like presenting compelling personal narratives or changing perceptions of the social norm. If so, the typical, discourse-based work of living together in a democracy is fruitless. Our findings about conspiracy theories are the latest—and perhaps most extreme—in an emerging body of research demonstrating the persuasive power of facts and evidence. For example, while it was once believed that correcting falsehoods that aligns with one's politics would just cause people to dig in and believe them even more, this idea of a “backfire” has itself been debunked: Many studies consistently find that corrections and warning labels reduce belief in, and sharing of, falsehoods—even among those who most distrust the fact-checkers making the corrections. Similarly, evidence-based arguments can change partisans' minds on political issues, even when they are actively reminded that the argument goes against their party leader's position. And simply reminding people to think about whether content is accurate before they share it can substantially reduce the spread of misinformation. And if facts aren't dead, then there's hope for democracy—though this arguably requires a consensus set of facts from which rival factions can work. There is indeed widespread partisan disagreement on basic facts, and a disturbing level of belief in conspiracy theories. When faced with evidence—even inconvenient or uncomfortable evidence—many people do shift their thinking in response. And so if it's possible to disseminate accurate information widely enough, perhaps with the help of AI, we may be able to reestablish the factual common ground that is missing from society today. Thomas Costello is an assistant professor in social and decision sciences at Carnegie Mellon University. His research integrates psychology, political science, and human-computer interaction to examine where our viewpoints come from, how they differ from person to person, and why they change—as well as the sweeping impacts of artificial intelligence on these processes. He examines the causes and consequences of analytic reasoning, exploring how intuitive versus deliberative thinking shapes decision-making to understand errors underlying issues such as climate inaction, health behaviors, and political polarization. They're risking their clients' trust and privacy in the process. Machine translators have made it easier than ever to create error-plagued Wikipedia articles in obscure languages. What happens when AI models get trained on junk pages? India is OpenAI's second-largest market, but ChatGPT and Sora reproduce caste stereotypes that harm millions of people. Discover special offers, top stories, upcoming events, and more. Try refreshing this page and updating them one more time.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/nasa-may-let-bezos-do-what-musk-is-struggling-to-deliver-land-astronauts-on-the-moon-2000678930'>Bezos's Blue Origin Could Leapfrog SpaceX as NASA's Lunar Lander Pick for Artemis 3</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-10-30 09:00:06
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>With SpaceX's lunar lander for NASA's Artemis 3 mission facing significant delays, the agency is looking to competitors who could provide a lander sooner. Blue Origin is a leading contender, but can Jeff Bezos's company really beat Elon Musk back to the Moon? Jacqueline Cortese, Blue Origin's Senior Director of Civil Space, represented the company on a Tuesday panel at the American Astronautical Society's 2025 von Braun Space Exploration Symposium. It's a stepping stone to the MK2 crew lander, which could (theoretically) replace SpaceX's Starship Human Landing System (HLS) as the Artemis 3 lander—if it's ready first. “Especially with MK1 and some of our preceding work we're doing, we have what we think are some good ideas about maybe a more incremental approach that could be taken advantage of for an acceleration-type scenario,” Cortese said, as SpaceflightNow reports. SpaceX signed a $2.9 billion contract with NASA in 2021 to provide the first crewed lunar lander for the agency's Artemis program. After a rough start to Starship's 2025 launch schedule, however, unmet technical milestones have piled up. Now, experts worry that Starship HLS could be years late for a 2027 Artemis 3 Moon landing. And as it's still in the early stages of development, its lunar landing capabilities remain unproven. “I'm going to let other space companies compete with SpaceX, like Blue Origin, and again, whatever one can get us there first, to the Moon, we're going to take,” Duffy said on CNBC. The Blue Moon landers offer a level of simplicity Starship HLS just can't provide. Not only are they based on a largely proven concept, they're also much smaller, with a lower center of gravity and an easier dismount. What's more, they're being built by a massive team of highly equipped engineers across Blue Origin, Lockheed Martin, Boeing, Draper, Astrobotic, and Honeybee Robotics. But the company is also developing plans for MK2 that could expedite Artemis 3. During Tuesday's panel, Cortese reportedly said that an MK1 lander is undergoing final stacking at a dedicated production facility in Port Canaveral in Florida. Once stacking is complete, the spacecraft will be transported to NASA's Johnson Space Center in Houston, Texas, for a series of tests that simulate the vacuum and extreme temperature fluctuations of space. MK1's inaugural demonstration mission—dubbed “Pathfinder”—will attempt to land at the Moon's south pole. This will allow Blue Origin to test critical systems and validate hardware for the MK2 lander. The mission will also carry two NASA payloads: SCALPSS (Stereo Cameras for Lunar-Plume Surface Studies) and LRA (Laser Retroreflective Array). That said, Blue Origin will still face major hurdles to launching a crewed MK2 mission, namely demonstrating a propellant transfer, validating the spacecraft's life-support system, and acquiring crew certification. And even if NASA did select it for Artemis 3, integrating this alternative landing system into the current Artemis 3 architecture could present unforeseen challenges. For now, the pressure remains on SpaceX to deliver a viable human landing system before mid-2027. Whether Blue Origin's progress lights a fire under Musk's company remains to be seen. X-59 is designed to usher in a new era of air travel with its quiet supersonic technology. Billionaire entrepreneur Jared Isaacman has re-emerged as the front runner for NASA Administrator, but it appears Acting Administrator Sean Duffy wants to secure the role for himself. Astronomers may be just weeks away from an unprecedented opportunity to learn more about our solar system's interstellar visitor.</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            