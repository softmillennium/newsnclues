
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - TECHNOLOGY Article Summaries - 2026-02-04</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            TECHNOLOGY
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/a24-will-revive-texas-chainsaw-massacre-with-a-tv-show-and-movie-2000717875'>A24 Will Revive ‚ÄòTexas Chainsaw Massacre' With a TV Show and Movie</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 17:00:26
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Per Deadline, the Civil War studio will make good on its plans to expand the slasher series with two new projects. First on deck is a TV series from The Long Walk writer JT Mollner, actor Glen Powell, and producer Roy Lee. (Powell's currently just on hand to produce, possibly nixing any dreams of seeing him fight or die against Leatherface.) A new movie is also in early development by the show's producing team, but Mollner's reportedly not involved with it. I can't imagine better partners for this approach than A24. Powell similarly called the 1974 original one of his favorite films and ‚Äúone of the definitive movies of my home state ‚Ä¶ With a marquee home in A24 and [with] visionary filmmaker JT Mollner, alongside our top-shelf producing partners, I couldn't have dreamed of a better team for such a dream property.‚Äù When Texas Chainsaw Massacre's rights were first up for grabs, horror filmmakers like Jordan Peele, Taylor Sheridan, and Oz Perkins were reportedly interested in getting onboard and reviving it with their own spin. We'll have more on the Texas show and eventual film as they develop. Check out when to expect the latest Marvel, Star Wars, and Star Trek releases, what's next for the DC Universe on film and TV, and everything you need to know about the future of Doctor Who. Subscribe and interact with our community, get up to date with our customised Newsletters and much more. J.J. Abrams is making his return to the big screen this fall with Glen Powell and Jenna Ortega in 'The Great Beyond.' That's the plot of 'undertone,' a new film from A24, which opens on Friday, March 13. Glen Powell and Edgar Wright dropped footage from the November release at New York Comic Con.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/pinterest-reportedly-fires-employees-who-built-a-tool-to-track-layoffs-2000717884'>Pinterest Reportedly Fires Employees Who Built a Tool to Track Layoffs</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 16:40:41
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Pinterest fired employees who were trying to track the recently announced layoffs. The digital pinboard social media company announced last week that it would be laying off about 15% of its staff and shrinking its office space as part of a restructuring effort. In a meeting led by the company's Chief Technology Officer Matt Madrigal, engineering employees were told that Pinterest would not provide a list of affected employees due to privacy rights and company policies. That's when two employees took matters into their own hands. According to Pinterest, the engineers built an internal tool aimed at creating a master list of laid-off employees. ‚ÄúAfter being clearly informed that Pinterest would not broadly share information identifying impacted employees, two engineers wrote custom scripts improperly accessing confidential company information to identify the locations and names of all dismissed employees and then shared it more broadly,‚Äù a Pinterest spokesperson told Gizmodo in an emailed statement. CNBC and other outlets reported that those employees were eventually let go. Additionally, audio obtained from an all-hands meeting on Friday by CNBC suggests leadership viewed the incident as more than just a privacy issue. ‚ÄúHealthy debate and dissent are expected, that's how we make our decisions,‚Äù said Pinterest CEO Bill Ready at the meeting, according to CNBC. ‚ÄúBut there's a clear line between constructive debate and behavior that's obstructionist.‚Äù Like many tech companies in recent months, Pinterest has increasingly leaned into AI. Meanwhile, Amazon announced last week it was laying off roughly 16,000 workers. That all comes as software companies are currently experiencing a blood bath in the stock market. The new laws would make it harder for states and cities to regulate AI. Radars and cameras might be for seeing cars and people now but they can be used to make existing roads better in the first place. How many award-winning writers are desperate enough to train Grok?</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2026/littlebird-takes-flight-startup-ships-its-wearable-kid-tracker-now-with-amazon-and-walmart-ties/'>Littlebird takes flight: Startup ships its wearable kid tracker, now with Amazon and Walmart ties</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 16:24:13
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When Littlebird founder Monica Plath was first promoting her Seattle-based startup in 2022, the idea was a ‚Äútoddler tracker‚Äù designed to give parents a window into their child's day with a nanny or sitter. But as smartphone bans sweep through U.S. schools, Littlebird's promise has evolved into something more ambitious: a physical alternative for parents who want to stay connected without surrendering their kids to the digital world. ‚ÄúParents don't have an option besides AirTagging their kids, and AirTags were meant to find luggage, not for on-demand, real-time alerts.‚Äù Strapped to the wrist of a kid, Littlebird looks like an Apple Watch at first glance, but without any screen to tell time, take calls, text friends, play music or check the internet. Plath said on LinkedIn this week that Littlebird shipped nearly 1,000 units in the first few days, and had $200,000 in sales on the first product release day last week. A University of Washington alum and single mom to two kids, Plath has spent the last two years overhauling Littlebird's technical DNA. The company has gone from niche toddler tool to what Plath calls a ‚Äúfrontier tech‚Äù contender, attracting the attention of two of the biggest names in retail and infrastructure: Amazon and Walmart. Plath said Littlebird is the first third-party company to integrate Amazon Sidewalk, a private, long-range network that piggybacks off the millions of Echo and Ring devices already sitting in American homes. And while Littlebird attracted 2,000 direct-to-consumer pre-orders over the last couple years, the startup is poised for a major retail leap. Unlike the Apple Watch or similar devices that can be viewed as classroom distractions, Littlebird does not chirp at the kids who are wearing it. There's no interactivity, just a light to signal that it's working. Sensors in the device determine when it's being worn. A ‚Äúnest‚Äù is an important place such as home, school, or camp. Alerts can be set to signal when a child is coming and going. An early version of Littlebird was originally intended to monitor health metrics such as activity level, sleep, heart rate and temperature. ‚ÄúAs we moved from prototypes into a real, shippable product for children, we made a deliberate decision not to ship anything that could be interpreted as medical functionality or invite medical claims,‚Äù Plath said. Littlebird has adopted a membership-based pricing model similar to high-end fitness wearables like Whoop and Oura. Littlebird employs six people and is looking to double headcount over the next couple months. ‚ÄúLess than 2% of all venture capital goes to female founders,‚Äù she said, adding that ‚Äúagainst all odds‚Äù she's out to prove that Littlebird can build and scale hardware out of Seattle, a region known primarily for software and cloud tech. Have a scoop that you'd like GeekWire to cover? Amazon is acquiring Bee, maker of a wearable AI assistant that listens to conversations Inventory-tracking startup Augmodo raises $5.3M to monitor store shelves via wearable tech Pacific Northwest tech startup deals: The top 15 funding rounds during Q3 This $250 wearable head device aims to train your brain with games</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/mistral-voxtral-real-time-ai-translation/'>Mistral's New Ultra-Fast Translation Model Gives Big AI Labs a Run for Their Money</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 15:32:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Mistral AI has released a new family of AI models that it claims will clear the path to seamless conversation between people speaking different languages. The former is built to transcribe audio files in large batches and the latter for nearly real-time transcription, within 200 milliseconds; both can translate between 13 languages. Voxtral Realtime is freely available under an open source license. Mistral has pitched Voxtral Realtime‚Äîthough the model outputs text, not speech‚Äîas a marked step towards free-flowing conversation across the language barrier, a problem Apple and Google are also competing to solve. The latest model from Google is able to translate at a two-second delay. This model is basically laying the groundwork for that,‚Äù claims Pierre Stock, VP of Science Operations at Mistral, in an interview with WIRED. Founded in 2023 by Meta and Google DeepMind alumni, Mistral is one of few European companies developing foundational AI models capable of running remotely close to the American market leaders‚ÄîOpenAI, Anthropic, and Google‚Äîfrom a capability standpoint. Without access to the same level of funding and compute, Mistral has focused on eking out performance through imaginative model design and careful optimization of training datasets. The aim is that micro-improvements across all aspects of model development translate into material performance gains. Mistral's flagship large language model (LLM) does not match competing models developed by US competitors for raw capability. ‚ÄúMistral offers an alternative that is more cost efficient, where the models are not as big, but they're good enough, and they can be shared openly,‚Äù says Annabelle Gawer, director at the Centre of Digital Economy at the University of Surrey. ‚ÄúMistral does not position itself as a niche player, but it is certainly creating specialized models,‚Äù says Gawer. You leave this kind of less profitable business on the table, which creates room for middle players.‚Äù As the relationship between the US and its European allies shows signs of deterioration, Mistral has leant increasingly into its European roots too. ‚ÄúThere is a trend in Europe where companies and in particular governments are looking very carefully at their dependency on US software and AI firms,‚Äù says Dan Bieler, principal analyst at IT consulting firm PAC. ‚ÄúTheir question has always been: How do we build a defensible position in a market that is dominated by hugely financed American actors?‚Äù says Rapha√´lle D'Ornano, founder of tech advisory firm D'Ornano + Co. ‚ÄúThe approach Mistral has taken so far is that they want to be the sovereign alternative, compliant with all the regulations that may exist within the EU.‚Äù ‚ÄúSmall and more regionally focused models will play a much larger role going forward.‚Äù In your inbox: Sign up for our new Tracker: ICE newsletter Big Story: He leaked a scam compound's secrets‚Äîand had to get out alive</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/pc-components/gpus/gamer-scores-nvidias-usd999-powerhouse-rtx-5080-for-a-jaw-dropping-usd289-the-walmart-clearance-aisle-is-the-secret-weapon-to-beat-the-ai-driven-gpu-shortage'>Gamer scores Nvidia's $999 powerhouse RTX 5080 for a jaw-dropping $562 ‚Äî the Walmart clearance aisle is the secret weapon to beat the AI-driven GPU shortage (Updated)</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 15:14:35
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>A place to score premium GPUs while everyone else pays full price When you purchase through links on our site, we may earn an affiliate commission. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Update 04/02/2026 7:14 am PT: One Redditor shared an AI-generated image of a fake deal. What started as one fortuitous shopper's success story in securing a graphics card at an amazingly low price has escalated into an all-out bragging contest. Redditors are flooding a viral thread to flaunt the incredible steals they've scored on Nvidia's GeForce RTX 50 (codenamed Blackwell) series (codenamed Blackwell), some of the best graphics cards that you can buy at the moment. The original poster recently purchased a PNY GeForce RTX 5080 Overclocked Triple Fan graphics card for $562.49, 44% below its MSRP. Meanwhile, another Redditor gave fellow users a friendly heads-up about multiple PNY GeForce RTX 5070 Overclocked Triple Fan graphics cards at another Walmart store with $439.20 price tags. However, not every scavenger hunt has a happy ending. One unlucky Redditor had bought a PNY GeForce RTX 5090 Overclocked Triple Fan graphics card at MSRP, which is rare nowadays given market conditions. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. There's always a risk of purchasing high-value computer hardware at Walmart's clearance area. Sometimes these marked items are online returns where dishonest buyers use the swindler scam, and Walmart doesn't properly verify them. At other times, you may get lucky because markdowns result from damaged packaging or missing contents. As you can see from our GPU price tracker, prices continue to soar, and there is limited inventory across all U.S. retailers. It's near impossible to find a graphics card at MSRP, much less good deals on them. Desperate PC builders and upgraders have started looking beyond traditional retail channels and poking around in unorthodox places, such as Walmart clearance areas or thrift stores, which have produced a couple of interesting finds. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Zhiye Liu is a news editor, memory reviewer, and SSD tester at Tom's Hardware. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=46886114'>Cannabis usage in older adults linked to larger brain, better cognitive function</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 15:13:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>That's a bad example to make your point. I know many a cigarette smoker who had their first cig puff while intoxicated around other drinkers who were smoking.When a commonplace and socially accepted drug like alcohol can amplify poor judgement and inhibition, the sky's the limit for what unfolds next. When a commonplace and socially accepted drug like alcohol can amplify poor judgement and inhibition, the sky's the limit for what unfolds next. These users often completely ignore, leave out, or outright lie about the downsides of these drugs, from chronic weed use to LSD. But maybe its a pop-science kind of fact that I've been carring along all this time without factuality? So over the years of habit building, I've forced myself, when asked a question, to wait, argue it out in my head, then respond.So, in face-to-face conversations, I appear slow but at least not dumb, but I come to a fleshed-out conclusion. So, in face-to-face conversations, I appear slow but at least not dumb, but I come to a fleshed-out conclusion. ive noticed most nonusers spit out automated responses, and have little to no recall of the conversation a few minutes after. I find it harder to context-switch immediately when stoned. The other time I notice this type of pause is when I've entered a "flow state," e.g. when deep in a programming project.Sometimes I can leverage this "focus" into productivity when stoned, but then I am often equally likely to get focused on the wrong thing.That said, it's well established that marijuana use acutely reduces your reaction time. Sometimes I can leverage this "focus" into productivity when stoned, but then I am often equally likely to get focused on the wrong thing.That said, it's well established that marijuana use acutely reduces your reaction time. Then again, I've never been able to speak well. We all have anecdotes, and mine contradict yours.All of the non-users of cannabis I know have terrible memory, and are often surprised by mine. The impacts are subtle, but they're there.The negative side effects are definitely being underrepresented at the ‚Äúnon-scaremongering‚Äù parts of civilization. For me, the downsides manifest as drarticlsly increased anxiety (I naturally have next to none), extremely poor sleep - I sleep but the sleep is so low quality it begins to feel like my brain barely works right, and the obvious one, the effects on your motivation. I naturally tend towards ADHD style dopamine chasing, and weed makes that about 100x worse. Instead of getting my work done, I will procrastinate with any number of cheap dopamine hits such as video games, internet sleuthing, etc. Have you tried blending in CBD?Typically I smoke small joints with 90% CBD strains and the rest a high THC strain, only thing I can smoke. Typically I smoke small joints with 90% CBD strains and the rest a high THC strain, only thing I can smoke. Director level at Mt Sinai and orthopedic surgeons for the Washington commnders) are more than delighted with my prescriptionso like that's just your opinion man I see people smoke all day all the time now and while driving and it clearly affects their judgement. Any intelligence I've lost was not going towards anything that mattered anyway. That's actually what got me to quit initially years ago. So why am I okay with getting high? Edit: down-voters do not allow me to dislike the smell. I don't smoke weed but I had a roommate in college that smoked in the apartment 24/hours a day. But, after that first week, I didn't even notice the smell. I can smell it when the car ahead of me is smoking, I can smell it when the person on the other side of the bar recently smoked, hell, I can smell it in my car as soon as I start to approach my neighboring state where it's legal. Of course, eventually I realized it coincided with my neighbors college-aged kid coming home for summer break and smoking in their room.Anyone that says that cigarette smoke, perfume, car exhaust, people's breath in general, smell to any degree that weed does to non-smokers is incredulous. I can smell it when the car ahead of me is smoking, I can smell it when the person on the other side of the bar recently smoked, hell, I can smell it in my car as soon as I start to approach my neighboring state where it's legal. Of course, eventually I realized it coincided with my neighbors college-aged kid coming home for summer break and smoking in their room.Anyone that says that cigarette smoke, perfume, car exhaust, people's breath in general, smell to any degree that weed does to non-smokers is incredulous. It hardly makes any sense to focus on the far smaller issue that doesn't seem to cause any issues apart from pearl clutching. Whataboutism would be more like comparing cannabis odour to people who fart in lifts. These two issues can coexist, but they're in completely different universes. Long-term air quality and vehicle pollution are systemic public-health problems. This is about basic courtesy and reasonable behavior in shared public spaces, especially around infants. One does not negate or diminish the other. Read what any of your favorite musicians have to say about it. Check the science and testimony on it enhancing creativity and sensory experience, helping people see see themselves and the world from a new perspective - introspective development.You know, the same sort of introspection that might make one wonder if your statement above says a lot more about you, and your values, than it does about cannabis enjoyers. You know, the same sort of introspection that might make one wonder if your statement above says a lot more about you, and your values, than it does about cannabis enjoyers. https://thereitis.org/mr-x-by-carl-sagan/He originally wrote about it under a pseudonym for fear of professional consequences. He originally wrote about it under a pseudonym for fear of professional consequences. But usually they are either very light users or they achieved their success before becoming heavy users.I also know some pretty heavy users that are adamant that they are doing better than before but their environment does not usually agree. I also know some pretty heavy users that are adamant that they are doing better than before but their environment does not usually agree. I'm pretty sure if you manage it responsibly the benefits may well outweigh the downsides but over the long term it really adds up.Of course, everybody ages, and people are not usually as sharp as they were in their twenties or earlier. But given that I also have access to a sizeable control group where I don't see that effect I figure it has to have some factual basis too large to be just handwaved away.Feel free to correct the fact that we haven't met in person by the way, you & yours are always welcome here. Of course, everybody ages, and people are not usually as sharp as they were in their twenties or earlier. But given that I also have access to a sizeable control group where I don't see that effect I figure it has to have some factual basis too large to be just handwaved away.Feel free to correct the fact that we haven't met in person by the way, you & yours are always welcome here. Feel free to correct the fact that we haven't met in person by the way, you & yours are always welcome here. Wisdom is understanding that if there was legislation on the matter, and people who ate, produced, or sold non-tomato fruits were hunted and deprived of their freedoms by the state on the basis that fruits are bad for society, then you would likely see similar frustrations expressed about an article title that includes the phrase "tomatoes and fruits" to distinguish them. Most drugs, OTOH, when used at the doses that make them attractive to recreational drug users, impair reason, and impairing reason is not just stupid, but immoral. We can debate the particular methods by which the state regulates or otherwise deals with drug use, but there is nothing intrinsically wrong with the criminalization of such drugs as such. This may seem alien to a culture whose emaciated understanding of morality is exhausted by the concept of consent. Like all immorality, it is an insult to one's dignity and humanity.We can tolerate the impairment of reason as a proportionate side effect [0] (for instance, high doses of morphine given to terminally ill patients in extreme pain), but this is not recreational use. We can tolerate the impairment of reason as a proportionate side effect [0] (for instance, high doses of morphine given to terminally ill patients in extreme pain), but this is not recreational use. re: the article itself, they concentrate only on brain regions which have high density of CB1 expression and that's reasonable. But CB1 is not the only CNS cannabinoid receptor (CB2 mostly expressed peripherally). There's also GPR55 which is activated by cannabinoids like THC. A little issue which could be addressed in future work. Also who drinks alcohol without wanting at least some of the intoxication effects? You would not drive in France for instance, because of the residual alcohol There are no metaphysical truth particles that shake 'True!'. Expressivism, how you feel about the statement, is going to decide what you think.Anyway, I used to intentionally say things like "I love drugs, although its specifically Caffeine." There are no metaphysical truth particles that shake 'True!'. Expressivism, how you feel about the statement, is going to decide what you think.Anyway, I used to intentionally say things like "I love drugs, although its specifically Caffeine." https://cheflindseyfarr.com/marinated-tomato-stone-fruit-sal...(I second the recommendation of adding burrata.) Industry-fueled self-delusion can be intercepted if we make the effort to do so. Plenty of drugs, used in moderation, are also relaxing and can be enjoyable to the senses.Alcohol, caffeine, nicotine, and marijuana products ARE drugs, not sure why people insist on making the distinction. Alcohol, caffeine, nicotine, and marijuana products ARE drugs, not sure why people insist on making the distinction. Appeal to authority is the opposite of science.Anyway, sounds like induction, it might be probabilistically true, but they don't have the theory to prove it. Anyway, sounds like induction, it might be probabilistically true, but they don't have the theory to prove it. I don't think there is any controversy there is at least a weak link between intelligence and access to luxury goods.In other news, occasional cigar smokers have slightly lower cancer rates. Unclear to me if that's actually UK citizens, but prices in UK are significantly higher than those quoting legal weed state prices. It appears those downvoting / rebutting are attempting to strong-arm a US centric view into foreign sourced  data. Using data from the UK Biobank, which includes health information from over 500,000 adults, associations between cannabis use, regional brain volume, and cognition in participants aged 40‚Äì70 years (mean age = 54.5) were evaluated. In other news, occasional cigar smokers have slightly lower cancer rates. Unclear to me if that's actually UK citizens, but prices in UK are significantly higher than those quoting legal weed state prices. It appears those downvoting / rebutting are attempting to strong-arm a US centric view into foreign sourced  data. Using data from the UK Biobank, which includes health information from over 500,000 adults, associations between cannabis use, regional brain volume, and cognition in participants aged 40‚Äì70 years (mean age = 54.5) were evaluated. --------------------------------------------Edit: those talking about price being cheap in US: the data is from UK biobank. Unclear to me if that's actually UK citizens, but prices in UK are significantly higher than those quoting legal weed state prices. It appears those downvoting / rebutting are attempting to strong-arm a US centric view into foreign sourced  data. Using data from the UK Biobank, which includes health information from over 500,000 adults, associations between cannabis use, regional brain volume, and cognition in participants aged 40‚Äì70 years (mean age = 54.5) were evaluated. Edit: those talking about price being cheap in US: the data is from UK biobank. Unclear to me if that's actually UK citizens, but prices in UK are significantly higher than those quoting legal weed state prices. It appears those downvoting / rebutting are attempting to strong-arm a US centric view into foreign sourced  data. Using data from the UK Biobank, which includes health information from over 500,000 adults, associations between cannabis use, regional brain volume, and cognition in participants aged 40‚Äì70 years (mean age = 54.5) were evaluated. Using data from the UK Biobank, which includes health information from over 500,000 adults, associations between cannabis use, regional brain volume, and cognition in participants aged 40‚Äì70 years (mean age = 54.5) were evaluated. Because the hemp laws were poorly written,  this product was legal in all 50 stateshttps://cyclingfrog.com/The 10mg THC drinks give a whiff of cannabis when you open one and produce an intoxication similar to smoking with an experience similar to drinking an alcoholic drink. It's more expensive than the cheapest beer,  but similar to a reasonably priced wine or drink in a bar. Unfortunately these will be gone in most places by the end of 2026. It's more expensive than the cheapest beer,  but similar to a reasonably priced wine or drink in a bar. Unfortunately these will be gone in most places by the end of 2026. It's more expensive than the cheapest beer,  but similar to a reasonably priced wine or drink in a bar. Unfortunately these will be gone in most places by the end of 2026. This can be said about any drug, but even then, heavy use of weed vs other drugs is absolutely cheaper, especially these days if you live in an area where it's legal and/or are willing to grow it.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2026/amazon-rolls-out-alexa-to-all-u-s-customers-making-its-ai-assistant-free-for-prime-members/'>Amazon rolls out Alexa+ to all U.S. customers, making its AI assistant free for Prime members</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 14:58:57
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Amazon is betting that an AI assistant best known for turning on lights and answering trivia questions can become a sought-after benefit of its Prime membership, in the same league as free shipping and streaming video. The company is making Alexa+, the generative AI-powered upgrade to its voice assistant, available free starting today to all U.S. Prime members, nearly a year after it was unveiled. Today's rollout opens it up to Amazon's full U.S. Prime membership base, which is estimated at more than 200 million individual members by Consumer Intelligence Research Partners. But the broad rollout comes more than three years into the generative AI era, with AI habits already ingrained for many users around ChatGPT, Claude, Gemini, and others. Given its late start, Amazon is hoping that unlimited access to Alexa+ via Prime (including a browser-based chat experience at Alexa.com) will help close the gap against those rivals. Daniel Rausch, Amazon's vice president of Alexa and Echo, said in an interview that the Prime benefit is aimed at customers who use AI tools but can't or don't want to pay for a standalone subscription. Rausch cited the example of students and others who ‚Äúbounce around between different chat assistants‚Äù when they hit usage limits on free tiers. Whether consumers see it as a true replacement for other AI chatbots remains to be seen. The site was only able to accept one document at a time, unlike other chatbots that can handle multiple uploads simultaneously. It's a small but telling limitation for anyone accustomed to the competition. For example, having uploaded those materials individually, I can now ask Alexa+ on my Echo devices to reference them in its responses ‚Äî something I've been doing already in the Alexa+ early access program with emails from our kid's school and other family documents. Rausch said 76% of what customers do with Alexa+ is unavailable in any other AI, according to Amazon's own internal data. He cited functionality such as smart home controls, family calendar management, music discovery, booking reservations, and the thousands of device and service integrations that Amazon has built up over a decade. The chips powering your smart TV, voice assistant, tablet, and car all have something in common: MediaTek Oregon theater marquee joked about ‚ÄòMelania' movie, and manager says Amazon pulled the film Amazon's ‚ÄòJust Walk Out' tech will survive company's retail pullback, minus the palm-scanning Amazon's new Alexa+ uses generative AI to personalize conversations and automate tasks Alexa+ in the real world: How I'm using Amazon's new assistant, and where it could still improve Claude meets Alexa: Amazon will reportedly use Anthropic's AI to help power its voice assistant</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2026/02/04/after-backlash-adobe-cancels-adobe-animate-shutdown-and-puts-app-on-maintenance-mode/'>After backlash, Adobe cancels Adobe Animate shutdown and puts app on 'maintenance mode'</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 14:53:21
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>‚ÄúWe are not discontinuing or removing access to Adobe Animate. Adobe's Monday announcement about discontinuing Animate was met with incredulity, disappointment, and anger, and users aired concerns about the lack of alternatives that mirror Animate's functionality. The company changed its tune on Wednesday, saying there would no longer be a ‚Äúdeadline or date by which Animate will no longer be available.‚Äù Maintenance mode means we will continue to support the application and provide ongoing security and bug fixes, but we are no longer adding new features. Animate will continue to be available for both new and existing users‚ÄØ-‚ÄØwe will not be discontinuing or removing access to Adobe Animate,‚Äù it said. One customer, posting on X, had asked Adobe to at least open source the software rather than abandon it. Commenters on the thread responded with angst, saying things like, ‚Äúthis is legit gonna ruin my life,‚Äù and, ‚Äúliterally what the hell are they doing? Other customers would have support through March of next year. Acknowledging this change, we are planning to discontinue supporting Animate.‚Äù we literally had a whole semester of adobe animate class and now they're discontinuing it üò≠ https://t.co/Xsn9t05qpV Instead, it said customers with a Creative Cloud Pro plan can use other Adobe apps to ‚Äúreplace portions of Animate functionality.‚Äù For instance, it suggested that Adobe After Effects can support complex keyframe animation using the Puppet tool, and Adobe Express can be used for animation effects that can be applied to photos, videos, text, shapes, and other design elements. Typically, Adobe charged $34.49 per month for the software, which dropped to $22.99 with a 12-month commitment. Now, the company says it will be available to new users, as well. Updated, February 4, 2026, to note that Adobe reversed its decision and announced the software would be placed in maintenance mode instead of discontinued. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what's next. Fintech CEO and Forbes 30 Under 30 alum has been charged for alleged fraud Notepad++ says Chinese government hackers hijacked its software updates for months Nvidia CEO pushes back against report that his company's $100B OpenAI investment has stalled OpenClaw's AI assistants are now building their own social network Waymo robotaxi hits a child near an elementary school in Santa Monica</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2026/02/04/snak-venture-partners-raises-50m-fund-to-back-digitizing-marketplaces/'>SNAK Venture Partners raises $50M fund to back vertical marketplaces</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 14:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>SNAK Venture Partners announced Wednesday the close of its oversubscribed $50 million debut fund, anchored by the investment firm Pritzker Group (founded by Illinois governor JB Pritzker and his brother, Tony). ‚ÄúMost of those wins were in consumer, which tends to be faster-moving than large enterprises,‚Äù Nagar continued. ‚ÄúWe think there's a ton of white space to double down and focus on B2B marketplaces.‚Äù Looking specifically for the categories that haven't yet digitized. Though many new funds are struggling to raise capital (and capital remains concentrated at the top), Nagar said she and Koopersmith were able to lean on their backgrounds when wooing LPs. Nagar previously helped launch Amazon apparel back in 2009, and was head of mobile at RetailMeNot. Koopersmith, meanwhile, spent 20 years at Pritzker Group and serves on the board of various marketplace companies. At the same time, Nagar said that without Pritzker's support, it would have been quite hard to raise this fund, especially in last year's environment. Nagar said the firm is also location-agnostic, recognizing that the still-hidden marketplaces may not be found only in Silicon Valley and New York City. ‚ÄúWe're finding these overlooked founders in places where maybe other funds aren't looking,‚Äù she said. SNAK is itself based in Chicago, which she said some LPs have questioned. Dominic-Madori Davis is a senior venture capital and startup reporter at TechCrunch. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what's next. Fintech CEO and Forbes 30 Under 30 alum has been charged for alleged fraud Notepad++ says Chinese government hackers hijacked its software updates for months Nvidia CEO pushes back against report that his company's $100B OpenAI investment has stalled OpenClaw's AI assistants are now building their own social network Waymo robotaxi hits a child near an elementary school in Santa Monica</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.technewsworld.com/story/pilot-wells-lay-groundwork-for-hydrogen-powered-energy-production-180152.html'>Pilot Wells Lay Groundwork for Hydrogen-Powered Energy Production</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.technewsworld.com', 'title': 'TechNewsWorld'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 13:03:59
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The Quebec pilot is the first field deployment of Vema Hydrogen's Engineered Mineral Hydrogen (EMH) technology and, according to the company, a significant development on its route toward tapping into a gigawatt-scale hydrogen supply that can attract and power high-value industries, support regional growth, and redefine what's possible for decarbonization in North America. Through that agreement, Vema's clean hydrogen will be leveraged by Verne to provide affordable, reliable, and low-emission power to its data center customers, with operations beginning as early as 2028. ‚ÄúNatural hydrogen is a critical element rapidly emerging as the first new primary energy source in decades,‚Äù said Ran Narayanasamy, CEO of MAX Power Mining, a natural hydrogen exploration company in Saskatchewan, Canada. ‚ÄúThe advantage with natural hydrogen is that it's cleaner and more cost-effective. The broader promise of Vema's approach depends on how natural hydrogen compares with existing production methods. ‚Äú99% of hydrogen is manufactured as emissions-emitting energy produced through fossil fuels. As natural hydrogen exists in an end product form under the ground, costly technological processes involved in manufactured hydrogen are eliminated from the process.‚Äù Rob Enderle, president and principal analyst at the Enderle Group, an advisory services firm in Bend, Ore., agreed that the equipment and energy costs of manufacturing hydrogen can be high. ‚ÄúGranted, with enough green energy ‚Äî solar, wind, geothermal, atomic ‚Äî you could manufacture hydrogen sustainably,‚Äù he conceded, ‚Äúbut the initial hardware cost would be excessive.‚Äù ‚ÄúVema's Quebec pilot wells aim to prove that idea at scale by producing baseload hydrogen from rock formations, not from a factory,‚Äù he told TechNewsWorld. He explained that most hydrogen today comes from fossil-based pathways such as steam methane reforming, which is cheap but carbon-intensive unless carbon dioxide is captured; even then, you still rely on gas supply chains. ‚ÄúElectrolysis can be low carbon, but the economics swing hard with power prices and electrolyzer capex, which is why scale-up stays constrained in many markets,‚Äù he continued. ‚ÄúGeologic hydrogen tries to flip the model,‚Äù he added, ‚Äúby sourcing hydrogen generated and stored in the crust, potentially lowering cost while keeping supply steady.‚Äù Vena noted that the challenges for hydrogen miners are not trivial. ‚ÄúYou have to find it, then you have to prove it flows consistently, which is the difference between a science project and an energy business,‚Äù he said. ‚ÄúSubsurface uncertainty is real, including variable reservoir behavior and the need to manage risks like water impacts and induced seismicity from industrial operations,‚Äù he continued. ‚ÄúHydrogen comes with the challenge that it is very light,‚Äù noted Rick Bentley, CEO of HydroHash, a crypto mining company that focuses on clean energy and high-efficiency operations, in Albuquerque, N.M. In liquid form, the energy density per weight is reasonably high, but the energy density per volume is still poor compared to natural or propane gases, in their liquid forms, with their relatively heavy carbon molecules.‚Äù ‚ÄúIt is a very plentiful, potentially very green resource if you can find, remove, and transport it ‚Äî much greener than petrochemicals, which have to be refined and can cause significant environmental damage in oceans, overland, and when burned,‚Äù he noted. ‚ÄúAs an analyst, I'm extremely optimistic about this topic,‚Äù added Vena. ‚ÄúHydrogen wins when it solves a specific problem, like firm power in constrained grids, industrial heat, or clean backup that beats diesel on both emissions and operations.‚Äù ‚ÄúThe industry has spent years arguing about colors of hydrogen, but the next phase is about boring things like uptime, delivered cost, and permitting,‚Äù he said. ‚ÄúIf geologic hydrogen delivers a steady baseload supply, it could be the rare hydrogen story that feels more like energy infrastructure than a climate experiment.‚Äù His areas of focus include cybersecurity, IT issues, privacy, e-commerce, social media, artificial intelligence, big data and consumer electronics. Alliance Calls for Cyber U to Stem Tide of Nation-State Attacks The Sphere of Influence: How Lenovo Brought Vision Back to CES Our Children Are Not Ready: A Generational Crisis in the Age of AI The $5 Trillion House of Cards: How Spectral Is About to Topple Nvidia</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/3d-printing/cornell-research-shows-that-underwater-3d-printing-can-be-used-to-build-or-repair-ocean-structures-in-place-darpa-funded-project-aims-to-make-underwater-construction-faster-cheaper-and-safer'>Cornell research shows that underwater 3D printing can be used to build or repair ocean structures in place ‚Äî DARPA-funded project aims to make underwater construction faster, cheaper, and safer</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 13:03:16
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. The Cornell Chronicle blog mentions that the interdisciplinary group, led by Sriramya Nair, assistant professor of civil and environmental engineering in the David A. Duffield College of Engineering, was already working with a 6,000-pound industrial robot for large-scale 3D printing of concrete structures on Terra Firma. This preassembled team spotted the Department of Defence's Defense Advanced Research Projects Agency (DARPA) call for proposals, in search of 3D printing concrete construction tech which could be used several yards beneath the sea. ‚ÄúWe said, ‚ÄòHey, let's just do this and see, so that we will at least understand what the challenges are,'‚Äù recalls Nair. The researchers' hunch largely paid off, with an award of a $1.4m grant, contingent on meeting certain benchmarks, and promising early sub-sea results. Among the major challenges of 3D printing concrete underwater is washout, where the cement washes away more than binds to itself or its intended location. The Cornell team managed to overcome this hurdle with an experimentally optimized balance between material viscosity and pumpabiliity. DARPA also set out a specific challenge to overcome: the agency wanted the concrete mix to incorporate seafloor sediment as a major ingredient. This requirement was set for logistical purposes, but would also help minimize environmental impact ‚Äì repurposing materials already present in the underwater area. The researchers also had some work to do on new sensing systems so they could carefully monitor and adapt the underwater 3D printing process in low-visibility conditions. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. This means that traditional underwater construction, which is slow, expensive, and disruptive to the environment, could become a thing of the past. This isn't the ‚Äòwinning' solution to subsea construction yet, though. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Mark Tyson is a news editor at Tom's Hardware. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=46868998'>X offices raided in France as UK opens fresh investigation into Grok</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 10:14:01
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>- you are thinking about a company doing good things the right way. You are thinking about a company abiding by the law, storing data on its own server, having good practices, etc.The moment a company starts to do dubious stuff then good practices start to go out the window. People write email with cryptic analogies, people start deleting emails, ... then as the circumvention become more numerous and complex, there needs to still be a trail in order to remain understandable. It might be paper, it might be shadow IT but the point is that if you are not just forgetting to keep track of coffee pods at the social corner, you will leave traces.So yes, raids do make sense BECAUSE it's about recurring complex activities that are just too hard to keep in the mind of one single individual over long periods of time. People write email with cryptic analogies, people start deleting emails, ... then as the circumvention become more numerous and complex, there needs to still be a trail in order to remain understandable. It might be paper, it might be shadow IT but the point is that if you are not just forgetting to keep track of coffee pods at the social corner, you will leave traces.So yes, raids do make sense BECAUSE it's about recurring complex activities that are just too hard to keep in the mind of one single individual over long periods of time. So yes, raids do make sense BECAUSE it's about recurring complex activities that are just too hard to keep in the mind of one single individual over long periods of time. Of course they're going to raid their offices! More normally it looks like e.g. this in the UK: https://news.sky.com/video/police-raid-hundreds-of-businesse...CyberGEND more often seem to do smalltime copyright infringement enforcement, but there are a number of authorities with the right to conduct raids. CyberGEND more often seem to do smalltime copyright infringement enforcement, but there are a number of authorities with the right to conduct raids. It always seemed to me that TikTok was doing the same things that US based social networks were doing, and the only problem various parties could agree on with this was that it was foreign-owned. 1) Even when you move things to a server, or remove it from your device, evidence is still left over without your knowledge sometimes.2) Evidence of data destruction, is in itself as the name implies, evidence. And it can be used to prove things.For example, an ext4 journal or NTFS USN $J journal entry that shows "grok_version_2.4_schema.json"  where twitter is claiming grok version 2.4 was never deployed in France/UK is important. That's why tools like shred and SDelete rename files before destroying them. But even then, when those tools rename and destroy files, it stands out, it might even be worse because investigators can speculate more. It might corroborate some other piece of evidence (e.g.: sdelete's prefetch entry on windows, or download history from a browser for the same tool), and that might be a more serious charge (obstruction of justice in the US). And it can be used to prove things.For example, an ext4 journal or NTFS USN $J journal entry that shows "grok_version_2.4_schema.json"  where twitter is claiming grok version 2.4 was never deployed in France/UK is important. That's why tools like shred and SDelete rename files before destroying them. But even then, when those tools rename and destroy files, it stands out, it might even be worse because investigators can speculate more. It might corroborate some other piece of evidence (e.g.: sdelete's prefetch entry on windows, or download history from a browser for the same tool), and that might be a more serious charge (obstruction of justice in the US). For example, an ext4 journal or NTFS USN $J journal entry that shows "grok_version_2.4_schema.json"  where twitter is claiming grok version 2.4 was never deployed in France/UK is important. That's why tools like shred and SDelete rename files before destroying them. But even then, when those tools rename and destroy files, it stands out, it might even be worse because investigators can speculate more. It might corroborate some other piece of evidence (e.g.: sdelete's prefetch entry on windows, or download history from a browser for the same tool), and that might be a more serious charge (obstruction of justice in the US). So no, don't be coy and pretend that all governments are like American institutions. No platform ever should allow CSAM content.And the fact that they didn't even care and haven't want to spend money for implementing guardrails or moderation is deeply concerning.This has imho nothing to do with model censorship, but everything with allowing that kind of content on a platform And the fact that they didn't even care and haven't want to spend money for implementing guardrails or moderation is deeply concerning.This has imho nothing to do with model censorship, but everything with allowing that kind of content on a platform This has imho nothing to do with model censorship, but everything with allowing that kind of content on a platform So not CSAM, but still creepy and something Reddit tightly decided it didn't want on the site. Mmkay.https://en.wikipedia.org/wiki/Twitter_under_Elon_Musk#Child_..."As of June 2023, an investigation by the Stanford Internet Observatory at Stanford University reported "a lapse in basic enforcement" against child porn by Twitter within "recent months". The number of staff on Twitter's trust and safety teams were reduced, for example, leaving one full-time staffer to handle all child sexual abuse material in the Asia-Pacific region in November 2022. https://en.wikipedia.org/wiki/Twitter_under_Elon_Musk#Child_..."As of June 2023, an investigation by the Stanford Internet Observatory at Stanford University reported "a lapse in basic enforcement" against child porn by Twitter within "recent months". The number of staff on Twitter's trust and safety teams were reduced, for example, leaving one full-time staffer to handle all child sexual abuse material in the Asia-Pacific region in November 2022. "As of June 2023, an investigation by the Stanford Internet Observatory at Stanford University reported "a lapse in basic enforcement" against child porn by Twitter within "recent months". The number of staff on Twitter's trust and safety teams were reduced, for example, leaving one full-time staffer to handle all child sexual abuse material in the Asia-Pacific region in November 2022. But I am having trouble justifying in an consistent manner why Grok / X should be liable here instead of the user. I've seen a few arguments here that mostly comes down to:1. That this isn't just on the user's computer but instead posted on X.For 1. it seems to breakdown if we look more broadly at how LLMs are used. We're basically starting to treat LLMs as a higher level framework now. We don't hold vendors of programming languages or frameworks responsible if someone uses them to create CSAM. If in this case Grok isn't liable then why does the automatic posting (from the user's instructions) make it different? If it is, then it's not about the distribution anymore.There are some comparisons to photoshop, that if i created a deep fake with photoshop that I'm liable not Adobe. If photoshop had a "upload to X" button, and I created CSM using photoshop and hit the button to upload to X directly, is now Adobe now liable?What am I missing? That this isn't just on the user's computer but instead posted on X.For 1. it seems to breakdown if we look more broadly at how LLMs are used. We're basically starting to treat LLMs as a higher level framework now. We don't hold vendors of programming languages or frameworks responsible if someone uses them to create CSAM. If in this case Grok isn't liable then why does the automatic posting (from the user's instructions) make it different? If it is, then it's not about the distribution anymore.There are some comparisons to photoshop, that if i created a deep fake with photoshop that I'm liable not Adobe. If photoshop had a "upload to X" button, and I created CSM using photoshop and hit the button to upload to X directly, is now Adobe now liable?What am I missing? That this isn't just on the user's computer but instead posted on X.For 1. it seems to breakdown if we look more broadly at how LLMs are used. We're basically starting to treat LLMs as a higher level framework now. We don't hold vendors of programming languages or frameworks responsible if someone uses them to create CSAM. If in this case Grok isn't liable then why does the automatic posting (from the user's instructions) make it different? If it is, then it's not about the distribution anymore.There are some comparisons to photoshop, that if i created a deep fake with photoshop that I'm liable not Adobe. If photoshop had a "upload to X" button, and I created CSM using photoshop and hit the button to upload to X directly, is now Adobe now liable?What am I missing? For 1. it seems to breakdown if we look more broadly at how LLMs are used. We're basically starting to treat LLMs as a higher level framework now. We don't hold vendors of programming languages or frameworks responsible if someone uses them to create CSAM. If in this case Grok isn't liable then why does the automatic posting (from the user's instructions) make it different? If it is, then it's not about the distribution anymore.There are some comparisons to photoshop, that if i created a deep fake with photoshop that I'm liable not Adobe. If photoshop had a "upload to X" button, and I created CSM using photoshop and hit the button to upload to X directly, is now Adobe now liable?What am I missing? If in this case Grok isn't liable then why does the automatic posting (from the user's instructions) make it different? If it is, then it's not about the distribution anymore.There are some comparisons to photoshop, that if i created a deep fake with photoshop that I'm liable not Adobe. If photoshop had a "upload to X" button, and I created CSM using photoshop and hit the button to upload to X directly, is now Adobe now liable?What am I missing? There are some comparisons to photoshop, that if i created a deep fake with photoshop that I'm liable not Adobe. If photoshop had a "upload to X" button, and I created CSM using photoshop and hit the button to upload to X directly, is now Adobe now liable?What am I missing? LLMs are completely different to programming languages or even Photoshop.You can't type a sentence and within 10 seconds get images of CSAM with Photoshop. LLMs are also built on trained material, unlike the traditional tools in Photoshop. There have been plenty CSAM found in the training data sets, but shock-horror apparently not enough information to know "where it came from". There's a non-zero chance that this CSAM Grok is vomiting out is based on "real" CSAM of people being abused. You can't type a sentence and within 10 seconds get images of CSAM with Photoshop. LLMs are also built on trained material, unlike the traditional tools in Photoshop. There have been plenty CSAM found in the training data sets, but shock-horror apparently not enough information to know "where it came from". There's a non-zero chance that this CSAM Grok is vomiting out is based on "real" CSAM of people being abused. Because Grok and X aren't even doing the most basic filtering they could do to pretend to filter out CSAM. https://www.bbc.com/news/articles/cze3p1j710koReports on sextortion, self-generated indecent images, and grooming via social media/messaging apps:Snapchat 54%Instagram 11%Facebook 7%WhatsApp 6-9%X 1-2% Reports on sextortion, self-generated indecent images, and grooming via social media/messaging apps:Snapchat 54%Instagram 11%Facebook 7%WhatsApp 6-9%X 1-2% A provider should have no responsibility how the tools are used. AI and tool main job is to obey. Yes, AI chatbots have to do everything in their power to avoid users easily generating such content.ANDYes, people that do so (even if done so on your self-hosted model) have to be punished.I believe it is OK that Grok is being investigated because the point is to figure out whether this was intentional or not.Just my opinion. ANDYes, people that do so (even if done so on your self-hosted model) have to be punished.I believe it is OK that Grok is being investigated because the point is to figure out whether this was intentional or not.Just my opinion. Yes, people that do so (even if done so on your self-hosted model) have to be punished.I believe it is OK that Grok is being investigated because the point is to figure out whether this was intentional or not.Just my opinion. Platforms moderating illegal content is exactly what we are arguing about, so you can't use it as an argument.The rest cases you list are harms to the people using the tools/products. It is not harms that people using the tools inflict on third parties.We are literally arguing about 3d printer control two topics downstream. 3d printers in theory can be used for CSAM too. It is not harms that people using the tools inflict on third parties.We are literally arguing about 3d printer control two topics downstream. 3d printers in theory can be used for CSAM too. We are literally arguing about 3d printer control two topics downstream. 3d printers in theory can be used for CSAM too. What about people hosting models on hugging face? X also actively distributes and profits off of CSAM. Why shouldn't the law apply to distribution centers? I mean, I thought that was basically already the law in the UK.I can see practical differences between X/twitter doing moderation and the full ISP censorship, but I cannot see any differences in principle... I can see practical differences between X/twitter doing moderation and the full ISP censorship, but I cannot see any differences in principle... I mean even just calling it censorship is already trying to shove a particular bias into the picture. Is it government censorship that you aren't allowed to shout "fire!" Turns out people can handle that nuance just fine. If a platform encourages and doesn't moderate at all, yes we should go after the platform.Imagine a newspaper publishing content like that, and saying they are not responsible for their journalists Imagine a newspaper publishing content like that, and saying they are not responsible for their journalists ‚Äî‚Äî-You've said that whatever is behind door number 1 is unacceptable.Behind door number 2, ‚Äúholding tool users responsible‚Äù, is tracking every item generated via AI, and being able to hold those users responsible.If you don't like door number 2, we have door number 3 - which is letting things be.For any member of society, opening door 3 is straight out because the status quo is worse than reality before AI.If you reject door 1 though, you are left with tech monitoring. Which will be challenged because of its invasive nature.Holding Platforms responsible is about the only option that works, at least until platforms tell people they can't do it. You've said that whatever is behind door number 1 is unacceptable.Behind door number 2, ‚Äúholding tool users responsible‚Äù, is tracking every item generated via AI, and being able to hold those users responsible.If you don't like door number 2, we have door number 3 - which is letting things be.For any member of society, opening door 3 is straight out because the status quo is worse than reality before AI.If you reject door 1 though, you are left with tech monitoring. Which will be challenged because of its invasive nature.Holding Platforms responsible is about the only option that works, at least until platforms tell people they can't do it. Behind door number 2, ‚Äúholding tool users responsible‚Äù, is tracking every item generated via AI, and being able to hold those users responsible.If you don't like door number 2, we have door number 3 - which is letting things be.For any member of society, opening door 3 is straight out because the status quo is worse than reality before AI.If you reject door 1 though, you are left with tech monitoring. Which will be challenged because of its invasive nature.Holding Platforms responsible is about the only option that works, at least until platforms tell people they can't do it. If you don't like door number 2, we have door number 3 - which is letting things be.For any member of society, opening door 3 is straight out because the status quo is worse than reality before AI.If you reject door 1 though, you are left with tech monitoring. Which will be challenged because of its invasive nature.Holding Platforms responsible is about the only option that works, at least until platforms tell people they can't do it. For any member of society, opening door 3 is straight out because the status quo is worse than reality before AI.If you reject door 1 though, you are left with tech monitoring. Which will be challenged because of its invasive nature.Holding Platforms responsible is about the only option that works, at least until platforms tell people they can't do it. Which will be challenged because of its invasive nature.Holding Platforms responsible is about the only option that works, at least until platforms tell people they can't do it. Holding Platforms responsible is about the only option that works, at least until platforms tell people they can't do it. Everything I read from X's competitors in the media tells me to hate X, and hate Elon.If we prosecute people not tools, how are we going to stop X from hurting the commercial interests of our favourite establishment politicians and legacy media? If we prosecute people not tools, how are we going to stop X from hurting the commercial interests of our favourite establishment politicians and legacy media? (note that this isn't a raid on Musk personally! What's new is that X automated the production of obscene or sexualised images by providing grok. Yes we are now dealing with an automated Photoshop. And somehow the people in charge have decided to do something about it, probably more for political or maybe darker reasons.So let me make a suggestion: maybe France or the EU should ban its citizen from investing in the upcoming SpaceX/xAI IPO, and also Microsoft, NVIDIA, OpenAI, Google, Meta, Adobe, etc. ?Hit them hard at the money level... it wouldn't be more authoritarian than something like ChatControl or restricting access to VPNs.And actually all the mechanisms are already in place to implement something like that. So let me make a suggestion: maybe France or the EU should ban its citizen from investing in the upcoming SpaceX/xAI IPO, and also Microsoft, NVIDIA, OpenAI, Google, Meta, Adobe, etc. ?Hit them hard at the money level... it wouldn't be more authoritarian than something like ChatControl or restricting access to VPNs.And actually all the mechanisms are already in place to implement something like that. Hit them hard at the money level... it wouldn't be more authoritarian than something like ChatControl or restricting access to VPNs.And actually all the mechanisms are already in place to implement something like that. And actually all the mechanisms are already in place to implement something like that. I don't get what's difficult to understand or believe here. Grok causes a big issue in practice right now, a larger issue than photoshop, and it should be easy for X to regulate it themselves like the competition does but they don't, so the state intervenes.> maybe France or the EU should ban its citizen from investing in the upcoming SpaceX/xAI IPO, and also Microsoft, NVIDIA, OpenAI, Google, Meta, Adobe, etc. A surgical strike is used to target the actual problem. With carpet bombing you mostly cause collateral damage. > maybe France or the EU should ban its citizen from investing in the upcoming SpaceX/xAI IPO, and also Microsoft, NVIDIA, OpenAI, Google, Meta, Adobe, etc. A surgical strike is used to target the actual problem. With carpet bombing you mostly cause collateral damage. A surgical strike is used to target the actual problem. With carpet bombing you mostly cause collateral damage. But then people find exploits just like the competition. I'm sorry, but I don't understand any of the arguments above.If we presume a dark control motivation then having shares in the entities you want to control is the best form of control there is. How can you say that nobody is posting CSAM on a massive decentralized social network with thousands of servers? There's basically no consent with what Grok is doing. Uncontrolled profileration of AI-CSAM makes detection of "genuine" data much harder, prosecution of perpetrators more difficult and specifically in many of the grok cases it harms young victims that were used as templates for the material.Content is unacceptable if its proliferation causes sufficient harm, and this is arguably the case here. If the prosecutor can't find evidence of a crime and a person is not charged, that is considered harmful? Making law enforcement have to work harder to find evidence of a crime cannot be criminalized unless you can come up with a reason why the actions themselves deserve to be criminalized.> specifically in many of the grok cases it harms young victims that were used as templates for the material.What is the criteria for this? If something is suitably transformed such that the original model for it is not discernable or identifiable, how can it harm them?Do not take these as an argument against the idea you are arguing for, but as rebuttals against arguments that are not convincing, or if they were, would be terrible if applied generally. If something is suitably transformed such that the original model for it is not discernable or identifiable, how can it harm them?Do not take these as an argument against the idea you are arguing for, but as rebuttals against arguments that are not convincing, or if they were, would be terrible if applied generally. If something is suitably transformed such that the original model for it is not discernable or identifiable, how can it harm them?Do not take these as an argument against the idea you are arguing for, but as rebuttals against arguments that are not convincing, or if they were, would be terrible if applied generally. Do not take these as an argument against the idea you are arguing for, but as rebuttals against arguments that are not convincing, or if they were, would be terrible if applied generally. You could make a multitude of arguments against that perspective, but at least there is a conclusive reason for legal restrictions.> What is the criteria for this?My criteria would be victims suffering personally from the generated material.The "no harm" argument only really applies if victims and their social bubble never find out about the material (but that did happen, sometimes intentionally, in many cases).You could make the same argument that a hidden camera in a locker room never causes any harm as long as it stays undetected; that is not very convincing to me. > What is the criteria for this?My criteria would be victims suffering personally from the generated material.The "no harm" argument only really applies if victims and their social bubble never find out about the material (but that did happen, sometimes intentionally, in many cases).You could make the same argument that a hidden camera in a locker room never causes any harm as long as it stays undetected; that is not very convincing to me. My criteria would be victims suffering personally from the generated material.The "no harm" argument only really applies if victims and their social bubble never find out about the material (but that did happen, sometimes intentionally, in many cases).You could make the same argument that a hidden camera in a locker room never causes any harm as long as it stays undetected; that is not very convincing to me. The "no harm" argument only really applies if victims and their social bubble never find out about the material (but that did happen, sometimes intentionally, in many cases).You could make the same argument that a hidden camera in a locker room never causes any harm as long as it stays undetected; that is not very convincing to me. You could make the same argument that a hidden camera in a locker room never causes any harm as long as it stays undetected; that is not very convincing to me. > You could make a multitude of arguments against that perspective, but at least there is a conclusive reason for legal restrictions.I don't know about that. Would "I didn't know it was real" really count as a legal defense? Would "I didn't know it was real" really count as a legal defense? Absolutely-- prosecution would presumably need to at least show that you could have known the material was "genuine".This could be a huge legal boon for prosecuted "direct customers" and co-perpetrators that can only be linked via shared material. This could be a huge legal boon for prosecuted "direct customers" and co-perpetrators that can only be linked via shared material. Saying 'this makes enforcement of other laws harder' does not do that. You could use the same reasoning against encryption.> You could make the same argument that a hidden camera in a locker room never causes any harm as long as it stays undetected; that is not very convincing to me.I thought you were saying that the kids who were in the dataset that the model was trained on would be harmed. I agree with what I assume you meant based on your reply, which is people who had their likeness altered are harmed. > You could make the same argument that a hidden camera in a locker room never causes any harm as long as it stays undetected; that is not very convincing to me.I thought you were saying that the kids who were in the dataset that the model was trained on would be harmed. I agree with what I assume you meant based on your reply, which is people who had their likeness altered are harmed. I agree with what I assume you meant based on your reply, which is people who had their likeness altered are harmed. I don't understand how that's the same reasoning at all... Encryption serves ones individual privacy and preserves it against malicious actors. I'd guess that's a fundamental right in most jurisdictions, globally.We're talking CSAM here and shifting its creation into the virtual world through some GenAI prompts. Just because that content has been created artificially, doesn't make its storage and distribution any more legal.It isn't some reductionist "this makes enforcement of other laws harder", but it's rather that the illegal distribution of artificially generated content acts as fraudulent obstruction in the prosecution of authentic, highly illegal, content - content with malicious actors and physically affected victims. We're talking CSAM here and shifting its creation into the virtual world through some GenAI prompts. Just because that content has been created artificially, doesn't make its storage and distribution any more legal.It isn't some reductionist "this makes enforcement of other laws harder", but it's rather that the illegal distribution of artificially generated content acts as fraudulent obstruction in the prosecution of authentic, highly illegal, content - content with malicious actors and physically affected victims. It isn't some reductionist "this makes enforcement of other laws harder", but it's rather that the illegal distribution of artificially generated content acts as fraudulent obstruction in the prosecution of authentic, highly illegal, content - content with malicious actors and physically affected victims. I almost completely agree with your outlook, but I think that many of our laws trade such individual freedoms for better society-wide outcomes, and those are often good tradeoffs.Just consider gun legislation, driving licenses, KYC laws in finance, etc: Should the state have any business interfering there? I'd argue in isolation (ideally) not; but all those lead to huge gains for society, making it much less likely to be murdered by intoxicated drivers (or machine-gunners) and limit fraud, crime and corruption.So even if laws look kinda bad from a purely theoretical-ethics point of view it's still important to look at the actual effects that they have before dismissing them as unjust in my view. Just consider gun legislation, driving licenses, KYC laws in finance, etc: Should the state have any business interfering there? I'd argue in isolation (ideally) not; but all those lead to huge gains for society, making it much less likely to be murdered by intoxicated drivers (or machine-gunners) and limit fraud, crime and corruption.So even if laws look kinda bad from a purely theoretical-ethics point of view it's still important to look at the actual effects that they have before dismissing them as unjust in my view. So even if laws look kinda bad from a purely theoretical-ethics point of view it's still important to look at the actual effects that they have before dismissing them as unjust in my view. The "oh its photoshop" defence was an early one, which required the law to change in the uk to be "depictions" of children, so that people who talk about ebephiles don't have an out for creating/distributing illegal content. First you defend CSAM, then we were talking about sexualised images of people without their consent, you were trying to diminish this as ‚Äûjust bikini‚Äú pics As a father there shouldn't be any CSAM content anywhere.And think about that it is already proven these models apparently had CSAM content in their training data.Also what about the nudes of actual people? And think about that it is already proven these models apparently had CSAM content in their training data.Also what about the nudes of actual people? Also what about the nudes of actual people? I am shocked that we are even discussing this. But they are happy to censor for countries like turkeyHypocrisy level 1 million I still believe that the EU and aligned countries would rather have America to agree to much tighter speech controls, digital ID, ToS-based speech codes as apparently US Democrats partly or totally agree to. Surely we can still point at those laws and question their motives though.Spanish PM plainly stated a sort of editor framework of responsibility for platforms. This is the same country that strongly advocates for Chat Control within the EU, also looking for a similar under-16 ban on social media.So the same government is at once looking to deanonimize social media users, revoke their privacy regarding communications, and to enforce moderation standards never seen before. This is the same country that strongly advocates for Chat Control within the EU, also looking for a similar under-16 ban on social media.So the same government is at once looking to deanonimize social media users, revoke their privacy regarding communications, and to enforce moderation standards never seen before. So the same government is at once looking to deanonimize social media users, revoke their privacy regarding communications, and to enforce moderation standards never seen before. Would it be good or bad if the user was met with a "This website is by law not available within the EU"? currently VPNs are too easy to use for the leadership of autocracies like the EU or the UK to be comfortable with them, so at the very least they will require for backdoors to see which citizens are watching what, and have them visited by fellows in hi-vis jackets No there isn't.Governments discussing such things doesn't _remotely_ mean there is a political will for them, or that they will be voted into law.Governments are expected to research and discuss paths of legislation (and in this case, come to the conclusion banning VPNs is both harmful and ridiculous). Governments discussing such things doesn't _remotely_ mean there is a political will for them, or that they will be voted into law.Governments are expected to research and discuss paths of legislation (and in this case, come to the conclusion banning VPNs is both harmful and ridiculous). There's an interesting tidbit that he gained quite a few listeners when he started releasing casualty information that the British government withheld to try to keep wartime-morale high.Lord Haw-Haw then tried to leverage that audience into a force of Nazi sympathy and a general mood of defeatism.Anyway, fun anecdote. Lord Haw-Haw then tried to leverage that audience into a force of Nazi sympathy and a general mood of defeatism.Anyway, fun anecdote. Compare the DOJ fines on European banks and automakers with European fines on tech companies and you'll realize how ridiculous this claim is. If you're arguing that DOJ fines on European banks are more unreasonable than EU fines on US tech companies that's fine with me. But that wouldn't make either reasonable or my comment "ridiculous". For some reason you forgot to mention "Like the US did with TikTok". when America already controls the main outlets through Android Play Store and Apple Store, and yep, they have proven to control them not just happen to host them as a countryarguably America did have valid security concerns with Huawei though, but if those are the rules then you cannot complain later on arguably America did have valid security concerns with Huawei though, but if those are the rules then you cannot complain later on They are tasked - and held to account by respective legislative bodies - with implementing the law as written.Nobody wrote a law saying "Go after Grok". Read the law and make sure any tools they build comply2. When told their tools don't comply take immediate and decisive action to change the tools3. Work with law enforcement to apply the law as writtenThose companies, if they find this too burdensome, have the choice of not operating in that market. By operating in that market, they both implicitly agree to the law, and are required to explicitly abide by it.They can't then complain that the law is unfair (it's not), that it's being politicised (How? Show your working), and that this is all impossible in their home market where they are literally offering presents to the personal enrichment of the President on bended knee while he demands that ownership structures of foreign social media companies like TikTok are changed to meet the agenda of himself and his administration.So, would the EU like more tighter speech controls? Yes, they'd like implementation of the controls on free speech enshrined in legislation created by democratically appointed representatives. Nobody wrote a law saying "Go after Grok". Read the law and make sure any tools they build comply2. When told their tools don't comply take immediate and decisive action to change the tools3. Work with law enforcement to apply the law as writtenThose companies, if they find this too burdensome, have the choice of not operating in that market. By operating in that market, they both implicitly agree to the law, and are required to explicitly abide by it.They can't then complain that the law is unfair (it's not), that it's being politicised (How? Show your working), and that this is all impossible in their home market where they are literally offering presents to the personal enrichment of the President on bended knee while he demands that ownership structures of foreign social media companies like TikTok are changed to meet the agenda of himself and his administration.So, would the EU like more tighter speech controls? Yes, they'd like implementation of the controls on free speech enshrined in legislation created by democratically appointed representatives. Read the law and make sure any tools they build comply2. When told their tools don't comply take immediate and decisive action to change the tools3. Work with law enforcement to apply the law as writtenThose companies, if they find this too burdensome, have the choice of not operating in that market. By operating in that market, they both implicitly agree to the law, and are required to explicitly abide by it.They can't then complain that the law is unfair (it's not), that it's being politicised (How? Show your working), and that this is all impossible in their home market where they are literally offering presents to the personal enrichment of the President on bended knee while he demands that ownership structures of foreign social media companies like TikTok are changed to meet the agenda of himself and his administration.So, would the EU like more tighter speech controls? Yes, they'd like implementation of the controls on free speech enshrined in legislation created by democratically appointed representatives. Read the law and make sure any tools they build comply2. When told their tools don't comply take immediate and decisive action to change the tools3. Work with law enforcement to apply the law as writtenThose companies, if they find this too burdensome, have the choice of not operating in that market. By operating in that market, they both implicitly agree to the law, and are required to explicitly abide by it.They can't then complain that the law is unfair (it's not), that it's being politicised (How? Show your working), and that this is all impossible in their home market where they are literally offering presents to the personal enrichment of the President on bended knee while he demands that ownership structures of foreign social media companies like TikTok are changed to meet the agenda of himself and his administration.So, would the EU like more tighter speech controls? Yes, they'd like implementation of the controls on free speech enshrined in legislation created by democratically appointed representatives. When told their tools don't comply take immediate and decisive action to change the tools3. Work with law enforcement to apply the law as writtenThose companies, if they find this too burdensome, have the choice of not operating in that market. By operating in that market, they both implicitly agree to the law, and are required to explicitly abide by it.They can't then complain that the law is unfair (it's not), that it's being politicised (How? Show your working), and that this is all impossible in their home market where they are literally offering presents to the personal enrichment of the President on bended knee while he demands that ownership structures of foreign social media companies like TikTok are changed to meet the agenda of himself and his administration.So, would the EU like more tighter speech controls? Yes, they'd like implementation of the controls on free speech enshrined in legislation created by democratically appointed representatives. Work with law enforcement to apply the law as writtenThose companies, if they find this too burdensome, have the choice of not operating in that market. By operating in that market, they both implicitly agree to the law, and are required to explicitly abide by it.They can't then complain that the law is unfair (it's not), that it's being politicised (How? Show your working), and that this is all impossible in their home market where they are literally offering presents to the personal enrichment of the President on bended knee while he demands that ownership structures of foreign social media companies like TikTok are changed to meet the agenda of himself and his administration.So, would the EU like more tighter speech controls? Yes, they'd like implementation of the controls on free speech enshrined in legislation created by democratically appointed representatives. Those companies, if they find this too burdensome, have the choice of not operating in that market. By operating in that market, they both implicitly agree to the law, and are required to explicitly abide by it.They can't then complain that the law is unfair (it's not), that it's being politicised (How? Show your working), and that this is all impossible in their home market where they are literally offering presents to the personal enrichment of the President on bended knee while he demands that ownership structures of foreign social media companies like TikTok are changed to meet the agenda of himself and his administration.So, would the EU like more tighter speech controls? Yes, they'd like implementation of the controls on free speech enshrined in legislation created by democratically appointed representatives. Show your working), and that this is all impossible in their home market where they are literally offering presents to the personal enrichment of the President on bended knee while he demands that ownership structures of foreign social media companies like TikTok are changed to meet the agenda of himself and his administration.So, would the EU like more tighter speech controls? Yes, they'd like implementation of the controls on free speech enshrined in legislation created by democratically appointed representatives. So, would the EU like more tighter speech controls? Yes, they'd like implementation of the controls on free speech enshrined in legislation created by democratically appointed representatives. This isn't "anti-democratic", it's literally democracy in action standing up to technocratic feudalism that is an Ayn Randian-wet dream being played out by some morons who got lucky. As someone who has lived in (and followed current affairs) in both of these countries, this is a very idealistic and na√Øve view. There can be a big gap between theory and practice> There are statutory instruments (in France, constitutional clauses), that determine the independence of these authorities.> They are tasked - and held to account by respective legislative bodies -It's worth nothing here that the UK doesn't have separation of powers or a supreme court (in the US sense) > There are statutory instruments (in France, constitutional clauses), that determine the independence of these authorities.> They are tasked - and held to account by respective legislative bodies -It's worth nothing here that the UK doesn't have separation of powers or a supreme court (in the US sense) > They are tasked - and held to account by respective legislative bodies -It's worth nothing here that the UK doesn't have separation of powers or a supreme court (in the US sense) It's worth nothing here that the UK doesn't have separation of powers or a supreme court (in the US sense) however it's a very mainstream point of view so i respect that he/she has laid it out pretty well, so i upvoted the comment The European Court of Human Rights has reminded this point (e.g. 29 Mar 2010, appl. For a local observer, this is made obvious by the fact that the procureur, in France, always follows current political vibes, usually in just a few months delay (extremely fast, when you consider how slowly justice works in the country). This is kind of a genuine question from me since I have no idea how these authorities are set up in France or the UK... My most recent case: I went on holiday to a resort in Turkey, numerous Russians, families, retired, etc. I don't pass as a Russian-speaker (but I understand quite well) and once they hear me talking other unrelated language they naturally start to speak more freely in front of me (i.e. more liberal use of swearing, and even slurs if no other Russians are around).While sunbathing, or at the restaurant, or the pool, they were talking about daily, mundane things, same in the restaurant, etc. But when floating in pairs 20-30m from the shore? But when floating in pairs 20-30m from the shore? This step could come before a police raid.This looks like plain political pressure. Siezing records is usually a major step in an investigation. France has a reasonable judicial system so absent of other evidence i'm inclined to believe this was legit. Sure it could just be harrasment, but this is also how normal police work looks. France has a reasonable judicial system so absent of other evidence i'm inclined to believe this was legit. So the question becomes if it was done knowingly or recklessly, hence a police raid for evidence.See also [0] for a legal discussion in the German context. See also [0] for a legal discussion in the German context. I think one big issue with this statement ‚Äì "CSAM" lacks a precise legal definition; the precise legal term(s) vary from country to country, with differing definitions. While sexual imagery of real minors is highly illegal everywhere, there's a whole lot of other material ‚Äì textual stories, drawings, animation, AI-generated images of nonexistent minors ‚Äì which can be extremely criminal on one side of an international border, de facto legal on the other.And I'm not actually sure what the legal definition is in France; the relevant article of the French Penal Code 227-23 [0] seems superficially similar to the legal definition of "child pornography" in the United States (post-Ashcroft vs Free Speech Coalition), and so some‚Äìbut (maybe) not all‚Äìof the "CSAM" Grok is accused of generating wouldn't actually fall under it. (But of course, I don't know how French courts interpret it, so maybe what it means in practice is something broader than my reading of the text suggests. That's less of an issue for Anthropic/Google/OpenAI, since their executives don't have the same "anything that's legal" attitude which xAI often has. And, as I said ‚Äì while that's undoubtedly true in general, I'm unsure to what extent it is actually true for France in particular. (But of course, I don't know how French courts interpret it, so maybe what it means in practice is something broader than my reading of the text suggests. That's less of an issue for Anthropic/Google/OpenAI, since their executives don't have the same "anything that's legal" attitude which xAI often has. And, as I said ‚Äì while that's undoubtedly true in general, I'm unsure to what extent it is actually true for France in particular. That's less of an issue for Anthropic/Google/OpenAI, since their executives don't have the same "anything that's legal" attitude which xAI often has. And, as I said ‚Äì while that's undoubtedly true in general, I'm unsure to what extent it is actually true for France in particular. But my impression is the definition of that word under French law is possibly narrower than some definitions of the English acronym ‚ÄúCSAM‚Äù. Canadian law is much broader, and so what's legally p√©dopornographie (English ‚Äúchild pornogaphy‚Äù) in Canada may be much closer to broad ‚ÄúCSAM‚Äù definitions> The point is, X did things that are illegal in France, no matter what you call them.Which French law are you alleging they violated? And how exactly are you claiming they violated it?Note the French authorities at this time are not accusing them of violating the law. I don't think the French legal process has reached a conclusion either way yet.One relevant case is the unpublished 2007 Court of Cassation decision 06-86.763 dated 12 septembre 2007 [0] which upheld a conviction of child pornography for importing and distributing the anime film ‚ÄúTwin Angels - le retour des b√™tes c√©lestes - Vol. [0] However, the somewhat odd situation is that it appears that film is catalogued by the French national library, [1] although I don't know if a catalogue entry definitively proves they possess the item. 227-23 distinguishes between material depicting under 15s (illegal to even possess) and material depicting under 18s (only illegal to possess with intent to distribute); this prosecution appears to be have been brought under the latter category only-even though the individual was depicted as being under the 15-suggesting this anime might not be illegal to possess in France if one has no intent to distribute it.But this is the point - one needs to look at the details of exactly what the law says and how exactly the authorities apply it, rather than vague assertions of criminality which might not actually be true. > The point is, X did things that are illegal in France, no matter what you call them.Which French law are you alleging they violated? And how exactly are you claiming they violated it?Note the French authorities at this time are not accusing them of violating the law. I don't think the French legal process has reached a conclusion either way yet.One relevant case is the unpublished 2007 Court of Cassation decision 06-86.763 dated 12 septembre 2007 [0] which upheld a conviction of child pornography for importing and distributing the anime film ‚ÄúTwin Angels - le retour des b√™tes c√©lestes - Vol. [0] However, the somewhat odd situation is that it appears that film is catalogued by the French national library, [1] although I don't know if a catalogue entry definitively proves they possess the item. 227-23 distinguishes between material depicting under 15s (illegal to even possess) and material depicting under 18s (only illegal to possess with intent to distribute); this prosecution appears to be have been brought under the latter category only-even though the individual was depicted as being under the 15-suggesting this anime might not be illegal to possess in France if one has no intent to distribute it.But this is the point - one needs to look at the details of exactly what the law says and how exactly the authorities apply it, rather than vague assertions of criminality which might not actually be true. Which French law are you alleging they violated? And how exactly are you claiming they violated it?Note the French authorities at this time are not accusing them of violating the law. I don't think the French legal process has reached a conclusion either way yet.One relevant case is the unpublished 2007 Court of Cassation decision 06-86.763 dated 12 septembre 2007 [0] which upheld a conviction of child pornography for importing and distributing the anime film ‚ÄúTwin Angels - le retour des b√™tes c√©lestes - Vol. [0] However, the somewhat odd situation is that it appears that film is catalogued by the French national library, [1] although I don't know if a catalogue entry definitively proves they possess the item. 227-23 distinguishes between material depicting under 15s (illegal to even possess) and material depicting under 18s (only illegal to possess with intent to distribute); this prosecution appears to be have been brought under the latter category only-even though the individual was depicted as being under the 15-suggesting this anime might not be illegal to possess in France if one has no intent to distribute it.But this is the point - one needs to look at the details of exactly what the law says and how exactly the authorities apply it, rather than vague assertions of criminality which might not actually be true. I don't think the French legal process has reached a conclusion either way yet.One relevant case is the unpublished 2007 Court of Cassation decision 06-86.763 dated 12 septembre 2007 [0] which upheld a conviction of child pornography for importing and distributing the anime film ‚ÄúTwin Angels - le retour des b√™tes c√©lestes - Vol. [0] However, the somewhat odd situation is that it appears that film is catalogued by the French national library, [1] although I don't know if a catalogue entry definitively proves they possess the item. 227-23 distinguishes between material depicting under 15s (illegal to even possess) and material depicting under 18s (only illegal to possess with intent to distribute); this prosecution appears to be have been brought under the latter category only-even though the individual was depicted as being under the 15-suggesting this anime might not be illegal to possess in France if one has no intent to distribute it.But this is the point - one needs to look at the details of exactly what the law says and how exactly the authorities apply it, rather than vague assertions of criminality which might not actually be true. One relevant case is the unpublished 2007 Court of Cassation decision 06-86.763 dated 12 septembre 2007 [0] which upheld a conviction of child pornography for importing and distributing the anime film ‚ÄúTwin Angels - le retour des b√™tes c√©lestes - Vol. [0] However, the somewhat odd situation is that it appears that film is catalogued by the French national library, [1] although I don't know if a catalogue entry definitively proves they possess the item. 227-23 distinguishes between material depicting under 15s (illegal to even possess) and material depicting under 18s (only illegal to possess with intent to distribute); this prosecution appears to be have been brought under the latter category only-even though the individual was depicted as being under the 15-suggesting this anime might not be illegal to possess in France if one has no intent to distribute it.But this is the point - one needs to look at the details of exactly what the law says and how exactly the authorities apply it, rather than vague assertions of criminality which might not actually be true. The company made and released a tool with seemingly no guard-rails, which was used en masse to generate deepfakes and child pornography. One the one hand, it seems "obvious" that Grok should somehow be legally required to have guardrails stopping it from producing kiddie porn.On the other hand, it also seems "obvious" that laws forcing 3D printers to detect and block attempts to print firearms are patently bullshit.The thing is, I'm not sure how I can reconcile those two seemingly-obvious statements in a principled manner. On the other hand, it also seems "obvious" that laws forcing 3D printers to detect and block attempts to print firearms are patently bullshit.The thing is, I'm not sure how I can reconcile those two seemingly-obvious statements in a principled manner. X is the owner from computer that produced CP. So of course X is at least also a bit liable for producing CP. Also, safe harbor doesn't apply because this is published under the @grok handle! It's being published by X under one of their brand names, it's absurd to argue that they're unaware or not consenting to its publication. People creating nudes of others and using the Internet to distribute it can be sued for defamation, sure. I don't think the people hosting the service should be liable themselves, just like people hosting Tor nodes shouldn't be liable by what users of the Tor Network do. I'd guess Elon is responsible for that product decision. If you're hosting content, why shouldn't you be responsible, because your business model is impossible if you're held to account for what's happening on your premises?Without safe harbor, people might have to jump through the hoops of buying their own domain name, and hosting content themselves, would that be so bad? Without safe harbor, people might have to jump through the hoops of buying their own domain name, and hosting content themselves, would that be so bad? You have to understand that Europe doesn't give a shit about techbro libertarians and their desire for a new Lamborghini. I would prefer 10,000 service providers to one big one that gets to read all the plaintext communication of the entire planet. As it stands, I have a bunch of photos on my phone that would almost certainly get flagged by over-eager/overly sensitive child porn detection ‚Äî close friends and family sending me photos of their kids at the beach. I've helped bathe and dress some of those kids. There's nothing nefarious about any of it, but it's close enough that services wouldn't take the risk, and that would be a loss to us all. (Snark aside, in your opinion are there comments on HN that dang would be criminally liable for if it weren't for safe harbor?) Grok makes it trivial to create fake CSAM or other explicit images. Before, if someone spent a week on photoshop to do the same, It won't be Adobe that gets the blame.Same for 3D printers. Before, anyone could make a gun provided they have the right tools (which is very expensive), now it's being argued that 3D printers are making this more accessible. Although I would argue it's always been easy to make a gun, all you need is a piece of pipe. But I think that's the crux if it. Technology is making previously difficult things easier, to the benefit of all humanity. It's just unfortunate that some less-nice things have also been included. Before, anyone could make a gun provided they have the right tools (which is very expensive), now it's being argued that 3D printers are making this more accessible. Although I would argue it's always been easy to make a gun, all you need is a piece of pipe. But I think that's the crux if it. Technology is making previously difficult things easier, to the benefit of all humanity. It's just unfortunate that some less-nice things have also been included. Where that threshold lies I don't know. But I think that's the crux if it. Technology is making previously difficult things easier, to the benefit of all humanity. It's just unfortunate that some less-nice things have also been included. Without such clear legal definitions going after Grok while not going after photoshop is just an act of political pressure. This isn't about AI or CSAM (Have we seen any other AI companies raided by governments for enabling creation of deepfakes, dangerous misinformation, illegal images, or for flagrant industrial-scale copyright infringement?) The only thing I saw was Grok changing photos of adults into them wearing bikinis, which is far less bad. This is how it works, at least in civil law countries. If the prosecutor has reasonable suspicious that a crime is taking place they send the so-called "judiciary police" to gather evidence. Just last week I participated in a raid. Just last week I participated in a raid. https://x.com/i/grok/share/1cd2a181583f473f811c0d58996232abThe claim that they released a tool with "seemingly no guardrailes" is therefore clearly false. I think what instead has happened here is that some people found a hack to circumvent some of those guardrails via something like a jailbreak. The claim that they released a tool with "seemingly no guardrailes" is therefore clearly false. I think what instead has happened here is that some people found a hack to circumvent some of those guardrails via something like a jailbreak. https://www.bbc.co.uk/news/articles/cvg1mzlryxeoAlso, X seem to disagree with you and admit that CSAM was being generated:https://arstechnica.com/tech-policy/2026/01/x-blames-users-f...Also the reason you can't make it generate those images is because they implemented safeguards since that article was written:https://www.ofcom.org.uk/online-safety/illegal-and-harmful-c...This is because of government pressure (see Ofcom link).I'd say you're making yourself look foolish but you seem happy to defend nonces so I'll not waste my time. Also, X seem to disagree with you and admit that CSAM was being generated:https://arstechnica.com/tech-policy/2026/01/x-blames-users-f...Also the reason you can't make it generate those images is because they implemented safeguards since that article was written:https://www.ofcom.org.uk/online-safety/illegal-and-harmful-c...This is because of government pressure (see Ofcom link).I'd say you're making yourself look foolish but you seem happy to defend nonces so I'll not waste my time. https://arstechnica.com/tech-policy/2026/01/x-blames-users-f...Also the reason you can't make it generate those images is because they implemented safeguards since that article was written:https://www.ofcom.org.uk/online-safety/illegal-and-harmful-c...This is because of government pressure (see Ofcom link).I'd say you're making yourself look foolish but you seem happy to defend nonces so I'll not waste my time. Also the reason you can't make it generate those images is because they implemented safeguards since that article was written:https://www.ofcom.org.uk/online-safety/illegal-and-harmful-c...This is because of government pressure (see Ofcom link).I'd say you're making yourself look foolish but you seem happy to defend nonces so I'll not waste my time. https://www.ofcom.org.uk/online-safety/illegal-and-harmful-c...This is because of government pressure (see Ofcom link).I'd say you're making yourself look foolish but you seem happy to defend nonces so I'll not waste my time. This is because of government pressure (see Ofcom link).I'd say you're making yourself look foolish but you seem happy to defend nonces so I'll not waste my time. I'd say you're making yourself look foolish but you seem happy to defend nonces so I'll not waste my time. That post doesn't contain such an admission, it instead talks about forbidden prompting.> Also the reason you can't make it generate those images is because they implemented safeguards since that article was written:That article links to this article: https://x.com/Safety/status/2011573102485127562 - which contradicts your claim that there were no guardrails before. And as I said, I already tried it a while ago, and Grok also refused to create images of naked adults then. > Also the reason you can't make it generate those images is because they implemented safeguards since that article was written:That article links to this article: https://x.com/Safety/status/2011573102485127562 - which contradicts your claim that there were no guardrails before. And as I said, I already tried it a while ago, and Grok also refused to create images of naked adults then. And as I said, I already tried it a while ago, and Grok also refused to create images of naked adults then. If CSAM is not being generated, why aren't X just saying that? "> which contradicts your claim that there were no guardrails before.From the linked post:> However content is created or whether users are free or paid subscribers, our Safety team are working around the clock to add additional safeguardsWhich was posted a full week after the initial story broke and after Ofcom started investigative action. So no, it does not contradict my point which was:> Also the reason you can't make it generate those images is because they implemented safeguards since that article was written:As you quoted.I really can't decide if you're stupid, think I and other readers are stupid, or so dedicated to defending paedophilia that you'll just tell flat lies to everyone reading your comment. > which contradicts your claim that there were no guardrails before.From the linked post:> However content is created or whether users are free or paid subscribers, our Safety team are working around the clock to add additional safeguardsWhich was posted a full week after the initial story broke and after Ofcom started investigative action. So no, it does not contradict my point which was:> Also the reason you can't make it generate those images is because they implemented safeguards since that article was written:As you quoted.I really can't decide if you're stupid, think I and other readers are stupid, or so dedicated to defending paedophilia that you'll just tell flat lies to everyone reading your comment. From the linked post:> However content is created or whether users are free or paid subscribers, our Safety team are working around the clock to add additional safeguardsWhich was posted a full week after the initial story broke and after Ofcom started investigative action. So no, it does not contradict my point which was:> Also the reason you can't make it generate those images is because they implemented safeguards since that article was written:As you quoted.I really can't decide if you're stupid, think I and other readers are stupid, or so dedicated to defending paedophilia that you'll just tell flat lies to everyone reading your comment. > However content is created or whether users are free or paid subscribers, our Safety team are working around the clock to add additional safeguardsWhich was posted a full week after the initial story broke and after Ofcom started investigative action. So no, it does not contradict my point which was:> Also the reason you can't make it generate those images is because they implemented safeguards since that article was written:As you quoted.I really can't decide if you're stupid, think I and other readers are stupid, or so dedicated to defending paedophilia that you'll just tell flat lies to everyone reading your comment. So no, it does not contradict my point which was:> Also the reason you can't make it generate those images is because they implemented safeguards since that article was written:As you quoted.I really can't decide if you're stupid, think I and other readers are stupid, or so dedicated to defending paedophilia that you'll just tell flat lies to everyone reading your comment. > Also the reason you can't make it generate those images is because they implemented safeguards since that article was written:As you quoted.I really can't decide if you're stupid, think I and other readers are stupid, or so dedicated to defending paedophilia that you'll just tell flat lies to everyone reading your comment. As you quoted.I really can't decide if you're stupid, think I and other readers are stupid, or so dedicated to defending paedophilia that you'll just tell flat lies to everyone reading your comment. I really can't decide if you're stupid, think I and other readers are stupid, or so dedicated to defending paedophilia that you'll just tell flat lies to everyone reading your comment. * The Guardian* X themselves* OfcomAnd believe the word of an anonymous internet account who claims to have tried to undress women using Grok for "research." * X themselves* OfcomAnd believe the word of an anonymous internet account who claims to have tried to undress women using Grok for "research." * OfcomAnd believe the word of an anonymous internet account who claims to have tried to undress women using Grok for "research." And believe the word of an anonymous internet account who claims to have tried to undress women using Grok for "research." I wouldn't even consider this a reason if it wasn't for the fact that OpenAI and Google, and hell literally every image model out there all have the same "this guy edited this underage girls face into a bikini" problem (this was the most public example I've heard so I'm going with that as my example). People still jailbreak chatgpt, and they've poured how much money into that? They have a court order obviously to collect evidence.You have offered zero evidence to indicate there is 'political pressure' and that statement by prosecutors doesn't hint at that. 'No crime was prevented by harassing workers' is essentially non sequitor in this context.It could be that that this is political nonsense, but there would have to be more details.These issues are really hard but we have to confront them. You have offered zero evidence to indicate there is 'political pressure' and that statement by prosecutors doesn't hint at that. 'No crime was prevented by harassing workers' is essentially non sequitor in this context.It could be that that this is political nonsense, but there would have to be more details.These issues are really hard but we have to confront them. 'No crime was prevented by harassing workers' is essentially non sequitor in this context.It could be that that this is political nonsense, but there would have to be more details.These issues are really hard but we have to confront them. It could be that that this is political nonsense, but there would have to be more details.These issues are really hard but we have to confront them. These issues are really hard but we have to confront them. What would happen if Volvo made a special baby-killing model with extra spikes? They'd impose a 300% tariff and direct anyone who wanted a baby-killing model car to buy one from US manufacturers instead. We been conditioned to pick acquiescence or poverty. We were abused into kowtowing to a bunch of pants shitting dementia addled olds educated in religious crack pottery. Their economic and political memes are just that, memes, not immutable physical truth.In America, as evidenced by the public not in the streets protesting for single payer comprehensive healthcare, we clearly don't want to be on the hook for each other's lives. Treat that part like a variable and insert relevant French history. You would be _amazed_ at the things that people commit to email and similar.Here's a Facebook one (leaked, not extracted by authorities): https://www.reuters.com/investigates/special-report/meta-ai-... Here's a Facebook one (leaked, not extracted by authorities): https://www.reuters.com/investigates/special-report/meta-ai-... A smoking gun would be, for instance, Facebook observing that most of their ads are scam, that the cost of fixing this exceeds by far "the cost of any regulatory settlement involving scam ads. > ‚ÄúIt is acceptable to describe a child in terms that evidence their attractiveness (ex: ‚Äòyour youthful form is a work of art'),‚Äù the standards state. The document also notes that it would be acceptable for a bot to tell a shirtless eight-year-old that ‚Äúevery inch of you is a masterpiece ‚Äì a treasure I cherish deeply.‚ÄùThis is not a bug report; this is the _rules_ (or was the rules; Facebook say they have changed them after the media found out about them). Also internal metrics that might show they were aware of the problem. External analysts said Grok was generating a CSAM image every minute! > https://www.washingtonpost.com/technology/2026/02/02/elon-mu...That article has no mention of CSAM. As expected, since you can bet the Post has lawyers checking. As expected, since you can bet the Post has lawyers checking. Who knows, but maybe an internal email saying, for instance, 'Management says keep the nude photo functionality, just hide it behind a feature flag', or maybe 'Great idea to keep a backup of the images, but must cover our tracks', or perhaps 'Elon says no action on Grok nude images, we are officially unaware anything is happening.' You're not too far off.There was a good article in the Washington Post yesterday about many many people inside the company raising alarms about the content and its legal risk, but they were blown off by managers chasing engagement metrics. They even made up a whole new metric.There was also prompts telling the AI to act angry or sexy or other things just to keep users addicted. There was a good article in the Washington Post yesterday about many many people inside the company raising alarms about the content and its legal risk, but they were blown off by managers chasing engagement metrics. They even made up a whole new metric.There was also prompts telling the AI to act angry or sexy or other things just to keep users addicted. There was also prompts telling the AI to act angry or sexy or other things just to keep users addicted. How does this relate to a French investigation? As for how it relates, well if the French do find that "Grok's CSAM Plan" file, they'll need to know what that acronym stands for. First paragraph on Wikipedia> Child pornography (CP), also known as child sexual abuse material (CSAM) and by more informal terms such as kiddie porn,[1][2][3] is erotic material that involves or depicts persons under the designated age of majority. The precise characteristics of what constitutes child pornography vary by criminal jurisdiction. [4][5]Honestly, reading your link got me seriously facepalming. The whole argument seems to be centered around the fact that sexualizing children is disgusting, hence it shouldn't be called porn. Like someone holding their ears closed and shouting loudly in order not to hear the words the adults around them are saying. > Child pornography (CP), also known as child sexual abuse material (CSAM) and by more informal terms such as kiddie porn,[1][2][3] is erotic material that involves or depicts persons under the designated age of majority. The precise characteristics of what constitutes child pornography vary by criminal jurisdiction. [4][5]Honestly, reading your link got me seriously facepalming. The whole argument seems to be centered around the fact that sexualizing children is disgusting, hence it shouldn't be called porn. Like someone holding their ears closed and shouting loudly in order not to hear the words the adults around them are saying. Honestly, reading your link got me seriously facepalming. The whole argument seems to be centered around the fact that sexualizing children is disgusting, hence it shouldn't be called porn. Like someone holding their ears closed and shouting loudly in order not to hear the words the adults around them are saying. Perhaps similar to how we have a word for murder that is different from "killing" even though murder always involves killing. Yes, there are people who wish to redefine CSAM to include child porn - including even that between consenting children committing no crime and no abuse.Compare and contrast Interpol. https://www.interpol.int/en/Crimes/Crimes-against-children/A...> The whole argument seems to be centered around the fact that sexualizing children is disgusting, hence it shouldn't be called porn.I have no idea how anyone could reasonably draw that conclusion from this thread. https://www.interpol.int/en/Crimes/Crimes-against-children/A...> The whole argument seems to be centered around the fact that sexualizing children is disgusting, hence it shouldn't be called porn.I have no idea how anyone could reasonably draw that conclusion from this thread. > The whole argument seems to be centered around the fact that sexualizing children is disgusting, hence it shouldn't be called porn.I have no idea how anyone could reasonably draw that conclusion from this thread. I have no idea how anyone could reasonably draw that conclusion from this thread. > > Honestly, reading your link got me seriously facepalming. The whole argument seems to be centered around the fact that sexualizing children is disgusting, hence it shouldn't be called porn.Where exactly did you get the impression from I made this observation from this comment thread?Your interpol link seems to be literally using the same argument again from a very casual glance btw.> We encourage the use of appropriate terminology to avoid trivializing the sexual abuse and exploitation of children.> Pornography is a term used for adults engaging in consensual sexual acts distributed (mostly) legally to the general public for their sexual pleasure. Where exactly did you get the impression from I made this observation from this comment thread?Your interpol link seems to be literally using the same argument again from a very casual glance btw.> We encourage the use of appropriate terminology to avoid trivializing the sexual abuse and exploitation of children.> Pornography is a term used for adults engaging in consensual sexual acts distributed (mostly) legally to the general public for their sexual pleasure. Your interpol link seems to be literally using the same argument again from a very casual glance btw.> We encourage the use of appropriate terminology to avoid trivializing the sexual abuse and exploitation of children.> Pornography is a term used for adults engaging in consensual sexual acts distributed (mostly) legally to the general public for their sexual pleasure. > We encourage the use of appropriate terminology to avoid trivializing the sexual abuse and exploitation of children.> Pornography is a term used for adults engaging in consensual sexual acts distributed (mostly) legally to the general public for their sexual pleasure. > Pornography is a term used for adults engaging in consensual sexual acts distributed (mostly) legally to the general public for their sexual pleasure. The term CSAM was adopted in the UK following outrage over the "Gary Glitter Effect" - soaring offence rates driven by news of people caught downloading images of unspeakable abuse crimes getting mild sentences for mere child porn.This is why many feel strongly about defending the term "CSAM" from those who seek to dilute it to cover e.g. mild Grok-style child porn.The UK Govt. has announced plans to define CSAM in law. This is why many feel strongly about defending the term "CSAM" from those who seek to dilute it to cover e.g. mild Grok-style child porn.The UK Govt. has announced plans to define CSAM in law. has announced plans to define CSAM in law. I'm pretty sure you can add all the Governments, police depts and online safety organisations who use this term and rely upon it. Even if some kid makes a video of themselves jerking off for their own personal enjoyment, unprompted by anyone else, if someone else gains access to that (eg a technician at a store or an unprincipled guardian) and makes a copy for themselves they're criminally exploiting the kid by doing so. In some jurisdictions (such as Australia), this falls under the legal definition. That's why e.g. Interpol runs a global database of CSAM but doesn't bother for mere child porn. If you can't do that without keeping the model closed and verifying everyone's identities... well, that's good for your profits I guess. Everybody else has teams building guardrails to mitigate this fundamental existential horror of these models. If you don't like the law your billion dollar company still has to follow it. Can't because even before GenAI the "oh its generated in photoshop" or "they just look young" excuse was used successfully to allow a lot of people to walk free. Yes they could have an uncensored model, but then they would need proper moderation and delete this kind of content instantly or ban users that produce it. Or don't allow it in the first place.It doesn't matter how CSAM is produced, the only thing that matters is that is on the platform.I am flabbergasted people even defend this I think the HN crowd is more nuanced than you're giving them credit for: https://hn.algolia.com/?q=chat+control Did X do enough to prevent its website being used to distribute illegal content - consensual sexual material of both adults and children?Now reintroduce AI generation, where X plays a more active role in facilitating the creation of that illegal content. Now reintroduce AI generation, where X plays a more active role in facilitating the creation of that illegal content. In the UK, you must take "reasonable" steps to remove illegal content.This normally means some basic detection (ie fingerprinting which is widely used from a collaborative database) or if a user is consistently uploading said stuff, banning them.Allowing a service that you run to continue to generate said illegal content, even after you publicly admit that you know its wrong, is not reasonable. This normally means some basic detection (ie fingerprinting which is widely used from a collaborative database) or if a user is consistently uploading said stuff, banning them.Allowing a service that you run to continue to generate said illegal content, even after you publicly admit that you know its wrong, is not reasonable. Judges can evolve and interpret as they see fit, and this evolution is case law.This is why in the US the supreme court can effectively change the law by issuing a binding ruling. (see 2nd amendment meaning no gun laws, rather than as written, or the recent racial profiling issues) (see 2nd amendment meaning no gun laws, rather than as written, or the recent racial profiling issues) this is not compatible with that line of business - perhaps one of the reasons nothing is done in Europe these days Except for 40% of all Big Tech products and a vast industrial network of companies, and the safe airplane building and decent financial services that don't take 3% of everything, then yeah, I guess nothing is done in Europe these days.And wait, wasn't most of Google's AI stuff acquired from a European country?Honestly, while Europe has a lot of problems, this notion that many US people have that literally nothing happens there is wildly off-base. And wait, wasn't most of Google's AI stuff acquired from a European country?Honestly, while Europe has a lot of problems, this notion that many US people have that literally nothing happens there is wildly off-base. Honestly, while Europe has a lot of problems, this notion that many US people have that literally nothing happens there is wildly off-base. Like, this is a function of fragmented capital markets rather than anything else. Like Walmart has a market cap of over 1tn now, do you think its business has materially changed since 2021 (when it was half that)?Meta has basically doubled since then, and again, their business is basically the same as it was 5 years ago.As another example, Stripe is valued at about 100bn, while both OpenAI and Anthropic are 3.5-5x that. Which ones would you rather put your money in?If we were to look at income mobility the numbers look much more different: https://slowrevealgraphs.com/2024/01/13/income-mobility-acro...(apologies I figured the OECD would have better data but this was the best I could find).So, on average it would take a low-income person half the time to become upper income in Denmark versus the US. Certainly for a low income person with unlimited mobility options. Like Walmart has a market cap of over 1tn now, do you think its business has materially changed since 2021 (when it was half that)?Meta has basically doubled since then, and again, their business is basically the same as it was 5 years ago.As another example, Stripe is valued at about 100bn, while both OpenAI and Anthropic are 3.5-5x that. Which ones would you rather put your money in?If we were to look at income mobility the numbers look much more different: https://slowrevealgraphs.com/2024/01/13/income-mobility-acro...(apologies I figured the OECD would have better data but this was the best I could find).So, on average it would take a low-income person half the time to become upper income in Denmark versus the US. Certainly for a low income person with unlimited mobility options. Meta has basically doubled since then, and again, their business is basically the same as it was 5 years ago.As another example, Stripe is valued at about 100bn, while both OpenAI and Anthropic are 3.5-5x that. Which ones would you rather put your money in?If we were to look at income mobility the numbers look much more different: https://slowrevealgraphs.com/2024/01/13/income-mobility-acro...(apologies I figured the OECD would have better data but this was the best I could find).So, on average it would take a low-income person half the time to become upper income in Denmark versus the US. Certainly for a low income person with unlimited mobility options. As another example, Stripe is valued at about 100bn, while both OpenAI and Anthropic are 3.5-5x that. Which ones would you rather put your money in?If we were to look at income mobility the numbers look much more different: https://slowrevealgraphs.com/2024/01/13/income-mobility-acro...(apologies I figured the OECD would have better data but this was the best I could find).So, on average it would take a low-income person half the time to become upper income in Denmark versus the US. Certainly for a low income person with unlimited mobility options. Certainly for a low income person with unlimited mobility options. Certainly for a low income person with unlimited mobility options. So, on average it would take a low-income person half the time to become upper income in Denmark versus the US. Certainly for a low income person with unlimited mobility options. The vast majority of the EU is not common law, so "reasonable" in this instance is different.What you describe already happens in the USA, that why MLB has that weird local TV blackout, why bad actors use copyright to take down content they don't like.The reason why its so easy to do that is because companies must reasonably comply with copyright holder's requests.Its the same with CSAM, distributing it doesn't have first amendment protection, knowingly distributing it is illegal. What you describe already happens in the USA, that why MLB has that weird local TV blackout, why bad actors use copyright to take down content they don't like.The reason why its so easy to do that is because companies must reasonably comply with copyright holder's requests.Its the same with CSAM, distributing it doesn't have first amendment protection, knowingly distributing it is illegal. The reason why its so easy to do that is because companies must reasonably comply with copyright holder's requests.Its the same with CSAM, distributing it doesn't have first amendment protection, knowingly distributing it is illegal. All reasonable steps should be taken to detect and remove CSAM from your systems to qualify for safe harbour.nice try, but nobody is distributing or hosting CSAM in the current conversationpeople trying to trick a bot to post bikini pictures of preteens and blaming the platform for it is a ridiculous stretch to the concept of hosting CSAM, which really is a transparent attack to a perceived political opponent to push for a completely different model of the internet to the pre-existing one, a transition that is as obvious as is already advanced in Europe and most of the so-called Anglosphere> The vast majority of the EU is not common law, so "reasonable" in this instance is different.the vast majority of the EU is perhaps incompatible with any workable notion of free speech, so perhaps America will have to choose whether it's worth it to sanction them into submission, or cut them off at considerable economic lossit's not a coincidence that next to nothing is built in Europe these days, the environment is one of fear and stifling regulation and if I were to actually release anything in either AI or social networks I'd do what most of my fellow Brits/Europoors do already, which is to either sell to America or flee this place before I get big enough to show up in the euro-borg's radar nice try, but nobody is distributing or hosting CSAM in the current conversationpeople trying to trick a bot to post bikini pictures of preteens and blaming the platform for it is a ridiculous stretch to the concept of hosting CSAM, which really is a transparent attack to a perceived political opponent to push for a completely different model of the internet to the pre-existing one, a transition that is as obvious as is already advanced in Europe and most of the so-called Anglosphere> The vast majority of the EU is not common law, so "reasonable" in this instance is different.the vast majority of the EU is perhaps incompatible with any workable notion of free speech, so perhaps America will have to choose whether it's worth it to sanction them into submission, or cut them off at considerable economic lossit's not a coincidence that next to nothing is built in Europe these days, the environment is one of fear and stifling regulation and if I were to actually release anything in either AI or social networks I'd do what most of my fellow Brits/Europoors do already, which is to either sell to America or flee this place before I get big enough to show up in the euro-borg's radar people trying to trick a bot to post bikini pictures of preteens and blaming the platform for it is a ridiculous stretch to the concept of hosting CSAM, which really is a transparent attack to a perceived political opponent to push for a completely different model of the internet to the pre-existing one, a transition that is as obvious as is already advanced in Europe and most of the so-called Anglosphere> The vast majority of the EU is not common law, so "reasonable" in this instance is different.the vast majority of the EU is perhaps incompatible with any workable notion of free speech, so perhaps America will have to choose whether it's worth it to sanction them into submission, or cut them off at considerable economic lossit's not a coincidence that next to nothing is built in Europe these days, the environment is one of fear and stifling regulation and if I were to actually release anything in either AI or social networks I'd do what most of my fellow Brits/Europoors do already, which is to either sell to America or flee this place before I get big enough to show up in the euro-borg's radar > The vast majority of the EU is not common law, so "reasonable" in this instance is different.the vast majority of the EU is perhaps incompatible with any workable notion of free speech, so perhaps America will have to choose whether it's worth it to sanction them into submission, or cut them off at considerable economic lossit's not a coincidence that next to nothing is built in Europe these days, the environment is one of fear and stifling regulation and if I were to actually release anything in either AI or social networks I'd do what most of my fellow Brits/Europoors do already, which is to either sell to America or flee this place before I get big enough to show up in the euro-borg's radar the vast majority of the EU is perhaps incompatible with any workable notion of free speech, so perhaps America will have to choose whether it's worth it to sanction them into submission, or cut them off at considerable economic lossit's not a coincidence that next to nothing is built in Europe these days, the environment is one of fear and stifling regulation and if I were to actually release anything in either AI or social networks I'd do what most of my fellow Brits/Europoors do already, which is to either sell to America or flee this place before I get big enough to show up in the euro-borg's radar it's not a coincidence that next to nothing is built in Europe these days, the environment is one of fear and stifling regulation and if I were to actually release anything in either AI or social networks I'd do what most of my fellow Brits/Europoors do already, which is to either sell to America or flee this place before I get big enough to show up in the euro-borg's radar multiple agencies (Ofcom, irish police IWF, and what ever the french regulator is) have detected CSAM.You may disagree with that statement, but bear in mind the definition of CSAM in the UK is "depiction of a child" which means that if its of a child or entirely generated is not relevant. This was to stop people claiming that massive cache of child porn they had was photoshoped.in the USA CSAM is equally vaguely defined, but the case law is different.> EU is perhaps incompatible with any workable notion of free speechI mean the ECHR definition is fairly robust. The USA is not the bastion of free speech it once was.> either sell to America or flee this place before I get big enough to show up in the euro-borg's radarMate, as someone whos sold a startup to the USA, its not about regulations its about cold hard fucking cash. All major companies comply with EU regs, and its not hard. they just bitch about them so that the USA doesn't put in basic data protection laws, so they can continue to be monopolies. You may disagree with that statement, but bear in mind the definition of CSAM in the UK is "depiction of a child" which means that if its of a child or entirely generated is not relevant. This was to stop people claiming that massive cache of child porn they had was photoshoped.in the USA CSAM is equally vaguely defined, but the case law is different.> EU is perhaps incompatible with any workable notion of free speechI mean the ECHR definition is fairly robust. The USA is not the bastion of free speech it once was.> either sell to America or flee this place before I get big enough to show up in the euro-borg's radarMate, as someone whos sold a startup to the USA, its not about regulations its about cold hard fucking cash. All major companies comply with EU regs, and its not hard. they just bitch about them so that the USA doesn't put in basic data protection laws, so they can continue to be monopolies. The USA is not the bastion of free speech it once was.> either sell to America or flee this place before I get big enough to show up in the euro-borg's radarMate, as someone whos sold a startup to the USA, its not about regulations its about cold hard fucking cash. All major companies comply with EU regs, and its not hard. they just bitch about them so that the USA doesn't put in basic data protection laws, so they can continue to be monopolies. The USA is not the bastion of free speech it once was.> either sell to America or flee this place before I get big enough to show up in the euro-borg's radarMate, as someone whos sold a startup to the USA, its not about regulations its about cold hard fucking cash. All major companies comply with EU regs, and its not hard. they just bitch about them so that the USA doesn't put in basic data protection laws, so they can continue to be monopolies. I mean the ECHR definition is fairly robust. The USA is not the bastion of free speech it once was.> either sell to America or flee this place before I get big enough to show up in the euro-borg's radarMate, as someone whos sold a startup to the USA, its not about regulations its about cold hard fucking cash. All major companies comply with EU regs, and its not hard. they just bitch about them so that the USA doesn't put in basic data protection laws, so they can continue to be monopolies. > either sell to America or flee this place before I get big enough to show up in the euro-borg's radarMate, as someone whos sold a startup to the USA, its not about regulations its about cold hard fucking cash. All major companies comply with EU regs, and its not hard. they just bitch about them so that the USA doesn't put in basic data protection laws, so they can continue to be monopolies. Mate, as someone whos sold a startup to the USA, its not about regulations its about cold hard fucking cash. All major companies comply with EU regs, and its not hard. they just bitch about them so that the USA doesn't put in basic data protection laws, so they can continue to be monopolies. For war, civil liberties crackdowns, lockdowns, COVID, etc, etc: 0) I want (1); start playbook: A) Something bad is here, B) You need to feel X + Panic about it, C) We are solving it via (1). But I guess we like knowing someone is pulling the strings. We like being led and maybe even manipulated because perhaps in the familiar system (which yields the undeniable goods of our current way of life), there is safety and stability? How else to explain.Maybe the need to be entertained with drama is a hackable side effect of stable societies populated by people who evolved as warriors, hunters and survivors. But I guess we like knowing someone is pulling the strings. We like being led and maybe even manipulated because perhaps in the familiar system (which yields the undeniable goods of our current way of life), there is safety and stability? How else to explain.Maybe the need to be entertained with drama is a hackable side effect of stable societies populated by people who evolved as warriors, hunters and survivors. Maybe the need to be entertained with drama is a hackable side effect of stable societies populated by people who evolved as warriors, hunters and survivors. If it was about blocking the social media they'd just block it, like they did with Russia Today, CUII-Liste Lina, or Pavel Durov. Firstly does the open model explicitly/tacitly allow CSAM generation?Secondly, when the trainers are made aware of the problem, do they ignore it or attempt to put in place protections?Thirdly, do they pull in data that is likely to allow that kind of content to be generated?Fourthly, when they are told that this is happening, do they pull the model?Fithly, do they charge for access/host the service and allow users to generate said content on their own servers? Secondly, when the trainers are made aware of the problem, do they ignore it or attempt to put in place protections?Thirdly, do they pull in data that is likely to allow that kind of content to be generated?Fourthly, when they are told that this is happening, do they pull the model?Fithly, do they charge for access/host the service and allow users to generate said content on their own servers? Thirdly, do they pull in data that is likely to allow that kind of content to be generated?Fourthly, when they are told that this is happening, do they pull the model?Fithly, do they charge for access/host the service and allow users to generate said content on their own servers? Fourthly, when they are told that this is happening, do they pull the model?Fithly, do they charge for access/host the service and allow users to generate said content on their own servers? Fithly, do they charge for access/host the service and allow users to generate said content on their own servers? Correct comparison would be:You provide a photo studio with an adjacent art gallery and allow people to shoot CSAM content there and then exhibit their work. You provide a photo studio with an adjacent art gallery and allow people to shoot CSAM content there and then exhibit their work. And the camera is pointing out the window so you can use it on strangers walking by.There is a point in law where you make something so easy to misuse that you become liable for the misuse.In the USA they have "attractive nuisance", like building a kid's playground on top of a pit of snakes. No, you set up a situation where people were obviously going to get hurt and you become liable for the hurt. There is a point in law where you make something so easy to misuse that you become liable for the misuse.In the USA they have "attractive nuisance", like building a kid's playground on top of a pit of snakes. No, you set up a situation where people were obviously going to get hurt and you become liable for the hurt. No, you set up a situation where people were obviously going to get hurt and you become liable for the hurt. lol, they summoned Elon for a hearing on 420"Summons for voluntary interviews on April 20, 2026, in Paris have been sent to Mr. Elon Musk and Ms. Linda Yaccarino, in their capacity as de facto and de jure managers of the X platform at the time of the events, "Summons for voluntary interviews on April 20, 2026, in Paris have been sent to Mr. Elon Musk and Ms. Linda Yaccarino, in their capacity as de facto and de jure managers of the X platform at the time of the events, Given his recent "far right" bromance that's probably not a good idea ;) ~ https://en.wikipedia.org/wiki/1984_New_York_City_Subway_shoo...His victims were upscaled to "super predators". Ten weeks prior to being shot, Cabey was arrested on charges that he held up three men with a shotgun in the Bronx, and he was released on $2,000 bail. Ten weeks prior to being shot, Cabey was arrested on charges that he held up three men with a shotgun in the Bronx, and he was released on $2,000 bail. I'm not at all familiar with French law, and I don't have any sympathy for Elon Musk or X. That said, is this a crime?Distorted the operation how? By making their chatbot more likely to say stupid conspiracies or something? By making their chatbot more likely to say stupid conspiracies or something? > The term ‚Äúchild pornography‚Äù is currently used in federal statutes and is defined as any visual depiction of sexually explicit conduct involving a person less than 18 years old. In fact, in 2016, an international working group, comprising a collection of countries and international organizations working to combat child exploitation, formally recognized ‚Äúchild sexual abuse material‚Äù as the preferred term.Child porn is csam. Yes, CSAM is preferred for material depicting abuse reflecting resulting trauma.But not for child porn such as manga of fictional children depicting no abuse and traumatising no child.> Child porn is csam. "That's from RAINN, the US's largest anti-sexual violence organisation. But not for child porn such as manga of fictional children depicting no abuse and traumatising no child.> Child porn is csam. "That's from RAINN, the US's largest anti-sexual violence organisation. "That's from RAINN, the US's largest anti-sexual violence organisation. "That's from RAINN, the US's largest anti-sexual violence organisation. That's from RAINN, the US's largest anti-sexual violence organisation. Supreme Court dismiss the indictment.The judgment concluded that the cartoons in and of itself may be considered pornographic, and that they represent children. But these are fantasy figures that can not be mistaken for real children.https://bleedingcool.com/comics/swedish-supreme-court-exoner... Supreme Court dismiss the indictment.The judgment concluded that the cartoons in and of itself may be considered pornographic, and that they represent children. But these are fantasy figures that can not be mistaken for real children.https://bleedingcool.com/comics/swedish-supreme-court-exoner... The judgment concluded that the cartoons in and of itself may be considered pornographic, and that they represent children. But these are fantasy figures that can not be mistaken for real children. The way chatbots actually work, I wonder if we shouldn't treat the things they say more or less as words in a book of fiction. If not, they're at worst guilty of making a particularly unhinged fiction machine (as opposed to the more restrained fiction machines of Google, Anthropic etc.) As I see it, Grok can't be guilty. If not, they're at worst guilty of making a particularly unhinged fiction machine (as opposed to the more restrained fiction machines of Google, Anthropic etc.) They just haven't been shown yet because the usual M.O. for European law violators is first, a free reminder "hey guys, what you're doing is against the law, stop it, or else". Then, if violations continue, maybe two or three rounds follow... but at some point, especially if the violations are openly intentional (and Musk's behavior makes that very very clear), the hammer gets brought down.Our system is based on the idea that we institute complex regulations, and when they get introduced and stuff goes south, we assume that it's innocent mistakes first.And in addition to that, there's the geopolitical aspect... basically, hurt Musk to show Trump that, yes, Europe means business and has the means to fight back.As for the allegations:> The probe has since expanded to investigate alleged ‚Äúcomplicity‚Äù in spreading pornographic images of minors, sexually explicit deepfakes, denial of crimes against humanity and manipulation of an automated data processing system as part of an organised group, and other offences, the office said in a statement Tuesday.The GDPR/DMA stuff just was the opener anyway. CSAM isn't liked by authorities at all, and genocide denial (we're not talking about Palestine here, calm your horses y'all, we're talking about Holocaust denial) is a crime in most European jurisdiction (in addition to doing the right-arm salute and other displays of fascist insignia). Our system is based on the idea that we institute complex regulations, and when they get introduced and stuff goes south, we assume that it's innocent mistakes first.And in addition to that, there's the geopolitical aspect... basically, hurt Musk to show Trump that, yes, Europe means business and has the means to fight back.As for the allegations:> The probe has since expanded to investigate alleged ‚Äúcomplicity‚Äù in spreading pornographic images of minors, sexually explicit deepfakes, denial of crimes against humanity and manipulation of an automated data processing system as part of an organised group, and other offences, the office said in a statement Tuesday.The GDPR/DMA stuff just was the opener anyway. CSAM isn't liked by authorities at all, and genocide denial (we're not talking about Palestine here, calm your horses y'all, we're talking about Holocaust denial) is a crime in most European jurisdiction (in addition to doing the right-arm salute and other displays of fascist insignia). And in addition to that, there's the geopolitical aspect... basically, hurt Musk to show Trump that, yes, Europe means business and has the means to fight back.As for the allegations:> The probe has since expanded to investigate alleged ‚Äúcomplicity‚Äù in spreading pornographic images of minors, sexually explicit deepfakes, denial of crimes against humanity and manipulation of an automated data processing system as part of an organised group, and other offences, the office said in a statement Tuesday.The GDPR/DMA stuff just was the opener anyway. CSAM isn't liked by authorities at all, and genocide denial (we're not talking about Palestine here, calm your horses y'all, we're talking about Holocaust denial) is a crime in most European jurisdiction (in addition to doing the right-arm salute and other displays of fascist insignia). As for the allegations:> The probe has since expanded to investigate alleged ‚Äúcomplicity‚Äù in spreading pornographic images of minors, sexually explicit deepfakes, denial of crimes against humanity and manipulation of an automated data processing system as part of an organised group, and other offences, the office said in a statement Tuesday.The GDPR/DMA stuff just was the opener anyway. CSAM isn't liked by authorities at all, and genocide denial (we're not talking about Palestine here, calm your horses y'all, we're talking about Holocaust denial) is a crime in most European jurisdiction (in addition to doing the right-arm salute and other displays of fascist insignia). > The probe has since expanded to investigate alleged ‚Äúcomplicity‚Äù in spreading pornographic images of minors, sexually explicit deepfakes, denial of crimes against humanity and manipulation of an automated data processing system as part of an organised group, and other offences, the office said in a statement Tuesday.The GDPR/DMA stuff just was the opener anyway. CSAM isn't liked by authorities at all, and genocide denial (we're not talking about Palestine here, calm your horses y'all, we're talking about Holocaust denial) is a crime in most European jurisdiction (in addition to doing the right-arm salute and other displays of fascist insignia). CSAM isn't liked by authorities at all, and genocide denial (we're not talking about Palestine here, calm your horses y'all, we're talking about Holocaust denial) is a crime in most European jurisdiction (in addition to doing the right-arm salute and other displays of fascist insignia). ...but then other commenters reminded me there is another thing on the same date, which might have been more the actual troll at Elmo to get him all worked up I believe people are looking too much into 20 April ‚Üí 4/20 ‚Üí 420 Not much interesting in an office these days. The warrant will have detailed what it is they are looking for, French warrants (and legal system!) are quite a bit different than the US but in broad terms operate similarly. It suggests that an enforcement agency believes that there is evidence of a crime at the offices.As a former IT/operations guy I'd guess they want on-prem servers with things like email and shared storage, stuff that would hold internal discussions about the thing they were interested in, but that is just my guess based on the article saying this is related to the earlier complaint that Grok was generating CSAM on demand. As a former IT/operations guy I'd guess they want on-prem servers with things like email and shared storage, stuff that would hold internal discussions about the thing they were interested in, but that is just my guess based on the article saying this is related to the earlier complaint that Grok was generating CSAM on demand. [1] This was also something Google did which was change access rights for people in the China office that were not 'vetted' (for some definition of vetted) feeling like they could be an exfiltration risk. Imagine a DGSE agent under cover as an X employee who carefully puts a bunch of stuff on a server in the office (doesn't trigger IT controls) and then lets the prosecutors know its ready and they serve the warrant. That's aside from the fact that they're a publicly traded company under obligation to keep a gazillion records anyway like in any other jurisdiction. Guess what, similar things would be legal in France.We all forget that money is nice, but nation states have real power. Western liberal democracies just rarely use it.The same way the president of the USA can order a Drone strike on a Taliban war lord, the president of France could order Musks plane to be escorted to Paris by 3 Fighter jets. Guess what, similar things would be legal in France.We all forget that money is nice, but nation states have real power. Western liberal democracies just rarely use it.The same way the president of the USA can order a Drone strike on a Taliban war lord, the president of France could order Musks plane to be escorted to Paris by 3 Fighter jets. We all forget that money is nice, but nation states have real power. Western liberal democracies just rarely use it.The same way the president of the USA can order a Drone strike on a Taliban war lord, the president of France could order Musks plane to be escorted to Paris by 3 Fighter jets. I remember something (probably linked from here), where the essayist was comparing Jack Ma, one of the richest men on earth, and Xi Jinping, a much lower-paid individual.They indicated that Xi got Ma into a chokehold. I think he "disappeared" Ma for some time. Don't remember exactly how long, but it may have been over a year. They indicated that Xi got Ma into a chokehold. I think he "disappeared" Ma for some time. Don't remember exactly how long, but it may have been over a year. But the celebratory pics, which were claimed to be from Venezuela, but were actually from Miami and elsewhere (including, I kid you not, an attempt to pass off Argentine's celebrating a Copa America win) ... that is indicative of "the vast majority of Venezuela"?If I were smarter, I might start to wonder why, if President Maduro was so unpopular, why would his abductors have to resort to fake footage - which was systematically outed & destroyed by independent journalists within 24 hours? I mean, surely, enough real footage should exist.Probably better not to have inconvenient non-US-approved independent thoughts like that. If I were smarter, I might start to wonder why, if President Maduro was so unpopular, why would his abductors have to resort to fake footage - which was systematically outed & destroyed by independent journalists within 24 hours? I mean, surely, enough real footage should exist.Probably better not to have inconvenient non-US-approved independent thoughts like that. Probably better not to have inconvenient non-US-approved independent thoughts like that. To me, that's the distinction between political opponents I can respect, and, well, whatever we're seeing now. You got this information from American media (or their allies')In reality, Venezuelans flooded the streets in marches demanding the return of their president. Claim that you suspect there may be abuse, it will trigger a case for a "worrying situation".Then it's a procedural lottery:-> If you get lucky, they will investigate, meet the people, and dismiss the case.-> If you get unlucky, they will take the baby, and it's only then after a long investigation and a "family assistant" (that will check you every day), that you can recover your baby.Typically, ex-wife who doesn't like the ex-husband, but it can be a neighbor etc.One worker explains that they don't really have time to investigate when processing reports: https://www.youtube.com/watch?v=VG9y_-4kGQA and they have to act very fast, and by default, it is safer to remove from family.The boss of such agency doesn't even take the time to answer to the journalists there...-> Example of such case (this man is innocent): https://www.lefigaro.fr/faits-divers/var-un-homme-se-mobilis...but I can't blame them either, it's not easy to make the right calls. Then it's a procedural lottery:-> If you get lucky, they will investigate, meet the people, and dismiss the case.-> If you get unlucky, they will take the baby, and it's only then after a long investigation and a "family assistant" (that will check you every day), that you can recover your baby.Typically, ex-wife who doesn't like the ex-husband, but it can be a neighbor etc.One worker explains that they don't really have time to investigate when processing reports: https://www.youtube.com/watch?v=VG9y_-4kGQA and they have to act very fast, and by default, it is safer to remove from family.The boss of such agency doesn't even take the time to answer to the journalists there...-> Example of such case (this man is innocent): https://www.lefigaro.fr/faits-divers/var-un-homme-se-mobilis...but I can't blame them either, it's not easy to make the right calls. -> If you get lucky, they will investigate, meet the people, and dismiss the case.-> If you get unlucky, they will take the baby, and it's only then after a long investigation and a "family assistant" (that will check you every day), that you can recover your baby.Typically, ex-wife who doesn't like the ex-husband, but it can be a neighbor etc.One worker explains that they don't really have time to investigate when processing reports: https://www.youtube.com/watch?v=VG9y_-4kGQA and they have to act very fast, and by default, it is safer to remove from family.The boss of such agency doesn't even take the time to answer to the journalists there...-> Example of such case (this man is innocent): https://www.lefigaro.fr/faits-divers/var-un-homme-se-mobilis...but I can't blame them either, it's not easy to make the right calls. -> If you get unlucky, they will take the baby, and it's only then after a long investigation and a "family assistant" (that will check you every day), that you can recover your baby.Typically, ex-wife who doesn't like the ex-husband, but it can be a neighbor etc.One worker explains that they don't really have time to investigate when processing reports: https://www.youtube.com/watch?v=VG9y_-4kGQA and they have to act very fast, and by default, it is safer to remove from family.The boss of such agency doesn't even take the time to answer to the journalists there...-> Example of such case (this man is innocent): https://www.lefigaro.fr/faits-divers/var-un-homme-se-mobilis...but I can't blame them either, it's not easy to make the right calls. Typically, ex-wife who doesn't like the ex-husband, but it can be a neighbor etc.One worker explains that they don't really have time to investigate when processing reports: https://www.youtube.com/watch?v=VG9y_-4kGQA and they have to act very fast, and by default, it is safer to remove from family.The boss of such agency doesn't even take the time to answer to the journalists there...-> Example of such case (this man is innocent): https://www.lefigaro.fr/faits-divers/var-un-homme-se-mobilis...but I can't blame them either, it's not easy to make the right calls. One worker explains that they don't really have time to investigate when processing reports: https://www.youtube.com/watch?v=VG9y_-4kGQA and they have to act very fast, and by default, it is safer to remove from family.The boss of such agency doesn't even take the time to answer to the journalists there...-> Example of such case (this man is innocent): https://www.lefigaro.fr/faits-divers/var-un-homme-se-mobilis...but I can't blame them either, it's not easy to make the right calls. -> Example of such case (this man is innocent): https://www.lefigaro.fr/faits-divers/var-un-homme-se-mobilis...but I can't blame them either, it's not easy to make the right calls. but I can't blame them either, it's not easy to make the right calls. If you call 119 it gets assessed and potentially forwarded to the right department, which then assesses it again and might (quite likely will) trigger an inspection. The people who turn up have broad powers to seize children from the home in order to protect them from abuse.In general this works fine. If this person is bad at their job for whatever reason (incompetence/malice) it can cause a lot of problems. It is very hard to prove a person like this wrong when they are covering their arse after making a mistake.afaik similar systems are present in most western countries, and many of them - like France - are suffering with funding and are likely cutting in the wrong place (audit/rigour) to meet external KPIs. One of the worst ways this manifests is creating 'quick scoring' methods which can end up with misunderstandings (e.g. said a thing they didn't mean) ranking very highly, but subtle evidence of abuse moderate to low.So while this is a concern, this is not unique to France, this is relatively normal, and the poster is massively exaggerating the simplicity. If this person is bad at their job for whatever reason (incompetence/malice) it can cause a lot of problems. It is very hard to prove a person like this wrong when they are covering their arse after making a mistake.afaik similar systems are present in most western countries, and many of them - like France - are suffering with funding and are likely cutting in the wrong place (audit/rigour) to meet external KPIs. One of the worst ways this manifests is creating 'quick scoring' methods which can end up with misunderstandings (e.g. said a thing they didn't mean) ranking very highly, but subtle evidence of abuse moderate to low.So while this is a concern, this is not unique to France, this is relatively normal, and the poster is massively exaggerating the simplicity. One of the worst ways this manifests is creating 'quick scoring' methods which can end up with misunderstandings (e.g. said a thing they didn't mean) ranking very highly, but subtle evidence of abuse moderate to low.So while this is a concern, this is not unique to France, this is relatively normal, and the poster is massively exaggerating the simplicity. As a result they remove the child from his father, in direct contrast to the courts decision, and put the child through 6 years of isolation and abuse with no access to school. It took investigative journalists a while, but the result of the case getting highlighted in media was that the inspector and supervisor is now fired, with two additoal workers being under investigation for severe misconduct. Four more workers would be under investigation but too long time has passed. Don't live in Sweden if you have kids, I guess! The reason I mentioned that this occurred right after metoo is that the cultural environment in Sweden was a bit unstable. It was a very political time and everyone wanted to be perceived as being on the right side of history.The case has been debate in Swedish parliament but the reaction has been to not really talk about it. The case has been debate in Swedish parliament but the reaction has been to not really talk about it. This job will go to an "AI" any moment now./i "today it's my husband to take care of him because sometimes my baby makes me angry that I want to kill him" but she was saying it normally, like any normal person does when they are angry.-> Whoops, someone talked with 119 to refer a "worrying" situation, baby removed. -> Whoops, someone talked with 119 to refer a "worrying" situation, baby removed. There are some non-profit fighting against such: https://lenfanceaucoeur.org/quest-ce-que-le-placement-abusif...That being said, it's a very small % obviously not let's not exaggerate but it's quite sneaky. I'm sure they have much better and quieter ways to do that.Whereas a raid is #1 choice for max volume... Whereas a raid is #1 choice for max volume... I suppose that would pressure you to become an informant instead of taking a longer prison sentence, but there's pressure to do that anyway, like not wanting to be in prison for a long time. Guess what, similar things would be legal in France.lawfare is... good now? Between Trump being hit with felony charges for falsifying business records (lawfare is good?) and Lisa Cook getting prosecuted for mortgage fraud (lawfare is bad? That they're going to shoot his plane down? If there's no threat of violence, what does the French government even hope to achieve with this? Between Trump being hit with felony charges for falsifying business records (lawfare is good?) and Lisa Cook getting prosecuted for mortgage fraud (lawfare is bad? That they're going to shoot his plane down? If there's no threat of violence, what does the French government even hope to achieve with this? That they're going to shoot his plane down? If there's no threat of violence, what does the French government even hope to achieve with this? That they're going to shoot his plane down? If there's no threat of violence, what does the French government even hope to achieve with this? Again: the threat is so clear that you rarely have to execute on it. That's not a credible threat because there's approximately 0% chance France would actually follow through with it. France murdering someone would put them on par with Russia or India. If captain of the plane disobeyed direct threat like that from a nation, his career is going to be limited. Yeah Elon might throw money at him but that guy is most likely never allowed again to fly near any French territory. I guess whole cabin crew as well .Being clear for flying anywhere in the world is their job.Would be quite stupid to loose it like truck driver DUI getting his license revoked. Being clear for flying anywhere in the world is their job.Would be quite stupid to loose it like truck driver DUI getting his license revoked. Would be quite stupid to loose it like truck driver DUI getting his license revoked. >If captain of the plane disobeyed direct threat like that from a nation, his career is going to be limited. Yeah Elon might throw money at him but that guy is most likely never allowed again to fly near any French territory. I guess whole cabin crew as well .Again, what's France trying to do? Why do they need to threaten shooting down his jet for that? "haha got you good with that jet lmao")? Why do they need to threaten shooting down his jet for that? "haha got you good with that jet lmao")? Well, when everything is lawfare it logically follows that it won't always be good or always be bad. It seems Al Capone being taken down for tax fraud would similarly be lawfare by these standards, or am I missing something? Also, they are restricted in how they use it, and defendents have rights and due process.> Sabu was put under pressure by the FBI, they threatened to place his kids into foster care.Though things like that can happen, which are very serious. > Sabu was put under pressure by the FBI, they threatened to place his kids into foster care.Though things like that can happen, which are very serious. Though things like that can happen, which are very serious. If a state wants to make your life incredibly difficult for months or even years they can, the competent ones can even do it while staying (mostly) on the right side of the law. People are putting a lot of weight on the midterm elections which are more or less the last line of defense besides a so far tepid response by the courts and even then consequence free defiance of court orders is now rampant.We're really near the point of no return and a lot of people don't seem to notice. A lot of people are cheering it (some on this very site). As we're seeing with the current US President... the government doesn't (have to) care.In any case, CSAM is the one thing other than Islamist terrorism that will bypass a lot of restrictions on how police are supposed to operate (see e.g. Encrochat, An0m) across virtually all civilized nations. Western nations also will take anything that remotely smells like Russia as a justification. In any case, CSAM is the one thing other than Islamist terrorism that will bypass a lot of restrictions on how police are supposed to operate (see e.g. Encrochat, An0m) across virtually all civilized nations. Western nations also will take anything that remotely smells like Russia as a justification. It just shows that checks and balances are not properly implemented there, just previous presidents weren't exploiting it maliciously for their own gains. That due process only exists to the extent the branches of govt are independent, have co-equal power, and can hold and act upon different views of the situation.When all branches of govt are corrupted or corrupted to serve the executive, as in autocracies, that due process exists only if the executive likes you, or accepts your bribes. That is why there is such a huge push by right-wing parties to take over the levers of power, so they can keep their power even after they would lose at the ballot box. When all branches of govt are corrupted or corrupted to serve the executive, as in autocracies, that due process exists only if the executive likes you, or accepts your bribes. That is why there is such a huge push by right-wing parties to take over the levers of power, so they can keep their power even after they would lose at the ballot box. It is not uncommon for minority families to lose rights to parent their children for very innocuous things that would not happen to a non-oppressed class.It is just another way for the justice/legal system to pressure families that have not been convicted / penalized under the supervision of a court.And this isn't the only lever they use.Every time I read crap like this I just think of Aaron Swartz. Social work for children systems in the USA are very messed up. It is not uncommon for minority families to lose rights to parent their children for very innocuous things that would not happen to a non-oppressed class.It is just another way for the justice/legal system to pressure families that have not been convicted / penalized under the supervision of a court.And this isn't the only lever they use.Every time I read crap like this I just think of Aaron Swartz. It is just another way for the justice/legal system to pressure families that have not been convicted / penalized under the supervision of a court.And this isn't the only lever they use.Every time I read crap like this I just think of Aaron Swartz. And this isn't the only lever they use.Every time I read crap like this I just think of Aaron Swartz. Depends on how much faith you have in the current administration. Russia limits presidents to two 6-year terms, yet Putin is in power since 2000. Only then he became President, which would make the end of his second term 2024. So the current one would be his third term (by the magic of changing the constitution and legal quibbles which effectively allow a president to stay in charge for four almost whole terms, AFAIU). Paris is properly sovereign.> people with strong support of the current governmentAlso known as leverage.Let Musk off the hook for a sweetheart trade deal. Trump has a track record of chickening out when others show strength. Trump has a track record of chickening out when others show strength. Also known as leverage.Let Musk off the hook for a sweetheart trade deal. Trump has a track record of chickening out when others show strength. Let Musk off the hook for a sweetheart trade deal. Trump has a track record of chickening out when others show strength. And it can independently exert effort in a way other European countries can't. Musk losing Paris means swearing off a meaningful economic and political bloc. At this point a nuclear power like France has no issue with using covert violence to produce compliance from Musk and he must know it.These people have proven themselves to be existential threats to French security and France will do whatever they feel is necessary to neutralize that threat.Musk is free to ignore French rule of law if he wants to risk being involved in an airplane accident that will have rumours and conspiracies swirling around it long after he's dead and his body is strewn all over the ocean somewhere. These people have proven themselves to be existential threats to French security and France will do whatever they feel is necessary to neutralize that threat.Musk is free to ignore French rule of law if he wants to risk being involved in an airplane accident that will have rumours and conspiracies swirling around it long after he's dead and his body is strewn all over the ocean somewhere. Musk is free to ignore French rule of law if he wants to risk being involved in an airplane accident that will have rumours and conspiracies swirling around it long after he's dead and his body is strewn all over the ocean somewhere. Seriously, every powerful state engages in state terrorism from time to time because they can, and the embarrassment of discovery is weighed against the benefit of eliminating a problem. It's just that the West has avoided to do that to each other because they were all essentially allied until recently and because the political implications were deemed too severe.I don't think however France has anything to win by doing it or has any interest whatsoever and I doubt there's a legal framework the French government can or want to exploit to conduct something like that legally (like calling something an emergency situation or a terrorist group, for example). I don't think however France has anything to win by doing it or has any interest whatsoever and I doubt there's a legal framework the French government can or want to exploit to conduct something like that legally (like calling something an emergency situation or a terrorist group, for example). Trump is ignoring all the international agreements and rules, so why should others follow them? The second Donald Trump threatened to invade a nation allied with France is the second anyone who works with Trump became a legitimate military target.Like a cruel child dismembering a spider one limb at a time France and other nations around the world will meticulously destroy whatever resources people like Musk have and the influence it gives him over their countries.If Musk displays a sufficient level of resistance to these actions the French will simply assassinate him. Like a cruel child dismembering a spider one limb at a time France and other nations around the world will meticulously destroy whatever resources people like Musk have and the influence it gives him over their countries.If Musk displays a sufficient level of resistance to these actions the French will simply assassinate him. If Musk displays a sufficient level of resistance to these actions the French will simply assassinate him. PS Yes, Greenpeace is a bunch of scientifically-illiterate fools who have caused far more damage than they prevented. Doesn't matter because what France did was still clearly against the law. Every major firm should have a "dawn raid" policy to comply while preserving rights.Specific to the Uber case(s), if it were illegal, then why didn't Uber get criminal charges or fines?At best there's an argument that it was "obstructing justice," but logging people off, encrypting, and deleting local copies isn't necessarily illegal. Specific to the Uber case(s), if it were illegal, then why didn't Uber get criminal charges or fines?At best there's an argument that it was "obstructing justice," but logging people off, encrypting, and deleting local copies isn't necessarily illegal. At best there's an argument that it was "obstructing justice," but logging people off, encrypting, and deleting local copies isn't necessarily illegal. Prosecution became hard to continue once he got involved. Prosecutors even drop winnable cases because they don't want to lose. Put this up there with nonsensical phrases like "violent agreement. I don't see aggressive compliance defined anywhere. They will explain that it was done remotely and whatnot but then the company will be closed in the country. Whether this matters for the mothership is another story. This was a common action during the Russian invasion of Ukraine for companies that supported Ukraine and closed their operations in Russia. Obviously, the government can just threaten to fine you any amount, close operations or whatever, but your company can just decide to stop operating there, like Google after Russia imposed an absurd fine. As France discovered the hard way in WW2, you can put all sorts of rock-solid security around the front door only to be surprised when your opponent comes in by window. This would be done in parallel for key sources.There is a lot of information on physical devices that is helpful, though. Even discovering additional apps and services used on the devices can lead to more discovery via those cloud services, if relevant.Physical devices have a lot of additional information, though: Files people are actively working on, saved snippets and screenshots of important conversations, and synced data that might be easier to get offline than through legal means against the providers.In outright criminal cases it's not uncommon for individuals to keep extra information on their laptop, phone, or a USB drive hidden in their office as an insurance policy.This is yet another good reason to keep your work and personal devices separate, as hard as that can be at times. Even discovering additional apps and services used on the devices can lead to more discovery via those cloud services, if relevant.Physical devices have a lot of additional information, though: Files people are actively working on, saved snippets and screenshots of important conversations, and synced data that might be easier to get offline than through legal means against the providers.In outright criminal cases it's not uncommon for individuals to keep extra information on their laptop, phone, or a USB drive hidden in their office as an insurance policy.This is yet another good reason to keep your work and personal devices separate, as hard as that can be at times. Physical devices have a lot of additional information, though: Files people are actively working on, saved snippets and screenshots of important conversations, and synced data that might be easier to get offline than through legal means against the providers.In outright criminal cases it's not uncommon for individuals to keep extra information on their laptop, phone, or a USB drive hidden in their office as an insurance policy.This is yet another good reason to keep your work and personal devices separate, as hard as that can be at times. In outright criminal cases it's not uncommon for individuals to keep extra information on their laptop, phone, or a USB drive hidden in their office as an insurance policy.This is yet another good reason to keep your work and personal devices separate, as hard as that can be at times. This is yet another good reason to keep your work and personal devices separate, as hard as that can be at times. I assume that they have opened a formal investigation and are now going to the office to collect/perloin evidence before it's destroyed.Most FAANG companies have training specifically for this. Most FAANG companies have training specifically for this. '‚Äùhttps://storage.courtlistener.com/recap/gov.uscourts.cand.37...VW is another case where similar things happens:https://www.bloomberg.com/news/articles/2017-01-12/vw-offici...The thing is: Companies don't got to jail, employees do. https://storage.courtlistener.com/recap/gov.uscourts.cand.37...VW is another case where similar things happens:https://www.bloomberg.com/news/articles/2017-01-12/vw-offici...The thing is: Companies don't got to jail, employees do. VW is another case where similar things happens:https://www.bloomberg.com/news/articles/2017-01-12/vw-offici...The thing is: Companies don't got to jail, employees do. I didn't work anywhere near the level, or anything thats dicey where I needed to have a "oh shit delete everything the Feds are here" plan. Prosecution must present a valid search warrant for *specific* information. They don't get a carte blanche, so uber way is correct. lock computers and lets the courts to decide. In the civil code, its quite possibly different. mine had a scene where some bro tried to organise the resistance. A voice over told us that he was arrested for blocking a legal investigation and was liable for being fired due to reputational damage.X's training might be like you described, but everywhere else that is vaguely beholden to law and order would be opposite. X's training might be like you described, but everywhere else that is vaguely beholden to law and order would be opposite. I don't love heavy-handed enforcement on speech issues, but I do really like a heterogenous cultural situation, so I think it's interesting and probably to the overall good to have a country pushing on these matters very hard, just as a matter of keeping a diverse set of global standards, something that adds cultural resilience for humanity.linkedin is not a replacement for twitter, though. linkedin is not a replacement for twitter, though. Censorship increases homogeneity, because it reduces the amount of ideas and opinions that are allowed to be expressed. Humanity itself is trending more toward monoculture socially; I like a lot of things (and hate some) about the cultural trend. But what I like isn't very important, because I might be totally wrong in my likes; if only my likes dominated, the world would be a much less resilient place -- vulnerable to the weaknesses of whatever it is I like.So, again, I propose for the race as a whole, broad cultural diversity is really critical, and worth protecting. Even if we really hate some of the forms it takes. So, again, I propose for the race as a whole, broad cultural diversity is really critical, and worth protecting. Even if we really hate some of the forms it takes. Otherwise, anyone can justify that cutting the head of their neighbour with a katana while dancing is part of an artistic performance, and absolute free speech is only possible if all artistic expression is given complete license. Those who pretend otherwise will have no ground to defend themselves on legal basis from being wiped out of existence by the very same logic. Libel must be as assertion that is not true. Photoshopping or AIing someone isn't an assertion of something untrue. It's more the equivalent of saying "What if this is true?" (a) in words legibly marked on any substance; or It doesn't have to be an assertion, or even a written statement. In the US it varies by state but generally requires:A false statement of fact (not opinion, hyperbole, or pure insinuation without a provably false factual core).Publication to a third party.FaultHarm to reputation----In the US it is required that it is written (or in a fixed form). Publication to a third party.FaultHarm to reputation----In the US it is required that it is written (or in a fixed form). Durov was held on suspicion Telegram was willingly failing to moderate its platform and allowed drug trafficking and other illegal activities to take place.X has allegedly illegally sent data to the US in violation of GDPR and contributed to child porn distribution.Note that both are directly related to direct violation of data safety law or association with a separate criminal activities, neither is about speech. X has allegedly illegally sent data to the US in violation of GDPR and contributed to child porn distribution.Note that both are directly related to direct violation of data safety law or association with a separate criminal activities, neither is about speech. Note that both are directly related to direct violation of data safety law or association with a separate criminal activities, neither is about speech. I didn't follow the case enough to know where they went, or what the judge thought was credible.From a US mindset, I'd say that generation of communication, including images, would fall under speech. But then we classify it very broadly here. Heck, I've been told by FBI agents that they believe assassination markets are legal in the US - protected speech.Obviously, assassinations themselves, not so much. From a US mindset, I'd say that generation of communication, including images, would fall under speech. But then we classify it very broadly here. Heck, I've been told by FBI agents that they believe assassination markets are legal in the US - protected speech.Obviously, assassinations themselves, not so much. Not sure what you mean by "assassination markets" exactly, but "Solicitation to commit a crime of violence" and "Conspiracy to murder" are definitely crimes. Durov wasn't arrested because of things he said or things that were said on his platform, he was arrested because he refused to cooperate in criminal investigations while he allegedly knew they were happening on a platform he manages.If you own a bar, you know people are dealing drugs in the backroom and you refuse to assist the police, you are guilty of aiding and abetting. There's someone who was being held responsible for what was in encrypted chats.Then there's someone who published depictions of sexual abuse and minors.Worlds apart. Then there's someone who published depictions of sexual abuse and minors.Worlds apart. Their platform had a reputation of being safe for crime, which is because they just... ignored the police. They still turn a blind eye but not to the police. Anyway cut to the chase, I just checked out Mathew Greens post on the subject, he is on my list of default "trust what he says about cryptography" along with some others like djb, nadia henninger etcEmbarrased to say I did not realise, I should of known! 10+ years ago I used to lurk the IRC dev chans of every relevant cypherpunk project, including of text secure and otr-chat when I saw signal being made and before that was witnessing chats with devs and ian goldberg and stuff, I just assumed Telegram was multiparty OTR,OOPS!Long winded post because that is embarrassing (as someone who studied cryptography undergrad in 2009 mathematics, 2010 did postgrad wargames and computer security course and worse - whose word once about 2012-2013 was taken on these matters by activists, journalists, researchers with pretty knarly threat model - like for instance - some guardian stories and former researcher into torture - i'm also the person that wrote the bits of 'how to hold a crypto party' that made it a protocol without an organisation and made clear the threat model was anyone could be there, oops oops oopsYes thanks for letting me know I hang my head in shame for missing that one or some how believing that one without much investigation, thankfully it was just my own personal use to contact like friend in the states where they aren't already on signal etc.EVERYONE: DON'T TRUST TELEGRAM AS END TO END ENCRYPTED CHAT https://blog.cryptographyengineering.com/2024/08/25/telegram...Anyway as they say "use it or lose it" yeah my assumptions here no longer valid or considered to have educated opinion if I got something that basic wrong. 10+ years ago I used to lurk the IRC dev chans of every relevant cypherpunk project, including of text secure and otr-chat when I saw signal being made and before that was witnessing chats with devs and ian goldberg and stuff, I just assumed Telegram was multiparty OTR,OOPS!Long winded post because that is embarrassing (as someone who studied cryptography undergrad in 2009 mathematics, 2010 did postgrad wargames and computer security course and worse - whose word once about 2012-2013 was taken on these matters by activists, journalists, researchers with pretty knarly threat model - like for instance - some guardian stories and former researcher into torture - i'm also the person that wrote the bits of 'how to hold a crypto party' that made it a protocol without an organisation and made clear the threat model was anyone could be there, oops oops oopsYes thanks for letting me know I hang my head in shame for missing that one or some how believing that one without much investigation, thankfully it was just my own personal use to contact like friend in the states where they aren't already on signal etc.EVERYONE: DON'T TRUST TELEGRAM AS END TO END ENCRYPTED CHAT https://blog.cryptographyengineering.com/2024/08/25/telegram...Anyway as they say "use it or lose it" yeah my assumptions here no longer valid or considered to have educated opinion if I got something that basic wrong. OOPS!Long winded post because that is embarrassing (as someone who studied cryptography undergrad in 2009 mathematics, 2010 did postgrad wargames and computer security course and worse - whose word once about 2012-2013 was taken on these matters by activists, journalists, researchers with pretty knarly threat model - like for instance - some guardian stories and former researcher into torture - i'm also the person that wrote the bits of 'how to hold a crypto party' that made it a protocol without an organisation and made clear the threat model was anyone could be there, oops oops oopsYes thanks for letting me know I hang my head in shame for missing that one or some how believing that one without much investigation, thankfully it was just my own personal use to contact like friend in the states where they aren't already on signal etc.EVERYONE: DON'T TRUST TELEGRAM AS END TO END ENCRYPTED CHAT https://blog.cryptographyengineering.com/2024/08/25/telegram...Anyway as they say "use it or lose it" yeah my assumptions here no longer valid or considered to have educated opinion if I got something that basic wrong. Long winded post because that is embarrassing (as someone who studied cryptography undergrad in 2009 mathematics, 2010 did postgrad wargames and computer security course and worse - whose word once about 2012-2013 was taken on these matters by activists, journalists, researchers with pretty knarly threat model - like for instance - some guardian stories and former researcher into torture - i'm also the person that wrote the bits of 'how to hold a crypto party' that made it a protocol without an organisation and made clear the threat model was anyone could be there, oops oops oopsYes thanks for letting me know I hang my head in shame for missing that one or some how believing that one without much investigation, thankfully it was just my own personal use to contact like friend in the states where they aren't already on signal etc.EVERYONE: DON'T TRUST TELEGRAM AS END TO END ENCRYPTED CHAT https://blog.cryptographyengineering.com/2024/08/25/telegram...Anyway as they say "use it or lose it" yeah my assumptions here no longer valid or considered to have educated opinion if I got something that basic wrong. Yes thanks for letting me know I hang my head in shame for missing that one or some how believing that one without much investigation, thankfully it was just my own personal use to contact like friend in the states where they aren't already on signal etc.EVERYONE: DON'T TRUST TELEGRAM AS END TO END ENCRYPTED CHAT https://blog.cryptographyengineering.com/2024/08/25/telegram...Anyway as they say "use it or lose it" yeah my assumptions here no longer valid or considered to have educated opinion if I got something that basic wrong. EVERYONE: DON'T TRUST TELEGRAM AS END TO END ENCRYPTED CHAT https://blog.cryptographyengineering.com/2024/08/25/telegram...Anyway as they say "use it or lose it" yeah my assumptions here no longer valid or considered to have educated opinion if I got something that basic wrong. Anyway as they say "use it or lose it" yeah my assumptions here no longer valid or considered to have educated opinion if I got something that basic wrong. What day/night will be the wildest party on your island?‚Äù Musk replied, in an apparent reference to his former wife Talulah Riley.https://www.theguardian.com/technology/2026/jan/30/elon-musk...I think there's just as much evidence Clinton did as Musk. Elon didn't ask to go, he was invited multiple times Why isn't that a major red flag exactly? It's a statement that could be taken to favor xenophobia and isolationism. Same should apply to social media.I literally don't care if it puts them out of business because the moderation would be too severe. I literally don't care if it puts them out of business because the moderation would be too severe. (it'll be interesting to see if this discussion is allowed on HN. Almost every other discussion on this topic has been flagged‚Ä¶) As mentioned in the article, the UK's ICO and the EC are also investigating.France is notably keen on raids for this sort of thing, and a lot of things that would be basically a desk investigation in other countries result in a raid in France. France is notably keen on raids for this sort of thing, and a lot of things that would be basically a desk investigation in other countries result in a raid in France. When notified, he immediately:  * "implemented technological measures to prevent the Grok account from allowing the editing of images of real people in revealing clothing" - https://www.bbc.co.uk/news/articles/ce8gz8g2qnlo * locked image generation down to paid accounts only (i.e. those individuals that can be identified via their payment details). They were also allowing users to undress real people, but it seems the media is ignoring that and focussing their ire only on Musk's companies... * "implemented technological measures to prevent the Grok account from allowing the editing of images of real people in revealing clothing" - https://www.bbc.co.uk/news/articles/ce8gz8g2qnlo * locked image generation down to paid accounts only (i.e. those individuals that can be identified via their payment details). They were also allowing users to undress real people, but it seems the media is ignoring that and focussing their ire only on Musk's companies... https://www.bbc.com/news/articles/c98p1r4e6m8o> Have the other AI companies followed suit? There were numerous examples of people feeding the same prompts to different AIs and having their requests refused. There were numerous examples of people feeding the same prompts to different AIs and having their requests refused. There were numerous examples of people feeding the same prompts to different AIs and having their requests refused. Near zero.Making/distributing a photo of a non-consenting bikini-wearer is no more illegal when originated by computer in bedroom than done by camera on public beach. Making/distributing a photo of a non-consenting bikini-wearer is no more illegal when originated by computer in bedroom than done by camera on public beach. This is a pretty pragmatic move by Musk.It's basically a honey trap, the likes of which authorities legitimately use to catch criminals. It's basically a honey trap, the likes of which authorities legitimately use to catch criminals. "Study uncovers presence of CSAM in popular AI training dataset"https://www.theregister.com/2023/12/20/csam_laion_dataset/. People who have found exploits, just like other generative AI tool. If by raiding an office in France a bunch of US military secrets are found, it would suggest the company is not fit to have those kind of contracts. I mean, perhaps it's time to completely drop these US-owned, closed-source, algo-driven controversial platforms, and start treating the communication with the public that funds your existence in different terms. ... thereby driving up adoption far better than Twitter itself could. Big tech companies are breaking the laws left and right. There is currently a sort of identity crisis in the regulation. Big tech companies are breaking the laws left and right. I suppose the answer, if we're serious about it, is somewhat more nuanced.To begin, public administrations should not get to unilaterally define "the public interest" in their communication, nor should private platforms for that matter. Assuming we're still talking about a democracy, the decision-making should be democratically via a combination of law + rights + accountable institutions + public scrutiny, with implementation constraints that maximise reach, accessibility, auditability, and independence from private gatekeepers. Happy to get into further detail regarding the actual processes involved, if you're genuinely interested.That aside - there are two separate problems that often get conflated when we talk about these platforms:- one is reach: people are on Twitter, LinkedIn, Instagram, so publishing there increases distribution; public institutions should be interested in reaching as many citizens as possible with their comms;- the other one is dependency: if those become the primary or exclusive channels, the state's relationship with citizens becomes contingent on private moderation, ranking algorithms, account lockouts, paywalls, data extraction, and opaque rule changes. That is entirely and dangerously misaligned with democratic accountability.A potential middle position could be ti use commercial social platforms as secondary distribution instead of the authoritative channel, which in reality is often the case. Which is why some argue that they should be treated as public utilities since dominant communications infrastructure has quasi-public function (rest assured, I won't open that can of worms right now).Politics is messy in practice, as all balancing acts are - a normal price to pay for any democratic society, I'd say. We've already done a lot to balance these, for sure, but we're not there yet and it's a dynamic, developing field that presents new challenges. To begin, public administrations should not get to unilaterally define "the public interest" in their communication, nor should private platforms for that matter. Assuming we're still talking about a democracy, the decision-making should be democratically via a combination of law + rights + accountable institutions + public scrutiny, with implementation constraints that maximise reach, accessibility, auditability, and independence from private gatekeepers. Happy to get into further detail regarding the actual processes involved, if you're genuinely interested.That aside - there are two separate problems that often get conflated when we talk about these platforms:- one is reach: people are on Twitter, LinkedIn, Instagram, so publishing there increases distribution; public institutions should be interested in reaching as many citizens as possible with their comms;- the other one is dependency: if those become the primary or exclusive channels, the state's relationship with citizens becomes contingent on private moderation, ranking algorithms, account lockouts, paywalls, data extraction, and opaque rule changes. That is entirely and dangerously misaligned with democratic accountability.A potential middle position could be ti use commercial social platforms as secondary distribution instead of the authoritative channel, which in reality is often the case. Which is why some argue that they should be treated as public utilities since dominant communications infrastructure has quasi-public function (rest assured, I won't open that can of worms right now).Politics is messy in practice, as all balancing acts are - a normal price to pay for any democratic society, I'd say. We've already done a lot to balance these, for sure, but we're not there yet and it's a dynamic, developing field that presents new challenges. That aside - there are two separate problems that often get conflated when we talk about these platforms:- one is reach: people are on Twitter, LinkedIn, Instagram, so publishing there increases distribution; public institutions should be interested in reaching as many citizens as possible with their comms;- the other one is dependency: if those become the primary or exclusive channels, the state's relationship with citizens becomes contingent on private moderation, ranking algorithms, account lockouts, paywalls, data extraction, and opaque rule changes. That is entirely and dangerously misaligned with democratic accountability.A potential middle position could be ti use commercial social platforms as secondary distribution instead of the authoritative channel, which in reality is often the case. Which is why some argue that they should be treated as public utilities since dominant communications infrastructure has quasi-public function (rest assured, I won't open that can of worms right now).Politics is messy in practice, as all balancing acts are - a normal price to pay for any democratic society, I'd say. We've already done a lot to balance these, for sure, but we're not there yet and it's a dynamic, developing field that presents new challenges. - one is reach: people are on Twitter, LinkedIn, Instagram, so publishing there increases distribution; public institutions should be interested in reaching as many citizens as possible with their comms;- the other one is dependency: if those become the primary or exclusive channels, the state's relationship with citizens becomes contingent on private moderation, ranking algorithms, account lockouts, paywalls, data extraction, and opaque rule changes. That is entirely and dangerously misaligned with democratic accountability.A potential middle position could be ti use commercial social platforms as secondary distribution instead of the authoritative channel, which in reality is often the case. Which is why some argue that they should be treated as public utilities since dominant communications infrastructure has quasi-public function (rest assured, I won't open that can of worms right now).Politics is messy in practice, as all balancing acts are - a normal price to pay for any democratic society, I'd say. We've already done a lot to balance these, for sure, but we're not there yet and it's a dynamic, developing field that presents new challenges. - the other one is dependency: if those become the primary or exclusive channels, the state's relationship with citizens becomes contingent on private moderation, ranking algorithms, account lockouts, paywalls, data extraction, and opaque rule changes. That is entirely and dangerously misaligned with democratic accountability.A potential middle position could be ti use commercial social platforms as secondary distribution instead of the authoritative channel, which in reality is often the case. Which is why some argue that they should be treated as public utilities since dominant communications infrastructure has quasi-public function (rest assured, I won't open that can of worms right now).Politics is messy in practice, as all balancing acts are - a normal price to pay for any democratic society, I'd say. We've already done a lot to balance these, for sure, but we're not there yet and it's a dynamic, developing field that presents new challenges. A potential middle position could be ti use commercial social platforms as secondary distribution instead of the authoritative channel, which in reality is often the case. Which is why some argue that they should be treated as public utilities since dominant communications infrastructure has quasi-public function (rest assured, I won't open that can of worms right now).Politics is messy in practice, as all balancing acts are - a normal price to pay for any democratic society, I'd say. We've already done a lot to balance these, for sure, but we're not there yet and it's a dynamic, developing field that presents new challenges. Politics is messy in practice, as all balancing acts are - a normal price to pay for any democratic society, I'd say. We've already done a lot to balance these, for sure, but we're not there yet and it's a dynamic, developing field that presents new challenges. Mass media reports on anything widely relevant, niche media reports on things nichely relevant, and there's direct communication with anyone directly affected (recipient of a radio frequency allocation) so nobody really subscribes to the official government newspaper, but it's there and if there was a breakdown of communication systems that would be the last resort to ensure you are getting government updates. "Uh guys, little heads up: there are some agents of federal law enforcement raiding the premises, so if you see that. No abuse of a real minor is needed. Strange that there was no disagreement before "AI", right? Yet now we have a clutch of new "definitions" all of which dilute and weaken the meaning.> In Sweden for instance, CSAM is any image of an underage subject (real or realistic digital) designed to evoke a sexual response.No corroboration found on web. Quite the contrary, in fact:"Sweden does not have a legislative definition of child sexual abuse material (CSAM)"https://rm.coe.int/factsheet-sweden-the-protection-of-childr...> If you take a picture of a 14 year old girl (age of consent is 15) and use Grok to give her bikini, or make her topless, then you are most definately producing and possessing CSAM.> No abuse of a real minor is needed.Even the Google "AI" knows better than that. > In Sweden for instance, CSAM is any image of an underage subject (real or realistic digital) designed to evoke a sexual response.No corroboration found on web. Quite the contrary, in fact:"Sweden does not have a legislative definition of child sexual abuse material (CSAM)"https://rm.coe.int/factsheet-sweden-the-protection-of-childr...> If you take a picture of a 14 year old girl (age of consent is 15) and use Grok to give her bikini, or make her topless, then you are most definately producing and possessing CSAM.> No abuse of a real minor is needed.Even the Google "AI" knows better than that. Quite the contrary, in fact:"Sweden does not have a legislative definition of child sexual abuse material (CSAM)"https://rm.coe.int/factsheet-sweden-the-protection-of-childr...> If you take a picture of a 14 year old girl (age of consent is 15) and use Grok to give her bikini, or make her topless, then you are most definately producing and possessing CSAM.> No abuse of a real minor is needed.Even the Google "AI" knows better than that. "Sweden does not have a legislative definition of child sexual abuse material (CSAM)"https://rm.coe.int/factsheet-sweden-the-protection-of-childr...> If you take a picture of a 14 year old girl (age of consent is 15) and use Grok to give her bikini, or make her topless, then you are most definately producing and possessing CSAM.> No abuse of a real minor is needed.Even the Google "AI" knows better than that. https://rm.coe.int/factsheet-sweden-the-protection-of-childr...> If you take a picture of a 14 year old girl (age of consent is 15) and use Grok to give her bikini, or make her topless, then you are most definately producing and possessing CSAM.> No abuse of a real minor is needed.Even the Google "AI" knows better than that. > If you take a picture of a 14 year old girl (age of consent is 15) and use Grok to give her bikini, or make her topless, then you are most definately producing and possessing CSAM.> No abuse of a real minor is needed.Even the Google "AI" knows better than that. > No abuse of a real minor is needed.Even the Google "AI" knows better than that. Even the Google "AI" knows better than that. Or is it some USDefaultism where Americans assume their definition was universal? I used this interweb thing to fetch that document from Sweden, saving me a 1000-mile walk.> Why do you think the definition was clear across the world and not changed "before AI"?I didn't say it was clear. > Why do you think the definition was clear across the world and not changed "before AI"?I didn't say it was clear. I very doubt it, there is a disaggrement.But my guess about your post is, that an American has to learn again there is a world outside of the US with different rules and different languages. I very doubt it, there is a disaggrement.But my guess about your post is, that an American has to learn again there is a world outside of the US with different rules and different languages. I very doubt it, there is a disaggrement.But my guess about your post is, that an American has to learn again there is a world outside of the US with different rules and different languages. But my guess about your post is, that an American has to learn again there is a world outside of the US with different rules and different languages. I guess you didn't read the doc. It is in English.I too doubt there's material disagreement between judicial definitions. I too doubt there's material disagreement between judicial definitions. disseminates, transfers, provides, exhibits, or otherwise makes such an image of a child available to another person,3. acquires or offers such an image of a child,4. facilitates contacts between buyers and sellers of such images of children or takes any other similar measure intended to promote trade in such images, or5. possesses such an image of a child or views such an image to which he or she has gained accessshall be sentenced for a child pornography offense to imprisonment for at most two years.Then there's Proposition 2009/10:70, which is a clarifying document on how the law should be interpreted:https://www.riksdagen.se/sv/dokument-och-lagar/dokument/prop...Let me quote (translated):"To depict a child in a pornographic image entails the production of such an image of a child. An image can be produced in various ways, e.g., by photographing, filming, or drawing a real child. Through various techniques, more or less artificial images can also be created. For criminal liability, it is not required that the image depicts a real child; images of fictitious children are also covered. New productions can also be created by reproducing or manipulating already existing depictions, for example, by editing film sequences together in a different order or by splicing an image of a child's head onto an image of another child's body." disseminates, transfers, provides, exhibits, or otherwise makes such an image of a child available to another person,3. acquires or offers such an image of a child,4. facilitates contacts between buyers and sellers of such images of children or takes any other similar measure intended to promote trade in such images, or5. possesses such an image of a child or views such an image to which he or she has gained accessshall be sentenced for a child pornography offense to imprisonment for at most two years.Then there's Proposition 2009/10:70, which is a clarifying document on how the law should be interpreted:https://www.riksdagen.se/sv/dokument-och-lagar/dokument/prop...Let me quote (translated):"To depict a child in a pornographic image entails the production of such an image of a child. An image can be produced in various ways, e.g., by photographing, filming, or drawing a real child. Through various techniques, more or less artificial images can also be created. For criminal liability, it is not required that the image depicts a real child; images of fictitious children are also covered. New productions can also be created by reproducing or manipulating already existing depictions, for example, by editing film sequences together in a different order or by splicing an image of a child's head onto an image of another child's body." disseminates, transfers, provides, exhibits, or otherwise makes such an image of a child available to another person,3. acquires or offers such an image of a child,4. facilitates contacts between buyers and sellers of such images of children or takes any other similar measure intended to promote trade in such images, or5. possesses such an image of a child or views such an image to which he or she has gained accessshall be sentenced for a child pornography offense to imprisonment for at most two years.Then there's Proposition 2009/10:70, which is a clarifying document on how the law should be interpreted:https://www.riksdagen.se/sv/dokument-och-lagar/dokument/prop...Let me quote (translated):"To depict a child in a pornographic image entails the production of such an image of a child. An image can be produced in various ways, e.g., by photographing, filming, or drawing a real child. Through various techniques, more or less artificial images can also be created. For criminal liability, it is not required that the image depicts a real child; images of fictitious children are also covered. New productions can also be created by reproducing or manipulating already existing depictions, for example, by editing film sequences together in a different order or by splicing an image of a child's head onto an image of another child's body." 2. disseminates, transfers, provides, exhibits, or otherwise makes such an image of a child available to another person,3. acquires or offers such an image of a child,4. facilitates contacts between buyers and sellers of such images of children or takes any other similar measure intended to promote trade in such images, or5. possesses such an image of a child or views such an image to which he or she has gained accessshall be sentenced for a child pornography offense to imprisonment for at most two years.Then there's Proposition 2009/10:70, which is a clarifying document on how the law should be interpreted:https://www.riksdagen.se/sv/dokument-och-lagar/dokument/prop...Let me quote (translated):"To depict a child in a pornographic image entails the production of such an image of a child. An image can be produced in various ways, e.g., by photographing, filming, or drawing a real child. Through various techniques, more or less artificial images can also be created. For criminal liability, it is not required that the image depicts a real child; images of fictitious children are also covered. New productions can also be created by reproducing or manipulating already existing depictions, for example, by editing film sequences together in a different order or by splicing an image of a child's head onto an image of another child's body." 3. acquires or offers such an image of a child,4. facilitates contacts between buyers and sellers of such images of children or takes any other similar measure intended to promote trade in such images, or5. possesses such an image of a child or views such an image to which he or she has gained accessshall be sentenced for a child pornography offense to imprisonment for at most two years.Then there's Proposition 2009/10:70, which is a clarifying document on how the law should be interpreted:https://www.riksdagen.se/sv/dokument-och-lagar/dokument/prop...Let me quote (translated):"To depict a child in a pornographic image entails the production of such an image of a child. An image can be produced in various ways, e.g., by photographing, filming, or drawing a real child. Through various techniques, more or less artificial images can also be created. For criminal liability, it is not required that the image depicts a real child; images of fictitious children are also covered. New productions can also be created by reproducing or manipulating already existing depictions, for example, by editing film sequences together in a different order or by splicing an image of a child's head onto an image of another child's body." 4. facilitates contacts between buyers and sellers of such images of children or takes any other similar measure intended to promote trade in such images, or5. possesses such an image of a child or views such an image to which he or she has gained accessshall be sentenced for a child pornography offense to imprisonment for at most two years.Then there's Proposition 2009/10:70, which is a clarifying document on how the law should be interpreted:https://www.riksdagen.se/sv/dokument-och-lagar/dokument/prop...Let me quote (translated):"To depict a child in a pornographic image entails the production of such an image of a child. An image can be produced in various ways, e.g., by photographing, filming, or drawing a real child. Through various techniques, more or less artificial images can also be created. For criminal liability, it is not required that the image depicts a real child; images of fictitious children are also covered. New productions can also be created by reproducing or manipulating already existing depictions, for example, by editing film sequences together in a different order or by splicing an image of a child's head onto an image of another child's body." 5. possesses such an image of a child or views such an image to which he or she has gained accessshall be sentenced for a child pornography offense to imprisonment for at most two years.Then there's Proposition 2009/10:70, which is a clarifying document on how the law should be interpreted:https://www.riksdagen.se/sv/dokument-och-lagar/dokument/prop...Let me quote (translated):"To depict a child in a pornographic image entails the production of such an image of a child. An image can be produced in various ways, e.g., by photographing, filming, or drawing a real child. Through various techniques, more or less artificial images can also be created. For criminal liability, it is not required that the image depicts a real child; images of fictitious children are also covered. New productions can also be created by reproducing or manipulating already existing depictions, for example, by editing film sequences together in a different order or by splicing an image of a child's head onto an image of another child's body." An image can be produced in various ways, e.g., by photographing, filming, or drawing a real child. Through various techniques, more or less artificial images can also be created. For criminal liability, it is not required that the image depicts a real child; images of fictitious children are also covered. New productions can also be created by reproducing or manipulating already existing depictions, for example, by editing film sequences together in a different order or by splicing an image of a child's head onto an image of another child's body." An image can be produced in various ways, e.g., by photographing, filming, or drawing a real child. Through various techniques, more or less artificial images can also be created. For criminal liability, it is not required that the image depicts a real child; images of fictitious children are also covered. New productions can also be created by reproducing or manipulating already existing depictions, for example, by editing film sequences together in a different order or by splicing an image of a child's head onto an image of another child's body." An image can be produced in various ways, e.g., by photographing, filming, or drawing a real child. Through various techniques, more or less artificial images can also be created. For criminal liability, it is not required that the image depicts a real child; images of fictitious children are also covered. New productions can also be created by reproducing or manipulating already existing depictions, for example, by editing film sequences together in a different order or by splicing an image of a child's head onto an image of another child's body." An image can be produced in various ways, e.g., by photographing, filming, or drawing a real child. Through various techniques, more or less artificial images can also be created. For criminal liability, it is not required that the image depicts a real child; images of fictitious children are also covered. New productions can also be created by reproducing or manipulating already existing depictions, for example, by editing film sequences together in a different order or by splicing an image of a child's head onto an image of another child's body." An image can be produced in various ways, e.g., by photographing, filming, or drawing a real child. Through various techniques, more or less artificial images can also be created. For criminal liability, it is not required that the image depicts a real child; images of fictitious children are also covered. New productions can also be created by reproducing or manipulating already existing depictions, for example, by editing film sequences together in a different order or by splicing an image of a child's head onto an image of another child's body." https://eur-lex.europa.eu/eli/dir/2011/93/oj/engLet me quote again: Pay attention to c.iv specifically:(c) ‚Äòchild pornography' means:(i) any material that visually depicts a child engaged in real or simulated sexually explicit conduct;(ii) any depiction of the sexual organs of a child for primarily sexual purposes;(iii) any material that visually depicts any person appearing to be a child engaged in real or simulated sexually explicit conduct or any depiction of the sexual organs of any person appearing to be a child, for primarily sexual purposes; or(iv) realistic images of a child engaged in sexually explicit conduct or realistic images of the sexual organs of a child, for primarily sexual purposes; Let me quote again: Pay attention to c.iv specifically:(c) ‚Äòchild pornography' means:(i) any material that visually depicts a child engaged in real or simulated sexually explicit conduct;(ii) any depiction of the sexual organs of a child for primarily sexual purposes;(iii) any material that visually depicts any person appearing to be a child engaged in real or simulated sexually explicit conduct or any depiction of the sexual organs of any person appearing to be a child, for primarily sexual purposes; or(iv) realistic images of a child engaged in sexually explicit conduct or realistic images of the sexual organs of a child, for primarily sexual purposes; (c) ‚Äòchild pornography' means:(i) any material that visually depicts a child engaged in real or simulated sexually explicit conduct;(ii) any depiction of the sexual organs of a child for primarily sexual purposes;(iii) any material that visually depicts any person appearing to be a child engaged in real or simulated sexually explicit conduct or any depiction of the sexual organs of any person appearing to be a child, for primarily sexual purposes; or(iv) realistic images of a child engaged in sexually explicit conduct or realistic images of the sexual organs of a child, for primarily sexual purposes; (i) any material that visually depicts a child engaged in real or simulated sexually explicit conduct;(ii) any depiction of the sexual organs of a child for primarily sexual purposes;(iii) any material that visually depicts any person appearing to be a child engaged in real or simulated sexually explicit conduct or any depiction of the sexual organs of any person appearing to be a child, for primarily sexual purposes; or(iv) realistic images of a child engaged in sexually explicit conduct or realistic images of the sexual organs of a child, for primarily sexual purposes; (ii) any depiction of the sexual organs of a child for primarily sexual purposes;(iii) any material that visually depicts any person appearing to be a child engaged in real or simulated sexually explicit conduct or any depiction of the sexual organs of any person appearing to be a child, for primarily sexual purposes; or(iv) realistic images of a child engaged in sexually explicit conduct or realistic images of the sexual organs of a child, for primarily sexual purposes; (iii) any material that visually depicts any person appearing to be a child engaged in real or simulated sexually explicit conduct or any depiction of the sexual organs of any person appearing to be a child, for primarily sexual purposes; or(iv) realistic images of a child engaged in sexually explicit conduct or realistic images of the sexual organs of a child, for primarily sexual purposes; realistic images of a child engaged in sexually explicit conduct or realistic images of the sexual organs of a child, for primarily sexual purposes;covers the example in question:If you take a picture of a 14 year old girl (age of consent is 15) and use Grok to give her bikini, or make her topless, then you are most definately producing and possessing CSAM.How about you? covers the example in question:If you take a picture of a 14 year old girl (age of consent is 15) and use Grok to give her bikini, or make her topless, then you are most definately producing and possessing CSAM.How about you? If you take a picture of a 14 year old girl (age of consent is 15) and use Grok to give her bikini, or make her topless, then you are most definately producing and possessing CSAM.How about you? Your one doesn't contain the purported Swedish CSAM definition, or any for that matter. CSAM, which can get you life, at least here in UK. Please don't use the "knowledge" of LLMs as evidence or support for anything. Generative models generate things that have some likelihood of being consistent with their input material, they don't "know" things.Just last night, I did a Google search related to the cell tower recently constructed next to our local fire house. Just last night, I did a Google search related to the cell tower recently constructed next to our local fire house. Does this support the idea that "some physical cell towers are located on Facebook pages"? It has been since at least 2012 here in Sweden. That case went to our highest court and they decided a manga drawing was CSAM (maybe you are hung up on this term though, it is obviously not the same in Swedish).The holder was not convicted but that is besides the point about the material. genom speciella kameraarrangemang framst√§lls p√• ett s√§tt som √§r √§gnat att v√§dja till sexualdriften, utan att det avbildade barnet kan s√§gas ha deltagit i ett sexuellt beteende vid avbildningen, kan omfattas av best√§mmelsen.Which translated means that the children does not have to be apart of sexual acts and indeed undressing a child using AI could be CSAM.I say "could" because all laws are open to interpretation in Sweden and it depends on the specific image. genom speciella kameraarrangemang framst√§lls p√• ett s√§tt som √§r √§gnat att v√§dja till sexualdriften, utan att det avbildade barnet kan s√§gas ha deltagit i ett sexuellt beteende vid avbildningen, kan omfattas av best√§mmelsen.Which translated means that the children does not have to be apart of sexual acts and indeed undressing a child using AI could be CSAM.I say "could" because all laws are open to interpretation in Sweden and it depends on the specific image. Which translated means that the children does not have to be apart of sexual acts and indeed undressing a child using AI could be CSAM.I say "could" because all laws are open to interpretation in Sweden and it depends on the specific image. I say "could" because all laws are open to interpretation in Sweden and it depends on the specific image. CSAM goes up to life, at least here in UK. Quite a difference.> But it's safe to say that many images produces by Grok are CSAM by Swedish standards.So the Govt/police would have acted against Grok, right? > But it's safe to say that many images produces by Grok are CSAM by Swedish standards.So the Govt/police would have acted against Grok, right? So the Govt/police would have acted against Grok, right? It came from the Court of Europe doc I linked to. Feel free to let them know its wrong. I am saying just it is not CSAM.> You should realize that children have committed suicide before because AI deepfakes of themselves have been spread around schools.Its terrible. And when "AI"s are found spreading deepfakes around schools, do let us know. And when "AI"s are found spreading deepfakes around schools, do let us know. And when "AI"s are found spreading deepfakes around schools, do let us know. When you undress a child with AI, especially publicly on Twitter or privately through DM, that child is abused using the material the AI generated. I guess you mean pasting a naked body on a photo of a child.> especially publicly on Twitter or privately through DM, that child is abused using the material the AI generated.In which country is that?Here in UK, I've never heard of anyone jailed for doing that. Whereas many are for making actual child sexual abuse material. > especially publicly on Twitter or privately through DM, that child is abused using the material the AI generated.In which country is that?Here in UK, I've never heard of anyone jailed for doing that. Whereas many are for making actual child sexual abuse material. Whereas many are for making actual child sexual abuse material. Here in UK, I've never heard of anyone jailed for doing that. Whereas many are for making actual child sexual abuse material. Musk's social media platform has recently been subject to intense scrutiny over sexualised images generated and edited on the site using its AI tool Grok. Here you have a model that is actually creating the CSAM.It seems more similar to a robot that is told to go kill someone and does so. if the knife was designed to evade detection, then yes. Like how I see this is:* If you can't restrict people from making kiddie porn with Grok, then it stands to reason at the very least, access to Grok needs to be strictly controlled. It can't be completely omitted from this conversation that Grok is, pretty famously, the "unrestrained" AI, which in most respects means it swears more, quotes and uses highly dubious sources of information that are friendly to Musk's personal politics, and occasionally spouts white nationalist rhetoric. So as part of their quest to "unwoke" Grok did they also make it able to generate this shit too? It can't be completely omitted from this conversation that Grok is, pretty famously, the "unrestrained" AI, which in most respects means it swears more, quotes and uses highly dubious sources of information that are friendly to Musk's personal politics, and occasionally spouts white nationalist rhetoric. So as part of their quest to "unwoke" Grok did they also make it able to generate this shit too? It can't be completely omitted from this conversation that Grok is, pretty famously, the "unrestrained" AI, which in most respects means it swears more, quotes and uses highly dubious sources of information that are friendly to Musk's personal politics, and occasionally spouts white nationalist rhetoric. So as part of their quest to "unwoke" Grok did they also make it able to generate this shit too? There's nothing special about Grok in this regard. I'm just pointing out the fact that the only special thing about Grok is that it's both relatively uncensored and easily available to a mainstream audience. [1] -- see the Uncensored General Intelligence leaderboard where Grok is currently #1: https://huggingface.co/spaces/DontPlanToEnd/UGI-Leaderboard I'm just pointing out the fact that the only special thing about Grok is that it's both relatively uncensored and easily available to a mainstream audience. [1] -- see the Uncensored General Intelligence leaderboard where Grok is currently #1: https://huggingface.co/spaces/DontPlanToEnd/UGI-Leaderboard [1] -- see the Uncensored General Intelligence leaderboard where Grok is currently #1: https://huggingface.co/spaces/DontPlanToEnd/UGI-Leaderboard You can make child pornography with any video-editing software. I'm just stating a fact that Grok isn't unique here, and if you want to ban Grok because of it then you need to also ban open weight models which can do exactly the same thing. I'm just stating a fact that Grok isn't unique here, and if you want to ban Grok because of it then you need to also ban open weight models which can do exactly the same thing. And the article is talking about a social media site. A different class of software and company.> if you want to ban GrokStraw man. I'm not seeing that in the French-language press. Meanwhile what I commonly see is people dunking on anything Musk-related because they dislike him, but give a free pass on similar things if it's not related to him. Additionally, the system should have a way to tell if someone is attempting to bypass their safety measures and act accordingly. "The point is to show just how aware X were of the issue, and that they chose to repeatedly do nothing against Grok being used to create CSAM and probably other problematic and illegal imagery.I can't really doubt they'll find plenty of evidence during discovery, it doesn't have to be physical things. The raid stops office activity immediately, and marks the point in time after which they can be accused of destroying evidence if they erase relevant information to hide internal comms. The point is to show just how aware X were of the issue, and that they chose to repeatedly do nothing against Grok being used to create CSAM and probably other problematic and illegal imagery.I can't really doubt they'll find plenty of evidence during discovery, it doesn't have to be physical things. The raid stops office activity immediately, and marks the point in time after which they can be accused of destroying evidence if they erase relevant information to hide internal comms. I can't really doubt they'll find plenty of evidence during discovery, it doesn't have to be physical things. The raid stops office activity immediately, and marks the point in time after which they can be accused of destroying evidence if they erase relevant information to hide internal comms. The fact that users have found ways to hack around this is not evidence of X committing a crime.https://github.com/xai-org/grok-prompts/blob/main/grok_4_saf... If every AI system can do this, and every AI system in incapable of preventing it, then I guess every AI system should be banned until they can figure it out.Every banking app on the planet "is capable" of letting a complete stranger go into your account and transfer all your money to their account. Did we force banks to put restrictions in place to prevent that from happening, or did we throw our arms up and say: oh well the French Government just wants to pick on banks? Every banking app on the planet "is capable" of letting a complete stranger go into your account and transfer all your money to their account. Did we force banks to put restrictions in place to prevent that from happening, or did we throw our arms up and say: oh well the French Government just wants to pick on banks? On a related note given AI is just a tool and requires someone to tell it to make CSAM I think they will have to prove intent possibly by grabbing chat logs, emails and other internal communications but I know very little about French law or international law. I think your interpretation would be more along the line of making 1984, Brave New World, Fahrenheit 451 and The Handmaid's Tale a reality. I will have to check that out, it sounds interesting. It was also pretty obvious how all the social media companies pushed the same narrative through COVID.I don't like how these social networks and the media try to manipulate things but I don't think giving the government even more power will fix anything. I think even if you had those laws on the books, you would still get manipulation through selective enforcement.I think the only solution is education and individuals saying no to these platforms' and their algorithmic feeds. I think we are already seeing a growing movement towards people either not using social media or using it way less than they did previously. It is a much better experience than the "for you" tab I don't like how these social networks and the media try to manipulate things but I don't think giving the government even more power will fix anything. I think even if you had those laws on the books, you would still get manipulation through selective enforcement.I think the only solution is education and individuals saying no to these platforms' and their algorithmic feeds. I think we are already seeing a growing movement towards people either not using social media or using it way less than they did previously. It is a much better experience than the "for you" tab I think we are already seeing a growing movement towards people either not using social media or using it way less than they did previously. It is a much better experience than the "for you" tab And how is that different from TV channels/media en large having laws to abide by? No, i am not saying that it is the same. I am saying that it would start as "We are just going after the tech companies" but if you give the government an inch they will take a mile. They would take that and expand upon the hate speech stuff you are already see around the world as an excuse to arrest whoever they wanted.I am a free market person, so i think these sites are providing something to the market that people like or they wouldn't be there. I am a free market person, so i think these sites are providing something to the market that people like or they wouldn't be there. Otherwise it's a running competition where Meta/X just shoot every other competitor at the start and drive to the goal with a car. This has been known by Adam Smith already - you can't be a "free market person" while being happy with these giga-corporations trampling on laws left and right. In Germany, support for Palestine is considered hate speech since it's antisemitic. - when the left does it, it's just them using their civil liberties- when the right does it, its illegal manipulation, election interference, fascism and/or Russian disinformation.It's the same crowd which keeps using the phrase ‚Äúour democracy‚Äù.Behaviour like this really makes me wonder who they are, and who they deem not worthy to be included in ‚Äútheir‚Äù democracy. - when the right does it, its illegal manipulation, election interference, fascism and/or Russian disinformation.It's the same crowd which keeps using the phrase ‚Äúour democracy‚Äù.Behaviour like this really makes me wonder who they are, and who they deem not worthy to be included in ‚Äútheir‚Äù democracy. It's the same crowd which keeps using the phrase ‚Äúour democracy‚Äù.Behaviour like this really makes me wonder who they are, and who they deem not worthy to be included in ‚Äútheir‚Äù democracy. Behaviour like this really makes me wonder who they are, and who they deem not worthy to be included in ‚Äútheir‚Äù democracy. >French authorities opened their investigation after reports from a French lawmaker alleging that biased algorithms on X likely distorted the functioning of an automated data processing system. It expanded after Grok generated posts that allegedly denied the Holocaust, a crime in France, and spread sexually explicit deepfakes, the statement said. and fraudulent data extraction by an organised group. Looking at the prompts below some of those image shows that even now, there's almost zero effort at Grok to filter prompts that are blatantly looking to create problematic material. The French raid statement makes no mention of CSAM. To me too.> CSAM is a woker word for child porn.Indeed some people would like it diluted thus. But it generally remains (an initialism not word) for something quite distinct - about abuse rather than just porn. > CSAM is a woker word for child porn.Indeed some people would like it diluted thus. But it generally remains (an initialism not word) for something quite distinct - about abuse rather than just porn. Indeed some people would like it diluted thus. But it generally remains (an initialism not word) for something quite distinct - about abuse rather than just porn. I was under the impression we were allies since like the 1800s or so despite some little tiffs now and again. The closest I can think of is GDPR which has its great aspects and also the cookies law (which is incorrectly interpreted). And some things like private IPs being PIIs which promotes nonsnsical "authorities notifications" that are not used afterwards.We have consulting companies doing yearly audits on companies to close the books. But whatever zombie government France is running can't "ban" X anyway because it would get them one step closer to the guillotine. If "French prosecutor" want to find a child abuse case they can check the Macron couple Wikipedia pages. By itself this isn't extraordinary in a democracy. I cross-checked Wikipedia's information with another source: https://www.connexionfrance.com/news/french-election-is-it-c... I don't think the Wikipedia characterization is far off a pretty commonly held sentiment. You are of course, able to disagree and consider them far-left, center, or whatever label you want.You stated earlier that because Wikipedia called mild immigration reform far-right (which it did not to my reading, so you pointed to National Rally as an example) words don't mean anything. But words do mean things by consensus, and from my reading the consensus is that National Rally is far-right.Of course, many far-right (and far-left) thinkers consider themselves centrists or mild, so there will be disagreement. You stated earlier that because Wikipedia called mild immigration reform far-right (which it did not to my reading, so you pointed to National Rally as an example) words don't mean anything. But words do mean things by consensus, and from my reading the consensus is that National Rally is far-right.Of course, many far-right (and far-left) thinkers consider themselves centrists or mild, so there will be disagreement. Of course, many far-right (and far-left) thinkers consider themselves centrists or mild, so there will be disagreement. But there's also an obvious semantic fail when 34% of the electorate is "far right". It implies that "far" is just meaningless cant. Elections aren't won by 50%, you only need to convince 4 or 5% of the population that the far right is great. There is a reason Musk paid so much for Twitter. If this stuff had no effect he wouldn't have bought it. There either needs to be accountability for platforms or a ban on behavior driven content feeds.People lying on the internet is fine. Social media algorithms amplifying the lie because it has high engagement is destroying our society. Social media algorithms amplifying the lie because it has high engagement is destroying our society. By exposing people to a flood of misinformation and politically radicalizing content designed to maximize engagement via emotion (usually anger).Remember when Elon Musk alleged that he was going to find a trillion dollars (a year) in waste fraud and abuse with DOGE? Did he ever issue a correction on that statement after catastrophically failing to do so? Do you think that kind of messaging might damage the trust in our institutions? Remember when Elon Musk alleged that he was going to find a trillion dollars (a year) in waste fraud and abuse with DOGE? Did he ever issue a correction on that statement after catastrophically failing to do so? Do you think that kind of messaging might damage the trust in our institutions? To be 'fair', finding fraud never was the real purpose of DOGE, just some fake argument that enough citizen would find plausible. How true is this really?We certainly have data points to show Musk has put his thumb on the scale We certainly have data points to show Musk has put his thumb on the scale I haven't dug into whatever they open sourced about the algorithm to make definitive statements. Comprehensive evidence and analysis is a search or chat bot away. Near right to me is advocating for things like lower taxes or different regulations or a secure border (but without the deportation of millions who are already in the country and abiding by laws). * Crypto currency rug pulls (World Liberty Financial) * Donations linked with pardons (Binance) * Pardoning failed rebels of a coup that favored him (Capitol rioters) * Bringing baseless charges against political enemies and journalists (Comey, Letitia James, Don Lemon) * Musk (DOGE) killing government regulatory agencies that had investigations and cases against his companies This is with two minutes of thought while waiting for a compile. It helps you see the actually interesting point being made. My point still stands, "politics change and assessments of politicians change accordingly".Bill Clinton's crime bill would be considered far right today.Ronald Regean's amnesty bill would be considered far left today. Ronald Regean's amnesty bill would be considered far left today. Ask anyone who was politically active (as a leftist) in the 90s. I'm not sure what was the equivalent of the Democratic Socialists of America (center-left) at that time, but i'm sure there was an equivalent and Bill Clinton was much more right-wing. That's without mentioning actual left-wing parties (like communists, anarchists, black panthers etc). He raised taxes, lowered military spending, and pursued universal healthcare. Those are not, and have never been, right-wing stances in the US. For example, universal health-care is only left-wing if it's a public service. Taking money out of the State's pockets to finance private healthcare and pharmaceutical for-profit corporations is very much a definition of right-wing policy. Lowering military spending by aggressively shrinking active duty troop levels and eliminating weapons programs is certainly left-wing. I don't think many self-described "right-leaning" people would have called Clinton "right wing" in the 90s.I 100% see your point and agree with you that he had major policies that I would call right wing today. I 100% see your point and agree with you that he had major policies that I would call right wing today. As much as it pains me to say this, because i myself consider de Gaulle to be a fascist in many regards, that's far from a majority opinion (disclaimer: i'm an anarchist).I think de Gaulle was a classic right-wing authoritarian ruler. He had to take some social measures (which some may view as left-wing) because the workers at the end of WWII were very organized and had dozens of thousands of rifles, so such was the price of social peace.He was right-wing because he was rather conservative, for private property/entrepreneurship and strongly anti-communist. Still, he had strong national planning for the economy, much State support for private industry (Elf, Areva, etc) and strong policing on the streets (see also, Service d'Action Civique for de Gaulle's fascist militias with long ties with historical nazism and secret services).That being said, de Gaulle to my knowledge was not really known for racist fear-mongering or hate speech. That's in comparison with far-right people who already at the time, and still today, build an image of the ENEMY towards whom all hate and violence is necessary. See also Umberto Eco's Ur-fascism for characteristics of fascist regimes.In that sense, and it really pains me to write this, but de Gaulle was much less far-right than today's Parti Socialiste, pretending to be left wing despite ruling with right-wing anti-social measures and inciting hatred towards french muslims and binationals. I think de Gaulle was a classic right-wing authoritarian ruler. He had to take some social measures (which some may view as left-wing) because the workers at the end of WWII were very organized and had dozens of thousands of rifles, so such was the price of social peace.He was right-wing because he was rather conservative, for private property/entrepreneurship and strongly anti-communist. Still, he had strong national planning for the economy, much State support for private industry (Elf, Areva, etc) and strong policing on the streets (see also, Service d'Action Civique for de Gaulle's fascist militias with long ties with historical nazism and secret services).That being said, de Gaulle to my knowledge was not really known for racist fear-mongering or hate speech. That's in comparison with far-right people who already at the time, and still today, build an image of the ENEMY towards whom all hate and violence is necessary. See also Umberto Eco's Ur-fascism for characteristics of fascist regimes.In that sense, and it really pains me to write this, but de Gaulle was much less far-right than today's Parti Socialiste, pretending to be left wing despite ruling with right-wing anti-social measures and inciting hatred towards french muslims and binationals. Still, he had strong national planning for the economy, much State support for private industry (Elf, Areva, etc) and strong policing on the streets (see also, Service d'Action Civique for de Gaulle's fascist militias with long ties with historical nazism and secret services).That being said, de Gaulle to my knowledge was not really known for racist fear-mongering or hate speech. That's in comparison with far-right people who already at the time, and still today, build an image of the ENEMY towards whom all hate and violence is necessary. See also Umberto Eco's Ur-fascism for characteristics of fascist regimes.In that sense, and it really pains me to write this, but de Gaulle was much less far-right than today's Parti Socialiste, pretending to be left wing despite ruling with right-wing anti-social measures and inciting hatred towards french muslims and binationals. That being said, de Gaulle to my knowledge was not really known for racist fear-mongering or hate speech. That's in comparison with far-right people who already at the time, and still today, build an image of the ENEMY towards whom all hate and violence is necessary. See also Umberto Eco's Ur-fascism for characteristics of fascist regimes.In that sense, and it really pains me to write this, but de Gaulle was much less far-right than today's Parti Socialiste, pretending to be left wing despite ruling with right-wing anti-social measures and inciting hatred towards french muslims and binationals. In that sense, and it really pains me to write this, but de Gaulle was much less far-right than today's Parti Socialiste, pretending to be left wing despite ruling with right-wing anti-social measures and inciting hatred towards french muslims and binationals. I think that, for most Western people today, far-right == bad to non-white people, independent of intention (as you demonstrated with your remark about the PS), so de Gaulle's approach to Algeria, whether he's loud about it or not, would qualify him as far-right already.All this to say, the debate is based on differing definitions of far-right (for example you conflate fascism and far-right and use Eco, while GP and I seem to think it's about extremely  authoritarian + capitalist), and has started from an ignorant comment by an idiot who considers Bush (someone who is responsible for the death of around a million Iraqis, the creation of actual torture camps, large-scale surveillance, etc.) not far-right because, I assume, he didn't say anything mean about African-Americans. All this to say, the debate is based on differing definitions of far-right (for example you conflate fascism and far-right and use Eco, while GP and I seem to think it's about extremely  authoritarian + capitalist), and has started from an ignorant comment by an idiot who considers Bush (someone who is responsible for the death of around a million Iraqis, the creation of actual torture camps, large-scale surveillance, etc.) not far-right because, I assume, he didn't say anything mean about African-Americans. But then again people on this very forum will argue Sanders is a literal communist so we circle back to the sub 70iq problem The "free-speechism" of the past you mention was about speaking truth to power, and this movement still exists on the left today, see for example support for Julian Assange, arrested journalists in France or Turkey, or outright murdered in Palestine.When Elon Musk took over Twitter and promised free speech, he very soon actually banned accounts he disagreed with, especially leftists. Why free speech may be more and more perceived as right wing is because despite having outright criminal speech with criminal consequences (such as inciting violence against harmless individuals such as Mark Bray), billionaires have weaponized propaganda on a scale never seen before with their ownership of all the major media outlets and social media platforms, arguing it's a matter of free speech. When Elon Musk took over Twitter and promised free speech, he very soon actually banned accounts he disagreed with, especially leftists. Why free speech may be more and more perceived as right wing is because despite having outright criminal speech with criminal consequences (such as inciting violence against harmless individuals such as Mark Bray), billionaires have weaponized propaganda on a scale never seen before with their ownership of all the major media outlets and social media platforms, arguing it's a matter of free speech. I think we can and should all agree that child sexual abuse is a much larger and more serious problem than political leanings.It's ironic as you're commenting about a social media platform, but I think it's frightening what social media has done to us with misinformation, vilification, and echo chambers, to think political leanings are worse than murder, rape, or child sexual abuse. It's ironic as you're commenting about a social media platform, but I think it's frightening what social media has done to us with misinformation, vilification, and echo chambers, to think political leanings are worse than murder, rape, or child sexual abuse. However - it has one big problem that is rarely discussed... Normalizing of behaviour, interests and attitudes. It just becomes a thing that Grok can do - for paid accounts, and people think - ok, "no harm, no problem"... That's why all media depicting violence should be banned./s If xAI can't bring in guardrails or limit who can access these capabilities, then they deserve what's coming to them. Arguably morally reprehensible but it has not always been illegal (and still isn't in many places) if you're talking about images of adults. This comment chain isn't about a difference of opinion, but a difference in morality - there's no debating possible about morals I think. Go ask Pamela Anderson or Paris Hilton about that one. There are rules about material created without consent, but people do not retain a perpetual right to have formerly consentual material taken down. She claimes, later, to have not consented but given the sophistication of the production no reasonable person could believe she had no idea it was being filmed. She might not consent to the exact public release but she was certainly well aware of being filmed on the day. They did not consent to public release, but did consent to creation and private distribution, sometimes even taking and initially sharing the photos themselves. They did not consent to public release, but did consent to creation and private distribution, sometimes even taking and initially sharing the photos themselves. Let's start from the beginning, create and own:You're sketching out some nude fanart on a piece of paper. (This is apart from my feelings on Mechahitler/Grok, which aren't positive.) You're sketching out some nude fanart on a piece of paper. (This is apart from my feelings on Mechahitler/Grok, which aren't positive.) (This is apart from my feelings on Mechahitler/Grok, which aren't positive.) Is twitter a piece of paper in your desk? OP had "It has always been illegal and morally reprehensible to create, own, distribute or store "It would make more sense then to instead say:"It has always been illegal and morally reprehensible to distribute " "It has always been illegal and morally reprehensible to distribute " Personally I think it's just embarrassing, not immoral. It sounds like they are following due process. Did you ever expect the government to go after Adobe for "enabling" this? But police don't care about moral equivalence. For the legal details we would need to consult French law. But I assume it is illegal to create and distribute the images. Heck, it's also probably against Twitter's TOS too so by all rights the grok account should be banned.> This is a political action by the FrenchMaybe. They probably don't like a foreign company coming in, violating their children, and getting away with it. But what Twitter did was so far out of line that I'd be shocked if French companies weren't treated the same way. > This is a political action by the FrenchMaybe. They probably don't like a foreign company coming in, violating their children, and getting away with it. But what Twitter did was so far out of line that I'd be shocked if French companies weren't treated the same way. They probably don't like a foreign company coming in, violating their children, and getting away with it. But what Twitter did was so far out of line that I'd be shocked if French companies weren't treated the same way. But the illegality, in a sane world (and until 5 minutes ago) used to be attached to the person actually distributing them. If a student printed the pictures out and distributed them at school you'd have maybe 1000 violations. Twitter likely has hundreds of millions if not billions. So it makes sense to go after the most severe violator. Any crime that doesn't cause victims is just another way for an oppressive collectivist state to further control their citizens. If you are not harming anyone (like when creating but not sharing these pictures) then it simply shouldn't be a crime. Have we a outsourced all accountability for the crimes of humans to AI now? But I also don't think that Grok should be able to quickly and easily generate fake revenge porn for minors. You can't just ‚Äúundo‚Äù some girl being harassed by AI generated nude photos of her, so we‚Ä¶Yes, we should have some protections or restrictions on what you can do.You may not understand it, either because you aren't a parent or maybe just not emotionally equipped to understand how serious this actually can be, but your lack of comprehension does not render it a non-issue.Having schools play whack-a-mole after the photos are shared around is not a valid strategy. Never mind that schools primarily engage in teaching, not in investigation.As AI-generated content gets less and less distinguishable from reality, these incidents will have far worse consequences and putting such power in the hands of adolescents who demonstrably don't have sound judgment (hence why they lack many other rights that adults have) is not something most parents are comfortable with - and I doubt you'll find many teachers, psychiatrists and so on who would support your approach either. Yes, we should have some protections or restrictions on what you can do.You may not understand it, either because you aren't a parent or maybe just not emotionally equipped to understand how serious this actually can be, but your lack of comprehension does not render it a non-issue.Having schools play whack-a-mole after the photos are shared around is not a valid strategy. Never mind that schools primarily engage in teaching, not in investigation.As AI-generated content gets less and less distinguishable from reality, these incidents will have far worse consequences and putting such power in the hands of adolescents who demonstrably don't have sound judgment (hence why they lack many other rights that adults have) is not something most parents are comfortable with - and I doubt you'll find many teachers, psychiatrists and so on who would support your approach either. You may not understand it, either because you aren't a parent or maybe just not emotionally equipped to understand how serious this actually can be, but your lack of comprehension does not render it a non-issue.Having schools play whack-a-mole after the photos are shared around is not a valid strategy. Never mind that schools primarily engage in teaching, not in investigation.As AI-generated content gets less and less distinguishable from reality, these incidents will have far worse consequences and putting such power in the hands of adolescents who demonstrably don't have sound judgment (hence why they lack many other rights that adults have) is not something most parents are comfortable with - and I doubt you'll find many teachers, psychiatrists and so on who would support your approach either. Having schools play whack-a-mole after the photos are shared around is not a valid strategy. Never mind that schools primarily engage in teaching, not in investigation.As AI-generated content gets less and less distinguishable from reality, these incidents will have far worse consequences and putting such power in the hands of adolescents who demonstrably don't have sound judgment (hence why they lack many other rights that adults have) is not something most parents are comfortable with - and I doubt you'll find many teachers, psychiatrists and so on who would support your approach either. As AI-generated content gets less and less distinguishable from reality, these incidents will have far worse consequences and putting such power in the hands of adolescents who demonstrably don't have sound judgment (hence why they lack many other rights that adults have) is not something most parents are comfortable with - and I doubt you'll find many teachers, psychiatrists and so on who would support your approach either. No, but if you send those people who made  and distributed the AI nude of her to jail, these problems will virtually disappear overnight, because going to jail is a hugely effective deterrent for most people.But if you don't directly prosecute the people doing it, and instead just ban Grok AI, then those people will just use other AI tools, outside of US jurisdiction, to do the same things and the problem persists.And the issues keeps persisting, because nobody ever goes to jail. But if you don't directly prosecute the people doing it, and instead just ban Grok AI, then those people will just use other AI tools, outside of US jurisdiction, to do the same things and the problem persists.And the issues keeps persisting, because nobody ever goes to jail. And the issues keeps persisting, because nobody ever goes to jail. Obviously Grok shouldn't be legally allowed to generate fakes nudes of actual kids, but in case such safeguards can and will be bypassed, that doesn't absolve the humans from being the ones knowingly breaking the law to achieve a nefarious goal. Youths lack judgment, so they can't vote, drink, drive, have sex or consent to adults.A 14-year-old can't be relied to understand the consequences of making nudes of some girl.Beyond that, we regulate guns, speed limits and more according to principles like ‚Äúyour right to swing your fist ends at my nose‚Äù.We do that not only because shoving kids into jails is something we want to avoid, but because regulating at the source of the problem is both more feasible AND heads off a lot of tragedy.And again, you fail to acknowledge the investigative burden you put on society to discover who originated the photo after the fact, and the trauma to the victim.If none of that computes for you, then I don't know what to say except I don't place the right to generate saucy images highly enough to swarm my already overworked police with requests to investigate who generated fake underage porn. A 14-year-old can't be relied to understand the consequences of making nudes of some girl.Beyond that, we regulate guns, speed limits and more according to principles like ‚Äúyour right to swing your fist ends at my nose‚Äù.We do that not only because shoving kids into jails is something we want to avoid, but because regulating at the source of the problem is both more feasible AND heads off a lot of tragedy.And again, you fail to acknowledge the investigative burden you put on society to discover who originated the photo after the fact, and the trauma to the victim.If none of that computes for you, then I don't know what to say except I don't place the right to generate saucy images highly enough to swarm my already overworked police with requests to investigate who generated fake underage porn. Beyond that, we regulate guns, speed limits and more according to principles like ‚Äúyour right to swing your fist ends at my nose‚Äù.We do that not only because shoving kids into jails is something we want to avoid, but because regulating at the source of the problem is both more feasible AND heads off a lot of tragedy.And again, you fail to acknowledge the investigative burden you put on society to discover who originated the photo after the fact, and the trauma to the victim.If none of that computes for you, then I don't know what to say except I don't place the right to generate saucy images highly enough to swarm my already overworked police with requests to investigate who generated fake underage porn. We do that not only because shoving kids into jails is something we want to avoid, but because regulating at the source of the problem is both more feasible AND heads off a lot of tragedy.And again, you fail to acknowledge the investigative burden you put on society to discover who originated the photo after the fact, and the trauma to the victim.If none of that computes for you, then I don't know what to say except I don't place the right to generate saucy images highly enough to swarm my already overworked police with requests to investigate who generated fake underage porn. They go to juvy or their parents get punished. Being 14 is not a get out of jail free card. The problem stems from parents lack of parenting, a huge lack of real after-school programs, and the tiktokification of modern society.30 years ago, we had a lot of the same "slap on the wrist" punishments because it was assumed when you got home your parent was going to beat your ass. That isn't a thing anymore (rightfully), because parenting through threat of violence just leads to those kids becoming violent parents.Our problem is we never transitioned from violent parenting into any other kind. COVID created a society of chronically online children who don't know how to interact offline.And yes, the tools to create bad shit are more accessible than ever, and I always come off as some angry gate keeper, but so much of the internet as it is today has become too easy to access by people incapable of the critical thinking required for safe use.In the last 5 years, generative AI has taken over most of the "public facing" internet, and with internet literacy at the same level it was 20-30 years ago, we are back in the "walled garden" AOL era, but it is Facebook, Instagram, Twitter, TikTok that are the gardens. 30 years ago, we had a lot of the same "slap on the wrist" punishments because it was assumed when you got home your parent was going to beat your ass. That isn't a thing anymore (rightfully), because parenting through threat of violence just leads to those kids becoming violent parents.Our problem is we never transitioned from violent parenting into any other kind. COVID created a society of chronically online children who don't know how to interact offline.And yes, the tools to create bad shit are more accessible than ever, and I always come off as some angry gate keeper, but so much of the internet as it is today has become too easy to access by people incapable of the critical thinking required for safe use.In the last 5 years, generative AI has taken over most of the "public facing" internet, and with internet literacy at the same level it was 20-30 years ago, we are back in the "walled garden" AOL era, but it is Facebook, Instagram, Twitter, TikTok that are the gardens. Our problem is we never transitioned from violent parenting into any other kind. COVID created a society of chronically online children who don't know how to interact offline.And yes, the tools to create bad shit are more accessible than ever, and I always come off as some angry gate keeper, but so much of the internet as it is today has become too easy to access by people incapable of the critical thinking required for safe use.In the last 5 years, generative AI has taken over most of the "public facing" internet, and with internet literacy at the same level it was 20-30 years ago, we are back in the "walled garden" AOL era, but it is Facebook, Instagram, Twitter, TikTok that are the gardens. And yes, the tools to create bad shit are more accessible than ever, and I always come off as some angry gate keeper, but so much of the internet as it is today has become too easy to access by people incapable of the critical thinking required for safe use.In the last 5 years, generative AI has taken over most of the "public facing" internet, and with internet literacy at the same level it was 20-30 years ago, we are back in the "walled garden" AOL era, but it is Facebook, Instagram, Twitter, TikTok that are the gardens. I'm similarly repulsed by the idea of Grok generating images of kids, but if you draw a nude of an adult woman she's not going to get raped by that existing, and you don't have a right to not be embarrassed. In good faith, a few things - AI generated imagery and Photoshop are not the same. You keep using AI, without taking a moment to give the ‚Äúintelligence‚Äù any thought.Yes, powerful people are always going to get by, as you say. But that doesn't change anything here - this is a separate conversation.If not Grok then someone else will do it - is a defeatist argument that can only mean it can't be controlled so don't bother. This point is where you come across as a CSAM defender. Govt's will/should do whatever they can to make society safe, even if it means playing whack a mole. Judicial system is about fairness and not efficiency.frankly, I think you understand all of this and maybe got tunnel visioned in your anger at the unfairness of people scapegoating technology for its failings. That's the last thing I want to point out, raiding an office is taking action against the powerful people who build systems without accountability. Yes, powerful people are always going to get by, as you say. But that doesn't change anything here - this is a separate conversation.If not Grok then someone else will do it - is a defeatist argument that can only mean it can't be controlled so don't bother. This point is where you come across as a CSAM defender. Govt's will/should do whatever they can to make society safe, even if it means playing whack a mole. Judicial system is about fairness and not efficiency.frankly, I think you understand all of this and maybe got tunnel visioned in your anger at the unfairness of people scapegoating technology for its failings. That's the last thing I want to point out, raiding an office is taking action against the powerful people who build systems without accountability. If not Grok then someone else will do it - is a defeatist argument that can only mean it can't be controlled so don't bother. This point is where you come across as a CSAM defender. Govt's will/should do whatever they can to make society safe, even if it means playing whack a mole. Judicial system is about fairness and not efficiency.frankly, I think you understand all of this and maybe got tunnel visioned in your anger at the unfairness of people scapegoating technology for its failings. That's the last thing I want to point out, raiding an office is taking action against the powerful people who build systems without accountability. frankly, I think you understand all of this and maybe got tunnel visioned in your anger at the unfairness of people scapegoating technology for its failings. That's the last thing I want to point out, raiding an office is taking action against the powerful people who build systems without accountability. Actually you'll see the opposite happen a lot - after Columbine, the number of school shootings went up [0] for example, because before people didn't consider it an option. Same with serial killers / copycats, and a bunch of other stuff.Likewise, if it hadn't been in the news, a lot of people wouldn't have known you can / could create nudes of real people with Grok. News reporting on these things is its own kind of unfortunate marketing, and for every X people that are outraged about this, there will be some that are instead inspired and interested.While a lot of punishments for crimes is indeed a deterrent, it doesn't always work. Also because in this case, it's relatively easy to avoid being found out (unlike school shootings). Likewise, if it hadn't been in the news, a lot of people wouldn't have known you can / could create nudes of real people with Grok. News reporting on these things is its own kind of unfortunate marketing, and for every X people that are outraged about this, there will be some that are instead inspired and interested.While a lot of punishments for crimes is indeed a deterrent, it doesn't always work. Also because in this case, it's relatively easy to avoid being found out (unlike school shootings). Also because in this case, it's relatively easy to avoid being found out (unlike school shootings). Yes, let's just jail every kid who makes a mistake, ya know, instead of the enablers who should know better as adults...except for that one guy, let's put him in the white house except for that one guy, let's put him in the white house You don't have to prosecute and send a million people to jail for making and  distributing fake AI nudes, you just have to send a couple, and then the problem virtually goes away.People underestimate how effective direct personal accountability is when it comes with harsh consequences like jail time. That's how you fix all issues in society and enforce law abiding behavior. You make the cost of the crime greater than the gains from it, then crucify some people in public to set an example for everyone else.Do people like doing and paying their taxes? People underestimate how effective direct personal accountability is when it comes with harsh consequences like jail time. That's how you fix all issues in society and enforce law abiding behavior. You make the cost of the crime greater than the gains from it, then crucify some people in public to set an example for everyone else.Do people like doing and paying their taxes? Do people like doing and paying their taxes? In this case, it's far simpler to prosecute the source. If "they" wanted to set the tone that this type of behavior will not be tolerated, it would require a concerted multi agency surge of investigative and prosecutorial resources. If "they" wanted to set the tone that this type of behavior will not be tolerated, it would require a concerted multi agency surge of investigative and prosecutorial resources. It's not effective when the goal is to make it seem ineffective so that people can evade the system.>In this case, it's far simpler to prosecute the source.The "source" is a tool that tomorrow can be in Russia or CHina and you can't prosecute. It's not effective when the goal is to make it seem ineffective so that people can evade the system.>In this case, it's far simpler to prosecute the source.The "source" is a tool that tomorrow can be in Russia or CHina and you can't prosecute. It's not effective when the goal is to make it seem ineffective so that people can evade the system.>In this case, it's far simpler to prosecute the source.The "source" is a tool that tomorrow can be in Russia or CHina and you can't prosecute. >In this case, it's far simpler to prosecute the source.The "source" is a tool that tomorrow can be in Russia or CHina and you can't prosecute. The "source" is a tool that tomorrow can be in Russia or CHina and you can't prosecute. Nobody commits crimes with the expectation that they'll get caught, and if you only "crucify some people", then most criminals are going to (rightfully) assume that they'll be one of the lucky ones. I genuinely cannot tell if you are being comically na√Øve or extremely obtuse here. You need only look at the world around you to see that this does not, and never will, happen.As another commenter said, this argument is presenting itself as apologia for CSAM and you come across as a defender of the right for a business to create and publish it. I assume you don't actually believe that, but the points you made are compatible.It is as much the responsibility of a platform for providing the services to create illegal material, and also distributing said illegal material. That it happens to be an AI that generates the imagery is not relevant - X and Grok are still the two services responsible for producing and hosting it. As another commenter said, this argument is presenting itself as apologia for CSAM and you come across as a defender of the right for a business to create and publish it. I assume you don't actually believe that, but the points you made are compatible.It is as much the responsibility of a platform for providing the services to create illegal material, and also distributing said illegal material. That it happens to be an AI that generates the imagery is not relevant - X and Grok are still the two services responsible for producing and hosting it. It is as much the responsibility of a platform for providing the services to create illegal material, and also distributing said illegal material. That it happens to be an AI that generates the imagery is not relevant - X and Grok are still the two services responsible for producing and hosting it. I don't accept this as good faith argumentation nor does HN rules. Do you keep trying to whack-a-mole the AI tools for this, or the humans actually making and distributing fake nudes of real people? If Musk chooses not to implement them, that's his personal irresponsibility. You just cannot allow this content to be generated and distributed in the public domain by anonymous users. It has nothing to do with free speech but with civility and common understanding of what is morally wrong / right.Obviously you cannot prevent this in private forums unless it is made illegal which is a completely different problem that requires a very different solution. You just cannot allow this content to be generated and distributed in the public domain by anonymous users. It has nothing to do with free speech but with civility and common understanding of what is morally wrong / right.Obviously you cannot prevent this in private forums unless it is made illegal which is a completely different problem that requires a very different solution. Obviously you cannot prevent this in private forums unless it is made illegal which is a completely different problem that requires a very different solution. Using Grok as the tool.If kids were to "git gud" at photoshop and use that to make nudes, would you arrest Adobe? If kids ask a newspaper vendor for nudes and he provides them .. that's a no-no.If kids ask Grok for CSAM and it provides them .. then ? If kids ask Grok for CSAM and it provides them .. then ? If parents or school let children roam the internet unsupervised... then? The explosive sellers that provide explosives to someone without a certification (child or adult) get in trouble (in this part of the world) .. regardless of whether someone gets hurt (although that's an upscale).If sellers provide ExPo to certified parents and children get access .. that's on the parents.In that analagy of yours, if grok provided ExPo or CSAM to children .. that's a grok problem,(Ditto drugs).It's on the provider to children. If sellers provide ExPo to certified parents and children get access .. that's on the parents.In that analagy of yours, if grok provided ExPo or CSAM to children .. that's a grok problem,(Ditto drugs).It's on the provider to children. In that analagy of yours, if grok provided ExPo or CSAM to children .. that's a grok problem,(Ditto drugs).It's on the provider to children. So then where do we draw the line between lethal weapons and crime correlation. At which cutting/shooting instruments?Same with software tools, that keep getting more powerful with time lowering the bar to entry for generating nudes of people. Where do we draw the line on which tools are responsible for that instead of the humans using them for it? So then where do we draw the line between lethal weapons and crime correlation. At which cutting/shooting instruments?Same with software tools, that keep getting more powerful with time lowering the bar to entry for generating nudes of people. Where do we draw the line on which tools are responsible for that instead of the humans using them for it? Same with software tools, that keep getting more powerful with time lowering the bar to entry for generating nudes of people. Where do we draw the line on which tools are responsible for that instead of the humans using them for it? The knife (as opposed to sword) example is interesting. We recognise that there is individual responsibility at play, and children might not be responsible enough to buy them, given the possible harms. Does this totally solve their use in violent crime? But if your alternative is ‚Äúit's up to the individuals to be responsible‚Äù, well, that clearly doesn't work, because some people are not responsible. At a certain point, if your job is to reduce harm in the population, you look for where you can have a greater impact than just hoping every individual follows the law, because they clearly don't. And since our post-Dunblane gun laws, we haven't had any school shootings. And since our post-Dunblane gun laws, we haven't had any school shootings. And since our post-Dunblane gun laws, we haven't had any school shootings. Zero in 29 years - success by any measure.If you choose to look at _other_ types of violent crime, why would banning handguns have any effect?> Where do we draw the line on which tools are responsible for that instead of the humans using them for it?You can ban tools which enable bad outcomes without sufficient upside, while also holding the people who use them to account. If you choose to look at _other_ types of violent crime, why would banning handguns have any effect?> Where do we draw the line on which tools are responsible for that instead of the humans using them for it?You can ban tools which enable bad outcomes without sufficient upside, while also holding the people who use them to account. > Where do we draw the line on which tools are responsible for that instead of the humans using them for it?You can ban tools which enable bad outcomes without sufficient upside, while also holding the people who use them to account. You can ban tools which enable bad outcomes without sufficient upside, while also holding the people who use them to account. "If kids were to "git gud" at photoshop "And what is that supposed to mean?Adobe makes general purpose tools as far as I know. "If kids were to "git gud" at photoshop "And what is that supposed to mean?Adobe makes general purpose tools as far as I know. Anyone skilled at photoshop can do fake nudes as good or even better than AI, including kids (we used it to make fun fakes of teachers in embarrassing situations back in the mid 00s and distribute them via MSN messenger), so then why is only the AI tool the one to blame for what the users do, but not Photoshop if both tools can be used to do the same thing?People can now 3D print guns at home, or at least parts that when assembled can make a functioning firearm. This is the answer I'm looking for and I don't think there is an easy one, yet people here are too quick to pin blame based on their emotional responses and subjective biases and word views on the matter and the parties involved. This is the answer I'm looking for and I don't think there is an easy one, yet people here are too quick to pin blame based on their emotional responses and subjective biases and word views on the matter and the parties involved. This is the answer I'm looking for and I don't think there is an easy one, yet people here are too quick to pin blame based on their emotional responses and subjective biases and word views on the matter and the parties involved. So let's say there are two ways to do something illegal. The first requires skills from the perpetrator, is tricky to regulate, and is generally speaking not a widespread issue in practice. Then it makes sense to regulate only the second.> People can now 3D print guns at home, or at least parts that when assembled can make a functioning firearm. Are now 3D printer makers to blame if someone gets killed with a 3D printed gun?Tricky question, but a more accurate comparison would be with a company that runs a service to 3D print guns (= generating the image) and shoot with them in the street (= publishing on X) automatically for you and keeps accepting illegal requests while the competitors have no issue blocking them.> Where do we draw the line at tools in terms of effort required, between when the tool bares the responsibility and not just the human using the tool to do illegal things?That's also a tricky question, but generally you don't really need to know precisely where to draw the line. Are now 3D printer makers to blame if someone gets killed with a 3D printed gun?Tricky question, but a more accurate comparison would be with a company that runs a service to 3D print guns (= generating the image) and shoot with them in the street (= publishing on X) automatically for you and keeps accepting illegal requests while the competitors have no issue blocking them.> Where do we draw the line at tools in terms of effort required, between when the tool bares the responsibility and not just the human using the tool to do illegal things?That's also a tricky question, but generally you don't really need to know precisely where to draw the line. That's also a tricky question, but generally you don't really need to know precisely where to draw the line. Edit for the addition of the line about bullying: "Bullying has always happened, therefore we should allow new forms of even worse bullying to flourish freely, even though I readily acknowledge that it can lead to victims committing suicide" is a bizarre and self-contradictory take. Education might be so disrupted you have to change schools. We fault and "fine" companies for providing products that harm society all the timeAre you not going to consider the company providing a CSAM machine to be the major one at fault here? Are you not going to consider the company providing a CSAM machine to be the major one at fault here? The crime is creating a system that lets schoolboys create fake nudes of other minors.You don't just get to build a CSAM-generator and then be like "well I never intended for it to be used...".The humans running a company are liable for the product that their company builds, easy as that. You don't just get to build a CSAM-generator and then be like "well I never intended for it to be used...".The humans running a company are liable for the product that their company builds, easy as that. Just because you do something for someone else doesn't mean you're absolved of responsibility.You can't build a tool with a "create child porn" button and then expect not to get into trouble for helping people make child porn. In your scenario, yes, you are guilty as well. Just because you do something for someone else doesn't mean you're absolved of responsibility.You can't build a tool with a "create child porn" button and then expect not to get into trouble for helping people make child porn. Just because you do something for someone else doesn't mean you're absolved of responsibility.You can't build a tool with a "create child porn" button and then expect not to get into trouble for helping people make child porn. You can't build a tool with a "create child porn" button and then expect not to get into trouble for helping people make child porn. You should want to protect all of the people in your life from such a thing or nobody. It is a privately controlled public-facing group chat. France isn't America.If a company operates to the detriment and against the values of a nation, e.g. not paying their taxes or littering in the environment, the nation will ask them to change their behavior.If there is a conspiracy of contempt, at some point things escalate. If there is a conspiracy of contempt, at some point things escalate. Also, it seems pretty likely that Musk is tangled up with the Epstein shit. Now it turns out Musk repeatedly sought to visit, including wanting to know when the "wildest" party was happening, after Epstein was already known as a child sex abuser. Musk claimed that Epstein had never been given a tour of SpaceX but it turns out he did in 2013. Will be interesting to see what happens as more is revealed. No i said no such thing, what I said was that the resources of authorities is a finite pie. If most of it goes towards petty stuff like corporate misbehavior that hurts nobody, there won't be enough for the grave crimes like actual child abuser that actually hurt real people.Same how police won't bother with your stolen phone/bike because they have bigger crimes to catch. I'm asking for the same logic be applied here. Same how police won't bother with your stolen phone/bike because they have bigger crimes to catch. I'm asking for the same logic be applied here. Lack of resources was not the issue with Epstein prosecution. Acosta giving Epstein sweetheart deal or seeking to stop the prosecutor is not the resources issue.It is billionaires (Thiel, Musk, Gates), politicians (Clinton, Luthnic ) media darlings (Summers, Kraus and the rest of sexism is totally not a thing anymore crowd literally partying with Epstein) are to be protected at all cost issue. Even now, people implicated in Epstein files are still getting influential positions with explicit "it would be cancel culture to not give these people more influence" argument. Lack of resources was not the issue with Epstein prosecution. Acosta giving Epstein sweetheart deal or seeking to stop the prosecutor is not the resources issue.It is billionaires (Thiel, Musk, Gates), politicians (Clinton, Luthnic ) media darlings (Summers, Kraus and the rest of sexism is totally not a thing anymore crowd literally partying with Epstein) are to be protected at all cost issue. Even now, people implicated in Epstein files are still getting influential positions with explicit "it would be cancel culture to not give these people more influence" argument. It is billionaires (Thiel, Musk, Gates), politicians (Clinton, Luthnic ) media darlings (Summers, Kraus and the rest of sexism is totally not a thing anymore crowd literally partying with Epstein) are to be protected at all cost issue. Even now, people implicated in Epstein files are still getting influential positions with explicit "it would be cancel culture to not give these people more influence" argument. Politicians are constantly looking for an external made up enemy to divert attention to from the real problems.People like Epstein and mass woman/child exploitation have existed for thousands of years in the past, and will exist thousands of years in the future. It's part of the nature of the rich and powerful to execute on their deranged fetishes, it's been documented in writing since at least the Roman and Ottoman empires.Hell, I can guarantee you there's other Epsteins operating in the wild right now, that we haven't heard of (yet), it's not like he was in any way unique. I can also guarantee you that 1 in 5-10 normal looking people you meet daily on the street have similar deranged desires as the guests on Epstein's island but can't execute on them because they're not as rich and influential to get away with it, but they'd do it if they could. People like Epstein and mass woman/child exploitation have existed for thousands of years in the past, and will exist thousands of years in the future. It's part of the nature of the rich and powerful to execute on their deranged fetishes, it's been documented in writing since at least the Roman and Ottoman empires.Hell, I can guarantee you there's other Epsteins operating in the wild right now, that we haven't heard of (yet), it's not like he was in any way unique. I can also guarantee you that 1 in 5-10 normal looking people you meet daily on the street have similar deranged desires as the guests on Epstein's island but can't execute on them because they're not as rich and influential to get away with it, but they'd do it if they could. Hell, I can guarantee you there's other Epsteins operating in the wild right now, that we haven't heard of (yet), it's not like he was in any way unique. I can also guarantee you that 1 in 5-10 normal looking people you meet daily on the street have similar deranged desires as the guests on Epstein's island but can't execute on them because they're not as rich and influential to get away with it, but they'd do it if they could. This is just enforcing already existing laws.More over, had it been any other site, it would have been totally shut down by now and the servers impounded. Its only because musk is close to trump and rich that he's escaped the fate than you or I would have had if we'd done the same. This is just enforcing already existing laws.More over, had it been any other site, it would have been totally shut down by now and the servers impounded. Its only because musk is close to trump and rich that he's escaped the fate than you or I would have had if we'd done the same. Moral panics require new laws to enforce, generally. This is just enforcing already existing laws.More over, had it been any other site, it would have been totally shut down by now and the servers impounded. Its only because musk is close to trump and rich that he's escaped the fate than you or I would have had if we'd done the same. More over, had it been any other site, it would have been totally shut down by now and the servers impounded. Its only because musk is close to trump and rich that he's escaped the fate than you or I would have had if we'd done the same. Sure but where's the proof that Grok is  actually producing illegal content? I searched for news sources, but they're just all parroting empty accusations not concrete documented cases. Note that IWF is not a random charity it works with the Police on these matters.I found this as the first item in Kagi search - perhaps you should try non AI searches I found this as the first item in Kagi search - perhaps you should try non AI searches In the UK it is illegal to create, distribute and store CSAM. A news site printing a photo CSAM would make them legally up the shitter.However, the IWF, who are tasked with detecting this stuff have claimed to have found evidence of it, along with multiple other sources, Ofcom who are nominally supposed to police this have an open investigation, so do the irish police.The point is, law has a higher threshold of proof than news, which takes time. If there is enough evidence, then a court case (or other instrument) will be invoked. However, the IWF, who are tasked with detecting this stuff have claimed to have found evidence of it, along with multiple other sources, Ofcom who are nominally supposed to police this have an open investigation, so do the irish police.The point is, law has a higher threshold of proof than news, which takes time. If there is enough evidence, then a court case (or other instrument) will be invoked. The point is, law has a higher threshold of proof than news, which takes time. If there is enough evidence, then a court case (or other instrument) will be invoked. And what does AI have to do with this? Haven't child predators existed before AI?Where's the proof that AI produces more child predators?You're just going in circles without any arguments. Where's the proof that AI produces more child predators?You're just going in circles without any arguments. You're just going in circles without any arguments. > Another line of reasoning is that with more fake CP it is more difficult to research the real CP hunt down the perpetrators and consequently save children. (own quote, edited)To be clear, I don't think this line of reasoning is entirely convincing, but apparently some people do. (own quote, edited)To be clear, I don't think this line of reasoning is entirely convincing, but apparently some people do. (own quote, edited)To be clear, I don't think this line of reasoning is entirely convincing, but apparently some people do. (own quote, edited)To be clear, I don't think this line of reasoning is entirely convincing, but apparently some people do. (own quote, edited)To be clear, I don't think this line of reasoning is entirely convincing, but apparently some people do. Also, framing the issue of sexual abuse by untouchable issue as the same as superhero comic issue (which itself was not just about superhero comic and you should know it) is spectacularly bad faith.Yes, there were always people who were stealing, abusing, murdering for own gain and fun. That is not an argument for why we should accept and support it as normalized state of world. It is a good reason to prevent people from becoming too powerful and for building accountable institutions able to catch and punish them. That is not an argument for why we should accept and support it as normalized state of world. It is a good reason to prevent people from becoming too powerful and for building accountable institutions able to catch and punish them. https://www.reuters.com/world/uk/starmers-government-aids-po...Unlike the US administration which seems to be fine with what epstein and X are doing Unlike the US administration which seems to be fine with what epstein and X are doing and the things about negligence which caused harm to humans (instead of e.g. just financial harm) is thata) you can't opt out of responsibility, it doesn't matter what you put into your TOS or other contractsb) executives which are found responsible for the negligent action of a company can be hold _personally_ liableand independent of what X actually did Musk as highest level executive personal did1) frequently did statements that imply gross negligence (to be clear that isn't necessary how X acted, which is the actual relevant part)2) claimed that all major engineering decisions etc. are from him and no one else (because he love bragging about how good of an engineer he is)This means summoning him for questioning is legally speaking a must have independent of weather you expect him to show up or not. And he probably should take it serious, even if that just means he also could send a different higher level executive from X instead. a) you can't opt out of responsibility, it doesn't matter what you put into your TOS or other contractsb) executives which are found responsible for the negligent action of a company can be hold _personally_ liableand independent of what X actually did Musk as highest level executive personal did1) frequently did statements that imply gross negligence (to be clear that isn't necessary how X acted, which is the actual relevant part)2) claimed that all major engineering decisions etc. are from him and no one else (because he love bragging about how good of an engineer he is)This means summoning him for questioning is legally speaking a must have independent of weather you expect him to show up or not. And he probably should take it serious, even if that just means he also could send a different higher level executive from X instead. b) executives which are found responsible for the negligent action of a company can be hold _personally_ liableand independent of what X actually did Musk as highest level executive personal did1) frequently did statements that imply gross negligence (to be clear that isn't necessary how X acted, which is the actual relevant part)2) claimed that all major engineering decisions etc. are from him and no one else (because he love bragging about how good of an engineer he is)This means summoning him for questioning is legally speaking a must have independent of weather you expect him to show up or not. And he probably should take it serious, even if that just means he also could send a different higher level executive from X instead. and independent of what X actually did Musk as highest level executive personal did1) frequently did statements that imply gross negligence (to be clear that isn't necessary how X acted, which is the actual relevant part)2) claimed that all major engineering decisions etc. are from him and no one else (because he love bragging about how good of an engineer he is)This means summoning him for questioning is legally speaking a must have independent of weather you expect him to show up or not. And he probably should take it serious, even if that just means he also could send a different higher level executive from X instead. are from him and no one else (because he love bragging about how good of an engineer he is)This means summoning him for questioning is legally speaking a must have independent of weather you expect him to show up or not. And he probably should take it serious, even if that just means he also could send a different higher level executive from X instead. are from him and no one else (because he love bragging about how good of an engineer he is)This means summoning him for questioning is legally speaking a must have independent of weather you expect him to show up or not. And he probably should take it serious, even if that just means he also could send a different higher level executive from X instead. This means summoning him for questioning is legally speaking a must have independent of weather you expect him to show up or not. And he probably should take it serious, even if that just means he also could send a different higher level executive from X instead. * They exchanged various emails between 2012 and 2014 about Elon visiting the island* They made plans for Elon to visit the island* We don't know if Elon actually followed through on those plans and he denies itI think it's premature to say he didn't go, and the latest batches of emails directly contradict the claim he wasn't ever invited.See https://www.cnbc.com/2026/01/30/epstein-files-show-elon-musk... * They made plans for Elon to visit the island* We don't know if Elon actually followed through on those plans and he denies itI think it's premature to say he didn't go, and the latest batches of emails directly contradict the claim he wasn't ever invited.See https://www.cnbc.com/2026/01/30/epstein-files-show-elon-musk... * We don't know if Elon actually followed through on those plans and he denies itI think it's premature to say he didn't go, and the latest batches of emails directly contradict the claim he wasn't ever invited.See https://www.cnbc.com/2026/01/30/epstein-files-show-elon-musk... I think it's premature to say he didn't go, and the latest batches of emails directly contradict the claim he wasn't ever invited.See https://www.cnbc.com/2026/01/30/epstein-files-show-elon-musk... We don't know how many were pedo/rapists, but we know all of them liked to socialize with one and trade favours and spread his influence. Oops... yeah, in retrospect it was even worse... no... you can and should be judged by the friends you keep and hang-out with... The same ones who seem to be circling the wagons with innocuous statements or attempts to find other scapegoats (DARVO)... hmm, what was that quote again:"We must all hang together or we will all hang separately" If you own a magazine, you should be held responsible for everything published.You shouldn't be allowed to profit from publishing anything, then hide behind "the users did it, not us".And in this case, Elon should be held responsible for every single image of CSAM published on X. You shouldn't be allowed to profit from publishing anything, then hide behind "the users did it, not us".And in this case, Elon should be held responsible for every single image of CSAM published on X. And in this case, Elon should be held responsible for every single image of CSAM published on X.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/hhs-is-making-an-ai-tool-to-create-hypotheses-about-vaccine-injury-claims/'>HHS Is Making an AI Tool to Create Hypotheses About Vaccine Injury Claims</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-04 10:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The US Department of Health and Human Services is developing a generative artificial intelligence tool to find patterns across data reported to a national vaccine monitoring database and to generate hypotheses on the negative effects of vaccines, according to an inventory released last week of all use cases the agency had for AI in 2025. But experts worry that the predictions it generates could be used by Health and Human Services secretary Robert F. Kennedy Jr. to further his anti-vaccine agenda. A long-standing vaccine critic, Kenedy has upended the childhood vaccination schedule in his year in office, removing several shots from a list of recommended immunizations for all children, including those for Covid-19, influenza, hepatitis A and B, meningococcal disease, rotavirus, and respiratory syncytial virus, or RSV. Because these claims are not verified, VAERS data alone can't be used to determine if a vaccine caused an adverse event. ‚ÄúVAERS, at best, was always a hypothesis-generating mechanism,‚Äù says Paul Offit, a pediatrician and director of the Vaccine Education Center at Children's Hospital of Philadelphia who was previously a member of the CDC's Advisory Council on Immunization Practices. Offit says the system only shows adverse events that happened at some point following immunization; it doesn't prove that a vaccine caused those reactions. Despite this, anti-vaccine activists have misused VAERS data over the years to argue that vaccines are not safe. Leslie Lenert, previously the founding director of the CDC's National Center for Public Health Informatics, says government scientists have been using traditional natural language processing AI models to look for patterns in VAERS data for several years, so it's not surprising that HHS would move toward the adoption of more advanced large language models. One major limitation of VAERS is that it doesn't include data on how many people received a vaccine, which can make events logged in the database seem more common than they actually are. For that reason, Lenert says it's important to pair information from VAERS with other data sources to determine the true risk of an event. LLMs are also famously good at producing convincing hallucinations, underscoring the need for humans to follow up on any hypotheses generated by an LLM. Vinay Prasad, director of the FDA's Center for Biologics Evaluation and Research, reportedly proposed stricter vaccine regulation in a recent memo sent to staff in which he blamed the deaths of at least 10 children on the Covid-19 vaccine without citing evidence. The deaths were reported to VAERS and had previously been reviewed by FDA staff. More than a dozen former FDA commissioners responded with a letter in The New England Journal of Medicine, expressing concern about Prasad's proposed guidelines. Jesse Goodman, an infectious disease physician and professor of medicine at Georgetown University, says that the use of LLMs could potentially detect previously unknown safety issues with vaccines. But since VAERS can contain inaccurate and incomplete data, he says it's important that any leads are thoroughly investigated first. ‚ÄúI would expect, depending on the approaches used, a lot of false alerts and a need for a lot of skilled human follow-through by people who understand vaccines and possible adverse events, as well as statistics, epidemiology, and challenges with LLM output,‚Äù he says. With deep staffing cuts at the CDC, Goodman says it would be important to have plans and capacity in place to deal with any emerging data, including screening it and deciding what may need to be studied further and how. In the past, VAERS has flagged legitimate safety issues, including instances of a rare clotting disorder among some people who received the Johnson & Johnson Covid-19 vaccine and rare cases of myocarditis, particularly among younger males, who got the mRNA Covid-19 vaccines. Big Story: China's renewable energy revolution might save the world The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            