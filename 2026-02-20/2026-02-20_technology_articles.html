
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - TECHNOLOGY Article Summaries - 2026-02-20</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            TECHNOLOGY
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/paradise-season-2-review-hulu-2000720809'>‘Paradise' Season 2 Breaks Out of the Bunker and Brings Even More Tension and Thrills</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 17:00:28
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>and new intrigue (billionaires are always up to something) when Paradise, Hulu's dystopian thriller, returns. Season two brings back the show's flashes of melodrama and frequent pop culture references, emphasizing its complicated characters while also reminding the viewer that this is taking place in a version of our world that's gone very, very sideways. Season one, which unfolded almost entirely in an underground city created to withstand a global environmental disaster, closed the case on its presidential assassination whodunit—but left plenty of bunker-bound intrigue in its wake. The main timeline of season two picks up just a few weeks after season one, but once again Paradise—created by This Is Us' Dan Fogelman—relies on frequent flashbacks to bring fresh context and perspective to what we only think we know. A big reason Paradise is so entertaining is the way it constantly subverts expectations, springing surprise twists that in retrospect feel logical rather than random—and revealing over and over that first impressions aren't always what they seem. Paradise season two once again runs eight episodes, with the first three arriving together; it's a smart choice since each episode focuses on a different character and entry point into the drama. We don't have to wait very long to see how Secret Service agent Xavier Collins (Sterling K. Brown, who brings plenty of gravitas but also looks convincingly like a guy who could kill you with his hands) fared after escaping the bunker. In the course of discovering who killed President Cal Bradford (James Marsden), Xavier uncovered hidden truths about the bunker and its most powerful resident, billionaire Samantha “Sinatra” Redmond (Julianne Nicholson). All three of those storylines—Xavier's journey to find Teri, Sinatra's desire to conceal just how deep her well of secrets goes, and Teri's survival struggles after what Paradise calls “the Day”—propel season two. After barely getting any time with Teri in season one, we finally get a chance to see why Xavier thinks she hung the moon, and the show is better for it. Season two also digs into the turmoil left behind in Liberty Grove, the underground community that even Paradise itself has started calling “Paradise.” After season one's upheavals, the facade of normalcy is poised to crumble anew with every new confrontation. This includes the tension between Sinatra, recovering from a bullet wound sustained in the season one finale, and her former confidante, Dr. Gabriela Torabi (Sarah Shahi). There's also the increasing distrust that Agent Nicole Robinson (Krys Marshall) feels about Agent Jane Driscoll (Nicole Brydon Bloom), who viewers well know is a vicious killer only pretending to be, as Robinson once pegged her, “Holly Hobbie with a gun.” As Paradise switches between these separate—yet interlinked, all part of the show's precise design—plotlines, it also makes room for brand-new characters. While fans might be eager to see what happened to Xavier and Sinatra immediately, season two instead spends its entire premiere with a fresh face: Annie (Shailene Woodley), a med school dropout who's just starting to find happiness working as a tour guide at Graceland (another example of interlinking: as we know, Teri's such a big Elvis fan, her daughter with Xavier is named “Presley”) when disaster strikes. Annie's experiences give us a whole new point of view on the Day as well as the first three years of its devastating aftermath. There are also considerable challenges associated with living in a world where an EMP, set off by Bradford to prevent nuclear war, has knocked out all power sources beyond the most primitive. She's all alone and would prefer to keep it that way, so we feel her terror when a group of rough-looking men suddenly appears at Graceland's gate. It's in this way we meet another significant new character: Link, played by Thomas Doherty. Paradise manages to successfully juggle all these threads because each character has a very clear destination, a very clear motivation, or often both. We don't always know what's driving them at first, but they do, and that helps the pieces of the narrative slot into place. Even the most slippery characters have an inner code—which is not always a moral code, mind you—that they remain loyal to above everything else. That includes Jane, whose tendencies toward evil are further explored across season two—very necessary, after sort of materializing out of nowhere in season one—and the deeply complex Sinatra, who remains Paradise's most enigmatic character even as we learn more about her. Check out when to expect the latest Marvel, Star Wars, and Star Trek releases, what's next for the DC Universe on film and TV, and everything you need to know about the future of Doctor Who. Director Dan Trachtenberg notched the streamer's biggest movie debut since another Trachtenberg-directed ‘Predator' entry: 2022's ‘Prey.' Sci-fi's odd couple extraordinaire is coming to streaming just in time for Valentine's Day.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/pc-components/acer-and-asus-shut-down-support-for-pc-and-laptops-in-wake-of-patent-dispute-ruling-drivers-and-updates-inaccessible-to-existing-customers-german-website-finds-a-workaround'>Acer and Asus shut down support for PC and laptops in wake of patent dispute ruling, drivers and updates inaccessible to existing customers — German website finds a workaround (Update)</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 16:58:55
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Update 2/20/2026 8:40 am PT: We have added Acer's statement to Tom's Hardware below, along with other updates on the situation. Besides the high RAM and SSD prices everyone else is experiencing, both Asus and Acer's German websites are completely down due to the companies' recent spat with Nokia over the HEVC codec — meaning customers can't find any downloads or reach support pages for their hardware. Trying to use a VPN and setting (for example) a U.S. location to reach the German sites doesn't work either. Their only recourse is to use a VPN endpoint outside Germany and visit the non-German websites to find downloads for their wares. In a further update to the original story, ComputerBase has now confirmed that affected users can obtain drivers for Asus motherboards using the Asus DriverHub; this won't work on notebooks or NUCs, and requires the aforementioned software (the site is still inaccessible). The site has further identified a workaround enabled by visiting Acer's Swiss support website, which is published in German, so it doesn't even require translation. Nokia managed to get a German court to issue an injunction against both makers, blocking them from "offering, placing on the market, using, or importing or possessing such devices in Germany." It's worth noting that Germany is the largest consumer computing market in Europe. In a public statement, Asus said that "all after-sales services in Germany remain fully operational, and existing customers will continue to receive uninterrupted support in full compliance with the current court order," adding that it is "evaluating and pursuing further legal action to reach a fair resolution as soon as possible". There's no telling if email support has also been taken offline, but you couldn't even find that to begin with. In a further response to this story, Acer issued Tom's Hardware with the following statement: "Acer respects the intellectual property of other companies and organizations. In accordance with a ruling by the Munich Regional Court between Nokia and Acer we were required to temporarily suspend our sales activities in Germany for the impacted products. At the same time, we are reviewing additional legal options in order to reach a fair solution as quickly as possible. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. While it's hard to pin down the exact rationale for a complete geo-block of both German websites and German users, it's simply due to unintended consequences. In theory, all the companies would have to do would be to ensure that their respective German online stores are disabled, and that any other regions' stores no longer ship to Germany, but the block is much broader. In the past, Oppo/OnePlus, Vivo, and Lenovo went through similar situations, but reports indicate that their respective websites weren't completely taken offline. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Bruno Ferreira is a contributing writer for Tom's Hardware. When not doing that, he's usually playing games, or at live music shows and festivals. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York,</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2026/02/20/lucid-motors-slashes-12-of-its-workforce-as-it-seeks-profitability/'>Lucid Motors slashes 12% of its workforce as it seeks profitability</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 15:51:18
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Save up to $680 on your pass with Super Early Bird rates. Lucid Motors is laying off 12% of its workforce in a bid to “improve operational effectiveness and optimize our resources as we continue on our path toward profitability,” according to an internal memo that was obtained by TechCrunch. Lucid Motors reported having 6,800 full-time employees globally at the end of 2024. “Saying goodbye to colleagues is never easy,” interim CEO Marc Winterhoff wrote in the memo. “We are grateful for the contributions of those impacted by today's actions, and we are providing severance, bonus, continued health benefits, and transition support to help them through this period.” The company did not immediately respond to a request for comment. It's collaborating with Uber and autonomous vehicle company Nuro on launching a robotaxi service in the San Francisco area this year, too. The company is scheduled to release its financial results for 2025 next week. “Importantly, today's actions do not affect our strategy,” Winterhoff wrote in the memo. Since then, Lucid Motors has seen a significant amount of turnover in its executive ranks, including the loss of its chief engineer, who sued the company in December for wrongful termination and discrimination. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane. Save up to $680 on your pass before February 27.Meet investors. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what's next. FBI says ATM ‘jackpotting' attacks are on the rise, and netting hackers millions in stolen cash Meta's own research found parental supervision doesn't really help curb teens' compulsive social media use How Ricursive Intelligence raised $335M at a $4B valuation in 4 months Hollywood isn't happy about the new Seedance 2.0 video generator The great computer science exodus (and where students are going instead)</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/desktops/pc-building/thermal-grizzlys-delidded-ryzen-7-9850x3d-is-twice-the-price-but-packs-a-two-year-warranty-pre-tested-chip-is-covered-for-nearly-any-chip-failure'>Thermal Grizzly pops the top on Ryzen 7 9850X3Ds for you, charges eyewatering premium for delidded chips — almost double the cost of a regular model, comes with its own warranty</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 15:50:05
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>They don't come cheap, but TG is picking up warranty service, so it's a more sensible option than it looks. When you purchase through links on our site, we may earn an affiliate commission. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Folks who follow hardware might recall that, right about a year ago, Thermal Grizzly started selling delidded Ryzen 7 9800X3D processors for a small markup. These CPUs are functionally identical to the chips sold by AMD — indeed, they were chips sold by AMD to begin with — except that they've had their Integrated Heatspreaders (IHS) removed. Well, if the Ryzen 7 9800X3D isn't good enough for you anymore, you can now pick up a Ryzen 7 9850X3D with the top popped for a bit extra. With the new addition, Thermal Grizzly is now offering four models of delidded CPUs. Meanwhile, the Intel chip is a bit cheaper at $934.83. Given that AMD and Intel are obviously not going to warranty your modified CPU, Thermal Grizzly itself is taking on the burden of warranty service for the delidded chips. Quite generous, although it also doesn't cover "overclocking beyond the manufacturer's specified values"; a bit peculiar given that we expect most people who delid their CPUs are chasing clocks, not improved thermals or better acoustics. Given that, it's a little odd that the part is included, but I suppose you could turn it into a keychain or something. For folks who want to get into direct-die cooling, or who simply want the absolute best cooling efficiency, this saves a lot of hassle, but there are absolutely still challenges to be aware of. Oldheads like this nerd in particular will recall the bad old days of the original AMD Athlon, which came bare-die with no heatspreader; it was all too easy to crack those chips when installing a heatsink. That risk is no less salient today with delidded CPUs. Moreover, you've got to make sure that your cooling solution is properly spaced for the lid-less chip; both AMD and Intel use thick heatspreaders that will leave an air gap under their stock heatsinks. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Zak is a freelance contributor to Tom's Hardware with decades of PC benchmarking experience who has also written for HotHardware and The Tech Report. A modern-day Renaissance man, he may not be an expert on anything, but he knows just a little about nearly everything. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2026/02/20/peak-xv-raises-1-3b-doubles-down-on-ai-as-global-vc-rivalry-in-india-heats-up/'>Peak XV raises $1.3B, doubles down on AI as global VC rivalry in India heats up</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 15:10:40
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Save up to $680 on your pass with Super Early Bird rates. Peak XV announced on Friday that it has raised $1.3 billion across new India and Asia-focused funds. The firm, which now manages more than $10 billion in assets, is sharpening its focus on artificial intelligence and cross-border bets amid intensifying competition for deals in the region. The firm now counts more than 450 portfolio companies across fintech, software, and consumer internet, spanning seed to growth stages. Singh said Peak XV is not trying to match rivals dollar-for-dollar, emphasizing that the firm's priority is generating strong returns rather than maximizing assets under management. The firm will continue to size its funds based on where it sees the best opportunity to deliver “high-performing funds,” he said. “In the U.S. market, we are an underdog — and that's great,” Singh said, adding that the firm is focusing on areas where its experience in software, developer tools, and fintech gives it an edge. The latest fundraise follows a period of leadership changes at Peak XV, including the recent departures of senior partner Ashish Agrawal and investors Ishaan Mittal and Tejeshwi Sharma. Singh told TechCrunch the firm retains significant experience on its leadership team, noting that five of its seven managing partners have been with Peak XV for more than a decade. The broader Peak XV team includes more than 30 full-time investors, with about a dozen leading investments across its markets. Peak XV has returned more than $7 billion in cash to investors since inception, Singh said, adding that 35 of its portfolio companies have gone public. He declined to specify distributions since the firm's split from Sequoia Capital. The earlier pool included Peak XV's India growth strategy, and Singh said the firm does not plan to raise a new growth fund until more of that dry powder is deployed. Singh expects to deploy the new capital primarily into AI, fintech, and consumer startups, while also seeing emerging opportunities in deep tech. The firm has made more than 80 investments in AI startups to date. Jagmeet covers startups, tech policy-related updates, and all other major tech-centric developments from India for TechCrunch. You can contact or verify outreach from Jagmeet by emailing mail@journalistjagmeet.com. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what's next. FBI says ATM ‘jackpotting' attacks are on the rise, and netting hackers millions in stolen cash Meta's own research found parental supervision doesn't really help curb teens' compulsive social media use Hollywood isn't happy about the new Seedance 2.0 video generator The great computer science exodus (and where students are going instead)</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=47088166'>Show HN: A native macOS client for Hacker News, built with SwiftUI</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 15:00:34
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>GitHub: https://github.com/IronsideXXVI/Hacker-NewsDownload (signed & notarized DMG, macOS 14.0+): https://github.com/IronsideXXVI/Hacker-News/releasesScreenshots: https://github.com/IronsideXXVI/Hacker-News#screenshotsI spend a lot of time reading HN — I wanted something that felt like a proper Mac app: a sidebar for browsing stories, an integrated reader for articles, and comment threading — all in one window. Essentially, I wanted HN to feel like a first-class citizen on macOS, not a website I visit.What it does:- Split-view layout — stories in a sidebar on the left, articles and comments on the right, using the standard macOS NavigationSplitView pattern.- Built-in ad blocking — a precompiled WKContentRuleList blocks 14 major ad networks (DoubleClick, Google Syndication, Criteo, Taboola, Outbrain, Amazon ads, etc.) Session is stored in the macOS Keychain, and cookies are injected into the WebView so you can upvote, comment, and submit stories while staying logged in.- Bookmarks — save stories locally for offline access. Filter by content type (All, Ask, Show, Jobs, Comments), date range (Today, Past Week, Past Month, All Time), and sort by hot or recent.- Scroll progress indicator — a small orange bar at the top tracks your reading progress via JavaScript-to-native messaging.- Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. Some ideas I'm considering: keyboard-driven navigation (j/k to move between stories), a reader mode that strips articles down to text, and notification support for replies to your comments. Download (signed & notarized DMG, macOS 14.0+): https://github.com/IronsideXXVI/Hacker-News/releasesScreenshots: https://github.com/IronsideXXVI/Hacker-News#screenshotsI spend a lot of time reading HN — I wanted something that felt like a proper Mac app: a sidebar for browsing stories, an integrated reader for articles, and comment threading — all in one window. Essentially, I wanted HN to feel like a first-class citizen on macOS, not a website I visit.What it does:- Split-view layout — stories in a sidebar on the left, articles and comments on the right, using the standard macOS NavigationSplitView pattern.- Built-in ad blocking — a precompiled WKContentRuleList blocks 14 major ad networks (DoubleClick, Google Syndication, Criteo, Taboola, Outbrain, Amazon ads, etc.) Session is stored in the macOS Keychain, and cookies are injected into the WebView so you can upvote, comment, and submit stories while staying logged in.- Bookmarks — save stories locally for offline access. Filter by content type (All, Ask, Show, Jobs, Comments), date range (Today, Past Week, Past Month, All Time), and sort by hot or recent.- Scroll progress indicator — a small orange bar at the top tracks your reading progress via JavaScript-to-native messaging.- Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. Some ideas I'm considering: keyboard-driven navigation (j/k to move between stories), a reader mode that strips articles down to text, and notification support for replies to your comments. Screenshots: https://github.com/IronsideXXVI/Hacker-News#screenshotsI spend a lot of time reading HN — I wanted something that felt like a proper Mac app: a sidebar for browsing stories, an integrated reader for articles, and comment threading — all in one window. Essentially, I wanted HN to feel like a first-class citizen on macOS, not a website I visit.What it does:- Split-view layout — stories in a sidebar on the left, articles and comments on the right, using the standard macOS NavigationSplitView pattern.- Built-in ad blocking — a precompiled WKContentRuleList blocks 14 major ad networks (DoubleClick, Google Syndication, Criteo, Taboola, Outbrain, Amazon ads, etc.) Session is stored in the macOS Keychain, and cookies are injected into the WebView so you can upvote, comment, and submit stories while staying logged in.- Bookmarks — save stories locally for offline access. Filter by content type (All, Ask, Show, Jobs, Comments), date range (Today, Past Week, Past Month, All Time), and sort by hot or recent.- Scroll progress indicator — a small orange bar at the top tracks your reading progress via JavaScript-to-native messaging.- Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. I spend a lot of time reading HN — I wanted something that felt like a proper Mac app: a sidebar for browsing stories, an integrated reader for articles, and comment threading — all in one window. Essentially, I wanted HN to feel like a first-class citizen on macOS, not a website I visit.What it does:- Split-view layout — stories in a sidebar on the left, articles and comments on the right, using the standard macOS NavigationSplitView pattern.- Built-in ad blocking — a precompiled WKContentRuleList blocks 14 major ad networks (DoubleClick, Google Syndication, Criteo, Taboola, Outbrain, Amazon ads, etc.) Session is stored in the macOS Keychain, and cookies are injected into the WebView so you can upvote, comment, and submit stories while staying logged in.- Bookmarks — save stories locally for offline access. Filter by content type (All, Ask, Show, Jobs, Comments), date range (Today, Past Week, Past Month, All Time), and sort by hot or recent.- Scroll progress indicator — a small orange bar at the top tracks your reading progress via JavaScript-to-native messaging.- Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. What it does:- Split-view layout — stories in a sidebar on the left, articles and comments on the right, using the standard macOS NavigationSplitView pattern.- Built-in ad blocking — a precompiled WKContentRuleList blocks 14 major ad networks (DoubleClick, Google Syndication, Criteo, Taboola, Outbrain, Amazon ads, etc.) Session is stored in the macOS Keychain, and cookies are injected into the WebView so you can upvote, comment, and submit stories while staying logged in.- Bookmarks — save stories locally for offline access. Filter by content type (All, Ask, Show, Jobs, Comments), date range (Today, Past Week, Past Month, All Time), and sort by hot or recent.- Scroll progress indicator — a small orange bar at the top tracks your reading progress via JavaScript-to-native messaging.- Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. - Split-view layout — stories in a sidebar on the left, articles and comments on the right, using the standard macOS NavigationSplitView pattern.- Built-in ad blocking — a precompiled WKContentRuleList blocks 14 major ad networks (DoubleClick, Google Syndication, Criteo, Taboola, Outbrain, Amazon ads, etc.) Session is stored in the macOS Keychain, and cookies are injected into the WebView so you can upvote, comment, and submit stories while staying logged in.- Bookmarks — save stories locally for offline access. Filter by content type (All, Ask, Show, Jobs, Comments), date range (Today, Past Week, Past Month, All Time), and sort by hot or recent.- Scroll progress indicator — a small orange bar at the top tracks your reading progress via JavaScript-to-native messaging.- Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. - Built-in ad blocking — a precompiled WKContentRuleList blocks 14 major ad networks (DoubleClick, Google Syndication, Criteo, Taboola, Outbrain, Amazon ads, etc.) Session is stored in the macOS Keychain, and cookies are injected into the WebView so you can upvote, comment, and submit stories while staying logged in.- Bookmarks — save stories locally for offline access. Filter by content type (All, Ask, Show, Jobs, Comments), date range (Today, Past Week, Past Month, All Time), and sort by hot or recent.- Scroll progress indicator — a small orange bar at the top tracks your reading progress via JavaScript-to-native messaging.- Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. Session is stored in the macOS Keychain, and cookies are injected into the WebView so you can upvote, comment, and submit stories while staying logged in.- Bookmarks — save stories locally for offline access. Filter by content type (All, Ask, Show, Jobs, Comments), date range (Today, Past Week, Past Month, All Time), and sort by hot or recent.- Scroll progress indicator — a small orange bar at the top tracks your reading progress via JavaScript-to-native messaging.- Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. Session is stored in the macOS Keychain, and cookies are injected into the WebView so you can upvote, comment, and submit stories while staying logged in.- Bookmarks — save stories locally for offline access. Filter by content type (All, Ask, Show, Jobs, Comments), date range (Today, Past Week, Past Month, All Time), and sort by hot or recent.- Scroll progress indicator — a small orange bar at the top tracks your reading progress via JavaScript-to-native messaging.- Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. - Bookmarks — save stories locally for offline access. Filter by content type (All, Ask, Show, Jobs, Comments), date range (Today, Past Week, Past Month, All Time), and sort by hot or recent.- Scroll progress indicator — a small orange bar at the top tracks your reading progress via JavaScript-to-native messaging.- Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. - Search and filtering — powered by the Algolia HN API. Filter by content type (All, Ask, Show, Jobs, Comments), date range (Today, Past Week, Past Month, All Time), and sort by hot or recent.- Scroll progress indicator — a small orange bar at the top tracks your reading progress via JavaScript-to-native messaging.- Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. - Scroll progress indicator — a small orange bar at the top tracks your reading progress via JavaScript-to-native messaging.- Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. - Auto-updates via Sparkle with EdDSA-signed updates served from GitHub Pages.- Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. - Dark mode — respects system appearance with CSS and meta tag injection.Tech details for the curious:The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. The whole app is ~2,050 lines of Swift across 16 files. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. The Algolia API is surprisingly powerful for this — it lets you do date-range filtering, pagination, and full-text search that the Firebase API doesn't support.CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. CI/CD:The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. The release pipeline is a single GitHub Actions workflow (467 lines) that handles the full macOS distribution story: build and archive, code sign with Developer ID, notarize with Apple (with a 5-retry staple loop for ticket propagation delays), create a custom DMG with AppleScript-driven icon positioning, sign and notarize the DMG, generate an EdDSA Sparkle signature, create a GitHub Release, and deploy an updated appcast.xml to GitHub Pages.Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.The entire project is MIT licensed. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. PRs and issues welcome: https://github.com/IronsideXXVI/Hacker-NewsI'd love feedback — especially on features you'd want to see. I'd love feedback — especially on features you'd want to see. I'm probably just a anti-app guy, but I tried it out.First thing I went to do was CMD-F to search for some strings in the comments section.Actually, the real first thing I did, was click on the left-side article preview  on the text that said "1 hr ago | 63 comments" thinking it'd navigate me to the comments. Am I missing some core concept here? Why would I want to browse the web in this app as opposed to a web browser? I like native apps for things, even link aggregators, because my I want to use my OS's native window management and app management instead of just shoving everything into a browser tab, of which I already have too many. Because then it's just CMD+Tab to Chrome, and then figure out which of the 20+ tabs I'm trying to get to instead of CMD+Tab directly to that specific app.Anyway, just a bit of old man yelling at cloud but I've always disliked the proliferation of "web app all the things." Anyway, just a bit of old man yelling at cloud but I've always disliked the proliferation of "web app all the things." It's just nice to have HN as it's own app instead of just another tab in a single app. Same reason I use mail.app vs. webmail, native music app vs the web player, etc.PWAs also solve the problem, more or less, but it is nice to have something native. PWAs also solve the problem, more or less, but it is nice to have something native. There will be a way to do user actions like upvote/comment/favorite/flag soon. Thank you for the MIT license, I'll be able to add my own.It also works on my fork of the old news server. It also works on my fork of the old news server. First feature request from me would be to adjust text size. I've start bumping up the default text size on all sites by one or two notches in the past year. But also, as someone pointed out on a design blogpost a decade ago, why not make things easier to read. I'm not upgrading to the crap they've been putting out lately.I'll be able to read details more later (getting ready for the job). Hope I didn't miss anything and comment about something that was already addressed. Really happy that I can run this on MacOS14 cause I've been locked out of some neat things people have built recently. I'm not upgrading to the crap they've been putting out lately.I'll be able to read details more later (getting ready for the job). Hope I didn't miss anything and comment about something that was already addressed. I'll be able to read details more later (getting ready for the job). Hope I didn't miss anything and comment about something that was already addressed. I've been doing this too; at some point I should probably just change the scaling of my desktop as a whole. But I like my high resolution, multiple windows layout too much to do it yet! This is a good start, but I think a better approach would be to piggyback off of ublock origin's lists. Otherwise, there is probably a decent set of filter lists with an MIT license somewhere. The goal is for you to NOT become a filter list maintainer, and by piggybacking off an already respected set of lists, you'd build user trust in your adblocking. I don't necessarily have a ready solution to offer, but these are the obstacles preventing someone like me from being able to use apps like this comfortably and safely, especially knowing we are entering a transitional period where new apps are being vibe-coded every day and formal verification has not yet caught up.Even if a given app has had every line of code reviewed by a human, or has well-defined interfaces that allow for sloppier internal code, how do I know that without cracking it open myself or asking an agent to help me audit it? Even if a given app has had every line of code reviewed by a human, or has well-defined interfaces that allow for sloppier internal code, how do I know that without cracking it open myself or asking an agent to help me audit it? Also would be nice to be able store notes or short blurbs about usernames that will show up in the app. Btw, can you allow me to set the font-family, font-size, etc. I can't even do the default `CMD + +` to zoom in. - It's a way to help you prevent yourself from spending too much time on HN. If you turn it on you'll only be allowed to visit the site for maxvisit minutes at a time, with gaps of minaway minutes in between. The defaults are 20 and 180, which would let you view the site for 20 minutes at a time, and then not allow you back in for 3 hours. - It's a way to help you prevent yourself from spending too much time on HN. If you turn it on you'll only be allowed to visit the site for maxvisit minutes at a time, with gaps of minaway minutes in between. The defaults are 20 and 180, which would let you view the site for 20 minutes at a time, and then not allow you back in for 3 hours. One thing: I really like the colors of Hacker News. It feels weird to me when Hacker News is presented in other colors. If I were to use your app I'd want to change the color pallet back to what it looks like on HN.> Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.Yes, in a past life I shipped a Mac application. This aspect is always a little bit of black magic. I will say that the Windows installer situation was a lot worse, IMO. > Getting macOS code signing and notarization working in CI was honestly the hardest part of this project. If anyone is distributing a macOS app outside the App Store via GitHub Actions, I'm happy to answer questions — the workflow is fully open source.Yes, in a past life I shipped a Mac application. This aspect is always a little bit of black magic. I will say that the Windows installer situation was a lot worse, IMO. This aspect is always a little bit of black magic. I will say that the Windows installer situation was a lot worse, IMO. Also I appreciate how you made all backend calls just static functions which they always should be. People tend to overcomplicate these things and add a lot of boiler plate and unnecessary bureaucracy.Going to try your app, thank you!P.S. tried it, already miss the `threads` tab Going to try your app, thank you!P.S. tried it, already miss the `threads` tab tried it, already miss the `threads` tab In other similar news, I've been working on enhancing the HN ux, but still in the browser as an extension. My only nitpick is I wish I could force dark mode on web pages with a light background, but that's minor. SwiftUI is something entirely different and not trying to be cross-platform at all.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/fender-mix-headphones-review-so-much-more-than-a-branding-gimmick-2000723612'>Fender Mix Headphones Review: So Much More Than a Branding Gimmick</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 15:00:02
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Fender has been a big name in the audio world for a long time, but even old dogs learn new tricks, and the guitar icon's newest trick is a pair of wireless headphones. For the first time, you can wear Fender on your head instead of slung over your shoulder, thanks to the Mix, a pair of Fender-branded wireless headphones that focus on modularity—the earcups, batteries, and headbands are all replaceable here. If you notice, I wrote “Fender-branded” headphones, and your alarm bells are going off, let me elaborate: Fender isn't technically making the hardware (that would be a company called Riffsound Pte. Ltd.), though it does have a say in its design. The modular Fender Mix are a strong start for the iconic guitar brand's first-ever pair of wireless headphones. Fender's focus on modularity made its wireless headphones stand out, but there was one thing in particular that had me interested above the rest: a dongle. The Fender Mix come with a USB-C dongle that you can stick into your phone or another device to achieve lossless, low-latency audio. It's not a novel solution—competitors like Sennheiser's HDB 630 also employ that design—but it is somewhat rare, especially at the Mix's price point. Fender's wireless headphones cost $299 as opposed to the Sennheiser HDB 630's $499. Why exactly was I so intrigued by a dongle, you ask? Well, because I'm not typically a wire guy, that's why. As much as I love how affordable and hi-fi wired headphones are, how a lot of them look, they're a pain to deal with on the train. Dongles like the one included in the Fender Mix eliminate that pain point in theory and, as I've learned, in practice as well—all while providing a better-than-Bluetooth listening experience. While the headphones sound solid with a standard Bluetooth connection, slotting the dongle into my phone and playing tunes that way moves the needle from solid to legitimately good. I listened to Pavement's “Cut Your Hair” back-to-back, and the whole song had more presence. Snare hits were louder, vocals were more upfront, and the mix of guitars was more evenly spread out, making it easier to pick up on each track. As an added bonus, there's also a volume boost, which makes listening in loud environments easier. These wireless headphones also have Auracast, which lets you group audio products together for simultaneous listening, and to activate that feature, you tap the dongle button three times until the light turns purple. I also tested the dongle's low-latency mode by playing some Fortnite on my laptop and was pleased with the speed. Having tried to use regular Bluetooth wireless earbuds in the past to play, the Fender Mix were leaps and bounds better for making sure I heard every gunshot and footfall on time. I wouldn't replace a gaming headset with the Mix anytime soon, but if you did want to use these headphones in a pinch when you're traveling, they're not a bad option. Yes, most headphones can be used wired in some capacity, but the Fender Mix gives you low-latency audio without wires. One of the best parts of the dongle is that once you're done using it, you can easily take it out of your phone or another device and put it in the headphones, so you don't lose it. To store the tiny piece of important plastic and metal, just take off the magnetic earcup and place it into its rightful slot. Powering the Fender Mix's sound are what the company is calling 40mm “hyper-efficient graphene drivers,” which definitely hold their own compared to other headphones at this price range, including Nothing's Headphone 1, which also debuted at $299. As I mentioned, the earcups are magnetic and can be popped off easily. I didn't try to do this myself since I don't have an extra battery, but I did pop it out just to see how easy the whole thing was, and it felt pretty straightforward. My black unit came with additional tan earcups. Weirdly, Fender didn't share pricing for them. I've reached out to the company and will update this review with pricing info when I have it. The earcups aren't premium-feeling in any way, but they are comfortable, and it's hard to speak to durability since that type of thing takes many months of use. I did notice some scuffing on the outside of the left earcup after keeping the headphones in my bag for a little over a week, so take that anecdote how you will. Headbands are also replaceable, and though I wasn't provided an additional headband, the process of taking off both earcups (speakers and all) was easy. Just pull them straight from the band with a little force, and you've got everything in neat little pieces. I wouldn't describe the build quality as feeling premium, nor is the design particularly eye-catching—they're a bit bulky for my taste. Buttons are also on the conservative side, but they're responsible for controlling a lot. The joystick button (which can be moved left, right, up, or down) controls things like track skipping, on/off, and adjusting volume (and checking battery levels with a double-press), while the flatter button switches between EQ modes and also ANC modes. I highly recommend taking a look at the manual I've linked here (page 3) to see which button commands do what, because these two pieces of plastic/rubber are responsible for a lot. This is just how it goes when you don't have a companion app. If you're looking for style, you can always go with Nothing's Headphone 1—those are guaranteed to turn heads on your commute into work. On top of good sound, the Fender Mix also perform well in two other key departments: active noise-cancellation (ANC) and battery life. I put the Mix through an obligatory subway test and was pleased at the amount of sound that these wireless headphones block out. It lets some sound in, but my voice still sounds a little tinny—Apple's AirPods Max still have the best transparency in town. There's also a mode for having ANC and transparency off, which could be useful for extending battery life, but not much else. Fender advertises up to 52 hours when ANC is activated and up to 100 hours when it's turned off. Having used the Fender Mix on and off for the majority of a 10-hour workday, it seems Fender isn't lying. For context, comparable competitors like Nothing's Headphone 1 get up to 35 hours of battery life with ANC on and about 80 hours with ANC off. If there's one thing I can knock Fender for a little bit, it's not being the most feature-rich. While the Mix have ANC, there are no perks like a personalized hearing test or customizable EQ. Those aren't dealbreakers (I'm sure lots of people don't even know those features exist), but as someone who's taken advantage of them in the past, I can attest that they're nice to have. To cycle through those, you have to use the Mix's buttons, which is less than ideal, especially because the in-ear voice that tells you which setting you're on is hard to hear over music. I was also calling from my office, which isn't a particularly noisy place. The ambient noise pickup is particularly surprising given the fact that Fender touts a dual-mic design with “ENC,” which is short for environmental noise-cancellation. I suppose if you're in a quiet spot, you may not notice any problems, but be wary of using these wireless headphones while out and about. The Mix, as I mentioned, do have newer features like Auracast so clearly Fender has its eye on ways to enhance its headphones with software. If you're reading, Fender, take this as a formal invite to expand EQ options! The Fender Mix are a strong start from a brand just dipping its toes into the wireless headphones game, and the best part is that Fender isn't phoning it in. It's taking modularity seriously with the Mix, which is great for consumers and theoretically better for the environment. On top of that, the included dongle makes what would otherwise be a pretty mid-sounding pair of wireless headphones into good-sounding ones. All of that for $299, coupled with the fact that these wireless headphones also have great battery life and solid ANC, makes the Mix worthy of consideration. Turns out licensing your name can be more than a gimmick, and Fender is proof. Subscribe and interact with our community, get up to date with our customised Newsletters and much more. Sony's WF-1000XM6 are my new favorite earbuds for sound. Come with me on my adventure to craft a PC when memory prices are worse than ever.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2026/02/20/why-investors-are-going-gaga-over-solid-state-transformers/'>Exclusive: Why investors are going gaga over solid-state transformers</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 14:30:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Save up to $680 on your pass with Super Early Bird rates. Transformers haven't changed much since Thomas Edison made his first light bulb. Now, a string of startups are working to modernize the transformer, replacing it with modern power electronics that promise to give grid operators more control over how and where electricity flows. “It becomes a very powerful device, equivalent to your internet router,” Subhashish Bhattacharya, co-founder and CTO of DG Matrix, told TechCrunch. Three startups recently raised sizable rounds to scale up production of their solid-state transformer technologies. In November, Amperesand raised $80 million to chase after the burgeoning data center market. Existing transformers are reliable and efficient, but that's about it. They're relatively crude instruments, made largely of copper and iron. They react passively to changes on the grid and are capable of tackling only one task per device. “An old-school steel, copper, and oil transformer doesn't have any monitoring, doesn't have any control,” Drew Baglino, founder and CEO of Heron Power, told TechCrunch. The devices can incorporate power from a range of difference sources — including traditional power plants, renewables, and batteries — and transform that electricity into either alternating current (AC) or direct current (DC) at a number of different voltages, allowing them to replace several devices. For data centers, solid-state transformers offer an appealing alternative, allowing them to shrink the footprint of their power systems while giving them finer control over where and how electricity is directed. Solid-state transformers poised to arrive at a time when existing transformers are aging and demand for new ones is surging — a classic tech supercycle. There's a big need for an upgrade,” Baglino said. They're also immune from price fluctuations that rock the copper market. Steel, copper, and oil, unfortunately, is not in that situation,” Baglino said. In an old-style transformer, power flows into the transformer through copper wires wound around one side of an O-shaped iron core. Solid-state transformers eschew the copper windings in favor of semiconductors, using materials like silicon carbide or gallium nitride to handle frequency conversion. Unlike iron-core transformers, solid-state transformers can handle power that flows in both directions, making them useful in places that need backup power, like data centers. In a data center, a solid-state transformer can replace several different pieces of equipment, not just the transformer that steps voltage down from the grid. Solid-state transformers can handle all of those duties in one box. And when coupled with grid-scale batteries, solid-state transformers can eliminate uninterruptible power supplies (UPS), too, freeing up space inside the data center for more racks. In a data center, it's Heron Link transformers can provide racks with 30 seconds of power while backup sources come online. Altogether, Heron Link occupy 70% less space than existing parts. At a solar farm, Heron Power's transformers can perform the duties of an inverter and a transformer for the same price. But in data centers and at EV charging hubs, where solid-state transformers take the place of several pieces of equipment, they'll start making inroads. Because today's transformers are passive, unable to react to fluctuations, distribution networks have been built with a significant amount of spare capacity, Baglino said. Solid-state transformers, though, and can respond to changing conditions, allowing grid operators to send more power through the same lines. “You can actually make the infrastructure more affordable because you're putting more kilowatt-hours through the same poles and wires,” he said. Tim De Chant is a senior climate reporter at TechCrunch. He has written for a wide range of publications, including Wired magazine, the Chicago Tribune, Ars Technica, The Wire China, and NOVA Next, where he was founding editor. De Chant is also a lecturer in MIT's Graduate Program in Science Writing, and he was awarded a Knight Science Journalism Fellowship at MIT in 2018, during which time he studied climate technologies and explored new business models for journalism. You can contact or verify outreach from Tim by emailing tim.dechant@techcrunch.com. Save up to $680 on your pass before February 27.Meet investors. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building what's next. FBI says ATM ‘jackpotting' attacks are on the rise, and netting hackers millions in stolen cash Meta's own research found parental supervision doesn't really help curb teens' compulsive social media use How Ricursive Intelligence raised $335M at a $4B valuation in 4 months Hollywood isn't happy about the new Seedance 2.0 video generator The great computer science exodus (and where students are going instead)</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/new-research-suggests-you-actually-want-qr-code-menus-replaced-by-augmented-reality-2000724318'>New Research Suggests You Actually Want QR Code Menus Replaced by... Augmented Reality?</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 14:10:07
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>If there's one bet that will always hit on one of the various “prediction markets” that are now apparently undergirding our economy, it's that America will take the wrong lesson from a crisis. Our all-too-brief tastes of government-funded healthcare and meaningful unemployment relief came and went in the blink of an eye. Even as many restaurants have had to begrudgingly relinquish the “al fresco” dining areas they colonized on sidewalks and parking spaces back to the cars and pedestrians, another innovation of the early pandemic is still going frustratingly strong. During their initial 2020 boom, QR code menus were an annoyance collectively suffered for the sake of public health. But today, long after the mask mandates were lifted and our government stopped even acknowledging the existence of a virus that's still very much around (and, uh… surging again), the QR code menu soldiers on like a barnacle that demands “you WILL pull out your phone on this date.” Despite some landmark victories in the arena of pushing back this and other loathed forms of technology creeping onto our plates, some restaurateurs and the consulting firms they overpay doggedly insist that customers love QR code menus; they just don't know it. Well, new research out of Washington State University posits that consumers want even more screen time baked into their dining experience. The study, led by Soobin Seo of WSU's Carson College of Business, seems to suggest that restaurants could boost customer interest in and willingness to tell others about their establishment by adding augmented reality (AR) elements to their digital menus. That said, there's no reason to doubt Seo and her team's work is anything but scientifically rigorous. The paper even notes numerous qualifying limitations to its studies and suggests further research would be prudent before widespread adoption by businesses. In fact, digging into the specifics of the team's methodology reveals several key elements that make it seem we may not necessarily be destined for a future of AR at Arby's after all. First, the research's focus was entirely on the disclosure of a restaurant's farm-to-table (FTT) supply chain via AR and how that gimmick hypothetically affects a customer's likelihood to visit the restaurant and tell others about it. A sample size of 243 study participants were shown one of three menu formats—AR, QR, and classic printed—then asked to imagine ordering the menu's signature burger dish and digest information about its many FTT ingredients in their menu's respective format. While those with the AR menus did indeed score higher when it came to their willingness to visit, remember, and yap about a theoretical restaurant, their average self-selected response was roughly only .5 higher than those with the QR and paper menus. “Consumers increasingly want transparency about where their food comes from, but the way that information is presented really matters,” Seo told WSU Insider. “Augmented reality allows restaurants to share that information in a more vivid, interactive, and engaging way.” That may very well be true, but does vivid, interactive, and engaging info about the farm your Big Mac's tomatoes came from translate to customers opening their wallets, let alone restaurant owners hiring web developers? Smart glasses out of China are operating on another level, and a rumored pair from Alibaba is the latest example.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/pc-components/save-usd379-99-on-this-asus-x870e-motherboard-and-32gb-of-ddr5-ram-newegg-combo-deal-is-cheaper-than-buying-the-memory-separately'>Save $379.99 on this Asus X870E motherboard and 32GB of DDR5 RAM — Newegg combo deal is cheaper than buying the memory separately</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 12:25:03
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. If you haven't already been put off from ever building a PC again, thanks to the skyrocketing prices of PC components, then you may have already noticed the influx of component bundles popping up from retailers that pull together a few pieces of hardware to try to offset the high prices. From bundles that contain almost all the parts for an entire PC build, to smaller combinations of components like today's that pair a motherboard with some valuable memory, it's worth taking a look and seeing if any of these combos may help in getting a new PC build or upgrade off the ground. If we take a deeper dive and look at the individual components, we can see that the Asus TUF Gaming X870E-Plus WiFi7 motherboard in the offer has a list price of $349.99 with a current sale price of $329.99. It also comes with a complimentary copy of the latest Resident Evil: Requiem video game, valued at $70. Asus' X870E motherboard comes with an excellent array of features, including four M.2 slots for plenty of storage, WiFi 7 connectivity, 16+2+1 80A power stages, and PCIe 5.0. The list price of this RAM is $499.99 at Newegg, although there is currently an offer running where you can reduce the price by $70 when using code PDSF285 at checkout, making the price $429.99 This Newegg combo bundle pairs an Asus TUF Gaming X870E-Plus WiFi7 motherboard with 32GB (2x 16GB) of V-Color Manta XSky DDR5 6400MT/s Memory. Perfect to pair with an AMD Ryzen 7000 - 9000 series processor. In the current climate of rising memory, storage, and GPU prices, this bundle deal is a pretty solid offering. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Stewart Bendle is a deals and coupon writer at Tom's Hardware. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/leading-us-research-lab-appears-to-be-squeezing-out-foreign-scientists/'>Leading US Research Lab Appears to Be Squeezing Out Foreign Scientists</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 10:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Many of the agency's thousands of employees, postdoctoral scientists, contractors, and guest researchers are brought in from around the world for their specialized expertise. “For weeks now, rumors of draconian new measures have been spreading like wildfire, while my staff's inquiries to NIST have gone unanswered,” Zoe Lofgren, the top Democrat on the House Committee on Science, Space, and Technology, wrote in a letter sent to acting NIST director Craig Burkhardt on Thursday. Lofgren wrote that while her staff has heard about multiple rumored changes, what they have confirmed through unnamed sources is that the Trump administration “has begun taking steps to limit the ability of foreign-born researchers to conduct their work at NIST.” The congressional letter follows a Boulder Reporting Lab article on February 12 that said international graduate students and postdoctoral researchers would be limited to a maximum of three years at NIST going forward, despite many of them needing five to seven years to complete their work. A NIST employee tells WIRED that some plans to bring on foreign workers through the agency's Professional Research and Experience Program have recently been canceled because of uncertainty about whether they would make it through the new security protocols. On Thursday, the Colorado Sun reported that “noncitizens” lost after-hours access to a NIST lab last month and could soon be banned from the facility entirely. Jennifer Huergo, a spokesperson for NIST, tells WIRED that the proposed changes are aimed at protecting US science from theft and abuse, echoing a similar statement issued this week to other media outlets. She also didn't immediately respond to a request for comment on the lawmakers' letter. Preventing foreign adversaries from stealing valuable American intellectual property has been a bipartisan priority, with NIST among the agencies in recent years to receive Congressional scrutiny about the adequacy of its background checks and security policies. Just last month, Republican lawmakers renewed calls to put restrictions in place preventing Chinese nationals from working at or with national labs run by the Department of Energy. But Lofgren's letter contends that the rumored restrictions on non-US scientists at NIST goes beyond “what is reasonable and appropriate to protect research security.” The letter demands transparency about new policies by February 26 and a pause on them “until Congress can weigh in on whether these changes are necessary at all.” The potential loss of research talent at NIST would add to a series of other Trump administration policies that some US tech industry leaders have warned will dismantle the lives of immigrant researchers already living in the US and hamper economic growth. The Trump administration has also announced plans to limit post-graduation job training for international students. “Industry, universities, and the global measurement community knew they could work with NIST.” As of a couple of years ago, NIST welcomed 800 researchers on average annually from outside the US to work in its offices and collaborate directly with staff. Lofgren expressed fear that rumors may be enough to scare away researchers and undermine US competitiveness in vital research. In your inbox: Maxwell Zeff's dispatch from the heart of AI Big Tech says AI will save the planet—it doesn't offer much proof The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=47069299'>Anthropic officially bans using subscription auth for third party use</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 04:32:37
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Claude Code is a lock in, where Anthropic takes all the value.If the frontend and API are decoupled, they are one benchmark away from losing half their users.Some other motivations: they want to capture the value. Even if it's unprofitable they can expect it to become vastly profitable as inference cost drops, efficiency improves, competitors die out etc. Or worst case build the dominant brand then reduce the quotas.Then there's brand - when people talk about OpenCode they will occasionally specify "OpenCode (with Claude)" but frequently won't.Then platform - at any point they can push any other service.Look at the Apple comparison. They get to sell cloud storage, and even somehow a TV. That's all super profitable.At some point Claude Code will become an ecosystem with preferred cloud and database vendors, observability, code review agents, etc. If the frontend and API are decoupled, they are one benchmark away from losing half their users.Some other motivations: they want to capture the value. Even if it's unprofitable they can expect it to become vastly profitable as inference cost drops, efficiency improves, competitors die out etc. Or worst case build the dominant brand then reduce the quotas.Then there's brand - when people talk about OpenCode they will occasionally specify "OpenCode (with Claude)" but frequently won't.Then platform - at any point they can push any other service.Look at the Apple comparison. They get to sell cloud storage, and even somehow a TV. That's all super profitable.At some point Claude Code will become an ecosystem with preferred cloud and database vendors, observability, code review agents, etc. Some other motivations: they want to capture the value. Even if it's unprofitable they can expect it to become vastly profitable as inference cost drops, efficiency improves, competitors die out etc. Or worst case build the dominant brand then reduce the quotas.Then there's brand - when people talk about OpenCode they will occasionally specify "OpenCode (with Claude)" but frequently won't.Then platform - at any point they can push any other service.Look at the Apple comparison. They get to sell cloud storage, and even somehow a TV. That's all super profitable.At some point Claude Code will become an ecosystem with preferred cloud and database vendors, observability, code review agents, etc. Then there's brand - when people talk about OpenCode they will occasionally specify "OpenCode (with Claude)" but frequently won't.Then platform - at any point they can push any other service.Look at the Apple comparison. They get to sell cloud storage, and even somehow a TV. That's all super profitable.At some point Claude Code will become an ecosystem with preferred cloud and database vendors, observability, code review agents, etc. They get to sell cloud storage, and even somehow a TV. That's all super profitable.At some point Claude Code will become an ecosystem with preferred cloud and database vendors, observability, code review agents, etc. They get to sell cloud storage, and even somehow a TV. That's all super profitable.At some point Claude Code will become an ecosystem with preferred cloud and database vendors, observability, code review agents, etc. But Apple also gets to charge Google $billions for being the default search engine. They get to sell cloud storage, and even somehow a TV. That's all super profitable.At some point Claude Code will become an ecosystem with preferred cloud and database vendors, observability, code review agents, etc. At some point Claude Code will become an ecosystem with preferred cloud and database vendors, observability, code review agents, etc. I think Github Co-Pilot is most annoying from what I've tried... it's great for finishing off a task that's half done where the structure is laid out, as long as you put blinders keeping it focused on it. OpenAI and Google's options seem to get things mostly right, but do some really goofy wrong things from my own experiences.They all seem to have trouble using state of the art and current libraries by default, even when you explicitly request them. They all seem to have trouble using state of the art and current libraries by default, even when you explicitly request them. If the default option isn't at least arguably the best option I can't really speak to that. I would suggest that maybe metrics on a given set of technologies be done and that based on the project in use, that it should choose the best option dynamically by default. This coding agent is minimal, and it completely changed how I used models and Claude's cli now feels like extremely slow bloat.I'd not be surprised if you're right in that this is companies / management will prefer to "pay for a complete package" approach for a long while, but power-users should not care for the model providers.I have like 100 lines of code to get me a tmux controls & semaphore_wait extension in the pi harness. That gave me a better orchestration scheme a month ago when I adopted it, than Claude has right now.As far as I can tell, the more you try to train your model on your harness, the worse they get. I'd not be surprised if you're right in that this is companies / management will prefer to "pay for a complete package" approach for a long while, but power-users should not care for the model providers.I have like 100 lines of code to get me a tmux controls & semaphore_wait extension in the pi harness. That gave me a better orchestration scheme a month ago when I adopted it, than Claude has right now.As far as I can tell, the more you try to train your model on your harness, the worse they get. I have like 100 lines of code to get me a tmux controls & semaphore_wait extension in the pi harness. That gave me a better orchestration scheme a month ago when I adopted it, than Claude has right now.As far as I can tell, the more you try to train your model on your harness, the worse they get. As far as I can tell, the more you try to train your model on your harness, the worse they get. The reason these LLM tools being good is they can "just do stuff." I'll just have my other tool use Claude Code in tmux. If third party agents can be banned from doing stuff (some advanced always on spyware or whatever), then a large chunk of the promise of AI is dead.Amp just announced today they are dumping IDE integration. Models seem to run better on bare-bones software like Pi, and you can add or remove stuff on the fly because the whole things open source. Someone like Microsoft can also provide a SLA and price such appropriately. If you don't own a business or funding source, the way state of the art LLMs are being used today is totally uneconomical (easy $200+ an hour at API prices. )36+ months out, if they overbuild the data centers and the revenue doesn't come in like OpenAI & Anthropic are forecasting, there will be a glut of hardware. If that's the case I'd expect local model usage will scale up too and it will get more difficult for enterprise providers. (Nothing is certain but some things have become a bit more obvious than they were 6 months ago.) Amp just announced today they are dumping IDE integration. Models seem to run better on bare-bones software like Pi, and you can add or remove stuff on the fly because the whole things open source. Someone like Microsoft can also provide a SLA and price such appropriately. If you don't own a business or funding source, the way state of the art LLMs are being used today is totally uneconomical (easy $200+ an hour at API prices. )36+ months out, if they overbuild the data centers and the revenue doesn't come in like OpenAI & Anthropic are forecasting, there will be a glut of hardware. If that's the case I'd expect local model usage will scale up too and it will get more difficult for enterprise providers. (Nothing is certain but some things have become a bit more obvious than they were 6 months ago.) Someone like Microsoft can also provide a SLA and price such appropriately. If you don't own a business or funding source, the way state of the art LLMs are being used today is totally uneconomical (easy $200+ an hour at API prices. )36+ months out, if they overbuild the data centers and the revenue doesn't come in like OpenAI & Anthropic are forecasting, there will be a glut of hardware. If that's the case I'd expect local model usage will scale up too and it will get more difficult for enterprise providers. (Nothing is certain but some things have become a bit more obvious than they were 6 months ago.) 36+ months out, if they overbuild the data centers and the revenue doesn't come in like OpenAI & Anthropic are forecasting, there will be a glut of hardware. If that's the case I'd expect local model usage will scale up too and it will get more difficult for enterprise providers. (Nothing is certain but some things have become a bit more obvious than they were 6 months ago.) (Nothing is certain but some things have become a bit more obvious than they were 6 months ago.) If I'm in a competitive industry that slow down alone can mean failure. Is there any conceivable GUI overlay that Anthropic or OpenAI can add to make their software better than the current terminal apps? Sure, for certain edge cases, but then why isn't the user building those themselves? 24 months ago we could have said that's too hard, but that isn't the case in 2026.Microsoft added all of this stuff in to Windows, and it's a 5 alarm fire. Stuff that used to be usable is a mess and really slow. Running linux with Claude Code, Codex, or Pi is clearly superior to having a Windows device with neither (if it wasn't possible to run these in Windows; just a hypothetical. Monday morning, an the Anthropic API endpoint is down, uh oh! 2030, the data center expansion is bust, nVidia starts selling all of these cards to consumers directly and has a huge financial incentive to make sure the performant local models exist. Everyone in the semiconductor supply chain below nvidia only cares about keeping sales going, so it stops with them.Maybe nvidia is the real winner?Also is it just me or does it now feel like hn comments are just talking to a future LLM? Microsoft added all of this stuff in to Windows, and it's a 5 alarm fire. Stuff that used to be usable is a mess and really slow. Running linux with Claude Code, Codex, or Pi is clearly superior to having a Windows device with neither (if it wasn't possible to run these in Windows; just a hypothetical. Monday morning, an the Anthropic API endpoint is down, uh oh! 2030, the data center expansion is bust, nVidia starts selling all of these cards to consumers directly and has a huge financial incentive to make sure the performant local models exist. Everyone in the semiconductor supply chain below nvidia only cares about keeping sales going, so it stops with them.Maybe nvidia is the real winner?Also is it just me or does it now feel like hn comments are just talking to a future LLM? Monday morning, an the Anthropic API endpoint is down, uh oh! 2030, the data center expansion is bust, nVidia starts selling all of these cards to consumers directly and has a huge financial incentive to make sure the performant local models exist. Everyone in the semiconductor supply chain below nvidia only cares about keeping sales going, so it stops with them.Maybe nvidia is the real winner?Also is it just me or does it now feel like hn comments are just talking to a future LLM? If the end game is just the same as talking to the Star Trek computer, and competitors are narrowing gaps rather than widening them (e.g. Anthropic and OpenAI releases models minutes from each other now, Chinese frontier models getting closer in capability not further), then it is really hard to see how either company achieves a vertical lock down.We could actually move down the stack, and then the real problem for OpenAI and Anthropic is nVidia. 2030, the data center expansion is bust, nVidia starts selling all of these cards to consumers directly and has a huge financial incentive to make sure the performant local models exist. Everyone in the semiconductor supply chain below nvidia only cares about keeping sales going, so it stops with them.Maybe nvidia is the real winner?Also is it just me or does it now feel like hn comments are just talking to a future LLM? 2030, the data center expansion is bust, nVidia starts selling all of these cards to consumers directly and has a huge financial incentive to make sure the performant local models exist. Everyone in the semiconductor supply chain below nvidia only cares about keeping sales going, so it stops with them.Maybe nvidia is the real winner?Also is it just me or does it now feel like hn comments are just talking to a future LLM? Maybe nvidia is the real winner?Also is it just me or does it now feel like hn comments are just talking to a future LLM? Also is it just me or does it now feel like hn comments are just talking to a future LLM? The advances in the Claude Code harness have been more around workflow automation rather than capability improvements, and truthfully workflows are very user-dependent, so an opinionated harness is only ever going to be "right" for a narrow segment of users, and it's going to annoy a lot of others. There are parallels to the silly Metaverse hype wave from a few years ago. At the time I saw a surprising number of people defending the investment saying it was important for Facebook to control their own platform. Well sure it's beneficial for Facebook to control a platform, but that benefit is purely for the company and if anything it would harm current and future users. This whole game is a bizarre battle.In the future, many companies will have slightly different secret RL sauces. I'd want to use Gemini for documentation, Claude for design, Codex for planning, yada yada ... there will be no generalist take-all model, I just don't believe RL scaling works like that.I'm not convinced that a single company can own the best performing model in all categories, I'm not even sure the economics make it feasible.Good for us, of course. In the future, many companies will have slightly different secret RL sauces. I'd want to use Gemini for documentation, Claude for design, Codex for planning, yada yada ... there will be no generalist take-all model, I just don't believe RL scaling works like that.I'm not convinced that a single company can own the best performing model in all categories, I'm not even sure the economics make it feasible.Good for us, of course. I'm not convinced that a single company can own the best performing model in all categories, I'm not even sure the economics make it feasible.Good for us, of course. With how comically extensible pi is and how much control it gives you over every aspect of the pipeline, as soon as you start building extensions for your own, personal workflow, Claude Code legimitely feels like a trash app in comparison.I don't care what Anthropic does - I'll keep using pi. Apple can do those things because they control the hardware device, which has physical distribution, and they lock down the ecosystem. With Claude Code, just export an env variable or use a MITM proxy + some middleware to forward requests to OpenAI instead. i've been wondering how anthropic is going to survive long term. If they could build out an infrastructure and services to complete with the hyperscalers but surfaced as a tool for claude to use then maybe. You pay Anthropic $20/user/month for ClaudeCode but also $100k/month to run your applications. Allow other to take all the value you provide? Asking people who pay for a personal subscription rather than paying by the API call to use that subscription themselves sounds to me like it is. Rather like the way I pay for my internet connectivity with a fixed monthly bill. Sure, someone with extremely heavy usage might not be able to use a normal consumer internet subscription; but it works fine for my personal use. Rather like the way I pay for my internet connectivity with a fixed monthly bill. Sure, someone with extremely heavy usage might not be able to use a normal consumer internet subscription; but it works fine for my personal use. This statement is plainly wrong.If you boost and praise AI usage, you have to face the real cost.Can't have your cake and eat it, too. If you boost and praise AI usage, you have to face the real cost.Can't have your cake and eat it, too. Can't have your cake and eat it, too. If they can provide a relatively cheap subscription against the direct API use, this is because they can control the stuff end-to-end, the application running on your system (Claude Code, Claude Desktop) and their systems.As you subscribe to these plans, this is the "contract", you can use only through their tools. If you want full freedom, use the API, with a per token pricing.For me, this is fair. If you want full freedom, use the API, with a per token pricing.For me, this is fair. Their costs are not magically lower when you use claude code vs when you use a third-party client.> For me, this is fair.This is, plain and simple, a tie-in sale of claude code. I am particularly amused by people accepting it as "fair" because in Brazil this is an illegal practice. I am particularly amused by people accepting it as "fair" because in Brazil this is an illegal practice. This is, plain and simple, a tie-in sale of claude code. I am particularly amused by people accepting it as "fair" because in Brazil this is an illegal practice. I am very curious what is particularly illegal about this. You are paying for access to Claude Code.Is it also illegal that if you pay for Playstation Plus that you can't play those games on an Xbox?Is it illegal that you can't use third party netflix apps?I really don't want to defend and AI company here but this is perfectly normal. In no other situation would we expect access to the API, the only reason this is considered different is because they also have a different service that gives access to the API. Now we all know obviously the API is being used because that is how things work, but you are not actually paying a subscription for the API. You are paying for access to Claude Code.Is it also illegal that if you pay for Playstation Plus that you can't play those games on an Xbox?Is it illegal that you can't use third party netflix apps?I really don't want to defend and AI company here but this is perfectly normal. In no other situation would we expect access to the API, the only reason this is considered different is because they also have a different service that gives access to the API. Is it also illegal that if you pay for Playstation Plus that you can't play those games on an Xbox?Is it illegal that you can't use third party netflix apps?I really don't want to defend and AI company here but this is perfectly normal. In no other situation would we expect access to the API, the only reason this is considered different is because they also have a different service that gives access to the API. Is it illegal that you can't use third party netflix apps?I really don't want to defend and AI company here but this is perfectly normal. In no other situation would we expect access to the API, the only reason this is considered different is because they also have a different service that gives access to the API. I really don't want to defend and AI company here but this is perfectly normal. In no other situation would we expect access to the API, the only reason this is considered different is because they also have a different service that gives access to the API. Anthropic provides an API third-party clients can use. Or should every app/service be required to expose documented APIs? While I do personally disagree with thinking that you should be able to do this when it was never sold in that way, at the end of the day as a customer you can choose if you want to use the product in the way that they are saying or use something else if you don't want to support that model.However the person I was responding too brought up legality which is a very different discussion. However the person I was responding too brought up legality which is a very different discussion. But if that is the service they are making and they are clear about what it is when you sign up... That does not make it illegal.I can see why people think they should be entitled to do this, but it does not align with how they are selling the service or how many other companies sell services. In most situations you don't get unlimited access to the individual components of how a service works (the API), you are expected to use the service (in this case Claude Code) directly. I can see why people think they should be entitled to do this, but it does not align with how they are selling the service or how many other companies sell services. In most situations you don't get unlimited access to the individual components of how a service works (the API), you are expected to use the service (in this case Claude Code) directly. "Both parties are okay with the terms" is far from being sufficient to make something "legal".Tie-in sales between software and services is not different from price dumping. Tie-in sales between software and services is not different from price dumping. MMO's (and gaming in general) being a major example of this, but so are many of the apps I pay for subscriptions for on my phone.The actual technical implementation of how it works is irrelevant when it is clear what it is you are paying for.> "Both parties are okay with the terms" is far from being sufficient to make something "legal".True but the opposite is also true, just because you don't like the terms it does not make it illegal. MMO's (and gaming in general) being a major example of this, but so are many of the apps I pay for subscriptions for on my phone.The actual technical implementation of how it works is irrelevant when it is clear what it is you are paying for.> "Both parties are okay with the terms" is far from being sufficient to make something "legal".True but the opposite is also true, just because you don't like the terms it does not make it illegal. The actual technical implementation of how it works is irrelevant when it is clear what it is you are paying for.> "Both parties are okay with the terms" is far from being sufficient to make something "legal".True but the opposite is also true, just because you don't like the terms it does not make it illegal. > "Both parties are okay with the terms" is far from being sufficient to make something "legal".True but the opposite is also true, just because you don't like the terms it does not make it illegal. True but the opposite is also true, just because you don't like the terms it does not make it illegal. And in many cases like Claude Code and the Anthropic models, they can and do work perfectly independently.> True but the opposite is also true, just because you don't like the terms it does not make it illegal.This is not me "not liking it". This practice is clearly not done to favor the consumer. This practice is clearly not done to favor the consumer. This practice is clearly not done to favor the consumer. Is Spotify, Apple Music, etc etc etc also illegal in Brazil?It would be ridiculous to argue that I could pay for a subscription to World of Warcraft and make my own third party client to play the game with. (Obviously you are free to argue it all you want but I would be very surprised if this was actually illegal).> And in many cases like Claude Code and the Anthropic models, they can and do work perfectly independently.Unless I am mistaken Claude Code does not have a local model built into it, so it requires a server side component to work?As far as the Anthropic models, yes like many other services they ALSO have a public API that is separate from the subscription that you are paying for.The critical difference here being that in the subscription it is very clear that you are paying for “Claude Code” which is a combination of an application and a server side component. It makes no claims about API usage as part of your subscription, again the technical implementation of the service you are actually paying for “Claude Code” is irrelevant.When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for, they could be sending the information to Gemini or or a human looks at it. (Obviously you are free to argue it all you want but I would be very surprised if this was actually illegal).> And in many cases like Claude Code and the Anthropic models, they can and do work perfectly independently.Unless I am mistaken Claude Code does not have a local model built into it, so it requires a server side component to work?As far as the Anthropic models, yes like many other services they ALSO have a public API that is separate from the subscription that you are paying for.The critical difference here being that in the subscription it is very clear that you are paying for “Claude Code” which is a combination of an application and a server side component. It makes no claims about API usage as part of your subscription, again the technical implementation of the service you are actually paying for “Claude Code” is irrelevant.When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for, they could be sending the information to Gemini or or a human looks at it. > And in many cases like Claude Code and the Anthropic models, they can and do work perfectly independently.Unless I am mistaken Claude Code does not have a local model built into it, so it requires a server side component to work?As far as the Anthropic models, yes like many other services they ALSO have a public API that is separate from the subscription that you are paying for.The critical difference here being that in the subscription it is very clear that you are paying for “Claude Code” which is a combination of an application and a server side component. It makes no claims about API usage as part of your subscription, again the technical implementation of the service you are actually paying for “Claude Code” is irrelevant.When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for, they could be sending the information to Gemini or or a human looks at it. Unless I am mistaken Claude Code does not have a local model built into it, so it requires a server side component to work?As far as the Anthropic models, yes like many other services they ALSO have a public API that is separate from the subscription that you are paying for.The critical difference here being that in the subscription it is very clear that you are paying for “Claude Code” which is a combination of an application and a server side component. It makes no claims about API usage as part of your subscription, again the technical implementation of the service you are actually paying for “Claude Code” is irrelevant.When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for, they could be sending the information to Gemini or or a human looks at it. As far as the Anthropic models, yes like many other services they ALSO have a public API that is separate from the subscription that you are paying for.The critical difference here being that in the subscription it is very clear that you are paying for “Claude Code” which is a combination of an application and a server side component. It makes no claims about API usage as part of your subscription, again the technical implementation of the service you are actually paying for “Claude Code” is irrelevant.When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for, they could be sending the information to Gemini or or a human looks at it. The critical difference here being that in the subscription it is very clear that you are paying for “Claude Code” which is a combination of an application and a server side component. It makes no claims about API usage as part of your subscription, again the technical implementation of the service you are actually paying for “Claude Code” is irrelevant.When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for, they could be sending the information to Gemini or or a human looks at it. When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for, they could be sending the information to Gemini or or a human looks at it. "Tie-in sale": the business practice where a seller conditions the sale of one product (the tying good) on the buyer's agreement to purchase a different product (the tied good).The examples you are giving are not "tie-in" sales because the service from Playstation Plus, Spotify, Apple Music, etc is the distribution of digital goods.> Unless I am mistaken Claude Code does not have a local model built into it, so it requires a server side component to work?Which part are you not understanding?I don't care about Claude Code. All I care about is the access to the models through the client that I was already using!> When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for.No, it is not! The examples you are giving are not "tie-in" sales because the service from Playstation Plus, Spotify, Apple Music, etc is the distribution of digital goods.> Unless I am mistaken Claude Code does not have a local model built into it, so it requires a server side component to work?Which part are you not understanding?I don't care about Claude Code. All I care about is the access to the models through the client that I was already using!> When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for.No, it is not! > Unless I am mistaken Claude Code does not have a local model built into it, so it requires a server side component to work?Which part are you not understanding?I don't care about Claude Code. All I care about is the access to the models through the client that I was already using!> When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for.No, it is not! Which part are you not understanding?I don't care about Claude Code. All I care about is the access to the models through the client that I was already using!> When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for.No, it is not! All I care about is the access to the models through the client that I was already using!> When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for.No, it is not! > When it comes to “Claude Code” for all that we should care about, again given that “Claude Code” is what you are paying for.No, it is not! I will keep my response to this part in particular limited because I have limited understanding of this law. However based on doing a little bit of searching around the law is not as cut and dry as you are presenting it to be. It is possible that Claude code would fall under being fine under that law or no one has gone after them. It is no different that the people that have a free plan and can only chat through the web and the app also don't get access to the API even though it is obviously using an API to access those endpoints as well.Or are you also going to argue that free users should have access to the API because they are already using them in the browser.> No, it is not! And again not on that list is the API. That being said I do question how exactly “Claude code” differs from those services as a digital good.> I don't care about Claude Code. It is no different that the people that have a free plan and can only chat through the web and the app also don't get access to the API even though it is obviously using an API to access those endpoints as well.Or are you also going to argue that free users should have access to the API because they are already using them in the browser.> No, it is not! And again not on that list is the API. It is no different that the people that have a free plan and can only chat through the web and the app also don't get access to the API even though it is obviously using an API to access those endpoints as well.Or are you also going to argue that free users should have access to the API because they are already using them in the browser.> No, it is not! And again not on that list is the API. It is no different that the people that have a free plan and can only chat through the web and the app also don't get access to the API even though it is obviously using an API to access those endpoints as well.Or are you also going to argue that free users should have access to the API because they are already using them in the browser.> No, it is not! And again not on that list is the API. Or are you also going to argue that free users should have access to the API because they are already using them in the browser.> No, it is not! And again not on that list is the API. And again not on that list is the API. Claude Code is one of the features you are paying for as part of Claude Pro so yes in a way you are paying for it. And again not on that list is the API. If that was true, then getting equivalent usage of the API without claude.ai and Claude Code should cost less, not more.You can try to find all sorts of explanations for it, at the end of the day is quite simple: they are subsidizing one product in order to grow the market share, and they are doing it at a loss now, because they believe they will make up for it later. I understand the reasoning from a business point of view, but this doesn't mean they are entitled to their profits. I do not understand people that think we simply accept their premise and assume they can screw us over just because they asked and put it on a piece of paper. You can try to find all sorts of explanations for it, at the end of the day is quite simple: they are subsidizing one product in order to grow the market share, and they are doing it at a loss now, because they believe they will make up for it later. I understand the reasoning from a business point of view, but this doesn't mean they are entitled to their profits. I do not understand people that think we simply accept their premise and assume they can screw us over just because they asked and put it on a piece of paper. - OpenCode did not break any security protocol in order to integrate with them. - OAuth is *precisely* a system to let third-party applications use their resources. The fact that I was a customer does not mean that I need to protective of their profits.> (from their business perspective)So what? !Basically, they set up an strategy they thought it was going to work in their favor (offer a subsidized service to try to lock in customers), someone else found a way to turn things around and you believe that we should be okay with this? !Honestly, I do not understand why so many people here think it is fine to let these huge corporations run the same exploitation playbook over and over again. Basically they set up a mouse trap full of cheese and now that the mice found a way to enjoy the cheese without getting their necks broken, they are crying about it? - OpenCode did not break any security protocol in order to integrate with them. - OAuth is *precisely* a system to let third-party applications use their resources. The fact that I was a customer does not mean that I need to protective of their profits.> (from their business perspective)So what? !Basically, they set up an strategy they thought it was going to work in their favor (offer a subsidized service to try to lock in customers), someone else found a way to turn things around and you believe that we should be okay with this? !Honestly, I do not understand why so many people here think it is fine to let these huge corporations run the same exploitation playbook over and over again. Basically they set up a mouse trap full of cheese and now that the mice found a way to enjoy the cheese without getting their necks broken, they are crying about it? !Basically, they set up an strategy they thought it was going to work in their favor (offer a subsidized service to try to lock in customers), someone else found a way to turn things around and you believe that we should be okay with this? !Honestly, I do not understand why so many people here think it is fine to let these huge corporations run the same exploitation playbook over and over again. Basically they set up a mouse trap full of cheese and now that the mice found a way to enjoy the cheese without getting their necks broken, they are crying about it? !Basically, they set up an strategy they thought it was going to work in their favor (offer a subsidized service to try to lock in customers), someone else found a way to turn things around and you believe that we should be okay with this? !Honestly, I do not understand why so many people here think it is fine to let these huge corporations run the same exploitation playbook over and over again. Basically they set up a mouse trap full of cheese and now that the mice found a way to enjoy the cheese without getting their necks broken, they are crying about it? Basically, they set up an strategy they thought it was going to work in their favor (offer a subsidized service to try to lock in customers), someone else found a way to turn things around and you believe that we should be okay with this? !Honestly, I do not understand why so many people here think it is fine to let these huge corporations run the same exploitation playbook over and over again. Basically they set up a mouse trap full of cheese and now that the mice found a way to enjoy the cheese without getting their necks broken, they are crying about it? Honestly, I do not understand why so many people here think it is fine to let these huge corporations run the same exploitation playbook over and over again. Basically they set up a mouse trap full of cheese and now that the mice found a way to enjoy the cheese without getting their necks broken, they are crying about it? If something isn't explicitly provided in the contract, then it can be changed at any point in any way without notice.Honestly, I'm not big on capitalism in general, but I don't understand why people should expect companies to provide things exactly the way they want at exactly the prices they would like to be charged (if at all). That's just not how the world/system works, or should, especially given there are so many alternatives available. If one doesn't like what's happening with some service, then let the wallet do the talking and move to another. Emigration is a far more effective message than complaining. Honestly, I'm not big on capitalism in general, but I don't understand why people should expect companies to provide things exactly the way they want at exactly the prices they would like to be charged (if at all). That's just not how the world/system works, or should, especially given there are so many alternatives available. If one doesn't like what's happening with some service, then let the wallet do the talking and move to another. Emigration is a far more effective message than complaining. This is a gross misrepresentation of my argument.I wouldn't be complaining at all if they went up and said "sorry, we are not going to subsidize anyone anymore, so the prices are going up", and I wouldn't be complaining if they came up and said "sorry, using a third party client incurs an extra cost of on our side, so if you want to use that you'd have to pay extra".What I am against is the anti-competitive practice of price discrimination and the tie-in sale of a service. Otherwise it's just a game of "heads I win, tails you lose" where they always get to make up the rules.> Emigration is a far more effective message than complaining.Why not both? I wouldn't be complaining at all if they went up and said "sorry, we are not going to subsidize anyone anymore, so the prices are going up", and I wouldn't be complaining if they came up and said "sorry, using a third party client incurs an extra cost of on our side, so if you want to use that you'd have to pay extra".What I am against is the anti-competitive practice of price discrimination and the tie-in sale of a service. Otherwise it's just a game of "heads I win, tails you lose" where they always get to make up the rules.> Emigration is a far more effective message than complaining.Why not both? Otherwise it's just a game of "heads I win, tails you lose" where they always get to make up the rules.> Emigration is a far more effective message than complaining.Why not both? > Emigration is a far more effective message than complaining.Why not both? There was a third choice, which was better than both of the ones presented: use any other client that can talk with our API, at whatever usage rate they deemed acceptable. If the "private API" was accessible via OAuth, then it's hardly "private".We can argue all day, when I signed up there was nothing saying that access was exclusive via the tools they provided. They changed the rules not because it was costing them more (or even if does, they are losing money on Pro customers anyway so arguing about that is silly) but because they opened themselves for some valid and fair competition. We can argue all day, when I signed up there was nothing saying that access was exclusive via the tools they provided. They changed the rules not because it was costing them more (or even if does, they are losing money on Pro customers anyway so arguing about that is silly) but because they opened themselves for some valid and fair competition. > If the "private API" was accessible via OAuth, then it's hardly "private".If you invite people on your porch for a party, and someone finds that you left the house key under the mat and went off to restock, then it's hardly "private". It's perfectly fine for whomever feels like to take the party indoors without your permission. If you invite people on your porch for a party, and someone finds that you left the house key under the mat and went off to restock, then it's hardly "private". It's perfectly fine for whomever feels like to take the party indoors without your permission. They can try as hard as they want to market it as Claude being the product and access to the model being an ancillary service, but to me this is just marketing bs. Sorry, there is nothing extraordinary about using an undocumented API. Sorry, there is nothing extraordinary about using an undocumented API. Sorry, there is nothing extraordinary about using an undocumented API. The laws prohibiting tie-ins don't make it illegal to sell two products that work well together. That way consumers would go "well it's expensive but I get excel with it so it's ok" and even if someone else made a slightly better spreadsheet they didn't have the chance to convince users because they had to buy it all as one package.Anthropic would be doing something much closer to that if they did what you wanted. They'd be saying: hey we have this neat Claude code thing you all want to use but you can't buy that without also purchasing third party access. Now some company offering a cheaper/better third party usage product doesn't get the chance to convince you because anthropic forced you to buy that just to get claude code.Ultimately this change unbundled products the opposite of a tie-in. Anthropic would be doing something much closer to that if they did what you wanted. They'd be saying: hey we have this neat Claude code thing you all want to use but you can't buy that without also purchasing third party access. Now some company offering a cheaper/better third party usage product doesn't get the chance to convince you because anthropic forced you to buy that just to get claude code.Ultimately this change unbundled products the opposite of a tie-in. Ultimately this change unbundled products the opposite of a tie-in. Those wanting direct access to the internal service can get an API key for that purpose. That's just how their product offering is structured. Anthropic isn't handing out free PCs or forcing people to use them. What I don't understand is why start this game of cat and mouse? YT-DLP, and the dozens of apps that use it, basically use Youtube's unofficial web API and it still works even after Youtube constantly patches their end. Though now, YT-DLP has to use a makeshift JS interpreter and maybe even spawn Chromium down the line. So if they can get away with routing 80% of the requests to Haiku and only route to Opus for the requests that really need it, that does give them a cost model where they can rely on lower costs than if a third-party client just routes to Opus for everything. They still have the total consumption under their control (*bar prompt caching and other specific optimizations) where in the past they even had different quotas per model, it shouldn't cost them more money, just be a worse/different service I guess As things are currently, better models mean bigger models that take more storage+RAM+CPU, or just spend more time processing a request. All this translates to higher costs, and may be mitigated by particular configs triggered by knowledge that a given client, providing particular guarantees, is on the other side. If subsidizing that offering is a good hook to get higher paying API users on board, then some of that cost is a customer aquisition cost, whereas the cost to them of providing the API doesn't have the same proportion that they can justify as a customer acquisition cost. Netflix: limits number of devices and stream quality and offline use.AWS: does not allow any number of applications (spamming, crypto mining, adult content)Airlines: do not allow smoking, boom boxesIs there any service that gives complete freedom? AWS: does not allow any number of applications (spamming, crypto mining, adult content)Airlines: do not allow smoking, boom boxesIs there any service that gives complete freedom? Airlines: do not allow smoking, boom boxesIs there any service that gives complete freedom? There's this pervasive idea left over from the pre-llm days that compute is free. This sounds like engineering, finance, and legal got together and decided they were in an untenable position if OpenAI started nudging OpenClaw to burn even more tokens on Anthropic (or just never optimize) + continually updated workarounds to using subscription auth. But I'm sure OpenAI would never do something like that...At the end of the day, it's the same 'fixed price plan for variable use on a constrained resource' cellular problem: profitability becomes directly linked to actual average usage. Not possible: OpenClaw is run by a foundation, and is open source, which means OpenAI has no leverage to do such a thing. You can of course use OpenCode or any other project with the API, which is also offered as a separate product. I don't use the Anthropic subscriptions either. You are paying for usage via their application.If their business plan is based on how quickly a human can enter requests and react to the results, and Claude Code is optimized for that, why should you be allowed to use an alternative client that e.g. always tries to saturate the token limits? If their business plan is based on how quickly a human can enter requests and react to the results, and Claude Code is optimized for that, why should you be allowed to use an alternative client that e.g. always tries to saturate the token limits? The rate limits aren't everything.If agent harnesses other than Claude Code consume more tokens than average, or rather, if users of agent harnesses other than CC consume more tokens than average, well, Anthropic wouldn't be unhappy if those consumers had to pay more for their tokens. If agent harnesses other than Claude Code consume more tokens than average, or rather, if users of agent harnesses other than CC consume more tokens than average, well, Anthropic wouldn't be unhappy if those consumers had to pay more for their tokens. Probably the ToS change was to make it more clear.To be fair, the developer is the one breaking the ToS in the most significant way, breaking boilerplate reverse engineering clauses.But the user also is very aware that they are doing something funny, in order to authenticate, the user is asked to authorize Claude Code, n ot Opencode or OpenClaw, it's clearly a hack and there is no authorization from Anthropic to OpenClaw, and you are not giving Anthropic authorization to give access to OC, the user asks Anthropic to give access to Claude Code, the only reason this works is because OC is pretending to be Claude Code.The bottom line issue is that as a user you are paying for a subscription to a package that includes an expected usage. That package is not metered, but it is given on the condition that you will use it as it is expected to be used, by chatting manually with the chatbot, which results in a reasonable expected token usage. By using a program that programatically calls the chat interface, the token consumption increases beyond what was part of the original deal, and so the price should be different.A similar scenario would be if you go to an all you can eat buffet, you pay for a single person, but then you actually unload an army of little clones that start eating the whole buffet. Well no, come on, don't play dumb. To be fair, the developer is the one breaking the ToS in the most significant way, breaking boilerplate reverse engineering clauses.But the user also is very aware that they are doing something funny, in order to authenticate, the user is asked to authorize Claude Code, n ot Opencode or OpenClaw, it's clearly a hack and there is no authorization from Anthropic to OpenClaw, and you are not giving Anthropic authorization to give access to OC, the user asks Anthropic to give access to Claude Code, the only reason this works is because OC is pretending to be Claude Code.The bottom line issue is that as a user you are paying for a subscription to a package that includes an expected usage. That package is not metered, but it is given on the condition that you will use it as it is expected to be used, by chatting manually with the chatbot, which results in a reasonable expected token usage. By using a program that programatically calls the chat interface, the token consumption increases beyond what was part of the original deal, and so the price should be different.A similar scenario would be if you go to an all you can eat buffet, you pay for a single person, but then you actually unload an army of little clones that start eating the whole buffet. Well no, come on, don't play dumb. That package is not metered, but it is given on the condition that you will use it as it is expected to be used, by chatting manually with the chatbot, which results in a reasonable expected token usage. By using a program that programatically calls the chat interface, the token consumption increases beyond what was part of the original deal, and so the price should be different.A similar scenario would be if you go to an all you can eat buffet, you pay for a single person, but then you actually unload an army of little clones that start eating the whole buffet. Well no, come on, don't play dumb. That package is not metered, but it is given on the condition that you will use it as it is expected to be used, by chatting manually with the chatbot, which results in a reasonable expected token usage. By using a program that programatically calls the chat interface, the token consumption increases beyond what was part of the original deal, and so the price should be different.A similar scenario would be if you go to an all you can eat buffet, you pay for a single person, but then you actually unload an army of little clones that start eating the whole buffet. Well no, come on, don't play dumb. Well no, come on, don't play dumb. It's just price differentiation - they know consumers are price sensitive, and that companies wanting to use their APIs to build products so they can slap AI on their portfolio and get access to AI-related investor money can be milked. On the consumer-facing front, they live off branding and if you're not using claude code, you might not associate the tool with Anthropic, which means losing publicity that drives API sales. So if they decide to raise prices in whatever shape or form then that's fine.Arbitrary restrictions do play a role for my own purchasing decisions though. Arbitrary restrictions do play a role for my own purchasing decisions though. Also why would you create a throwaway for this question? You should never question anyone's route to privacy :) If you have to ask, it's probably not rage bait. I'm just too lazy to come up with a username. Instead, many, many websites (especially in the music industry) have some sort of funky API that you can only get access to if you have enough online clout. Very few are transparent about what "enough clout" even means or how much it'd cost you, and there's like an entire industry of third-party API resellers that cost like 10x more than if you went straight to the source. Though, in this case, you get free API access to the model. I just think that OAI/Anthropic will try to keep both types of users locked into their walled garden via the UI.The APIs may have a future, but at our own peril and zero guarantees. The APIs may have a future, but at our own peril and zero guarantees. There is nothing here stopping cambridge analytica from doing this again, they will provide whatever details needed. But a small pre launch personal project work that might use a facebook publishing application can't be developed or tested without first going through all the bureaucracy.Nevermind the non profit 'free' application you might want to create on the FB platform, lets say a share chrome extension "Post to my FB", for personal use, you can't do this because you can't create an application without a company and IVA/TAX documents. It's hostile imo.Before, you could create an app, link your ToS, privacy policy etc, verify your domain via email, and then if users wanted to use your application they would agree, this is how a lot of companies still do it. I'm actually not sure why FB do this specifically. Nevermind the non profit 'free' application you might want to create on the FB platform, lets say a share chrome extension "Post to my FB", for personal use, you can't do this because you can't create an application without a company and IVA/TAX documents. It's hostile imo.Before, you could create an app, link your ToS, privacy policy etc, verify your domain via email, and then if users wanted to use your application they would agree, this is how a lot of companies still do it. I'm actually not sure why FB do this specifically. Before, you could create an app, link your ToS, privacy policy etc, verify your domain via email, and then if users wanted to use your application they would agree, this is how a lot of companies still do it. I'm actually not sure why FB do this specifically. Before you can sign up to build a WhatsApp bot, you need to jump through a million hoops, and after that, every automated message template must be vetted by Meta before it can be sent out, apple style.I'm glad of this, because unlike SMS and other messaging platforms, WhatsApp is spam free and a pleasure to use. I'm glad of this, because unlike SMS and other messaging platforms, WhatsApp is spam free and a pleasure to use. At least here in Italy whatsapp is a spam house unless you actively update the default privacy settings in-app. There is no discernable difference between SMS and WhatsApp to spammers. But the real issue is that these companies, once they have any market leverage, do things in their best interest to protect the little bit of moat they've acquired. The usual cycle with startups is to:- Start being very open, as this brings people developing over the platforms and generates growth- As long as they are growing, VC money will come to pay for everything. This is the company phase- Companies then have monetize their users (why not ads? ), close up free, or high-maintenance stuff that do not bring margin- and report that sweet $$$ growth quarter after quarter...until a new startup comes in and starts the cycle over again, destroying all the value the old company had.A mix of Enshittification and Innovators Dilemma theories This is the company phase- Companies then have monetize their users (why not ads? ), close up free, or high-maintenance stuff that do not bring margin- and report that sweet $$$ growth quarter after quarter...until a new startup comes in and starts the cycle over again, destroying all the value the old company had.A mix of Enshittification and Innovators Dilemma theories This is the company phase- Companies then have monetize their users (why not ads? ), close up free, or high-maintenance stuff that do not bring margin- and report that sweet $$$ growth quarter after quarter...until a new startup comes in and starts the cycle over again, destroying all the value the old company had.A mix of Enshittification and Innovators Dilemma theories - Then comes the VC exit, IPO or whatever- Now the new owners don't want user growth, they want margin growth. This is the company phase- Companies then have monetize their users (why not ads? ), close up free, or high-maintenance stuff that do not bring margin- and report that sweet $$$ growth quarter after quarter...until a new startup comes in and starts the cycle over again, destroying all the value the old company had.A mix of Enshittification and Innovators Dilemma theories This is the company phase- Companies then have monetize their users (why not ads? ), close up free, or high-maintenance stuff that do not bring margin- and report that sweet $$$ growth quarter after quarter...until a new startup comes in and starts the cycle over again, destroying all the value the old company had.A mix of Enshittification and Innovators Dilemma theories - Companies then have monetize their users (why not ads? ), close up free, or high-maintenance stuff that do not bring margin- and report that sweet $$$ growth quarter after quarter...until a new startup comes in and starts the cycle over again, destroying all the value the old company had.A mix of Enshittification and Innovators Dilemma theories - and report that sweet $$$ growth quarter after quarter...until a new startup comes in and starts the cycle over again, destroying all the value the old company had.A mix of Enshittification and Innovators Dilemma theories A mix of Enshittification and Innovators Dilemma theories Spotify in particular is just patently the very worst. It feels like their entire ecosystem has only ever gone downhill. https://web.archive.org/web/20141104154131/https://gigaom.co...But also, I feel like this broad repulsive trend is such an untenable position now that AI is here. Trying to make your app an isolated disconnected service is a suicide pact. And they are not going to be stopped even if you do try to control terms!Were I a smart engaged company, I'd be trying to build WebMCP access as soon as possible. Adoption will be slow, this isn't happening fast, but people who can mix human + agent activity on your site are going to be delighted by the experience, and that you will spread!WebMCP is better IMHO than conventional APIs because it layers into the experience you are already having. It's not a separate channel; it can build and use the session state of your browsing to do the things. Trying to make your app an isolated disconnected service is a suicide pact. And they are not going to be stopped even if you do try to control terms!Were I a smart engaged company, I'd be trying to build WebMCP access as soon as possible. Adoption will be slow, this isn't happening fast, but people who can mix human + agent activity on your site are going to be delighted by the experience, and that you will spread!WebMCP is better IMHO than conventional APIs because it layers into the experience you are already having. It's not a separate channel; it can build and use the session state of your browsing to do the things. Adoption will be slow, this isn't happening fast, but people who can mix human + agent activity on your site are going to be delighted by the experience, and that you will spread!WebMCP is better IMHO than conventional APIs because it layers into the experience you are already having. It's not a separate channel; it can build and use the session state of your browsing to do the things. WebMCP is better IMHO than conventional APIs because it layers into the experience you are already having. It's not a separate channel; it can build and use the session state of your browsing to do the things. I totally understand that I should not reuse my own account to provide services to others, as direct API usage is the obvious choice here, but this is a different case.I am currently developing something that would be the perfect fit for this OAuth based flow and I find it quite frustrating that in most cases I cannot find a clear answer to this question. I don't even know who I would be supposed to contact to get an answer or discuss this as an independent dev.EDIT: Some answers to my comment have pointed out that the ToS of Anthropic were clear, I'm not saying they aren't if taken in a vacuum, yet in practice even after this being published some confusion remained online, in particular regarding wether OAuth token usage was still ok with the Agent SDK for personal usage. Also, I am very interested about the stance of other companies on this subject.Maybe I am being overly cautious here but I want to be clear that this is just my personal opinion and me trying to understand what exactly is allowed or not. This is not some business or legal advice. I am currently developing something that would be the perfect fit for this OAuth based flow and I find it quite frustrating that in most cases I cannot find a clear answer to this question. I don't even know who I would be supposed to contact to get an answer or discuss this as an independent dev.EDIT: Some answers to my comment have pointed out that the ToS of Anthropic were clear, I'm not saying they aren't if taken in a vacuum, yet in practice even after this being published some confusion remained online, in particular regarding wether OAuth token usage was still ok with the Agent SDK for personal usage. Also, I am very interested about the stance of other companies on this subject.Maybe I am being overly cautious here but I want to be clear that this is just my personal opinion and me trying to understand what exactly is allowed or not. This is not some business or legal advice. EDIT: Some answers to my comment have pointed out that the ToS of Anthropic were clear, I'm not saying they aren't if taken in a vacuum, yet in practice even after this being published some confusion remained online, in particular regarding wether OAuth token usage was still ok with the Agent SDK for personal usage. Also, I am very interested about the stance of other companies on this subject.Maybe I am being overly cautious here but I want to be clear that this is just my personal opinion and me trying to understand what exactly is allowed or not. This is not some business or legal advice. Maybe I am being overly cautious here but I want to be clear that this is just my personal opinion and me trying to understand what exactly is allowed or not. This is not some business or legal advice. Subscriptions are for first-party products (claude.com, mobile and desktop apps, Claude Code, editor extensions, Cowork).Everything else must use API billing. But they're stating you can only use your subscription for your personal usage, not someone else's for their usage in your product.I honestly think they're being short sighted not just giving a "3rd party quota" since they already show users like 4 quotas.If the fear is 3rd party agents screwing up the math, just make it low enough for entry level usage. I suspect 3rd party token usage is bi-modal where some users just need enough to kick tires, but others are min-maxing for how mamy tokens they can burn as if that's its own reward I honestly think they're being short sighted not just giving a "3rd party quota" since they already show users like 4 quotas.If the fear is 3rd party agents screwing up the math, just make it low enough for entry level usage. I suspect 3rd party token usage is bi-modal where some users just need enough to kick tires, but others are min-maxing for how mamy tokens they can burn as if that's its own reward I suspect 3rd party token usage is bi-modal where some users just need enough to kick tires, but others are min-maxing for how mamy tokens they can burn as if that's its own reward Using OAuth tokens obtained through Claude Free, Pro, or Max accounts in any other product, tool, or service — including the Agent SDK — is not permitted and constitutes a violation of the Consumer Terms of Service. What's not allowed is offering OAuth authentication in your own product built with the SDK: https://x.com/trq212/status/2024212380142752025?s=20 I built a quick thing to download YouTube videos and transcribe them using with whisper, but it kind of feels clunky to summarize them using the claude CLI, even though that works. what if the "product" is a setup of documents that concisely describe the product so that a coding agent can reliable produce it correctly. Now all software is for personal use only. Companies released these things and, like Frankenstein, there's a strong possibility they will turn on their creators. These kinds of business decisions show how these $200.00 subscriptions for their slot/infinite jest machines basically light that $200.00 on fire, and in general how unsustainable these business models are.Can't wait for it all to fail, they'll eventually try to get as many people to pay per token as possible, while somehow getting people to use their verbose antigentic tools that are able to inflate revenue through inefficient context/ouput shenanigans. I used Claude back when API per token pricing was the only option and it was bad for all the usual reasons pay-per-use sucks compared to flat billing: you're constantly thinking about cost. Like trying to watch a Netflix video with a ticker in the corner counting up the cents you owe them.I don't understand your claim that they want people paying per token - the subscription is the opposite of that, and it also has upsides for them as a business since most people don't saturate the usage limits, and the business gets to stuff a bunch of value-adds on a bundle offering which is generally a more lucrative and enticing consumer pricing model. I don't understand your claim that they want people paying per token - the subscription is the opposite of that, and it also has upsides for them as a business since most people don't saturate the usage limits, and the business gets to stuff a bunch of value-adds on a bundle offering which is generally a more lucrative and enticing consumer pricing model. Subscription- oh well, let's try again with a different promptPay per use- I just wasted money, this product sucksEven if it is less common than not, it has an outsized impact on how people feel using it. I expect some big falls from 10 figure businesses in the next year or two as they realize this is impossible. They've built an industry on the backs of gambling addicts and dopamine feins (I'm generalizing but this is a thing with LLM users (just read vibe coders posts on twitter, they're slot machine users). Ask sports betting operators from back in 2019-2022 how it worked out for them when they tried to give out 1-2k a year to attract new customers, and then realized their customers will switch platforms in an instant they see a new shiny offer. Look up the Fanduel Founders "exit" for an insight into this.They have to eventually stop catering to the slot machine users, which are generally paying for these hugely lossy flat rate subscriptions, and somehow get them used to a different type of payment model, or cater strictly to enterprise... Which also aren't going to tolerate paying 20k a month in tokens per developer, is my guess.... Lots of delicate pricing problems to figure out for all these companies. Which also aren't going to tolerate paying 20k a month in tokens per developer, is my guess.... Lots of delicate pricing problems to figure out for all these companies. But I already own my gaming PC that can run local models, and electricity is cheap. this is UNIX and Linux all over again lol. The addictive gaming/gambling mechanics built into llm interfaces has been extensively written on, and its very visible to anyone with an eye for these things. The issue with Claude Code is it's not at all obvious how any given task or query translates to cost. I was finding some days I spent very little and other days cost a fortune despite what seemed to me to be similar levels of usage. https://github.com/rivet-dev/sandbox-agent/tree/main/gigacod... [I saw this inShow HN: Gigacode – Use OpenCode's UI with Claude Code/Codex/Amp] (https://news.ycombinator.com/item?id=46912682)This can make Opencode work with Claude code and the added benefit of this is that Opencode has a Typescript SDK to automate and the back of this is still running claude code so technically should work even with the new TOS?So in the case of the OP. Maybe Opencode TS SDK <-> claude code (using this tool or any other like this) <-> It uses the oauth sign in option of Claude code users?Also, zed can use the ACP protocol itself as well to make claude code work iirc. So is using zed with CC still allowed?> I don't see how they can get more clear about this, considering they have repeatedly answered it the exact same way.This is confusing quite frankly, there's also the claude agent sdk thing which firloop and others talked about too. Maybe Opencode TS SDK <-> claude code (using this tool or any other like this) <-> It uses the oauth sign in option of Claude code users?Also, zed can use the ACP protocol itself as well to make claude code work iirc. So is using zed with CC still allowed?> I don't see how they can get more clear about this, considering they have repeatedly answered it the exact same way.This is confusing quite frankly, there's also the claude agent sdk thing which firloop and others talked about too. Maybe Opencode TS SDK <-> claude code (using this tool or any other like this) <-> It uses the oauth sign in option of Claude code users?Also, zed can use the ACP protocol itself as well to make claude code work iirc. So is using zed with CC still allowed?> I don't see how they can get more clear about this, considering they have repeatedly answered it the exact same way.This is confusing quite frankly, there's also the claude agent sdk thing which firloop and others talked about too. Also, zed can use the ACP protocol itself as well to make claude code work iirc. So is using zed with CC still allowed?> I don't see how they can get more clear about this, considering they have repeatedly answered it the exact same way.This is confusing quite frankly, there's also the claude agent sdk thing which firloop and others talked about too. > I don't see how they can get more clear about this, considering they have repeatedly answered it the exact same way.This is confusing quite frankly, there's also the claude agent sdk thing which firloop and others talked about too. This is confusing quite frankly, there's also the claude agent sdk thing which firloop and others talked about too. You can't use Claude OAuth tokens for anything. Any solution that exists worked because it pretended/spoofed to be Claude Code. Same for Gemini (Gemini CLI, Antigravity)Codex is the only one that got official blessing to be used in OpenClaw and OpenCode, and even that was against the ToS before they changed their stance on it. Codex is the only one that got official blessing to be used in OpenClaw and OpenCode, and even that was against the ToS before they changed their stance on it. Use it when you want a deep integration inside your own product. But I believe OpenAI does let you use their subscription in third parties, so not an issue anyway. A third-party tool may be less efficient in saving costs (I have heard many of them don't hit Anthropic LLMs' caches as well).Would you be willing to pay more for your plan, to subsidize the use of third-party tools by others?---Note, afaik, Anthropic hasn't come out and said this is the reason, but it fits.Or, it could also just be that the LLM companies view their agent tools as the real moat, since the models themselves aren't. If OpenCode or whatever burns through your limits faster, are you likely to place the blame on OpenCode?Maybe a good analogy was when DoorDash/GrubHub/Uber Eats/etc signed up restaurants to their system without their permission. When things didn't go well, the customers complained about the restaurants, even though it wasn't their fault, because they chose not to support delivery at scale.Second, flat-rate pricing, unlike API pricing, is the same for cached vs uncached iirc, so even if total token limits are the same, less caching means higher costs. If OpenCode or whatever burns through your limits faster, are you likely to place the blame on OpenCode?Maybe a good analogy was when DoorDash/GrubHub/Uber Eats/etc signed up restaurants to their system without their permission. When things didn't go well, the customers complained about the restaurants, even though it wasn't their fault, because they chose not to support delivery at scale.Second, flat-rate pricing, unlike API pricing, is the same for cached vs uncached iirc, so even if total token limits are the same, less caching means higher costs. When things didn't go well, the customers complained about the restaurants, even though it wasn't their fault, because they chose not to support delivery at scale.Second, flat-rate pricing, unlike API pricing, is the same for cached vs uncached iirc, so even if total token limits are the same, less caching means higher costs. Second, flat-rate pricing, unlike API pricing, is the same for cached vs uncached iirc, so even if total token limits are the same, less caching means higher costs. Probably, but I get your point that your average user would blame Anthropic instead.> even if total token limits are the same, less caching means higher costsNot really, flat-rate pricing simply gives you a fixed token allotment, so less caching means you consume your 5-hour/weekly allotment faster. > even if total token limits are the same, less caching means higher costsNot really, flat-rate pricing simply gives you a fixed token allotment, so less caching means you consume your 5-hour/weekly allotment faster. Not really, flat-rate pricing simply gives you a fixed token allotment, so less caching means you consume your 5-hour/weekly allotment faster. With a tool that caches suboptimally, you cost Anthropic more per token. They control how fast your subscription tokens are burned They control how fast your subscription tokens are burned They control how fast your subscription tokens are burned Using OAuth tokens obtained through Claude Free, Pro, or Max accounts in any other product, tool, or service — including the Agent SDK — is not permitted and constitutes a violation of the Consumer Terms of Service. I have never noticed there are people who interpret it that way. I'm sure you can use context clues to figure this one out. Advertised usage limits for Pro and Max plans assume ordinary, individual usage of Claude Code and the Agent SDK ""That tool clearly falls under ordinary individual use of Claude code. Perfectly ordinary individual usage.https://yepanywhere.com/sdk-auth-clarification.htmlThe TOS are confusing because just below that section it talks about authentication/credential use. If an app starts reading api keys / credentials, that starts falling into territory where they want a hard line no. Advertised usage limits for Pro and Max plans assume ordinary, individual usage of Claude Code and the Agent SDK ""That tool clearly falls under ordinary individual use of Claude code. Perfectly ordinary individual usage.https://yepanywhere.com/sdk-auth-clarification.htmlThe TOS are confusing because just below that section it talks about authentication/credential use. If an app starts reading api keys / credentials, that starts falling into territory where they want a hard line no. That tool clearly falls under ordinary individual use of Claude code. Perfectly ordinary individual usage.https://yepanywhere.com/sdk-auth-clarification.htmlThe TOS are confusing because just below that section it talks about authentication/credential use. If an app starts reading api keys / credentials, that starts falling into territory where they want a hard line no. https://yepanywhere.com/sdk-auth-clarification.htmlThe TOS are confusing because just below that section it talks about authentication/credential use. If an app starts reading api keys / credentials, that starts falling into territory where they want a hard line no. The TOS are confusing because just below that section it talks about authentication/credential use. If an app starts reading api keys / credentials, that starts falling into territory where they want a hard line no. I can't find anything official from OpenAI, but they have worked with the OpenCode people to support using your ChatGPT subscription in OpenCode. Opus has gone down the hill continously in the last week (and before you start flooding with replies, I've been testing opus/codex in parallel for the last week, I've plenty of examples of Claude going off track, then apologising, then saying "now it's all fixed!" and then only fixing part of it, when codex nailed at the first shot).I can accept specific model limits, not an up/down in terms of reliability. And don't even let me get started on how bad Claude client has become. Others are finally catching up and gpt-5.3-codex is definitely better than opus-4.6Everyone else (Codex CLI, Copilot CLI etc...) is going opensource, they are going closed. I can accept specific model limits, not an up/down in terms of reliability. And don't even let me get started on how bad Claude client has become. Others are finally catching up and gpt-5.3-codex is definitely better than opus-4.6Everyone else (Codex CLI, Copilot CLI etc...) is going opensource, they are going closed. This hostile behaviour is just the last drop. It seems like they currently have a lot of false positives: https://github.com/openai/codex/issues?q=High%20risk That pattern is people complaining that a particular model has degraded in quality of its responses over time or that it has been “nerfed” etc.Although the models may evolve, and the tools calling them may change, I suspect a huge amount of this is simply confirmation bias. Although the models may evolve, and the tools calling them may change, I suspect a huge amount of this is simply confirmation bias. My brain trailed off after "won't be long enough to even finish"... ps: imafish may only be a fan of <https://mumband.bandcamp.com/track/if-i-were-a-fish> But if people really like Codex better, maybe I'll try it. I've been trying not to pay for 2 subscriptions at once but it might be worth a test. It does seem to spend a lot more time “thinking” before giving what feels like equivalent results, most of the time.Probably eats into the gambling-style adrenaline cycles. Opus 4.6 wrote me a working macos application.Codex wrote me a html + css mockup of a macos application that didn't even look like a macos application at all.Opus 4.5 was fine, but I feel that 4.6 is more often on the money on its implementations than 4.5 was. Codex wrote me a html + css mockup of a macos application that didn't even look like a macos application at all.Opus 4.5 was fine, but I feel that 4.6 is more often on the money on its implementations than 4.5 was. I generally don't like the way codex approaches coding itself so I just feed its review comments back in to Claude Code and off we go. In my experience, two different models together works much better than one, that's why this subscription banning is distressing. And there's a good reason the most "famous" vibe coders, including the OpenClaw creator all moved to Codex, it's just better.Claude writes a lot more code to do anything, tons of redundent code, repeated code etc. Codex is only model I've seen which occasionally removes more code than it writes. Codex is only model I've seen which occasionally removes more code than it writes. This was inevitable, I do not understand why we trust these companies, ever. It will be real interesting if the haters are right and this technology is not the breakthrough the investors assume it to be AFTER it is already sewn into everyone's work flows. Everyone keeps talking about how jobs will be displaced, yet few are asking what happens when a dependency is swept out from underneath the industry as a whole if/when this massive gamble doesn't pay off.Whatever. I am squawking into the void as we just repeat history. I am squawking into the void as we just repeat history. First, we are not talking about a cheap service here. We are talking about a monthly subscription which costs 100 USD or 200 USD per month, depending on which plan you choose.Second, it's like selling me a pizza and pretending I only eat it while sitting at your table. I want to eat the pizza at home. I want to eat the pizza at home. I have a feeling Anthropic might be in for an extremely rude awakening when that happens, and I don't think it's a matter of “if” anymore. The latest versions of claude code have been freezing and then crashing while waiting on long running commands. Claude has gotten a lot of popular media attention in the last few weeks, and the influx of users is constraining compute/memory on an already compute heavy model. So you get all the suspected "tricks" like quantization, shorter thinking, KV cache optimizations.It feels like the same thing that happened to Gemini 3, and what you can even feel throughout the day (the models seem smartest at 12am).Dario in his interview with dwarkesh last week also lamented the same refrain that other lab leaders have: compute is constrained and there are big tradeoffs in how you allocate it. It feels like the same thing that happened to Gemini 3, and what you can even feel throughout the day (the models seem smartest at 12am).Dario in his interview with dwarkesh last week also lamented the same refrain that other lab leaders have: compute is constrained and there are big tradeoffs in how you allocate it. Dario in his interview with dwarkesh last week also lamented the same refrain that other lab leaders have: compute is constrained and there are big tradeoffs in how you allocate it. At least weekly I run a set of prompts to compare codex/claude against each other. This is quite easy the prompt sessions are just text files that are saved.The problem is doing it enough for statistical significance and judging the output as better or not. * 4.6 is a lot worse about demonstrating critical details. I'm working through a refactor and I explicitly told it to use a block (as in Ruby Blocks) and it completely overlooked that. What is interesting is that OpenAI and GitHub seem to be taking the opposite approach with Copilot/OpenCode, essentially treating third-party tool access as a feature that increases subscription stickiness. Different bets on whether the LTV of a retained subscriber outweighs the marginal inference cost.Would not be surprised if this converges eventually. Either Anthropic opens up once their margins improve, or OpenAI tightens once they realize the arbitrage is too expensive at scale. Either Anthropic opens up once their margins improve, or OpenAI tightens once they realize the arbitrage is too expensive at scale. I'm rather certain, though cannot prove it, that buying the same tokens would cost at least 10x more if bought from API. Anecdotally, my cursor team usage was getting to around 700$ / month. After switching to claude code max, I have so far only once hit the 3h limit window on the 100$ sub.What Im thinking is that Anthropic is making loss with users who use it a lot, but there are a lot of users who pay for max, but don't actually use it.With the recent improvements and increase of popularity in projects like OpenClaw, the number of users that are generating loss has probably massively increased. What Im thinking is that Anthropic is making loss with users who use it a lot, but there are a lot of users who pay for max, but don't actually use it.With the recent improvements and increase of popularity in projects like OpenClaw, the number of users that are generating loss has probably massively increased. With the recent improvements and increase of popularity in projects like OpenClaw, the number of users that are generating loss has probably massively increased. edit: My $40/month subscription used $662 worth of API credits. I don't entirely mind, and am just considering it an even better work:life balance, but if this is $200 worth of queries, then all I can say is LOL. I'm messing around on document production, I can't imagine being on a crunch facing a deadline or dealing with a production issue and 1) seeing some random fuck-up eat my budget with no take backs (‘sure thing, I'll make a custom docx editor to open that…'), 2) having to explain to my boss why Thursday cost $500 more than expected because of some library mismatch, or 3) trying to decide whether we're gonna spend or wait while stressing some major issue (the LLM got us in it, so we kinda need the LLM to get us out).That's a lot of extra shizz on top of already tricky situations. API limits are infinite but you'd blow through $20 of usage in a maybe 1 hours or less of intense Opus use.The subscription at $20/mo (or $200) allows for vastly more queries than $20 would buy you via API but you are constrained by hourly/weekly limits.The $20/mo sub user will take a lot longer to complete a high token count task (due to start/stop) BUT they will cap their costs. The subscription at $20/mo (or $200) allows for vastly more queries than $20 would buy you via API but you are constrained by hourly/weekly limits.The $20/mo sub user will take a lot longer to complete a high token count task (due to start/stop) BUT they will cap their costs. The $20/mo sub user will take a lot longer to complete a high token count task (due to start/stop) BUT they will cap their costs. Their bet is that most people will not fill up 100% of their weekly usage for 4 consecutive weeks of their monthly plan, because they are humans and the limits impede long running tasks during working hours. I dont like it either, but its not an unreasonable restriction. obviously this WILL happen eventually when they need to pay for things. Banning third-party tools has nothing to do with rate limits. They're trying to position themselves as the Apple of AI companies -a walled garden. They may soon discover that screwing developers is not a good strategy.They are not 10× better than Codex; on the contrary, in my opinion Codex produces much better code. Forcing people to use ONLY a broken Claude Code UX with a subscription only ensures they loose advantage they had. Forcing people to use ONLY a broken Claude Code UX with a subscription only ensures they loose advantage they had. Google AI Pro is like $15/month for practically unlimited Pro requests, each of which take million tokens of context (and then also perform thinking, free Google search for grounding, inline image generation if needed). This includes Gemini CLI, Gemini Code Assist (VS Code), the main chatbot, and a bunch of other vibe-coding projects which have their own rate limits or no rate limits at all.It's crazy to think this is sustainable. Google has made custom AI chips for 11 years — since 2015 — and inference costs them 2-5x less than it does for every other competitor.The landmark paper that invented the techniques behind ChatGPT, Claude and modern AI was also published by Google scientists 9 years ago.That's probably how they can afford it. The landmark paper that invented the techniques behind ChatGPT, Claude and modern AI was also published by Google scientists 9 years ago.That's probably how they can afford it. Google already has a huge competitive advantage because they have more data than anyone else, bundle Gemini in each android to siphon even more data, and the android platform. The TPUs truly make me believe there actually could be a sort of monopoly on LLMs in the end, even though there are so many good models with open weights, so little (technical) reasons to create software that only integrates with Gemini, etc.Google will have a lion‘s share of inferring I believe. OpenAI and Claude will have a very hard time fighting this. Google will have a lion‘s share of inferring I believe. OpenAI and Claude will have a very hard time fighting this. 5h allowance is somewhere between 50M-100M tokens from what I can tell.On 200$ claude code plan you should be burning hundreds of millions of token per day to make anthropic hurt.IMHO subscription plans are totally banking on many users underusing them. Also LLM providers dont like to say exact numbers (how much you get , etc) On 200$ claude code plan you should be burning hundreds of millions of token per day to make anthropic hurt.IMHO subscription plans are totally banking on many users underusing them. Also LLM providers dont like to say exact numbers (how much you get , etc) IMHO subscription plans are totally banking on many users underusing them. Also LLM providers dont like to say exact numbers (how much you get , etc) Most people lose money on their gym subscription, but the convenience takes us. The interesting question is: In what scenario do you see any of the players as being able to stop spending ungodly amounts for R&D and hardware without losing out to the competitors? Why do people keep saying inference is cheap if they're losing so much money from it? You can buy a GPU that's been used to mine bitcoin for 5 years with zero downtime, and as long as it's been properly taken care of (or better, undervolted), that GPU functions the exact same as a 5 year old GPU in your PC. Probably even better.GPUs are rated to do 100%, all the time. GPUs are rated to do 100%, all the time. The only reason they're "perishable" is because of the GPU arms race, where renewing them every 5 years is likely to be worth the investment for the gains you make in power efficiency.Do you think Google has a pile of millions of older TPUs they threw out because they all failed, when chips are basically impossible to recycle ? Do you think Google has a pile of millions of older TPUs they threw out because they all failed, when chips are basically impossible to recycle ? "Synthesizing drugs is cheap - just a few dollars per million pills. "There's plenty of legit criticisms of this business model and Anthropic, but pointing out that R&D companies sink money into research and then charge more than the marginal cost for the final product, isn't one of them. "Synthesizing drugs is cheap - just a few dollars per million pills. "There's plenty of legit criticisms of this business model and Anthropic, but pointing out that R&D companies sink money into research and then charge more than the marginal cost for the final product, isn't one of them. There's plenty of legit criticisms of this business model and Anthropic, but pointing out that R&D companies sink money into research and then charge more than the marginal cost for the final product, isn't one of them. My point was simpler: they're almost certainly not losing money on subscriptions because of inference. They're competing with companies like Kimi and DeepSeek that also spend heavily on R&D but release strong models openly. That means anyone can run inference and customers can use it without paying for bundled research costs.Training frontier models takes months, costs billions, and the model is outdated in six months. I just don't see how a closed, subscription-only model reliably covers that in the long run, especially if you're tightening ecosystem access at the same time. They're competing with companies like Kimi and DeepSeek that also spend heavily on R&D but release strong models openly. That means anyone can run inference and customers can use it without paying for bundled research costs.Training frontier models takes months, costs billions, and the model is outdated in six months. I just don't see how a closed, subscription-only model reliably covers that in the long run, especially if you're tightening ecosystem access at the same time. I just don't see how a closed, subscription-only model reliably covers that in the long run, especially if you're tightening ecosystem access at the same time. They can totally lose money on subscriptions despite the costs of inference, because research costs have to be counted too. Of course they are losing money when you factor in R&D. If AI was truly this productive they wouldn't be struggling so hard to sell their wares. Enterprise products with sufficient market share and "stickiness", will not.For historical precedent, see the commercial practices of Oracle, Microsoft, Vmware, Salesforce, at the height of their power. The software is free (citation: Cuda, nvcc, llvm, olama/llama cpp, linux, etc)The hardware is *not* getting cheaper (unless we're talking a 5+ year time) as most manufacturers are signaling the current shortages will continue ~24 months. The hardware is *not* getting cheaper (unless we're talking a 5+ year time) as most manufacturers are signaling the current shortages will continue ~24 months. If you factor in the cost of integration and ongoing maintenance - by humans or llms - it is not free. Yes, that's the time I'm talking about.You also had a blip with increasing hard disk prices when Thailand flooded a few years ago. We see vendors reducing memory in new smart phones in 2026 vs 2025 for example.At least for the moment falling consumer tech hardware prices are over. At least for the moment falling consumer tech hardware prices are over. I recently encountered this randomly -- knives are apparently one of the few products that nearly every household has needed since antiquity, and they have changed fairly little since the bronze age, so they are used by economists as a benchmark that can span centuries.Source: it was an aside in a random economics conversation with charGPT (grain of salt? ).There is no practical upshot here, but I thought it was cool. Source: it was an aside in a random economics conversation with charGPT (grain of salt? ).There is no practical upshot here, but I thought it was cool. There is no practical upshot here, but I thought it was cool. Not to mention the advances in composite materials for handles.Then you need to look at substitute goods and the what people actually used knives for.A huge amount of the demand for knives evaporated thanks to societal changes and substitute goods like forks. Knives like that exist today but they're not something every household has or needs.This is a good example of why learning from ChatGPT is dangerous. This is a story that sounds very plausible at first glance, but doesn't make sense once you dig in. Not to mention the advances in composite materials for handles.Then you need to look at substitute goods and the what people actually used knives for.A huge amount of the demand for knives evaporated thanks to societal changes and substitute goods like forks. Knives like that exist today but they're not something every household has or needs.This is a good example of why learning from ChatGPT is dangerous. This is a story that sounds very plausible at first glance, but doesn't make sense once you dig in. Then you need to look at substitute goods and the what people actually used knives for.A huge amount of the demand for knives evaporated thanks to societal changes and substitute goods like forks. Knives like that exist today but they're not something every household has or needs.This is a good example of why learning from ChatGPT is dangerous. This is a story that sounds very plausible at first glance, but doesn't make sense once you dig in. A huge amount of the demand for knives evaporated thanks to societal changes and substitute goods like forks. Knives like that exist today but they're not something every household has or needs.This is a good example of why learning from ChatGPT is dangerous. This is a story that sounds very plausible at first glance, but doesn't make sense once you dig in. This is a story that sounds very plausible at first glance, but doesn't make sense once you dig in. It was sticker price of $33,000 adjusted for inflation:https://en.wikipedia.org/wiki/Ford_Taurus_%28second_generati...I don't think it would even feel safe to drive at all compared to what we have got use to with modern cars. No cell phone of course to call anyone.These were the mythic "good ol days". No cell phone of course to call anyone.These were the mythic "good ol days". No cell phone of course to call anyone.These were the mythic "good ol days". I also think we're, as ICs, being given Bentleys meanwhile they're trying to invent Waymos to put us all out of work.Humans are the cost center in their world model. Humans are the cost center in their world model. Finance 101 tldr explanation: The contribution margin (= price per token -variable cost per token ) this is positiveProfit (= contribution margin x cuantity- fix cost) i will not be as bullish to say they will no colapse (0 idear how much real debt and commitments they have, if after the bubble pop spending fall shraply, or a new deepseek moment) but this sound like good trajectory (all things considered) i heavily doubt the 380 billions in valuation"this is how much is spendeed in developers between $659 billion and $737 billion. If the answer is not yes, then they are making money on inference. The sounds like a confession that claude code is somewhat wasteful at token use. What a PR nightmare, on top of an already bad week. I've seen 20+ people on X complaining about this and the related confusion. It's slow to use and so far behind the Codex app that it's embarassing.- Claude Code is buggy has hell and I think I've never used a CLI tool that consume so much memory and CPU. Let's not talk about the feature parity with other agents.- Claude Agent SDK is poorly documented, half finished, and is just thin wrapper around a CLI tool…Oh and none of this is open source, so I can do nothing about it.My only option to stay with their model is to build my own tool. And now I discover that using my subscription with the Agent SDK is against the term of use?I'm not going to pay 500 USD of API credits every months, no way. - Claude Code is buggy has hell and I think I've never used a CLI tool that consume so much memory and CPU. Let's not talk about the feature parity with other agents.- Claude Agent SDK is poorly documented, half finished, and is just thin wrapper around a CLI tool…Oh and none of this is open source, so I can do nothing about it.My only option to stay with their model is to build my own tool. And now I discover that using my subscription with the Agent SDK is against the term of use?I'm not going to pay 500 USD of API credits every months, no way. And now I discover that using my subscription with the Agent SDK is against the term of use?I'm not going to pay 500 USD of API credits every months, no way. Oh and none of this is open source, so I can do nothing about it.My only option to stay with their model is to build my own tool. And now I discover that using my subscription with the Agent SDK is against the term of use?I'm not going to pay 500 USD of API credits every months, no way. And now I discover that using my subscription with the Agent SDK is against the term of use?I'm not going to pay 500 USD of API credits every months, no way. I'm not going to pay 500 USD of API credits every months, no way. It seems to me that other CLI agents are quite far from Claude Code in this regard. What do you mean feature parity with other agents? It seems to me that other CLI agents are quite far from Claude Code in this regard. Meanwhile with Claude Code I've had to get claude to decompile the editor (extract JS from the bun executable) _twice_ to diagnose weird things like why some documented config flags were not taking effect.Opus is great - but I'd rather use a different model than be forced back into Claude Code. Opus is great - but I'd rather use a different model than be forced back into Claude Code. It's funny, you are probably in the cohort that made Antropic have to pursue this type of decision so aggressively. FWIW this aligns completely with the LLM ethos. We are heading toward a $1000/month model just to use LLMs in the cloud. This policy is souring the relationship, and basically saying that Claude isn't a keeper.I'll keep my eye-watering sub for now because it's still working out, but this ensures I won't feel bad about leaving when the time comes.Update: yes yes, API, I know. We're in the part of the market cycle where everyone fights for marketshare by selling dollar bills for 50 cents.When a winner emerges they'll pull the rug out from under you and try to wall off their garden.Anthropic just forgot that we're still in the "functioning market competition" phase of AI and not yet in the "unstoppable monopoly" phase. When a winner emerges they'll pull the rug out from under you and try to wall off their garden.Anthropic just forgot that we're still in the "functioning market competition" phase of AI and not yet in the "unstoppable monopoly" phase. Anthropic just forgot that we're still in the "functioning market competition" phase of AI and not yet in the "unstoppable monopoly" phase. all closed AI model providers will stop selling APIs in the next 2-3 years. Only open models will be available via APIs (…) Closed model providers are trying to build non-commodity capabilities and they need great UIs to deliver those. "~ https://vintagedata.org/blog/posts/model-is-the-product A. Doria> new Amp Free (10$) access is also closed up since of last night ~ https://vintagedata.org/blog/posts/model-is-the-product A. Doria> new Amp Free (10$) access is also closed up since of last night > new Amp Free (10$) access is also closed up since of last night I only use LLMs through OpenRouter and switch somewhat randomly between frontier models; they each have some amount of personality but I wouldn't mind much if half of them disappeared overnight, as long as the other half remained available. I imagine the split will look a lot like b2b vs b2c in other technologies, b2b customers tend to be willing to pay for tech when it offers a competitive advantage, reduces their operating costs etc. (Not quite "every", but outside of tech, most professional workplaces don't support ad blocking or Kagi.) I just don't think this is the same as Google.Of course I could be entirely mistaken and there could emerge a single winner I just don't think this is the same as Google.Of course I could be entirely mistaken and there could emerge a single winner Every time a model gets used by esoteric use cases, it gets more training data (that a decentralized open weight model doesn't get) and it starts developing its moat. (For those unaware, AWS doesn't have a VM monopoly, and the market dynamics seem similar) They bundled it with PC hw and the vast majority of apps only ever got published for windows, and this over decades (one would argue it's still true).The starting point for LLMs is very different. Who would publish today a software that only integrates with chatGPT? The starting point for LLMs is very different. Who would publish today a software that only integrates with chatGPT? More directly, enterprise-software stocks are getting hammered because AI offers them competition. we don't, we have about 3 operating systems that have the decades of hardware and software compatibility that makes them widely usable. They're the most complex and complicated things we've built. This is the least defensible piece of software there ever has been. And if the frontier continues favouring centralised solutions, they'll get it. Just looking at how much Claude complains about me not paying for SSO-tier subscriptions to data tools when they work perfectly fine in a browser is starting to make running a slower, less-capable model locally competitive with it in some research contexts. It almost makes me feel sorry for Dario despite fundamentally disliking him as a person. First of all, custom harness parallel agent people are so far from the norm, and certainly not on the $20 plan, which doesn't even make sense because you'd hit token limit in about 90 seconds.Second, token limits. If I'm paying a blistering monthly fee, I should be able to use up to the limit.Now I know you've got a clear view of the typical user, but FWIW, I'm just an aging hacker using CC to build some personal projects (feeling modern ofc) but still driving, no yolo or gas town style. I've reached the point where I have a nice workflow, and CC is pretty decent, but it feels like it's putting on weight and adding things I don't want or need.I think LLMs are an exciting new interface to computers, but I don't want to be tied to someone else's idea of a client, especially not one that's changing so rapidly. I'd like to roll my own client to interface with the model, or maybe try out some other alternatives, but that's against the TOS, because: reasons.And no, I'm not interested in paying metered corporate rates for API access. I pay for a Max account, it's expensive, but predictable.The issue is Anthropic is trying for force users into using their tool, but that's not going to work for something so generic as interfacing with an LLM. Some folks want emacs while others want vim, and there will never be a consensus on the best editor (it's nvim btw), because developers are opinionated and have strong preferences for how they interface with computers. I don't give a shit about Anthropic's credit liability, I just want the freedom to hack on my own client. If I'm paying a blistering monthly fee, I should be able to use up to the limit.Now I know you've got a clear view of the typical user, but FWIW, I'm just an aging hacker using CC to build some personal projects (feeling modern ofc) but still driving, no yolo or gas town style. I've reached the point where I have a nice workflow, and CC is pretty decent, but it feels like it's putting on weight and adding things I don't want or need.I think LLMs are an exciting new interface to computers, but I don't want to be tied to someone else's idea of a client, especially not one that's changing so rapidly. I'd like to roll my own client to interface with the model, or maybe try out some other alternatives, but that's against the TOS, because: reasons.And no, I'm not interested in paying metered corporate rates for API access. I pay for a Max account, it's expensive, but predictable.The issue is Anthropic is trying for force users into using their tool, but that's not going to work for something so generic as interfacing with an LLM. Some folks want emacs while others want vim, and there will never be a consensus on the best editor (it's nvim btw), because developers are opinionated and have strong preferences for how they interface with computers. I don't give a shit about Anthropic's credit liability, I just want the freedom to hack on my own client. Now I know you've got a clear view of the typical user, but FWIW, I'm just an aging hacker using CC to build some personal projects (feeling modern ofc) but still driving, no yolo or gas town style. I've reached the point where I have a nice workflow, and CC is pretty decent, but it feels like it's putting on weight and adding things I don't want or need.I think LLMs are an exciting new interface to computers, but I don't want to be tied to someone else's idea of a client, especially not one that's changing so rapidly. I'd like to roll my own client to interface with the model, or maybe try out some other alternatives, but that's against the TOS, because: reasons.And no, I'm not interested in paying metered corporate rates for API access. I pay for a Max account, it's expensive, but predictable.The issue is Anthropic is trying for force users into using their tool, but that's not going to work for something so generic as interfacing with an LLM. Some folks want emacs while others want vim, and there will never be a consensus on the best editor (it's nvim btw), because developers are opinionated and have strong preferences for how they interface with computers. I don't give a shit about Anthropic's credit liability, I just want the freedom to hack on my own client. I think LLMs are an exciting new interface to computers, but I don't want to be tied to someone else's idea of a client, especially not one that's changing so rapidly. I'd like to roll my own client to interface with the model, or maybe try out some other alternatives, but that's against the TOS, because: reasons.And no, I'm not interested in paying metered corporate rates for API access. I pay for a Max account, it's expensive, but predictable.The issue is Anthropic is trying for force users into using their tool, but that's not going to work for something so generic as interfacing with an LLM. Some folks want emacs while others want vim, and there will never be a consensus on the best editor (it's nvim btw), because developers are opinionated and have strong preferences for how they interface with computers. I don't give a shit about Anthropic's credit liability, I just want the freedom to hack on my own client. And no, I'm not interested in paying metered corporate rates for API access. I pay for a Max account, it's expensive, but predictable.The issue is Anthropic is trying for force users into using their tool, but that's not going to work for something so generic as interfacing with an LLM. Some folks want emacs while others want vim, and there will never be a consensus on the best editor (it's nvim btw), because developers are opinionated and have strong preferences for how they interface with computers. I don't give a shit about Anthropic's credit liability, I just want the freedom to hack on my own client. The issue is Anthropic is trying for force users into using their tool, but that's not going to work for something so generic as interfacing with an LLM. Some folks want emacs while others want vim, and there will never be a consensus on the best editor (it's nvim btw), because developers are opinionated and have strong preferences for how they interface with computers. I don't give a shit about Anthropic's credit liability, I just want the freedom to hack on my own client. That's not a principled stance about interface freedom, it's just wanting something for less than it costs.The nvim analogy doesn't land either. Nobody's stopping you from writing your own client. Nobody's stopping you from writing your own client. Maybe the API would be cheaper for me, I don't know. I'm just a normal user, not scheduling an agent army to blast at maximum 24/7.You don't need to explain what Anthropic is selling, I get it, but you're off-base claiming that I'm pretending about editor philosophy as cope. I think Anthropic is where they are today because they have a good model for coding, made popular by software folks who value things like editor choice and customization. Anthropic is free to do as they wish of course, as am I, but I'm displeased with their decision here, and voicing my opinion about it.If usage is truly constrained by the client not the server, I guess I can't argue that, but it still feels bad as an end user. But that seems harder to find these days, and most businesses seem intent on maximum extraction by any means possible. I might be wrong, but this feels like business move to build a consumer moat by controlling the interface, because consumers don't want the API. It's not in my best interests, which alienates me as a customer. You don't need to explain what Anthropic is selling, I get it, but you're off-base claiming that I'm pretending about editor philosophy as cope. I think Anthropic is where they are today because they have a good model for coding, made popular by software folks who value things like editor choice and customization. Anthropic is free to do as they wish of course, as am I, but I'm displeased with their decision here, and voicing my opinion about it.If usage is truly constrained by the client not the server, I guess I can't argue that, but it still feels bad as an end user. But that seems harder to find these days, and most businesses seem intent on maximum extraction by any means possible. I might be wrong, but this feels like business move to build a consumer moat by controlling the interface, because consumers don't want the API. It's not in my best interests, which alienates me as a customer. If usage is truly constrained by the client not the server, I guess I can't argue that, but it still feels bad as an end user. But that seems harder to find these days, and most businesses seem intent on maximum extraction by any means possible. I might be wrong, but this feels like business move to build a consumer moat by controlling the interface, because consumers don't want the API. It's not in my best interests, which alienates me as a customer. The only thing I've seen from him that I don't like is the "SWEs will be replaced" line (which is probably true and it's more that I don't like the factuality of it). It's merely the hardware that should be charged for - which ought to drop in price if/when the demand for it rises. However, this is a bottleneck at the moment, and hard to see how it gets resolved amidst the current US environment on sanctioning anyone who would try. And i would also argue that the researchers doing this are built on shoulders of other public knowledge - things funded by public institutions with taxpayer money. The second appears to be hitching my wagon to Mistral even though it's apparently nowhere as powerful or featureful as the big guys. But do you know how many times they've screwed me over? Not once.Maybe it's my use cases that make this possible. I definitely modified my behavior to accommodate Linux. Maybe it's my use cases that make this possible. I definitely modified my behavior to accommodate Linux. Running locally is going to require a lot of memory, compute, and energy for the foreseeable future which makes it really hard to compete with ~$20/mo subscriptions. https://x.com/i/status/2024212378402095389---On a different note, it's surprising that a company that size has to clarify something as important as ToS via X ---On a different note, it's surprising that a company that size has to clarify something as important as ToS via X On a different note, it's surprising that a company that size has to clarify something as important as ToS via X Seriously it feels like half of the EU parliament live on twitter. Plus it's not a real clarification in anyway. Even if it's posted on Mastodon or Github or anywhere, I highly doubt you can use it to defend yourself if you get banned from violating their ToS. But the big guys don't seem interested in this, maybe some lesser known model will carve out this space I shudder to think what the industry will look like if software development and delivery becomes like Youtubing, where the whole stack and monetization is funneled through a single company (or a couple) get to decide who gets how much money. As an independent dev I also unfortunately don't have investors backing me to subsidize inference for my subscription plan. very comparable to sonnet/opus although kimi isn't the best in coding. I think its a really great solid model overall and might just be worth it in your use case?Is the use case extremely coding intensive related (where even some minor improvement can matter for 10-100x cost) or just in general. Because if not, then I can recommend Kimi. Is the use case extremely coding intensive related (where even some minor improvement can matter for 10-100x cost) or just in general. Because if not, then I can recommend Kimi. Please correct me if you feel I'm wrong after reading it. Maybe they are not worth building at all then. And historically, embedded/OEM use cases always have different pricing models for a variety of reasons why.How is this any different than this long established practice? And as a bonus, you can choose your harness. You don't have to suffer CC.And if something better appears tomorrow, you switch your model, while still using your harness of choice. > Authentication and credential use> Claude Code authenticates with Anthropic's servers using OAuth tokens or API keys. These authentication methods serve different purposes:> OAuth authentication (used with Free, Pro, and Max plans) is intended exclusively for Claude Code and Claude.ai. Using OAuth tokens obtained through Claude Free, Pro, or Max accounts in any other product, tool, or service — including the Agent SDK — is not permitted and constitutes a violation of the Consumer Terms of Service.> Developers building products or services that interact with Claude's capabilities, including those using the Agent SDK, should use API key authentication through Claude Console or a supported cloud provider. > Claude Code authenticates with Anthropic's servers using OAuth tokens or API keys. These authentication methods serve different purposes:> OAuth authentication (used with Free, Pro, and Max plans) is intended exclusively for Claude Code and Claude.ai. Using OAuth tokens obtained through Claude Free, Pro, or Max accounts in any other product, tool, or service — including the Agent SDK — is not permitted and constitutes a violation of the Consumer Terms of Service.> Developers building products or services that interact with Claude's capabilities, including those using the Agent SDK, should use API key authentication through Claude Console or a supported cloud provider. Using OAuth tokens obtained through Claude Free, Pro, or Max accounts in any other product, tool, or service — including the Agent SDK — is not permitted and constitutes a violation of the Consumer Terms of Service.> Developers building products or services that interact with Claude's capabilities, including those using the Agent SDK, should use API key authentication through Claude Console or a supported cloud provider. > Developers building products or services that interact with Claude's capabilities, including those using the Agent SDK, should use API key authentication through Claude Console or a supported cloud provider. Doesn't both count towards my usage limits the same? At its core it's a tragedy of commons situation. Using a third party tool like OpenClaw is augmenting your usage far beyond what was anticipated when the subscription plan was made.Same deal for unlimited storage on drive until people started abusing it. Same deal for unlimited storage on drive until people started abusing it. I didn't set the limits on the plan; change those if it's a problem, not irritate your customer base. The issue is not that it's limited or unlimited, but rather about expected token usage across a user cohort. When you set a usage limit on something like Claude, or a gym, or a tutoring center, you need to do two things at once; set the limit high enough to attract the aspirations of your intended client base ("oh good this gym lets me go every day of the month if I want to"), but priced accurately enough so that you actually turn a profit on the average usage across most users (you ended up going 20 times the first month, but settled into 15 times a month after).If there was suddenly a drug that you could take that would, while you slept, make your body walk to the gym and workout, so that you could max out that usage, the gym would be entitled to adjust either the pricing, the limit, or prohibit going to the gym while on the drug, given that they can't actually sustain all their members going every day.As a correction, I've done some reading and when I said tragedy of the commons, what would fit better is a "congestion externality in a  club good". If there was suddenly a drug that you could take that would, while you slept, make your body walk to the gym and workout, so that you could max out that usage, the gym would be entitled to adjust either the pricing, the limit, or prohibit going to the gym while on the drug, given that they can't actually sustain all their members going every day.As a correction, I've done some reading and when I said tragedy of the commons, what would fit better is a "congestion externality in a  club good". Absurd, and not beyond the realm of possibility It's more buying a season pass for Disneyland, then getting told you can't park for free if you're entering the park even though free parking is included with the pass. But 'you can't park even though the ticket includes parking' is not an appropriate analogy because 3rd party use is definitely not intended. They did not 'state one thing' and the 'disallow it'.This is a pretty straight forward case of people using their subscription for 'adjacent' use, and Anthropic being more explicit about it.There's nothing fancy going on here. This is a pretty straight forward case of people using their subscription for 'adjacent' use, and Anthropic being more explicit about it.There's nothing fancy going on here. You're now misinterpreting my argument and misrepresenting it. I did not, in any way, suggest that Anthropic was "pulling the rug" to its users nor that they were entitled to use their tokens using the API with third parties. Full stop.Of course, third-party API usage wasn't intended to be allowed for consuming subscription tokens. This is exactly what my analogy was structured to explain; a Disneyland season pass isn't intended to be used solely for parking. Your analogy missed that last part, which is absolutely crucial to understand.I don't understand how you're making the exact arguments I'm making, then somehow completely misunderstanding what's being said. Of course, third-party API usage wasn't intended to be allowed for consuming subscription tokens. This is exactly what my analogy was structured to explain; a Disneyland season pass isn't intended to be used solely for parking. Your analogy missed that last part, which is absolutely crucial to understand.I don't understand how you're making the exact arguments I'm making, then somehow completely misunderstanding what's being said. This is the moat for AI frontier companies. I think what they want to achieve here is less "kill openclaw" or similar and more "keep our losses under control in general". And now they have a clear criteria to refer when they take action and a good bisection on whom to act on.In case your usage is high they would block / take action. Because if you have your max subscription and not really losing them money, why should they push you (the monopoly incentive sounds wrong with the current market). In case your usage is high they would block / take action. Because if you have your max subscription and not really losing them money, why should they push you (the monopoly incentive sounds wrong with the current market). But Opus is particularly good for "agent with a personality" applications, so it's what thousands of OpenClaw users go with, mostly via the OAuth token, because it's much cheaper than the API. From a backend perspective, the subscription model creates perverse incentives. Third-party tools amplify this asymmetry.Anthropic's move is economically rational but strategically risky. Models are increasingly fungible - Gemini 3.1 and Claude 4.5 produce similar results for most tasks. Given how quickly open-source harnesses like pi have caught up, that's a bold bet. Anthropic's move is economically rational but strategically risky. Models are increasingly fungible - Gemini 3.1 and Claude 4.5 produce similar results for most tasks. Given how quickly open-source harnesses like pi have caught up, that's a bold bet. By forcing users onto Claude Code exclusively, they're betting their tooling moat is stronger than competitor models. Given how quickly open-source harnesses like pi have caught up, that's a bold bet. Also, can you not setup a proxy for the cert and a packet sniffer to watch whatever ClaudeCode is doing with respect to API access? To me, if you have "secret sauce" you have to keep it server side and make the client as dumb as possible. Especially if your client is executes as Javascript. a 200 dollar a month customer isn't trying to get around paying for tokens, theyre trying to use the tooling they prefer. opencode is better in a lot of ways.tokens get counted and put against usage limits anyway, unless theyre trying to eat analytics that are CC exclusive they should allow paying customers to consume to the usage limits in however way they want to use the models. I use opencode everyday; can you explain how claudecode is much different and what it lacks? They have competition if we don't like it. I don't get more requests for free If you are choosing to pay for a subscription instead, it is because Anthropic is offering those subscriptions at a much better value-per-token. This could be used to adhere to Claude's TOS while still allowing the user to switch AI companies at a moment's notice.Right now there's limited customizability in this approach, but I think it's not far-fetched to see FAR more integrated solutions in the future if the lock-in trend continues. For example: one MCP that you can configure into a coding agent like Claude Code that overrides its entire behavior (tools, skills, etc.) Think something similar to the existing IntelliJ IDEA's MCP that gives a separate file edit tool, etc. than the one the agent comes with.Illustration of what i'm talking about:- You install Claude Code with no configuration- Then you install the meta-agent framework- With one command the meta-agent MCP is installed in Claude Code, built-in tools are disabled via permissions override- You access the meta-agent through a different UI (similar to vibe-kanban's web UI)- Everything you do gets routed directly to Claude Code, using your Claude subscription legally. (Input-level features like commands get resolved by meta-agent UI before being sent to claude code)- Claude Code must use the tools and skills directly from meta-agent MCP as instructed in the prompt, and because its own tools are permission denied (result: very good UI integration with the meta-agent UI)- This would also work with any other CLI coding agent (Codex, Gemini CLI, Copilot CLI etc.) should they start getting ideas of locking users in- If Claude Code rug-pulls subscription quotas, just switch to a competitor instantlyAll it requires is a CLI coding agent with MCP support, and the TOS allowing automatic use of its UI (disallowing that would be massive hypocrisy as the AI companies themselves make computer use agents that allow automatic use of other apps' UI) Right now there's limited customizability in this approach, but I think it's not far-fetched to see FAR more integrated solutions in the future if the lock-in trend continues. For example: one MCP that you can configure into a coding agent like Claude Code that overrides its entire behavior (tools, skills, etc.) Think something similar to the existing IntelliJ IDEA's MCP that gives a separate file edit tool, etc. than the one the agent comes with.Illustration of what i'm talking about:- You install Claude Code with no configuration- Then you install the meta-agent framework- With one command the meta-agent MCP is installed in Claude Code, built-in tools are disabled via permissions override- You access the meta-agent through a different UI (similar to vibe-kanban's web UI)- Everything you do gets routed directly to Claude Code, using your Claude subscription legally. (Input-level features like commands get resolved by meta-agent UI before being sent to claude code)- Claude Code must use the tools and skills directly from meta-agent MCP as instructed in the prompt, and because its own tools are permission denied (result: very good UI integration with the meta-agent UI)- This would also work with any other CLI coding agent (Codex, Gemini CLI, Copilot CLI etc.) should they start getting ideas of locking users in- If Claude Code rug-pulls subscription quotas, just switch to a competitor instantlyAll it requires is a CLI coding agent with MCP support, and the TOS allowing automatic use of its UI (disallowing that would be massive hypocrisy as the AI companies themselves make computer use agents that allow automatic use of other apps' UI) Illustration of what i'm talking about:- You install Claude Code with no configuration- Then you install the meta-agent framework- With one command the meta-agent MCP is installed in Claude Code, built-in tools are disabled via permissions override- You access the meta-agent through a different UI (similar to vibe-kanban's web UI)- Everything you do gets routed directly to Claude Code, using your Claude subscription legally. (Input-level features like commands get resolved by meta-agent UI before being sent to claude code)- Claude Code must use the tools and skills directly from meta-agent MCP as instructed in the prompt, and because its own tools are permission denied (result: very good UI integration with the meta-agent UI)- This would also work with any other CLI coding agent (Codex, Gemini CLI, Copilot CLI etc.) should they start getting ideas of locking users in- If Claude Code rug-pulls subscription quotas, just switch to a competitor instantlyAll it requires is a CLI coding agent with MCP support, and the TOS allowing automatic use of its UI (disallowing that would be massive hypocrisy as the AI companies themselves make computer use agents that allow automatic use of other apps' UI) - You install Claude Code with no configuration- Then you install the meta-agent framework- With one command the meta-agent MCP is installed in Claude Code, built-in tools are disabled via permissions override- You access the meta-agent through a different UI (similar to vibe-kanban's web UI)- Everything you do gets routed directly to Claude Code, using your Claude subscription legally. (Input-level features like commands get resolved by meta-agent UI before being sent to claude code)- Claude Code must use the tools and skills directly from meta-agent MCP as instructed in the prompt, and because its own tools are permission denied (result: very good UI integration with the meta-agent UI)- This would also work with any other CLI coding agent (Codex, Gemini CLI, Copilot CLI etc.) should they start getting ideas of locking users in- If Claude Code rug-pulls subscription quotas, just switch to a competitor instantlyAll it requires is a CLI coding agent with MCP support, and the TOS allowing automatic use of its UI (disallowing that would be massive hypocrisy as the AI companies themselves make computer use agents that allow automatic use of other apps' UI) - Then you install the meta-agent framework- With one command the meta-agent MCP is installed in Claude Code, built-in tools are disabled via permissions override- You access the meta-agent through a different UI (similar to vibe-kanban's web UI)- Everything you do gets routed directly to Claude Code, using your Claude subscription legally. (Input-level features like commands get resolved by meta-agent UI before being sent to claude code)- Claude Code must use the tools and skills directly from meta-agent MCP as instructed in the prompt, and because its own tools are permission denied (result: very good UI integration with the meta-agent UI)- This would also work with any other CLI coding agent (Codex, Gemini CLI, Copilot CLI etc.) should they start getting ideas of locking users in- If Claude Code rug-pulls subscription quotas, just switch to a competitor instantlyAll it requires is a CLI coding agent with MCP support, and the TOS allowing automatic use of its UI (disallowing that would be massive hypocrisy as the AI companies themselves make computer use agents that allow automatic use of other apps' UI) - With one command the meta-agent MCP is installed in Claude Code, built-in tools are disabled via permissions override- You access the meta-agent through a different UI (similar to vibe-kanban's web UI)- Everything you do gets routed directly to Claude Code, using your Claude subscription legally. (Input-level features like commands get resolved by meta-agent UI before being sent to claude code)- Claude Code must use the tools and skills directly from meta-agent MCP as instructed in the prompt, and because its own tools are permission denied (result: very good UI integration with the meta-agent UI)- This would also work with any other CLI coding agent (Codex, Gemini CLI, Copilot CLI etc.) should they start getting ideas of locking users in- If Claude Code rug-pulls subscription quotas, just switch to a competitor instantlyAll it requires is a CLI coding agent with MCP support, and the TOS allowing automatic use of its UI (disallowing that would be massive hypocrisy as the AI companies themselves make computer use agents that allow automatic use of other apps' UI) - You access the meta-agent through a different UI (similar to vibe-kanban's web UI)- Everything you do gets routed directly to Claude Code, using your Claude subscription legally. (Input-level features like commands get resolved by meta-agent UI before being sent to claude code)- Claude Code must use the tools and skills directly from meta-agent MCP as instructed in the prompt, and because its own tools are permission denied (result: very good UI integration with the meta-agent UI)- This would also work with any other CLI coding agent (Codex, Gemini CLI, Copilot CLI etc.) should they start getting ideas of locking users in- If Claude Code rug-pulls subscription quotas, just switch to a competitor instantlyAll it requires is a CLI coding agent with MCP support, and the TOS allowing automatic use of its UI (disallowing that would be massive hypocrisy as the AI companies themselves make computer use agents that allow automatic use of other apps' UI) (Input-level features like commands get resolved by meta-agent UI before being sent to claude code)- Claude Code must use the tools and skills directly from meta-agent MCP as instructed in the prompt, and because its own tools are permission denied (result: very good UI integration with the meta-agent UI)- This would also work with any other CLI coding agent (Codex, Gemini CLI, Copilot CLI etc.) should they start getting ideas of locking users in- If Claude Code rug-pulls subscription quotas, just switch to a competitor instantlyAll it requires is a CLI coding agent with MCP support, and the TOS allowing automatic use of its UI (disallowing that would be massive hypocrisy as the AI companies themselves make computer use agents that allow automatic use of other apps' UI) - Claude Code must use the tools and skills directly from meta-agent MCP as instructed in the prompt, and because its own tools are permission denied (result: very good UI integration with the meta-agent UI)- This would also work with any other CLI coding agent (Codex, Gemini CLI, Copilot CLI etc.) should they start getting ideas of locking users in- If Claude Code rug-pulls subscription quotas, just switch to a competitor instantlyAll it requires is a CLI coding agent with MCP support, and the TOS allowing automatic use of its UI (disallowing that would be massive hypocrisy as the AI companies themselves make computer use agents that allow automatic use of other apps' UI) should they start getting ideas of locking users in- If Claude Code rug-pulls subscription quotas, just switch to a competitor instantlyAll it requires is a CLI coding agent with MCP support, and the TOS allowing automatic use of its UI (disallowing that would be massive hypocrisy as the AI companies themselves make computer use agents that allow automatic use of other apps' UI) - If Claude Code rug-pulls subscription quotas, just switch to a competitor instantlyAll it requires is a CLI coding agent with MCP support, and the TOS allowing automatic use of its UI (disallowing that would be massive hypocrisy as the AI companies themselves make computer use agents that allow automatic use of other apps' UI) All it requires is a CLI coding agent with MCP support, and the TOS allowing automatic use of its UI (disallowing that would be massive hypocrisy as the AI companies themselves make computer use agents that allow automatic use of other apps' UI) Also, why not distribute implementation documentation so claudecode can write OpenCode itself and use your oauth token. They are literally alienating a large percentage of OpenClaw, NanoClaw, PicoClaw, customers because those customers will surely not be willing to pay API pricing, which is at least 6-10x Max Plan pricing (for my usage).This isn't too surprising to me since they probably have a direct competitor to openclaw et al in the works right now, but until then I am cancelling my subscription and porting my nanoclaw fork with mem0 integration to work with OpenAI instead.Thats not a “That'll teach ‘em” statement, it is just my own cost optimization. I am quite fond of Anthropic's coding models and might still subscribe again at the $20 level, but they just priced me out for personal assistant, research, and 90% of my token use case. This isn't too surprising to me since they probably have a direct competitor to openclaw et al in the works right now, but until then I am cancelling my subscription and porting my nanoclaw fork with mem0 integration to work with OpenAI instead.Thats not a “That'll teach ‘em” statement, it is just my own cost optimization. I am quite fond of Anthropic's coding models and might still subscribe again at the $20 level, but they just priced me out for personal assistant, research, and 90% of my token use case. Thats not a “That'll teach ‘em” statement, it is just my own cost optimization. I am quite fond of Anthropic's coding models and might still subscribe again at the $20 level, but they just priced me out for personal assistant, research, and 90% of my token use case. in any case Codex is a better SOTA anyways and they let you do this. and if you aren't interested in the best models, Mistral lets you use both Vibe and their API through your vibe subscription api key which is incredible. Many ways, and they're under no obligation to play fair and tell you which way they're using at any given time. You decompile the minified JS code, figure out the protocol, try it from your own code but accidentally mess up a small detail (you didn't realize the nonce has a special suffix). If you share info, they'll probably see it eventually and change their method. They'll probably change it once a month anyway and see who they catch that way (and presumably add a minimum Claude Code version needed to reach their servers).They've got hundreds of super smart coders and one of the most powerful AI models, they can do this all day. So let's say they enforce it by adding an extra nonstandard challenge-response handshake at the beginning of the exchange, which generates a token which they'll expect on all requests going forward. You decompile the minified JS code, figure out the protocol, try it from your own code but accidentally mess up a small detail (you didn't realize the nonce has a special suffix). If you share info, they'll probably see it eventually and change their method. They'll probably change it once a month anyway and see who they catch that way (and presumably add a minimum Claude Code version needed to reach their servers).They've got hundreds of super smart coders and one of the most powerful AI models, they can do this all day. If you share info, they'll probably see it eventually and change their method. They'll probably change it once a month anyway and see who they catch that way (and presumably add a minimum Claude Code version needed to reach their servers).They've got hundreds of super smart coders and one of the most powerful AI models, they can do this all day. If you share info, they'll probably see it eventually and change their method. They'll probably change it once a month anyway and see who they catch that way (and presumably add a minimum Claude Code version needed to reach their servers).They've got hundreds of super smart coders and one of the most powerful AI models, they can do this all day. They've got hundreds of super smart coders and one of the most powerful AI models, they can do this all day. you just need to inspect the network traffic with Claude code and mimic that There are lots of ways they could be doing this. And remember again, if they get you, they don't have to tell you how they got you (so you might not be able to even glean information in return for the $200 you'd be losing).Sure the internet has hundreds of thousands of super smart coders, but the subset who are willing to throw money and credit cards down the drain in order to maintain a circumvention strategy for something like this is pretty low. I'm sure a few people will figure it out, but they won't want to tell anyone lest Anthropic nerf their workaround, so I doubt that exploits of this will become widespread.And if you're Anthropic, that's probably good enough. Sure the internet has hundreds of thousands of super smart coders, but the subset who are willing to throw money and credit cards down the drain in order to maintain a circumvention strategy for something like this is pretty low. I'm sure a few people will figure it out, but they won't want to tell anyone lest Anthropic nerf their workaround, so I doubt that exploits of this will become widespread.And if you're Anthropic, that's probably good enough. And if you're Anthropic, that's probably good enough. There are projects which can do this and hook natively to opencode and even its sdk/api.https://news.ycombinator.com/item?id=47069299#47070204 (I list a project which does this)I really don't know how anthropic can somehow detect something like this. https://news.ycombinator.com/item?id=47069299#47070204 (I list a project which does this)I really don't know how anthropic can somehow detect something like this. I really don't know how anthropic can somehow detect something like this. For example, you can "compact" just portions of the conversation and replace it with a summary. I am not sure how they can detect this. even after this change if you really wanted toBut at this point, to me the question of GP that is that is it even worth it is definitely what I am thinking?I think not. There are better options out there, they mentioned mistral and codex and I think kimi also supports maybe GLM/z.ai as well There are better options out there, they mentioned mistral and codex and I think kimi also supports maybe GLM/z.ai as well There are better options out there, they mentioned mistral and codex and I think kimi also supports maybe GLM/z.ai as well OpenAI will adjust, their investors will not allow money to be lost on ”being nice” forever, not until they're handsomely paid back at least. Start a new service that is relatively permissive, then gradually restrict APIs and permissions. Finally, start throwing in ads and/or making it more expensive to use. Part of the reason is in the beginning they are trying to get as many users as possible and burning VC money. Then once the honey moon is over, they need to make a profit so they cut back on services, nerf stuff, increase prices and start adding ads. If you are using your own hardware and not profiting directly from Claude's use (as in building a service powered by your subscription). I don't see how this is a problem. I am by no means blowing through my usage (usually <50% weekly with max x5). If you are using your own hardware and not profiting directly from Claude's use (as in building a service powered by your subscription). I don't see how this is a problem. I am by no means blowing through my usage (usually <50% weekly with max x5). https://github.com/agentify-sh/desktopDoes this mean I have to remove claude now and go back to copy & pasting prompts for a subscription I am paying for ? Does this mean I have to remove claude now and go back to copy & pasting prompts for a subscription I am paying for ? I'm more surprised by people using subscription auth for OpenClaw when its officially not allowed. I'm just going to accept that my €15 (which with vat becomes €21) is just enough usage to automate some boring tasks. It suggests to me Anthropic is less concerned with the financial impact of letting subscribers use alternative tools and more concerned with creating lock in to their products and subscriptions. It very well might backfire though, I was not considering alternative models yesterday, but today I am actively exploring other options and considering cancelling my sub. I've been using my subscription primarily through pi recently, so if they aren't interested in me as a customer, pretty much everyone else is. Things get banned, but that is OK along as they give us weeks or days to prep for alternative solution. Judging from account opening time and comments we can also tell the age group and which camp they are on. Such artificial "moats" are great for companies but harmful to consumers. Such artificial "moats" are great for companies but harmful to consumers. I can get a ridiculous amount of tokens in and out of something like gpt-5.2 via the API for $100.Is this primarily about gas town and friends? Is this primarily about gas town and friends? - Google reduced AI Studio's free rate limits by 1/10th- Perplexity imposing rate limits, card filing to continue free subscriptions- Now Anthropic as wellThere has been a false narrative that AI will get cheaper and more ubiquitous, but model providers have been stuck in a race for ever more capabilities and performance at higher costs. - Perplexity imposing rate limits, card filing to continue free subscriptions- Now Anthropic as wellThere has been a false narrative that AI will get cheaper and more ubiquitous, but model providers have been stuck in a race for ever more capabilities and performance at higher costs. - Now Anthropic as wellThere has been a false narrative that AI will get cheaper and more ubiquitous, but model providers have been stuck in a race for ever more capabilities and performance at higher costs. There has been a false narrative that AI will get cheaper and more ubiquitous, but model providers have been stuck in a race for ever more capabilities and performance at higher costs. Trying to prevent competitors from interoperating with the service also may be construed as anticompetitive behaviour.The implementation details of an authentication process do not beget legal privileges to be a monopolist. The implementation details of an authentication process do not beget legal privileges to be a monopolist. So it makes sense to offer simple flat pricing for first party apps, and usage priced apis for other usage. It's like the difference between Google Drive and S3. They're losing the exact crowd that they want in their corner because it's the crowd that's far more likely to be making the decisions when companies start pivoting their workflows en-masse. Can't this restriction for the time being be bypassed via -p command line flag? We're still collectively figuring out the best way to use models in software, this TOS change kills innovation. But if you're doing something very basic, you might be able to slop together a tool that does local inferencing based on a small, local model instead, alleviating the need to call Claude entirely. Instead of using SDKs, this will just shift the third party clients to use ACP to get around it - Claude Code is still under the hood but you're using a different interface.This all seems pretty idiotic on their part - I know why they're trying it but it won't work. There will always be someone working around it. There will always be someone working around it. Anthropic = goodGoogle = evilThat's pretty much HN crowd logic to be honest Google = evilThat's pretty much HN crowd logic to be honest That's pretty much HN crowd logic to be honest So, I guess it's time to look into OpenAI Codex. Opencode with CC underneath using Gigacode?OpenAI codex is also another viable path for what its worth.I think the best model to my liking open source is kimi k2.5, so maybe you can run that?Qwen is releasing some new models so I assume keep an eye on those and maybe some model can fit your use case as well? OpenAI codex is also another viable path for what its worth.I think the best model to my liking open source is kimi k2.5, so maybe you can run that?Qwen is releasing some new models so I assume keep an eye on those and maybe some model can fit your use case as well? I think the best model to my liking open source is kimi k2.5, so maybe you can run that?Qwen is releasing some new models so I assume keep an eye on those and maybe some model can fit your use case as well? Qwen is releasing some new models so I assume keep an eye on those and maybe some model can fit your use case as well? It's a little bit sleazy as a business model to try to wedge one's self between Claude and its users.OpenAI acquiring OpenClaw gives me bad vibes. It doesn't seem organic.I definitely feel much more aligned with Anthropic as a company. What they do seems more focused, meritocratic, organic and genuine.OpenAI essentially appropriated all their current IP from the people... They basically gutted the non-profit and stole its IP. Then they used media spin to make it sound like they appropriated it from Elon because Elon donated a few millions... I mean let's not even mention Suchir Balaji, the OpenAI researcher who supposedly "committed suicide" after trying to warn everyone about the stolen IP.OpenAI is clearly trying to slander Anthropic, trying to present themselves as the good guys after their OpenClaw acquisition and really rubbing it in all over HN... Over which they have much influence. It doesn't seem organic.I definitely feel much more aligned with Anthropic as a company. What they do seems more focused, meritocratic, organic and genuine.OpenAI essentially appropriated all their current IP from the people... They basically gutted the non-profit and stole its IP. Then they used media spin to make it sound like they appropriated it from Elon because Elon donated a few millions... I mean let's not even mention Suchir Balaji, the OpenAI researcher who supposedly "committed suicide" after trying to warn everyone about the stolen IP.OpenAI is clearly trying to slander Anthropic, trying to present themselves as the good guys after their OpenClaw acquisition and really rubbing it in all over HN... Over which they have much influence. I definitely feel much more aligned with Anthropic as a company. What they do seems more focused, meritocratic, organic and genuine.OpenAI essentially appropriated all their current IP from the people... They basically gutted the non-profit and stole its IP. Then they used media spin to make it sound like they appropriated it from Elon because Elon donated a few millions... I mean let's not even mention Suchir Balaji, the OpenAI researcher who supposedly "committed suicide" after trying to warn everyone about the stolen IP.OpenAI is clearly trying to slander Anthropic, trying to present themselves as the good guys after their OpenClaw acquisition and really rubbing it in all over HN... Over which they have much influence. OpenAI essentially appropriated all their current IP from the people... They basically gutted the non-profit and stole its IP. Then they used media spin to make it sound like they appropriated it from Elon because Elon donated a few millions... I mean let's not even mention Suchir Balaji, the OpenAI researcher who supposedly "committed suicide" after trying to warn everyone about the stolen IP.OpenAI is clearly trying to slander Anthropic, trying to present themselves as the good guys after their OpenClaw acquisition and really rubbing it in all over HN... Over which they have much influence. OpenAI is clearly trying to slander Anthropic, trying to present themselves as the good guys after their OpenClaw acquisition and really rubbing it in all over HN... Over which they have much influence. > The companies that will win long-term are the ones building open protocols and letting users bring their own model.These seem contradictory. The future I see is open source harnesses talking to commodity models. The future I see is open source harnesses talking to commodity models. Perhaps there's enough overlap among the low hanging fruit that you can initially sell a harness that makes both genomics researchers and urban planners happy... but pretty quickly you're going to need to be the right kind of specialist to build an effective harness for it. Try it: write your own harness with (bash, read, write, edit) ... it's trivial to get a 99% version of (pick your favorite harness) -- minus the bells and whistles.The "magic of the harness" comes from the fun auxiliary orchestration stuff - hard engineering for sure! It turns out that "most of the bell and whistles" could amount to instructing models how to use tools like tmux Unfortunately neither political party can get all of the above. People self-hosting don't look at their electricity bill. So, which two parties could they be referring to? All that to say, don't let the naysayers get you down. I bought my Mac Mini last week and have been really happy with it as an isolated environment. The always-on nature of OpenClaw means that it's nice to be able to restart my personal laptop or do gaming or whatever else I want and I'm not fighting for GPU resources in the background. It was animating a blue dot with my real time position at the same time.Don't get me started about the new iOS 26 notification and messaging filters. Those are causing real harm multiple times a day. Don't get me started about the new iOS 26 notification and messaging filters. Those are causing real harm multiple times a day. The markets value recurring subscription revenue at something like 10x “one-off” revenue, Anthropic is leaving a lot of enterprise value on the table with this approach.In practice this approach forces AI apps to pay Anthropic for tokens, and then bill their customers a subscription. And many categories of free app are simply excluded, which could in aggregate drive a lot more demand for subscriptions.If Anthropic is worried about quota, seems they could set lower caps for third-party subscription usage? (Maybe this is purely about displacing other IDE products, rather than a broader market play.) In practice this approach forces AI apps to pay Anthropic for tokens, and then bill their customers a subscription. And many categories of free app are simply excluded, which could in aggregate drive a lot more demand for subscriptions.If Anthropic is worried about quota, seems they could set lower caps for third-party subscription usage? (Maybe this is purely about displacing other IDE products, rather than a broader market play.) If Anthropic is worried about quota, seems they could set lower caps for third-party subscription usage? (Maybe this is purely about displacing other IDE products, rather than a broader market play.) (Maybe this is purely about displacing other IDE products, rather than a broader market play.) Allows them to optimize their clients and use private APIs for exclusive features etc. and there's really no reason to bootstrap other wannabe AI companies who just stick a facade experience in front of Anthropic's paying customer. Tell me if they are eating losses or not. I'm not making a point, actually do it and let me know. That means I'm subsidizing them (paying 3-4 times what it would cost with the API)! Over 9 days I would have spent roughly $63 dollars on Codex with 11.5M input tokens plus 141M cached input tokens and 1.3M output tokens.That roughly mirrors the $100-200/wk in API spending that drove me to the subscription. This is a 30/d window and I only used it for 9 days, $63 worth. OpenAI kept the other $137.It makes sense though for heavy use. This is a 30/d window and I only used it for 9 days, $63 worth. OpenAI kept the other $137.It makes sense though for heavy use. This is a 30/d window and I only used it for 9 days, $63 worth. OpenAI kept the other $137.It makes sense though for heavy use. DeepSeek has the tendency to think... a lot!. Without a good harness I can't evaluate it well; time will tell.OpenAI doesn't; it's embedded into the price, I think.Cheap = we can run 10x the workloads, bigger imagination = innovation. Maybe 10 dumb agents in a loop can beat 1 Opus? Maybe 10 dumb agents in a loop can beat 1 Opus? Cheap = we can run 10x the workloads, bigger imagination = innovation. Maybe 10 dumb agents in a loop can beat 1 Opus? I don't think Anthropic has any desire to be some B2C platform, they want high paying reliable customers (B2B, Enterprise). Cloud goes on the books as recurring revenue, not one-off; even though it's in principle elastic, in practice if I pay for a VM today I'll usually pay for one tomorrow. (I don't have the numbers but the vast majority of cloud revenue is also going to be pre-committed long-term contracts from enterprises. )> I don't think Anthropic has any desire to be some B2C platformThis is the best line of argument I can see. (I don't have the numbers but the vast majority of cloud revenue is also going to be pre-committed long-term contracts from enterprises. )> I don't think Anthropic has any desire to be some B2C platformThis is the best line of argument I can see. > I don't think Anthropic has any desire to be some B2C platformThis is the best line of argument I can see. This is the best line of argument I can see.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2026/nasa-smooth-rehearsal-artemis-2-moon-launch/'>NASA completes a smooth rehearsal for historic Artemis 2 moon launch</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 04:02:12
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>NASA counted down to T-minus 29 seconds during a smooth rehearsal for a historic launch that could send astronauts around the moon for the first time in more than half a century. The run-through at Launch Complex 39B, at Kennedy Space Center in Florida, was known as a wet dress rehearsal because it involved filling up the propellant tanks on NASA's Space Launch System, a 322-foot-tall rocket that made its debut with 2022's uncrewed Artemis 1 mission. Lori Glaze, acting associate administrator for NASA's Exploration Systems Development Mission Directorate, said the space agency is targeting March 6 for liftoff. This week's simulated countdown provided an opportunity for NASA to check out the Space Launch System rocket, the Orion crew capsule and ground support systems in advance of the actual launch. An initial rehearsal on Feb. 2 was stopped at roughly T-minus 5 minutes due to a liquid hydrogen leak. But the count eventually proceeded as planned to T-minus 33 seconds. At that point the countdown was paused and recycled to T-minus 10 minutes. It took about an hour to reconfigure the rocket's fueling system for another terminal count. Then NASA's launch team went through an even smoother second countdown and reached the scheduled stopping point at T-minus 29 seconds. Charlie Blackwell-Thompson, Artemis 2's launch director, said the maximum hydrogen leak rate during fueling was 1.6% — far below NASA's 16% limit. “Really no leakage to speak of,” she said. John Honeycutt, the chair of Artemis 2's Mission Management Team, had a similarly positive assessment. “Overall it was a good day for us,” he said. The four crew members for Artemis 2 are due to go into quarantine today. In addition to Wiseman, the crew includes NASA astronauts Christina Koch and Victor Glover, plus Canadian astronaut Jeremy Hansen. Glaze said the crew was in Florida for this week's rehearsal, but will start their quarantine back in Texas. That mission is officially set for no earlier than mid-2027, but industry experts expect the schedule to slip. A facility in Redmond operated by L3Harris (previously known as Aerojet Rocketdyne) builds thrusters for the Orion spacecraft — and Jeff Bezos' Blue Origin space venture, based in Kent, is developing a Blue Moon lander that's meant to put Artemis crews on the lunar surface starting in 2030. Blue Origin's New Glenn rocket is expected to send an uncrewed cargo version of its lander to the moon sometime in the next few months. This report has been updated with information from today's NASA news conference. Click for more about underwritten and sponsored content on GeekWire. Have a scoop that you'd like GeekWire to cover?</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2026/ballmer-bezos-sir-mix-a-lot-seahawks-sale-draws-more-hot-takes-on-potential-owners-and-price/'>Ballmer? Bezos? Sir Mix-a-Lot? Seahawks sale draws more hot takes on potential owners and price</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2026-02-20 00:52:08
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>“The Rich Eisen Show” on ESPN / Disney+ weighed in Thursday (above) with a flurry of Seattle-connected names who could step in to buy the NFL franchise — some serious and some not so much. Eisen said that the late Microsoft co-founder Paul Allen bought the team for about $140 million and change in 1997, and that while he's not an investor, Eisen knows the 2026 price tag “is gonna be more than that.” But Eisen listed Bellevue, Wash.-based ex-Microsoft CEO and Los Angeles Clippers owner Steve Ballmer as perhaps the most legitimate billionaire name on their speculative list. There's a belief in league circles that Jeff Bezos will not be in play for the team, says Mike Florio of NBC's “Pro Football Talk,” reiterating that while the Amazon founder lived in Seattle for 30 years, he's now an East Coast guy down in Miami. “We'll see, because obviously if he wants it he's gonna get it,” Florio said of Bezos in a nod to his $231 billion net worth. The bigger possibility, according to Florio, is that there's a tech billionaire out there “that we don't know about, who's gonna show up with the biggest bag of money.” “I'll be surprised if it's less than 9 [billion], I won't be surprised if it's more than 10,” he said. A concern for Seahawks fans, Florio says, is that a new owner comes in, and despite the turnkey and move-in ready appearance of the championship team, that owner will want to put his or her stamp on things. Click for more about underwritten and sponsored content on GeekWire. Have a scoop that you'd like GeekWire to cover? Microsoft co-founder Paul Allen's estate plans to sell NBA franchise Seattle Seahawks are for sale as Paul Allen estate seeks buyer shortly after Super Bowl win Want to own a piece of the Seahawks? Seattle startup presents its private equity idea to fans</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            