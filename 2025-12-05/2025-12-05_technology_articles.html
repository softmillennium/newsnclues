
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - TECHNOLOGY Article Summaries - 2025-12-05</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            TECHNOLOGY
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/microsoft-shareholders-invoke-orwell-and-copilot-as-execs-tout-generational-moment/'>Microsoft shareholders invoke Orwell and Copilot as Nadella cites ‘generational moment'</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 18:52:51
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Flaig invoked Orwell's dystopian vision of surveillance and thought control, citing the Ministry of Truth that “rewrites history and floods society with propaganda.” He then turned to Copilot, which responded to his query about an AI-driven future by noting that “the risk lies not in AI itself, but in how it's deployed.” Nadella said Microsoft has moved beyond abstract principles to “everyday engineering practice,” with safeguards for fairness, transparency, security, and privacy. Brad Smith, Microsoft's vice chair and president, said broader societal decisions, like what age kids should use AI in schools, won't be made by tech companies. He cited ongoing debates about smartphones in schools nearly 20 years after the iPhone. “I think quite rightly, people have learned from that experience,” Smith said, drawing a parallel to the rise of AI. Microsoft's board recommended that shareholders vote against all six outside proposals, which covered issues including AI censorship, data privacy, human rights, and climate. Final vote tallies have yet to be released as of publication time, but Microsoft said shareholders turned down all six, based on early voting. Satya Nadella's pay tops $96M as Microsoft stock soars; Walmart CFO set to join board Bitcoin gets almost no support from Microsoft shareholders, as AI data scrutiny tops voting Amazon shareholders reject oversight proposals as Andy Jassy disputes AI cutback claims</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/stars-on-the-ceiling-cher-on-the-speakers-notes-from-our-first-ride-in-amazons-zoox-robotaxi/'>Stars on the ceiling, Cher on the speakers: Notes from our first ride in Amazon's Zoox robotaxi</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 17:38:18
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Amazon's Zoox robotaxi service launched in Las Vegas this fall, and a few members of the hard-working GeekWire Studios crew joined me to try it out for a ride to dinner after a long day at AWS re:Invent. Zoox was nothing short of a hit with our group. The consensus: it was a smooth, futuristic shuttle ride that felt safe amid the Las Vegas chaos, with per-seat climate control, and customizable music. Zoox, founded in 2014, was acquired by Amazon in 2020 for just over $1 billion, marking the tech giant's move into autonomous vehicle technology and urban mobility. Zoox operates as an independent subsidiary, based in Foster City, Calif.​​ Unlike competitors that retrofit vehicles, Zoox designed its robotaxi from scratch. It's a compact, 12-foot-long electric pod, bidirectional, without steering wheel or pedals. A few of us had experienced Waymo in California, so it was natural to make the comparison. For this current phase of the Vegas rollout, one major downside is the limited service area — just seven fixed spots along the Las Vegas strip, like Resorts World, Luxor, and AREA15, requiring walks between hubs rather than seamless point-to-point hails. But hey, the rides are free for now, so it's hard to complain. And the ability to sit across from each other more than made up for any minor quibbles. (Our group of five split up and took two four-person carriages from Fashion Show Mall to Resorts World.) Compared to the Waymo experience, the Zoox vehicle feels less like sitting in a car and more like sharing a moving living room. “It felt very Disneyland,” said GeekWire Studios host Brian Westbrook, citing the creature comforts such as climate control that seemed to be isolated to each seat. GeekWire project manager Jessica Reeves said she almost forgot that there wasn't a human driving. “It didn't feel like I was riding in an autonomous vehicle, maybe it was just the buzz of experiencing this new way of transportation,” Jessica messaged me afterward, reflecting on the experience. “It felt less like a vehicle and more like a mobile karaoke studio with the customized climate control and ability to choose your music — Cher in Vegas, perfect!” Holly said. On that point: Zoox's purpose-built pod is engineered to reach highway speeds of up to about 75 mph, and the company has tested it at those velocities on closed tracks. In Las Vegas, though, the robotaxis currently stick to surface streets at lower speeds, and Zoox hasn't yet started mixing into freeway traffic. The Vegas service launch marked Zoox's first public robotaxi deployment, offering free rides along a fixed loop on and around the Strip while gathering data for paid trips. It's not hard to imagine similar vehicles shuttling packages in the future. The company has flagged Austin, Miami, Los Angeles, Atlanta, Washington, D.C., and Seattle as longer-term potential markets for the robotaxi service as regulations and technology mature. We've contacted Zoox for the latest update on its plans. If our own ride this week was any indication, the company's biggest challenge may simply be expanding the robotaxi service fast enough for more people to try it. The chips powering your smart TV, voice assistant, tablet, and car all have something in common: MediaTek Click for more about underwritten and sponsored content on GeekWire. Click for more about underwritten and sponsored content on GeekWire. Amazon will pay $3.7M to settle labor claims in Seattle for alleged gig worker ordinance violations The hot new thing at AWS re:Invent has nothing to do with AI Amazon's Zoox reaches robotaxi milestone with launch of service in Las Vegas Microsoft will take $800 million charge on Cruise investment as GM exits robotaxi business Waymo to start testing and ‘laying groundwork' for driverless taxi service in Seattle area</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/washington-state-lawmaker-says-proposed-payroll-tax-could-benefit-large-tech-companies/'>Washington state lawmaker says proposed payroll tax could benefit large tech companies</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 17:18:53
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>A newly proposed payroll tax would add new costs for large businesses in Washington state. “People are looking to the state legislature for leadership on protecting the programs that make our state actually a healthy climate to do business in,” Scott told GeekWire this week. House Bill 2100, pre-filed this week in Olympia, would create the “Well Washington Fund” and levy a 5% payroll expense tax on “large operating companies” for employee wages above a $125,000 threshold. Employers with total employee wages under $7 million in the prior year would be exempt. Scott is pitching the bill as a state backstop against federal cuts hitting Medicaid, higher education, housing and other programs. Seattle-based companies such as Amazon that already pay the city's JumpStart payroll tax would be exempt. Scott said there is a “corollary effect” on corporations from policies that benefit “everyday people.” Rachel Smith, the new CEO of Washington Roundtable, called it a “tax-first, plan later” idea. She also cited the state's recent tax increases impacting businesses — passed in part to help address a $16 billion budget shortfall — and broader economic uncertainty. Lawmakers tried to pass a similar statewide payroll tax this year, but the bill did not advance. Microsoft declined to comment on Rep. Scott's proposal when contacted by GeekWire this week. Rep. Scott said it's “disingenuous” that critics raise alarms about companies leaving when the state talks about funding the safety net, but don't ask similar questions when companies cut jobs on their own. He said the relocation question “does not come up when we see large tech firms investing in artificial intelligence, which is designed to divest from human labor.” Most state revenue comes from sales, property, and B&O taxes — a system critics say disproportionately burdens lower-income residents. Gabriella Buono, interim president and CEO at the Seattle Metro Chamber, said that “raising taxes in an affordability crisis will mean higher prices on everyday essentials, fewer job opportunities, and more closures in sectors that are already on the edge.” “Voters across the political spectrum are clear: they want smart spending, transparency, and results, not new taxes that make it harder to live and work in this state,” Buono said in a statement. Washington's proposed statewide payroll tax sparks backlash from tech industry and local leaders</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/12/05/new-streaming-channel-launches-to-give-viewers-a-peek-into-city-council-meetings/'>New streaming channel launches to give viewers a peek into city council meetings</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 17:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The launch of Hamlet was quite personal for Sunil Rajaraman. Since COVID, towns across the nation have started recording and posting their city meetings online. “We use AI to process thousands of hours of city council and planning commission meeting videos and turn them into intelligence they can actually use,” he said. At first, he thought it would be a media company, but then real estate developers and political action committees started reaching out. Rajaraman realized that private companies have to deal with local governments, too, and they also want more insight into what is happening in those city council meetings. For enterprise customers, the company helps track agendas and alerts them when relevant topics are addressed across target cities. It also synthesizes what happened after meetings, so they don't have to watch hourslong videos, and it lets them search the video archive to see, for example, when and how a competitor was mentioned in a local government setting. On Friday, Rajaraman announced he is expanding the company to launch Hamlet TV as a way to help keep regular citizens informed of what is happening inside their governments. “We've seen meetings that have lasted 15-plus hours without recess,” he said. He and his team started curating funny moments from those meetings, and they thought it was a good idea to use humor to get people more invested in the U.S. democracy. “If you show people procedural videos, they are just not going to care. But if you show them the funny stuff, they'll watch.” The most surprising thing he and his team have seen so far on Hamlet TV has been someone dressing up as a cockroach to address their city council about a pest problem. But it's not the funny stuff that surprises him, he said. He cited an example from earlier this year when the Tucson city council rejected Amazon's $3.6 billion data center. He said that the decision came after months of planning, but only a few people likely watched those videos to understand why it happened. He also ran a publication called The Bold Italic and then sold it to Medium. He knows Hamlet TV probably won't be a moneymaker and reiterated that he's doing this to get people more involved with the state of the country's democracy. “Data is great, but context matters so much,” he said. Next, the Hamlet company is looking to work with government affairs, advocacy organizations, and renewable energy developers. Dominic-Madori Davis is a senior venture capital and startup reporter at TechCrunch. Show your CFO the marketing proof they want!Join a free webinar hosted by Pantheon on Tuesday December 9 at 10am PT to learn where spend delivers & how to build a 2026 strategy grounded in real results. Andy Jassy says Amazon's Nvidia competitor chip is already a multibillion-dollar business Apple just named a new AI chief with Google and Microsoft expertise, as John Giannandrea steps down</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=46163121'>I'm Peter Roberts, immigration attorney who does work for YC and startups. AMA</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 16:05:17
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>I visit the US for work every now and then. I heard a lot of horror stories regarding border entries. If I am ever in a situation where the border police asks for access to my personal phone and pin code, what are my options? Can I refuse and what happens then? Peter might have good insights on whether the relevant case law has changed since 2017 though. Does the government have any direct link to meta re what accounts people actually have. I'm surprised people aren't up in arms about this, I guess it affects mostly visitors and immigrants but the fact that the government needs to see your activity on a private company's web app is wild to me. You'd presumably have to answer with HN, which maybe doesn't sound all that great :) The educational institution sent the student's home address some tax form that he had to file by April 15, but the former student forgot to do that.The question is: would the student have problems getting a U.S. visa as a tourist and entering the U.S. several years after that? If yes, how could that be fixed? If yes, how could that be fixed? And any changes on your perspective for YC harboring international talent in SF Bay Area? If an i-131 is pending, would you advise that person to return briefly to USA before their 1 year date of exit (ensuring that they are never out of USA for greater than 1 year prior to approved i-131)?Or does a reentry permit allow them to remain out of country for longer than that even if pending (presuming it gets approved)? Or does a reentry permit allow them to remain out of country for longer than that even if pending (presuming it gets approved)? However they keep flip flopping between me needing a B1 and me just using my ESTA for the training, and their communication hasn't been the most straight forward. What impacts are you seeing as a result of the $100K H-1B fee which took effect on 9/21/25? Assuming a US startup is considering engineering hires outside the United States, how does one currently assess the likelihood of getting them a visa to work in the USA? OR should I just close it and try the normal route? > Applicants for U.S. nonimmigrant visas (NIV) should schedule their visa interview appointments at the U.S. Embassy or Consulate in their country of nationality or residence> Applicants must be able to demonstrate residence in the country where they are applying, if the place of application is based on their residency.What sort of proof is required to demonstrate residence? What about cases where an applicant legally has residency in a particular country (e.g. PR card or work visa) but in practice lives in the US as an H-1B/TN/L-1/O-1/etc. > Applicants must be able to demonstrate residence in the country where they are applying, if the place of application is based on their residency.What sort of proof is required to demonstrate residence? What about cases where an applicant legally has residency in a particular country (e.g. PR card or work visa) but in practice lives in the US as an H-1B/TN/L-1/O-1/etc. Especially for the dual intent visas? What sort of proof is required to demonstrate residence? What about cases where an applicant legally has residency in a particular country (e.g. PR card or work visa) but in practice lives in the US as an H-1B/TN/L-1/O-1/etc. Especially for the dual intent visas? Do you think H1B visa holders looking to move to a Green Card (in coordination with their employer) should be concerned about rejected applications or other issues? Do you think there are risks involved with leaving (and hence returning to) the country on a Green Card?</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/12/05/the-new-york-times-is-suing-perplexity-for-copyright-infringement/'>The New York Times is suing Perplexity for copyright infringement</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 16:03:59
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Recognizing the AI tide cannot be stopped, publishers use lawsuits as leverage in negotiations in the hopes of forcing AI companies to formally license content in ways that compensate creators and maintain the economic viability of original journalism. Perplexity tried to address compensation demands by launching a Publishers' Program last year, which offers participating outlets like Gannett, TIME, Fortune and the Los Angeles Times a share of ad revenue. In August, Perplexity also launched Comet Plus, allocating 80% of its $5 monthly fee to participating publishers, and recently struck a multi-year licensing deal with Getty Images. “While we believe in the ethical and responsible use and development of AI, we firmly object to Perplexity's unlicensed use of our content to develop and promote their products,” Graham James, a spokesperson for The Times, said in a statement. Similar to the Tribune's suit, the Times takes issue with Perplexity's method for answering user queries by gathering information from websites and databases to generate responses via its retrieval-augmented generation (RAG) products, like its chatbots and Comet browser AI assistant. Or, as James put it in his statement,  “RAG allows Perplexity to crawl the internet and steal content from behind our paywall and deliver it to its customers in real time. That content should only be accessible to our paying subscribers.” “Publishers have been suing new tech companies for a hundred years, starting with radio, TV, the internet, social media, and now AI,” Jesse Dwyer, Perplexity's head of communications, told TechCrunch. “Fortunately it's never worked, or we'd all be talking about this by telegraph.” (Publishers have, at times, won or shaped major legal battles over new technologies, resulting in settlements, licensing regimes, and court precedents.) The lawsuit comes just over a year after The Times sent a cease and desist letter to Perplexity demanding it stop using its content for summaries and other output. OpenAI has argued that its use of publicly available data for AI training constitutes “fair use,” and has shot its own accusations at the Times, claiming the outlet manipulated ChatGPT to find evidence. That case is still ongoing, but a similar lawsuit directed against OpenAI competitor Anthropic could set a precedent in regards to fair use for training AI systems going forward. In that suit, in which authors and publishers sued the AI firm for using pirated books to train its models, the court ruled that while lawfully acquired books might be a safe fair use application, pirated ones infringe on copyrights. The latter claim is one that internet infrastructure provider Cloudflare recently confirmed. The Times is clearly not above working with AI firms that compensate for its reporters' work. Several other publishers and media companies have signed licensing deals with AI firms to use their content for training and to feature in chatbot responses. OpenAI has inked deals with Associated Press, Axel Springer, Vox Media, The Atlantic, and more. Rebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Show your CFO the marketing proof they want!Join a free webinar hosted by Pantheon on Tuesday December 9 at 10am PT to learn where spend delivers & how to build a 2026 strategy grounded in real results. Andy Jassy says Amazon's Nvidia competitor chip is already a multibillion-dollar business Apple just named a new AI chief with Google and Microsoft expertise, as John Giannandrea steps down</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=46162872'>Framework Laptop 13 gets ARM processor with 12 cores via upgrade kit</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 15:51:54
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>I wish someone made a keyboard that doesn't suck, ideally split as well. Although to be pedantic, that's not an "ortholinear" keyboard (as in a square grid) rather a keyboard with column stagger (which you should use).I wonder if you could make it for a FW13 too? I know QMK doesn't work for 13.Edit: I see now that it uses a separate microcontroller, so yes if you could make it fit then it should work. I wonder if you could make it for a FW13 too? I know QMK doesn't work for 13.Edit: I see now that it uses a separate microcontroller, so yes if you could make it fit then it should work. * Minutes in a meeting* Entries in a journal or travelogue* Writing the next great noveletc.Why have manufacturers simply taken that away from us, in favor of a terrible excuse with ridiculous tactile feedback? * Entries in a journal or travelogue* Writing the next great noveletc.Why have manufacturers simply taken that away from us, in favor of a terrible excuse with ridiculous tactile feedback? * Writing the next great noveletc.Why have manufacturers simply taken that away from us, in favor of a terrible excuse with ridiculous tactile feedback? etc.Why have manufacturers simply taken that away from us, in favor of a terrible excuse with ridiculous tactile feedback? Why have manufacturers simply taken that away from us, in favor of a terrible excuse with ridiculous tactile feedback? I don't like row stagger and non-split keyboards, for ergonomic reasons. That's definitely a niche preference, but if anyone would cater to it you'd expect it to be Framework or similar. (Answer: it's basically just keyboard covers, and the many options are due to variations of colors and languages. But I would take a hot pink / toxic green keyboard with ancient tibetan labels if the keys were non-chicklet, with decent travel, sizes, and feedback. (Answer: it's basically just keyboard covers, and the many options are due to variations of colors and languages. But I would take a hot pink / toxic green keyboard with ancient tibetan labels if the keys were non-chicklet, with decent travel, sizes, and feedback. (Answer: it's basically just keyboard covers, and the many options are due to variations of colors and languages. But I would take a hot pink / toxic green keyboard with ancient tibetan labels if the keys were non-chicklet, with decent travel, sizes, and feedback. ⇒ their market likely isn't enormous, but it is larger than that of Framework Laptop owners. But as much as I love the RK3588 it's very much in the "low perf utility SBC" world than "good performing general PC". I use my two boards for NAS, Plex, Forgejo CI builders, etc.I do recall that Jeff Geerling I think had some followup with that board that perhaps there could be firmware changes that improve the power efficiency later maybe? Generally I'm reluctant investing in Linux on a hardware from company more or less hostile to it, but I also don't have any need for ARM laptop, and I'm happy with my Framework. I wouldn't say the problem is hostility. Apple wisely allowed us to load a non-chain-of-trust OS while maintaining the chain of trust in macOS, which is an incredible advancement still unmatched by other manufacturers.And that's it. They have done zero work to accommodate Linux. Perhaps if Microsoft ever figures out that NT used to run on more than one arch, Apple will revive Boot Camp for Windows and deem it useful to include Linux this time? They have done zero work to accommodate Linux. Perhaps if Microsoft ever figures out that NT used to run on more than one arch, Apple will revive Boot Camp for Windows and deem it useful to include Linux this time? Cheap Windows Arm laptops are flooding the market, if someone can pick ONE laptop to support they could easily buy them on sale , refurbished them with Linux and make a profit.Looks likes their are some challenges with doing this. Looks likes their are some challenges with doing this. I was also slowly loosing hope, although I do still run some NixOS ARM Raspberry PIs. But with the recent Valve backing, I'm back on the train again, and eagerly awaiting the slow but steady improvements, and figuring out where I can contribute back. Can we please move on to microkernels already? To do that on a MacBook I'm spending a minimum of 3200$.If you have unlimited money ( or can expense it) a 3200$ to 4k MacBook is going to be the best experience money can buy.If you have limited funds, a 200$ used computer can get the job done with the right distro. If you have unlimited money ( or can expense it) a 3200$ to 4k MacBook is going to be the best experience money can buy.If you have limited funds, a 200$ used computer can get the job done with the right distro. If you have limited funds, a 200$ used computer can get the job done with the right distro. Looking at this I have so many questions. You have four options with 16/32gigs and 1tb of storage? I am assuming this is the mainboard even supporting framework extension cards.No listed Linux compatibility support. Forget if the NPU even works in Linux; I do not even know if this will boot Linux because the company did not bother to submit devicetree patches to the kernel for their SOC. No listed Windows support even.This company's copy is absolutely terrible. I am assuming this is the mainboard even supporting framework extension cards.No listed Linux compatibility support. Forget if the NPU even works in Linux; I do not even know if this will boot Linux because the company did not bother to submit devicetree patches to the kernel for their SOC. No listed Windows support even.This company's copy is absolutely terrible. Forget if the NPU even works in Linux; I do not even know if this will boot Linux because the company did not bother to submit devicetree patches to the kernel for their SOC. No listed Windows support even.This company's copy is absolutely terrible. Also worth looking at battery life compared to performance... EDIT: Sorry, not SnapdragonX - apparently I can't read.Also, who is "MetaComputing" and can I trust them with my money? Something about the big "Web 3 Integrated Devices" branding on their landing  page makes me less than enthusiastic. Also, who is "MetaComputing" and can I trust them with my money? Something about the big "Web 3 Integrated Devices" branding on their landing  page makes me less than enthusiastic.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/12/05/meta-signs-commercial-ai-data-agreements-with-publishers-to-offer-real-time-news-on-meta-ai/'>Meta signs commercial AI data agreements with publishers to offer real-time news on Meta AI</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 15:27:37
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Now, when users ask Meta AI news-related questions, it will surface information and links that draw from different content sources to help users discover timely and relevant content, the company announced on Friday. The company says this will allow its partners to reach new audiences. The move comes as Meta shifted away from making its platforms hubs for news. Additionally, Meta stopped compensating news publishers in 2022, but is now doing so to help supercharge its AI chatbot with real-time access to news. Meta is also looking to stay relevant in the AI race after the controversial release of Llama 4, which was met with complaints of poor performance earlier this year. Meta AI is available in over 200 countries and can be accessed through the company's apps, including Facebook, Instagram, WhatsApp, and Messenger, as well as through the standalone Meta AI app. Prior to joining the publication in 2021, she was a telecom reporter at MobileSyrup. Show your CFO the marketing proof they want!Join a free webinar hosted by Pantheon on Tuesday December 9 at 10am PT to learn where spend delivers & how to build a 2026 strategy grounded in real results. Andy Jassy says Amazon's Nvidia competitor chip is already a multibillion-dollar business Company backed by Donald Trump Jr.'s firm nabs $620M government contract Apple just named a new AI chief with Google and Microsoft expertise, as John Giannandrea steps down</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/trumps-tiny-car-wish-isnt-the-way-to-make-americans-want-smaller-cars-2000695886'>Trump's Tiny Car Wish Isn't The Way to Make Americans Want Smaller Cars</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 15:20:30
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>One of the longest and least stable will-they-or-won't-they relationships isn't between two people, but all Americans and small cars. The President thinks that includes very small cars, too. During the announcement of the plan to roll back US fuel economy standards to those of a decade ago on Wednesday, President Donald Trump said he wanted very small cars as widely seen in some parts of Asia, called kei cars in Japan, to come to this country and also be built here, saying that people told him they'd do well but that this country's regulations wouldn't allow it. What Trump was most likely referring to is a car that's defined by Japanese regulations as a vehicle that's no longer than 3.4 meters (11.15 feet), has an engine capacity no greater than 0.66 liters, with no more than 63 horsepower, and can seat no more than four people. The National Highway Traffic Safety Administration report and Transportation Secretary Sean Duffy backed this up by describing the changes necessary because under the previous standards, “consumers were denied the choice of what is best for their needs,” directly targeting any deadlines for required electrification. How does a kei car, many of which have top speeds around 80 mph, compete against a three-ton vehicle that's not only exponentially more powerful but also much taller and wider? We've been down this road a few times before with only temporary relief. The most notable tiny car was the Subaru 360, first imported in 1968 with a two-cylinder engine, weighing in at less than 1,000 pounds and thereby skirting any formal crash regulations at the time. Interestingly, Subaru attempted the same thing roughly 40 years later with the introduction of the Smart to the US amid surging fuel prices and a push for “affordability.” Two four-seat Subaru kei cars were imported to the company's US headquarters in New Jersey in 2007, according to a 2019 story from The Drive, but were ultimately deemed unsuitable for mainstream sales because they were too small, partly because of the driving conditions, but also because American people were too big for them. All of this reinforces the idea that what the American people, the EPA, NHTSA, and other agencies consider to be a small car is what many other countries think of as a large one. What's more, these tiny cars, in a bid to stay lighter and cheaper, stick predominantly to small gas-powered engines. Even though some are now available as EVs or hybrids, packaging requirements and price targets adversely affect the smallest cars on sale in every market. Trump and Duffy's argument is that smaller cars are automatically cheaper and that will keep more money in American wallets, and that doesn't pencil out in the proposed changes. Last week, US Senators confirmed a January meeting with auto executives about why new cars are so expensive, and, according to The Wall Street Journal, they believe the mandated safety technology, such as automatic emergency braking and backup cameras, is the culprit, and more efforts should be put into autonomous vehicles. Small, less expensive cars could once again lack standard driver assistance systems that minimize the risk of crashes and injuries not just to people in cars, but those outside of them. It's not like Americans don't have small-engined and compact cars available today, or even that they're not popular. More than 200,000 Honda Civics and roughly the same number of Toyota Corollas have been sold through this year, along with more than 170,000 three-cylinder-powered Chevy Trax small SUVs. They might be considered midsize cars everywhere else in the world, but they take up far less space than many popular cars sold in the US. The enthusiasts who've imported little Subarus, Mitsubishis, Nissans, and other kei cars to the US and have kept them running over the years are admirable for making them work and making those of us wishing for a smaller vehicle on certain streets envious. Americans already have a lot of choices, not just in cars, but in how to get around at all, what fuel powers their choice, and how much fuel is needed. For kei cars to ever have a chance in the U.S., it's going to take more than some lip service from a President who is desperate to show he has any policies that make life more affordable. Subscribe and interact with our community, get up to date with our customised Newsletters and much more. The idea sounds similar to Trump's "freedom cities" first pitched in 2023. "Today, we're taking one more step to kill the 'Green New Scam,'" Trump said. "Stop this boring insider trading," one X user complained. The government has argued that exceptional circumstances need to be met for such a deposition. "Secretary Kennedy has formally certified that these are the first ever MAHA turkeys," said Trump.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/review/gotrax-mustang-electric-bike/'>GoTrax's Mustang Electric Bike Makes Me Feel Like I'm in ‘Stranger Things'</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 14:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Looking more moped than ebike, the GoTrax Mustang electric bike appears to share more DNA with old-school dirt bikes than it does modern electric bicycles. Resting on its kickstand outside my garage, the GoTrax Mustang looks as if it's ready to play a role in the new season of Stranger Things. However, while it boasts imposing size and plenty of heft, the Mustang, the newest offering from Dallas-based GoTrax, is surprisingly nimble and easy to operate, owing in large part to its relatively short wheelbase. As soon as you start turning the pedals, it's easy to forget that it's a bicycle basically built on a moped platform. The Mustang is powered by a 750-watt motor nestled into the bike's rear hub, which can deliver up to 90 newton-meters of torque to its wheel. If you aren't versed in torque ratings, rest assured that 90 Nm is more than enough to get me, a 6' 4”, 255-pound bike commuter, up a hill near my home that averages a 4 percent gradient, with incline pitches over 15 percent. All of that is powered by a 48-volt, 15-Ah LG battery that, according to the company, offers up to 86 miles per change (more on that in a minute), charges from dead to full in fewer than two hours (by my watch), and boasts a UL 2272 safety certification, which will help you sleep better at night. Again, take that hill I have to climb up to my office—reverse it for my commute home, and imagine all 255 pounds of me plus the 50-plus pounds of the bike itself bombing down –15 percent grades. Those rotors and Tektro brakes combined to not only give all 300 pounds of Mike-and-bike plenty of stopping power, they also allowed me to feather my speed with extreme precision as I wound my way down the curvy hill toward home. Like most new ebikes, the Mustang—which employs a generic Shimano seven-speed thumb-shift gearset—features five pedal assist levels and has an independent thumb-based throttle, allowing the rider to fully avoid pedaling should they chose (at the sake of draining your battery even faster, of course). It sits on wheels that are small in diameter (20 inches … think a BMX bike) but massive in width (4 inches, so wider than your average mountain bike). It also features a massive LED headlight, which did plenty to illuminate the road in front of me. And though it only has a one-sided kickstand as opposed to a scooter-style underframe stand, the bike's aforementioned short wheelbase means it never felt unstable when I hopped off and kicked the stand down. Other than the ultra-cool, deep-red-logo-on-flat-metallic paint job, the real showstopper on the Mustang is its control system, which features a stunning, full-color LCD display that shows in real time your speed, remaining battery, pedal assist level, odometer, and how much of the motor's available 750 watts are being used at any given moment. The ones you can reportedly get on a single charge? Well, that's probably only if you live in a flat area and keep your Mustang on the lowest power setting. The product page on GoTrax's website has a handy little chart that tells you about how far each mode is estimated to get you on a full charge. But here in Chapel Hill (which, rest assured, is aptly named), I got closer to 28 miles on a single charge, constantly switching back and forth between all five power modes plus an often-wide-open throttle. Granted, 28 miles is not bad, especially if, like me, you use your e-bike to commute just a few miles to and from work or school. While there are mounts on the downtube for a decent-sized (and innovative-ly positioned) basket, there don't appear to be many other mounts for front- or rear-rack options, panniers, or additional seating. It all gives the sense that the Mustang, like those dirt bikes of 1980s yore, is really only meant to be ridden by one person at a time. If you're in search of a family hauler or something more adept at replacing your car for everyday errands, the Mustang probably isn't the bike. In the dozen or so hours I spent riding the Mustang, it felt like I was riding my kid brother's BMX bike, as my knees splayed out from the bike (a position that any cyclist can tell you could lead to minor pain at best, and lasting knee injury at worst). The only problem is, it's one size doesn't fit all. While I didn't manage to get multiple friends of different sizes on the Mustang, I'd be hard pressed to imagine anyone bigger than 5' 9” or 5' 10” being able to comfortably pedal a Mustang for more than a few minutes. However, I might recommend seeing if you can find anyone in your town who owns GoTrax's popular Ranger model, whose dimensions are similar to the Mustang, to check if you can fit first. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/pc-components/this-msi-pro-27-inch-gaming-monitor-plummets-to-its-lowest-ever-price-of-usd89-99-at-newegg-1080p-144hz-display-is-a-gaming-and-productivity-double-threat'>This MSI Pro 27-inch gaming monitor plummets to its lowest-ever price of $89.99 at Newegg — 1080p, 144Hz display is a gaming and productivity double-threat</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 13:39:38
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Capable MSI Pro MP273L panel is priced to perform, and still offers solid gaming features When you purchase through links on our site, we may earn an affiliate commission. Missed out on all the Black Friday and Cyber Monday fun? It's also well-equipped for gaming, with its 144Hz refresh rate and AMD FreeSync support. You'd be hard-pressed to find a better deal now that Black Friday and Cyber Monday are over. This budget-friendly 1920 x 1080 120Hz IPS panel offers solid value as an entry-level gaming monitor (office monitors can be almost anything). Key features include support for 102% of the sRGB color gamut, a dedicated gaming mode, and handy "Eye Saver" tech to cut down on blue light. The IPS panel also sports 1ms (MPRT) and 4ms (GtG) response times to minimize ghosting, while AMD FreeSync support prevents screen tearing when running titles at a variable frame rate. Unsurprisingly, it lacks DisplayPort, a headphone jack, or USB ports. Just note that you'll only be able to get the full 144Hz refresh rate by using the HDMI input.As far as aesthetics go, the MP237L E14 has ultra-thin bezels, a sleek design, and would look great on any office desk. If you choose an MSI Cubi Mini PC for this monitor, MSI's Power Link Support lets the mini-PC be powered on by the monitor's button for ease of use. Get the MSI Pro MP273L E14, a double-threat office and gaming monitor for $89.99/$40.00 off. Get it soon, as this deal expires in under 24 hours. If you're in the market for a new budget monitor that has accurate colors and is good for office work during the day and want to play games after hours without ghosting and screen tearing, the MSI Pro MP273L E14 is the monitor to get right now. It's on sale for a limited time, so be sure to act fast before you miss out. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Joe Shields is a staff writer at Tom's Hardware. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York,</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/cloud-gaming-is-looking-more-attractive-than-ever-for-all-the-wrong-reasons-2000695920'>Cloud Gaming Is Looking More Attractive Than Ever for All the Wrong Reasons</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 13:00:02
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>All products featured here are independently selected by our editors and writers. If you buy something through links on our site, Gizmodo may earn an affiliate commission. I was going to build my own version of Valve's Steam Machine using traditional PC parts, then stuff it all into my childhood PC case installed with SteamOS for the ultimate combination of convenience and nostalgia. The price of RAM has skyrocketed so high that even previous-generation PC components are now sitting at two, three, or four times as much as they were only two months ago. Building any size PC is more untenable than even back during the pandemic-era GPU shortage. Gamers everywhere are looking for an alternative to play their PC game library, and—unfortunately—one of the last remaining avenues demands a less-expensive-but-still-pricey cloud gaming subscription. My original plan was to heap my PC full of hand-me-down, used, and last-gen parts to get the best deal I could. On Wednesday, Micron, which owns the major DRAM (dynamic random access memory) brand Crucial, announced it made the “difficult decision” to kill its consumer-facing brand altogether. Sumit Sadana, Micron's chief business officer, made it clear this was to focus on fulfilling the insatiable demand for memory from AI data centers. There are few scenarios where this doesn't impact the price of computer parts even more. So where does that leave gamers who were too late upgrading their PC or who find they need new hardware to play their games? That 45% comes specifically from cloud streaming on consoles, but the service was seeing 26% more playtime on “other devices.” Xbox didn't break down how big a portion “other devices” made up PC, or perhaps former PC gamers. Earlier this year, Xbox raised the price of its Game Pass Ultimate subscription from $20 to $30 a month. The service can now stream games up to 1440p resolutions as well. The uptick in playtime may be related to recent games like Call of Duty: Black Ops 7 coming out on Game Pass, though that can't be the whole story. Gamers are looking for the best deal, and even a more expensive subscription service will be far cheaper than high-end 64GB RAM that costs close to $800 from some brands. Nvidia has added more over time; most recently titles like Enshrouded and Fallout 76. Nvidia also lets subscribers play a few extra games that don't appear on GeForce Now's supported list through the Install-to-Play feature. Even with fast internet speeds and low latency, there is a distinct difference in visual quality between games that are rendered on-device and those streamed over the internet, even at 1440p or 4K. And PC gamers are rarely the type to accept such tradeoffs. Crucial was busy posting ads for its gaming-ready SSDs (solid state drives) as recently as the day prior to the company's announcement. Events are moving fast, and we won't have time to blink before the news gets worse. Those two companies are similarly retooling their business to focus on making memory for AI data centers. Transcend, another major consumer-end memory maker, wrote to customers in a notice shared online that Samsung and Sandisk delayed their latest shipments of NAND, which is used for flash memory. “The situation worsened in Q4 due to increased demand from large data centers and hyperscalers driven by major cloud service providers' expansion plans. All major chip manufacturers are prioritizing supply for these customers, which has led to price increases and extremely… pic.twitter.com/q5Wp6N38dm These major tech brands have hinted the run on DRAM prices may last well past 2028. Korean language news site Hankyung reported Samsung and SK Hynix are both imagining their focus on AI data centers will last through the start of 2028. That sounds like magical thinking, but it shows just how willing memory makers are to leave the PC industry in the cold. Which means the consumer is going to need some alternatives, and soon. And it's making us even more excited for the rumored PlayStation 6 handheld. So-called 'Foot keyboards' are cursed in more ways than one. PC component prices are really out of control right now. Really, we need a new affordable option for gaming processors. Might as well rename November to Game-vember since there was so much great gaming hardware announced.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/pc-components/gpus/nvidia-replaces-entire-usd10-000-rtx-pro-6000-graphics-card-of-stricken-user-who-broke-it-in-transit-company-offers-to-ship-replacement-and-troubleshoot-busted-gpu'>Nvidia replaces entire $10,000 RTX Pro 6000 graphics card of stricken user who broke it in transit — company offers to ship replacement and troubleshoot busted GPU</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 11:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Nvidia won't send customers replacement parts to fix their cards themselves, but apparently, Nvidia will send them replacement units, even if the customer is at fault for the damage. When you purchase through links on our site, we may earn an affiliate commission. Last month, we covered a story where a customer's $10,000 RTX Pro 6000 graphics card's PCIe component got split in half after the customer accidentally forgot to remove the card from their machine before shipping it to another location. This is the second time that we have seen Nvidia replace a customer's GPU, even though the original damage was caused by user error. The first time we saw this was when a customer of an RTX 5090 Founders Edition accidentally damaged their card after attempting to install a waterblock on it (and voiding the card's warranty in the process). This latest story is an even worse tale revolving around Nvidia's $10,000 RTX Pro 6000 workstation graphics card. These two incidents reveal that Nvidia is apparently very lenient on its graphics card replacements, particularly for its OEM cards (not third-party cards from other vendors). Even if the customer is at fault for damaging their OEM Nvidia GPU, we now know that Nvidia won't rule out shipping the person a new graphics card (regardless of warranty). More encouragingly, Nvidia seems at least somewhat interested in examining the old card, possibly to check for structural weaknesses or flaws in the design. This is great for consumers of these cards since NorthridgeFix reports that Nvidia refuses to provide replacement components for its GPUs, even though its Blackwell-based dual-fan OEM graphics cards have modularity in their design. The PCIe finger and four rear display outputs on these Blackwell cards are connected to the GPU with their own independent boards, theoretically making these components easy to fix if either component breaks. All you would have to do is replace the bad board(s) with a new one, if only Nvidia provided the parts. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/artificial-intelligence/amazon-launches-trainium3-ai-accelerator-competing-directly-against-blackwell-ultra-in-fp8-performance-new-trn3-gen2-ultraserver-takes-vertical-scaling-notes-from-nvidias-playbook'>Amazon launches Trainium3 AI accelerator, competing directly against Blackwell Ultra in FP8 performance — new Trn3 Gen2 UltraServer takes vertical scaling notes from Nvidia's playbook</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 11:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. Amazon Web Services this week introduced its next-generation Trainium3 accelerator for AI training and inference. The AWS Trainium3 is a dual-chiplet AI accelerator that is equipped with 144 GB of HBM3E memory using four stacks, which provides peak memory bandwidth of up to 4.9 TB/s. Each compute chiplet, allegedly made by TSMC using its 3nm-class fabrication process, contains four NeuronCore-v4 cores (which feature an extended ISA compared to predecessors) and connects two HBM3E memory stacks. The two chiplets are connected using a proprietary high-bandwidth interface and share 128 independent hardware data-movement engines (which are key for the Trainium architecture), collective communication cores that coordinate traffic between chips, and four NeuronLink-v4 interfaces for scale-out connectivity. From a software development standpoint, the core is built around a software-defined dataflow model in which data is staged into SRAM by DMA engines, processed by the execution units, and then written back as near-memory accumulation enables DMA to perform read-add-write operations in a single transaction. The SRAM is not coherent across cores and is used for tiling, staging, and accumulation rather than general caching. Perhaps the most interesting component of NeuronCore-v4 is the GPSIMD block, which integrates eight fully-programmable 512-bit vector processors that can execute general-purpose code written in C/C++ while accessing local SRAM. GPSIMD is integrated into NeuronCore because not everything in real AI models maps cleanly to a tensor engine. Modern AI workloads contain a lot of code for unusual data layouts, post-processing logic, indexing, and model-specific math. These are hard or inefficient to express as matrix operations, and running them on the host CPU would introduce latency and costly data transfers. GPSIMD solves this by providing real general-purpose programmable vector units inside the core, so such logic runs directly next to the tensors at full speed and using the same local SRAM. In short, NeuronCore-v4 operates as a tightly coupled dataflow engine in which tensor math, vector transforms, scalar control, and custom code all share a local 32MB scratchpad and are orchestrated by the Neuron compiler rather than by a warp scheduler used on Nvidia hardware. Performance-wise, Trainium3 outperforms its direct predecessor in FP8 compute (well, MXFP8) by almost two times and hits 2.517 PFLOPS per package (clearly ahead of Nvidia's H100/H200, but behind Blackwell B200/B300) and adds MXFP4 support. However, Trainium3's BF16, TF32, and FP32 performance remains on par with Trainium2, which clearly shows that AWS is betting on MXFP8 for training and inference going forward. To that end, it does not develop its BF16 (which is widely used for training nowadays) and FP32 capabilities, as it seems to feel comfortable with the performance it has, given that these formats are now used primarily for gradient accumulation, master weights, optimizer states, loss scaling, and some precision-sensitive operations. One interesting capability that Trainium3 has that is worth mentioning is the Logical NeuronCore Configuration (LNC) feature, which lets the Neuron compiler fuse four physical cores into a wider automatically synchronized logical core with combined compute, SRAM, and HBM, which could be useful for very wide layers or big sequence lengths that are common with very large AI models. Much of Nvidia's success in the recent quarters was driven by its rack-scale NVL72 solutions featuring 72 of its Blackwell GPUs. Supporting a massive scale-up world size and an all-to-all topology, which is especially important for Mixture-of-Experts (MoE) and autoregressive inference. This gives Nvidia a massive advantage over AMD and developers of custom accelerators, such as AWS. To enable this capability, Nvidia had to develop NVLink switches, sophisticated network cards, and DPUs, a massive silicon endeavor. However, it looks like AWS's Trn3 UltraServers will give Nvidia's GB300 NVL72 a run for its money. Trn3 UltraServers, powered by Trainium3 AI accelerators, will be offered in two sizes: one configuration packs 64 accelerators and presumably an Intel Xeon CPU, while the larger variant brings together 144 accelerators and an Arm-based Graviton in a single rack-scale solution. In the larger system, the 144 Trainium3 accelerators are distributed across 36 physical servers with one Graviton CPU and four Trainium3 chips installed in each machine. In many ways, such an arrangement resembles Nvidia's NVL72 approach, which uses Nvidia's CPU, GPU, and connectivity silicon, highlighting AWS' direction of building vertically integrated AI platforms. Within a server, Trainium3 accelerators are linked through a first NeuronSwitch-v1 layer using NeuronLink-v4 (at 2 GiB/s per device, though it is unclear whether we are talking about a single direction bandwidth, or aggregated bidirectional bandwidth), and communication between different servers is routed through two additional NeuronSwitch-v1 fabric layers, again carried over NeuronLink-v4. Unfortunately, AWS does not publish aggregate NeuronSwitch-v1 bandwidth across the domain. From a performance standpoint, the larger configuration with 144 Trainium3 delivers 362.5 MXFP8/MXFP4 PetaFLOPS (dense) performance, which (on par with GB300 NVL72), 96.624 PFLOPS of BF16/FP16/TF32 throughput, and 26.352 PFLOPS in FP32. The system is also equipped with 21 TB of HBM3E memory, featuring an aggregate memory bandwidth of 705.6 TB/s, leaving Nvidia's GB300 NVL72 behind in this metric. FP8 is about to get more popular for training, so betting on this format makes a lot of sense. Of course, Nvidia has an ace up its sleeve in the form of NVFP4, which is positioned both for inference and training, and armed with this format, the company's Blackwell-based machines are unbeatable. Overall, while the AWS Trn3 Gen2 UltraServer with 144 Trainium3 accelerator looks quite competitive when it comes to FP8 compared to Nvidia's Blackwell-based NVL72 machines, Nvidia's solution is more universal in general. In addition to rolling out new AI hardware, AWS announced a broad expansion of its AWS Neuron software stack at its annual re:Invent conference this week. AWS positions this release as a shift toward openness and developer accessibility, so the update promises to make Trainium platforms easier to adopt, let standard machine learning frameworks run directly on Trainium hardware, give users deeper control over performance, and even expose low-level optimization paths for experts. A major addition is native PyTorch integration through an open-source backend named TorchNeuron. Using PyTorch's PrivateUse1 mechanism, Trainium now appears as a native device type, which enables existing PyTorch code to execute without modification. AWS also introduced an updated Neuron Kernel Interface (NKI) that gives developers direct control over hardware behavior, including instruction-level programming, explicit memory management, and fine-grained scheduling, exposing Trainium's instruction set to kernel developers. AWS also released its Neuron Explorer, a debugging and tuning toolkit that lets software developers and performance engineers improve how their models run on Trainium. This is done by tracing execution from high-level framework calls, all the way down to individual accelerator instructions, while offering layered profiling, source-level visibility, integration with development environments, and AI-guided suggestions for performance tuning. Finally, AWS introduced its Neuron Dynamic Resource Allocation (DRA) to integrate Trainium directly into Kubernetes without the need for custom schedulers. Neuron DRA relies on the native Kubernetes scheduler and adds hardware-topology awareness to enable complete UltraServers to be allocated as a single resource and then flexibly assign hardware for each workload. Neuron DRA supports Amazon EKS, SageMaker HyperPod, and UltraServer deployments, and is provided as open-source software with container images published in the AWS ECR public registry. In a nutshell, AWS is moving closer to making its Trainium-based platforms much more ubiquitous than they are today, in an effort to make them more competitive against CUDA-based offerings from Nvidia. This week, Amazon Web Services released its 3rd Generation Trainium accelerator for AI training and inference, as well as accompanying Trn3 UltraServers rack-scale solutions. For the first time, Trn3 Gen2 UltraServers rack-scale machines will rely solely on AWS in-house hardware, including CPU, AI accelerators, switching hardware, and connectivity fabrics, signalling that the company has adopted Nvidia's vertical integration hardware strategy. AWS claims that its Trainium3 processor offers roughly 2X higher performance and 4X better energy efficiency than Trainium2 as each accelerator delivers up to 2.517 PFLOPS (MXFP8) — beating Nvidia's H100, but trailing B200 — and is accompanied by 144 GB of HBM3E with 4.9 TB/s of bandwidth. Meanwhile, Trn3 Gen2 UltraServers scale to 144 accelerators for about 0.36 ExaFLOPS FP8 performance, which brings it on par with Nvidia's GB300 NVL72 rack-scale solution. Nonetheless, Nvidia's hardware still looks more universal than AWS's. Anton Shilov is a contributing writer at Tom's Hardware. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York,</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/big-interview-event-inside-doge-leland-dudek/'>Former USIP Lawyer on DOGE: ‘Brass Knuckles on an Authoritarian Fist'</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 01:44:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The DOGE team, Foote said, left behind a “half-pound of weed”—more probably, a fellow panelist noted, a half-ounce—and ultimately seemed to have “no idea what to do with the place.” It was, Foote said, indicative of a lot of the work of DOGE, which “arrived as the brass knuckles on an authoritarian fist.” He added that he wasn't sure what Musk wanted to do with DOGE, “but he took it to a destructive level.” In court documents, lawyers for the agency detailed a series of attempts by DOGE to enter the $500 million building before its operatives eventually succeeded. Ultimately, a judge ruled that DOGE and the US government didn't have the right to take control of USIP and its headquarters. Foote was one of several people on a panel, hosted by WIRED senior writer Vittoria Elliott, on the fallout from the move-fast-break-things ethos of DOGE. Foote was joined by former Social Security Administration commissioner Leland Dudek, and former DOGE engineer Sahil Lavingia, who announced during the panel that he's back in government at the Internal Revenue Service. As WIRED reported on Tuesday, many of the young technologists DOGE sent to various US agencies are still working with federal government entities. Edward “Big Balls” Coristine, Akash Bobba, Ethan Shaotran, Marko Elez, and Gavin Kliger all still seem affiliated with DOGE or the US government. As the effects of DOGE ripple out, Foote noted, it's important for people to keep an eye on what's happening. AMD CEO Lisa Su: Concerns About an AI Bubble Are Overblown Cloudflare Has Blocked 416 Billion AI Bot Requests Since July 1 Jon M. Chu: AI Couldn't Have Made One of Wicked's Best Moments WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/signalgate-inspector-general-report-hegseth-change/'>‘Signalgate' Inspector General Report Wants Just One Change to Avoid a Repeat Debacle</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-05 00:02:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>A United States Inspector General report publicly released today found that Secretary of Defense Pete Hegseth could have put US troops and military operations at risk by using the consumer messaging service Signal to share sensitive, real-time details in March about a planned attack on Houthi rebels in Yemen. The report contains only one direct recommendation: that the chief of US Central Command's Special Security Office “review the command's classification procedures for compliance” with Department of Defense regulations “and issue additional procedures, as necessary, to ensure proper portion marking of classified information.” The report also references another IG publication about use of “non–DOD-controlled electronic messaging systems” and points to its recommendations that DOD “improve training for senior DOD officials on the proper use of electronic devices.” "However, because the Secretary indicated that he used the Signal application on his personal cell phone to send nonpublic DOD information, we concluded that the Secretary's actions did not comply with DOD Instruction 8170.01, which prohibits using a personal device for official business and using a nonapproved commercially available messaging application to send nonpublic DOD information.” In response to WIRED's request for comment, chief Pentagon spokesperson Sean Parnell said: "This Inspector General review is a TOTAL exoneration of Secretary Hegseth and proves what we knew all along—no classified information was shared. Signal is the gold standard secure messaging app for consumer use. And Signal also collects very minimal metadata, so the company knows almost nothing about its users and has nothing to turn over if it receives law enforcement requests. No matter how excellent Signal is, though, the “threat model” and use case of individual consumers is very different than that of high-ranking government and military officials. Updated 12:25 pm ET, December 5: Added comment from a Pentagon spokesperson. Big Interview: Palantir's CEO Alex Karp goes to war Livestream: What businesses need to know about agentic AI WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            