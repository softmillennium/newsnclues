
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - TECHNOLOGY Article Summaries - 2025-07-18</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            TECHNOLOGY
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=44608622'>Replication of Quantum Factorisation Records with a VIC-20, an Abacus, and a Dog</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 19:11:14
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>

reply

reply

A relevant quote: "this is your daily reminder that "How large is the biggest number it can factorize" is NOT a good measure of progress in quantum computing. If you're still stuck in this mindset, you'll be up for a rude awakening."Related: this is from Dan Bernstein: https://blog.cr.yp.to/20250118-flight.html#moonA relevant quote: "Humans faced with disaster tend to optimistically imagine ways that the disaster will be avoided. Given the reality of more and more user data being encrypted with RSA and ECC, the world will be a better place if every effort to build a quantum computer runs into some insurmountable physical obstacle"

Related: this is from Dan Bernstein: https://blog.cr.yp.to/20250118-flight.html#moonA relevant quote: "Humans faced with disaster tend to optimistically imagine ways that the disaster will be avoided. Given the reality of more and more user data being encrypted with RSA and ECC, the world will be a better place if every effort to build a quantum computer runs into some insurmountable physical obstacle"

A relevant quote: "Humans faced with disaster tend to optimistically imagine ways that the disaster will be avoided. Given the reality of more and more user data being encrypted with RSA and ECC, the world will be a better place if every effort to build a quantum computer runs into some insurmountable physical obstacle"

reply

And a reminder that in the world of non-QC computing, right from its very roots, the ability of computers improved in mind boggling large steps every year.QC records, other than the odd statistic about how many bits they can make, have largely not made any strides in being able to solve real world sized problems (with exception of those that use QCs purely as an analog computer to model QC behavior)

QC records, other than the odd statistic about how many bits they can make, have largely not made any strides in being able to solve real world sized problems (with exception of those that use QCs purely as an analog computer to model QC behavior)

reply

Also, in the world of QC, right from its very roots, the ability of QC improved in mind boggling large steps every year. It's only that you cannot see it if you only look at the wrong metric, i.e., factorization records.It's a bit like saying "classical computing technology has not improved for 50 years, it's only recently that we finally start to have programs that are able to write other programs".

It's a bit like saying "classical computing technology has not improved for 50 years, it's only recently that we finally start to have programs that are able to write other programs".

reply</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/07/18/chatgpt-everything-to-know-about-the-ai-chatbot/'>ChatGPT: Everything you need to know about the AI-powered chatbot</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 16:34:13
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>ChatGPT, OpenAI's text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users. 2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora. OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI's transition to a for-profit. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history. Below, you'll find a timeline of ChatGPT product updates and releases, starting with the latest, which we've been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here. OpenAI has introduced ChatGPT Agent, which completes a wide variety of computer-based tasks on behalf of users and combines several capabilities like Operator and Deep Research, according to the company. OpenAI says the agent can automatically navigate a user's calendar, draft editable presentations and slideshows, run code, shop online, and handle complex workflows from end to end, all within a secure virtual environment. Researchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.” CEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing. we planned to launch our open-weight model next week.we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.while we trust the community will build great things with this model, once weights are… It will keep some user interactions within ChatGPT, rather than directing people to external websites. Some ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don't lead to clicks on news websites has increased from 56% to nearly 69% by May 2025. OpenAI has started using Google's AI chips to power ChatGPT and other products, as reported by Reuters. Researchers from MIT's Media Lab monitored the brain activity of writers in 32 regions. The participants were asked to write multiple SAT essays using tools such as OpenAI's ChatGPT, the Google search engine, or without any tools. The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb's X post. Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. OpenAI upgraded ChatGPT's conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. OpenAI plans to purchase Jony Ive's devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI's reach to a larger audience in the future. OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests. Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person's life when one attendee asked about how ChatGPT can become more personalized. By popular request, GPT-4.1 will be available directly in ChatGPT starting today.GPT-4.1 is a specialized model that excels at coding tasks & instruction following. OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI's products. OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI's products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company's expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg. OpenAI is working on “additional fixes” to the model's personality. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. Questions have been raised regarding OpenAI's transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI's top-reported score. OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI's safety report. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI's previous models. Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company's X post. OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition. OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk's X and Mark Zuckerberg's Instagram and Threads, according to The Verge. GPT-4.5 will be available in a research preview for paying customers. OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It's accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google's Gemini 2.5 Pro, Anthropic's Claude 3.7 Sonnet, and DeepSeek's upgraded V3. OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI's GPT-4o, which was released last year. OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland. It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.” OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos. In a series of posts on X, OpenAI CEO Sam Altman said the company's new image-generation tool's popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI's model behavior. OpenAI wants to incorporate Anthropic's Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. OpenAI on Tuesday rolled out a major upgrade to ChatGPT's image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI's AI video-generation tool, for subscribers of the company's Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company's API service. Brad Lightcap, OpenAI's chief operating officer, will lead the company's global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer. OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company's official media channels. Users on ChatGPT's free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch. OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI's ChatGPT. Reliance has proposed selling OpenAI's models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. OpenAI, Meta, and Reliance have not yet officially announced these plans. Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn't enough. You can't just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.” OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It's only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms. OpenAI CEO Sam Altman said, in a post on X, that the company has trained a “new model” that's “really good” at creative writing. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming. we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.PROMPT:Please write a metafictional literary short story… OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company's own AI models and frameworks. The tools are part of OpenAI's new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI's Operator product. OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It's unclear when these agentic tools might launch or which customers will be eligible to buy them. The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI's AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model's launch. Using OpenAI's latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. ChatGPT users will see an updated “chain of thought” that shows more of the model's “reasoning” steps and how it arrived at answers to questions. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot's last training update. OpenAI says the “agent” is intended for instances where you don't just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user's mind on a subject. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.” A new report from app analytics firm Appfigures found that over half of ChatGPT's mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI's tools for the handling of non-public sensitive data. Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they've used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company's AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator's. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online. Operator, OpenAI's agent tool, could be released sooner rather than later. Changes to ChatGPT's code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren't yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT's client-side code. TechCrunch separately identified the same references to Operator on OpenAI's website. However, users who create an account using their number can't upgrade to one of OpenAI's paid plans without verifying their account via an email. Multi-factor authentication also isn't supported without a valid email. ChatGPT's new beta feature, called tasks, allows users to set simple reminders. OpenAI is introducing a new way for users to customize their interactions with ChatGPT. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it's possible they went live prematurely. November 30, 2022 is when ChatGPT was released for public use. And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space. ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt. Due to the nature of how these models work, they don't know or care whether something is true, only that it looks true. Yes, there is a free ChatGPT mobile app for iOS and Android users. It's not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words. Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc. Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc. That's because ChatGPT lacks context awareness — in other words, the generated code isn't always appropriate for the specific context in which it's being used. There are multiple AI-powered chatbot competitors such as Together, Google's Gemini and Anthropic's Claude, and developers are creating open source alternatives. OpenAI has said that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”. In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here for instructions on how you can opt out of our use of your information to train our models.” Recently, Discord announced that it had integrated OpenAI's technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm. An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT's false claims that he had served time in prison for bribery. CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with. Several tools claim to detect ChatGPT-generated text, but in our tests, they're inconsistent at best. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users' conversations to other people on the service. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data. Alyssa Stringer was formerly the Audience Development Manager for TechCrunch. Prior to her experience in audience development, Alyssa worked as a content writer and holds a Bachelor's in Journalism at the University of North Texas. Amplify your reach, spark real connections, and lead the innovation charge. Starbase injury rates outpace rivals as SpaceX chases its Mars moonshot DuckDuckGo now lets you hide AI-generated images in search results With her app Smash, Kesha can be whoever she wants – even a tech CEO OpenAI, Thinking Machines Lab, and the built-in chaos of a $2B seed round Meta refuses to sign EU's AI code of practice Netflix starts using GenAI in its shows and films ChatGPT: Everything you need to know about the AI-powered chatbot</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/07/18/starbase-injury-rates-outpace-rivals-as-spacex-chases-its-mars-moonshot/'>Starbase injury rates outpace rivals as SpaceX chases its Mars moonshot</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 16:29:06
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>SpaceX employees are more likely to be injured while working at Starbase than any of its other manufacturing facilities, according to company worker safety records reviewed by TechCrunch. Starbase, a sprawling launch-and-manufacturing site that recently incorporated as its own Texas city, logged injury rates almost six times higher than the average for comparable space vehicle manufacturing outfits and nearly three times higher than aerospace manufacturing as a whole in 2024, according to Occupational Safety and Health Administration (OSHA) data released in May. Starbase is home to SpaceX's most ambitious program: a fully reusable, ultra-heavy-lift rocket called Starship. Since Starship's first orbital test in April 2023, SpaceX has attempted eight additional integrated flights. The data suggests that SpaceX's rapid progress comes at a cost. OSHA uses a standardized safety metric called Total Recordable Incident Rate (TRIR) to measure a company's safety record and compare it to industry peers, like Blue Origin and United Launch Alliance. It doesn't distinguish between minor injuries like stitches versus serious incidents such as amputations. TechCrunch calculated the TRIR based on that data, which includes the total number of incidents and total number of hours worked by SpaceX employees at each site. Starbase, which plays a central role in SpaceX CEO Elon Musk's mission to make life multi-planetary, is an outlier in the company and across the industry as a whole. Its TRIR topped out at 4.27 injuries per 100 workers in 2024, when it employed an average of 2,690 workers, according to the data submitted to OSHA. Injured Starbase employees were unable to perform their normal job duties for a total of 3,558 restricted-duty days, plus 656 lost-time days where injuries made them unable to work at all. Starbase is classified by the U.S. government as a space vehicle manufacturing operation. The injury rate in this sector has fallen dramatically since 1994, dropping from 4.2 injuries per 100 workers to 0.7 injuries per 100 workers in 2023, according to historical data from the Bureau of Labor Statistics. (BLS calculates these rates through its annual company surveys, which asks for the same information found in OSHA's worker injury forms.) These other facilities report lower TRIR rates, though most still exceed the industry averages. The 2024 TRIR for aerospace manufacturing as a whole is 1.6. SpaceX also operates several non-manufacturing sites, including barge operations off both coasts, offices in Sunnyvale, California, and launch sites at Cape Canaveral and Vandenberg Space Force Base. However, there is a debate among safety professionals about whether TRIR is the most reliable metric for assessing and predicting injury rates, particularly serious incidents like fatalities, and especially for small companies. A recent paper on TRIR questioned its statistical validity and advocated that organizations use alternative measures of safety performance instead. The 2024 injury rate at Starbase marks an improvement to that of the prior year, which topped out at 5.9 injuries per 100 workers in 2023 and 4.8 injuries in 2022. But it still leads among SpaceX's land-based facilities, and is second overall only to its west coast booster recovery operations, which has a TRIR of 7.6. OSHA confirmed TechCrunch's calculation of Starbase's TRIR over email, but otherwise did not respond to questions regarding that location's injury rate. While a persistently high TRIR rate can be evidence of a safety problem, it is not an automatic trigger for action, and does not fall under the definition of a “major breach of safety” in their contracts. “NASA interacts frequently with its partners, including SpaceX, to ensure safety from a mission assurance perspective, and remains in regular contact with the company during normal contract administration,” a NASA spokesperson told TechCrunch in response to questions about the company's TRIR. Aria Alamalhodaei covers the space and defense industries at TechCrunch. Amplify your reach, spark real connections, and lead the innovation charge. A former OpenAI engineer describes what it's really like to work there Cognition, maker of the AI coding agent Devin, acquires Windsurf Rivian CEO RJ Scaringe's voting control slips following divorce settlement Marc Andreessen reportedly told group chat that universities will ‘pay the price' for DEI Windsurf's CEO goes to Google; OpenAI's acquisition falls apart</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/07/18/duckduckgo-now-lets-you-hide-ai-generated-images-in-search-results/'>DuckDuckGo now lets you hide AI-generated images in search results</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 16:23:54
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>From there, they will see a new dropdown menu titled “AI images.” Users can then choose whether or not they want to see AI content by selecting “show” or “hide.” DuckDuckGo's new feature comes as the internet is being flooded with AI “slop,” which refers to low-quality media content made using generative AI technology. “The filter relies on manually curated open-source blocklists, including the ‘nuclear' list, provided by uBlockOrigin and uBlacklist Huge AI Blocklist,” DuckDuckGo said in a post on X. DuckDuckGo says it plans on adding additional filters in the future, but didn't provide specifics. Prior to joining the publication in 2021, she was a telecom reporter at MobileSyrup. Amplify your reach, spark real connections, and lead the innovation charge. A former OpenAI engineer describes what it's really like to work there Cognition, maker of the AI coding agent Devin, acquires Windsurf Rivian CEO RJ Scaringe's voting control slips following divorce settlement Marc Andreessen reportedly told group chat that universities will ‘pay the price' for DEI</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/gaming-laptops-have-a-secret-weapon-against-desktop-pcs-and-it-looks-a-lot-like-the-switch-2-2000631298'>Gaming Laptops Have a Secret Weapon Against Desktop PCs, and It Looks a Lot Like the Switch 2</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 16:00:37
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Maybe I'm a dreamer who needs to keep on dreaming, but I think that that pie-in-the-sky wonderland is closer to reality than you may think, and all PC component makers need to do is hop on the eGPU train. The recently revealed Razer Core X V2 has been weighing on my mind as much as it seems it would weigh down my desk. At its core, it's an eGPU, or external graphics processing unit. Razer's latest version is a $350 shoebox filled with surplus PC parts that could bump up the gaming potential of your average lightweight laptop. It makes use of Thunderbolt 5 connectivity to allow for faster data transfer speeds, though it will only grant those 80 Gbps bidirectional speeds with a compatible device that also has a Thunderbolt 5 port. It's compatible with USB-C-based Thunderbolt 4 laptops and USB 4 handhelds, but those devices also need to support external graphics to get the juice from the discrete GPU. We've seen similar designs from companies like Gigabyte with its recently announced Aorus RTX 5090 AI Box. It's the opposite of what I want to see from an eGPU. Even after you spend the Benjamins on Razer's case, you have to source your own graphics card and power supply with enough wattage to power it. This means you're already halfway there to a mini ATX desktop. Why does it have to be in a box, anyway? Couldn't an eGPU enclosure be a complete docking station for your laptop or handheld? Imagine how nice it would be, after schlepping around town all day, to take your lightweight laptop, slot it into your desktop battle station, and then be set up for a console-like gaming experience. Smaller companies like Ayaneo sell the $600 Graphics Starship with an AMD Radeon 7600M XT housed inside. That eGPU has reverse power support for up to four monitors. It's still pretty chunky, which is why the better options for some kind of dockable device lie in laptop GPUs. Asus kicked off 2025 with the promise of the XG Mobile eGPU with Thunderbolt 5 support and up to Nvidia GeForce RTX 5090-level graphics. Asus promised it would be compatible with a $900 Asus ROG Ally X, but we don't yet know how well this could improve the graphics capabilities of the company's most expensive handheld. As for pricing, all we have right now are rumors, but I don't expect either the Xbox Ally or XG Mobile to be cheap. Desktops will still have the edge in graphics capability above any mobile dock, especially if they house a solid gaming CPU like AMD's leading Ryzen 7 9800X3D. The data speeds will continue to be a hindrance. USB 4's bandwidth maxes out at 40 Gbps, which may not be enough for the highest-end GPUs. You can't hook up a Steam Deck unless you do surgery on your device to enable Oculink—a separate type of fast data connection. I'll just keep dreaming until some saint-like Santa figure finally hears my pleas. Get the best tech, science, and culture news in your inbox daily. News from the future, delivered to your present. You may be disappointed in how well your new M4 MacBook can handle one of the most graphically intensive games. Treat yourself or the student in your life to the best laptops, accessories, and study aids for a new semester. Why won't Microsoft cut Asus some slack for making its hardware? We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/china-honkers-elite-cyber-spies/'>How China's Patriotic ‘Honkers' Became the Nation's Elite Cyberspies</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 15:28:07
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The attacks were low-sophistication—mostly website defacements and denial-of-service operations targeting entities in the US, Taiwan, and Japan—but the Honkers advanced their skills over time, and Tan documented his escapades in blog posts. After publishing about hacking targets in Japan, the PLA came calling. The subsequent timeline of events is unclear, but Tan, who went by the hacker handles Wicked Rose and Withered Rose, then launched his own hacking group—the Network Crack Program Hacker (NCPH). They created the GinWui rootkit, one of China's first homegrown remote-access backdoors and then, experts believe, used it and dozens of zero-day exploits they wrote in a series of “unprecedented” hacks against US companies and government entities over the spring and summer of 2006. They did this on behalf of the PLA, according to Adam Kozy, who tracked Tan and other Chinese hackers for years as a former FBI analyst who now heads the SinaCyber consulting firm, focused on China. Tan revealed online at the time that he and his team were being paid about $250 a month for their hacking, though he didn't say who paid or what they hacked. The pay increased to $1,000 a month after their summer hacking spree, according to a 2007 report by former threat intelligence firm VeriSign iDefense. At some point, Tan switched teams and began contracting for the Ministry of State Security (MSS), China's civilian intelligence agency, as part of its notorious hacking group known as APT 41. And in 2020, when Tan was 36, the US Justice Department announced indictments against him and other alleged APT 41 members for hacking more than 100 targets, including US government systems, health care organizations, and telecoms. He's just one of many former Honkers who began their careers as self-directed patriotic hackers before being absorbed by the state into its massive spying apparatus. Not a lot has been written about the Honkers and their critical role in China's APT operations, outside of congressional testimony Kozy gave in 2022. But a new report, published this month by Eugenio Benincasa, senior cyberdefense researcher at the Center for Security Studies at ETH Zürich university in Switzerland, expands on Kozy's work to track the Honkers' early days and how this group of skilled youths became some of China's most prolific cyberspies. “This is not just about [Honkers] creating a hacker culture that was implicitly aligned with national security goals,” Benincasa says, “but also the personal relations they created [that] we still see reflected in the APTs today.” Like US hackers, the Honkers were self-taught tech enthusiasts who flocked to electronic bulletin boards (dial-up forums) to share programming and computer hacking tips. They soon formed groups like Xfocus, China Eagle Union, and The Honker Union of China and came to be known as Red Hackers or Honkers, a name derived from the Mandarin word “hong,” for red, and “heike,” for dark visitor—the Chinese term for hacker. The groups were self-governing with loosely formed hierarchies and even had codes of ethics shaped by influential members like Taiwanese hacker Lin Zhenglong (known by his handle “coolfire”). There were no simulated environments for hackers to build their skills at the time, so Honkers often resorted to hacking real networks. Lin didn't oppose this—hacking wasn't illegal in China except against government, defense, or scientific research networks—but he published a set of ethical guidelines advising hackers to avoid government systems or causing permanent damage and to restore systems to their original condition after Honkers finished hacking them. But these guidelines soon fell away, following a series of incidents involving foreign affronts to China. In 1998, a wave of violence in Indonesia broke out against ethnic Chinese there, and outraged Honker groups responded with coordinated website defacements and denial-of-service attacks against Indonesian government targets. In 2000, after participants at a conference in Japan denied facts around the Nanjing Massacre, in which an estimated 300,000 Chinese were killed during Japan's 1930's occupation of the city, Honkers circulated a list of more than 300 Japanese government and corporate sites, along with email addresses of Japanese officials, and prompted members to target them. A particularly influential group among these, whom Benincasa calls the Red 40, would go on to found or join many of China's top cybersecurity and tech firms and become integral to the state's cyberspy machine. There's no evidence that the government directed the patriotic hacking operations, says Benincasa, but their activity aligned with state interests, and they drew government attention. A retired People's Liberation Army rear admiral and former professor at the PLA National Defense University praised their patriotism. A report claimed that 84 percent of internet users in China favored the patriotic hacking. But in April 2001, this began to change after a Chinese fighter jet clipped a US reconnaissance plane midair off the coast of Hainan and sparked an international incident. The incident stoked nationalist sentiments among US and Chinese hackers alike, and both sides lobbed cyberattacks against the other country's systems. The Chinese government grew concerned over its lack of control of the Honkers and feared they could become a liability and escalate tensions. The former left to join tech firms like Baidu, Alibaba, and Huawei or cybersecurity firms like Venustech and Topsec. Hacker forums began to shutter, and some Honkers got arrested. According to Kozy, Tan faced seven and a half years in prison, though it's unclear whether he served any time. Kozy believes he cut a deal and began work for the MSS. In 2011, it appears he launched an antivirus firm named Anvisoft, which may have served as a front for his MSS work. Topsec and Venustech were two firms alleged to have assisted these efforts. Topsec employed a number of former Honkers, including the founder of the Honker Union of China, and Topsec's founder once acknowledged in an interview that the PLA directed his company. The next year, he and Yang Yong (coolc) from XFocus released X-Scan, a tool to scan networks for vulnerabilities that is still used by hackers in China today. In 2003, two members of Honker Union released HTRAN, a tool to hide an attacker's location by rerouting their traffic through proxy computers, which has been used by China's APTs. Tan and fellow NCPH member Zhou Jibing (whg) are believed to have created the PlugX backdoor in 2008, which has been used by more than 10 Chinese APTs. Over the years, leaks and US indictments against former Honkers have exposed their alleged post-Honker spy careers, as well as China's use of for-profit firms for state hacking operations. The latter include i-Soon and Integrity Tech, both launched by former Honkers. Wu Haibo (shutdown), formerly of Green Army and 0x557, launched i-Soon in 2010. In March this year, eight i-Soon employees and two MPS officers were indicted by the US for hacking operations that targeted US government agencies, Asian foreign ministries, dissidents, and media outlets. Integrity Tech, founded in 2010 by former Green Army member Cai Jingjing (cbird), was sanctioned by the US this year over ties to global infrastructure hacks. This year, the US also indicted former Green Army members Zhou and Wu for conducting state hacking operations and sanctioned Zhou over links to APT 27. In addition to engaging in state-sponsored hacking, he allegedly also ran a data-leak service selling some of the stolen data to customers, including intelligence agencies. This isn't unlike early-generation US hackers who also transitioned to become cybersecurity company founders and also got recruited by the National Security Agency and Central Intelligence Agency or hired by contractors to perform hacking operations for US operations. But unlike the US, China's whole-of-society intelligence authorities have compelled some Chinese citizens and companies to collaborate with the state in conducting espionage, Kozy notes. “And … because a lot of these young guys had patriotic leanings to begin with, they were kind of pressed into service by saying, ‘Hey you're going to be doing a lot of really good things for the country.' Also, many of them started to realize they could get rich doing it.” In your inbox: Our biggest stories, handpicked for you each day WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/gastrointestinal-cancers-are-surging-among-younger-americans-2000631264'>Gastrointestinal Cancers Are Surging Among Young Americans, and No One Is Quite Sure Why</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 15:12:56
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Young people appear to be increasingly vulnerable to gastrointestinal cancers, but researchers aren't entirely sure what is driving the surge in disease. In a new study out this week, scientists led by the Dana-Farber Cancer Institute found that rates of early-onset GI cancers—those occurring in people younger than 50—are rising more rapidly than other types of cancer. In particular, colorectal cancer cases have significantly increased, while rates of other forms of the disease, like stomach cancer, are creeping up, too. “Colorectal cancer is the most common early-onset GI cancer worldwide, accounting for more than half of the cases, but it is not the only GI cancer that is rising in younger adults,” said senior study author Kimmie Ng, director of the Young-Onset Colorectal Cancer Center at Dana-Farber, in a statement. “Unfortunately, pancreatic, gastric, and esophageal cancers are also increasing in young people,” she added. 45 Is the New 50 When It Comes to Colorectal Cancer Screening They also analyzed three publicly available cancer statistic databases. In 2022, there were at least 25,000 Americans under 50 who developed GI cancer. An earlier, separate review of data—by some of the same authors—over a similar time period concluded that the rate of GI cancer has tripled in young people aged between 15 and 19, and almost doubled in those aged between 20 and 24. “The rising incidence of early-onset GI cancers is alarming and underscores the need for enhanced prevention strategies and early detection methods,” said Ng. Scientists May Have Figured Out Why Young People Are Getting Colorectal Cancer More Often In 2020, public health experts recommended routine screening for colorectal cancer in people 45 and up, but the researchers noted that a year later, fewer than 20% of people ages 45 to 49 went for a screening. Another outstanding question is whether early-onset GI cancers are different from those caught later in life, and if so, should they be treated differently. “We need to be thinking not only about the risk factors for these diseases but also how to screen, diagnose, and treat young people with these cancers,” said Ng. Get the best tech, science, and culture news in your inbox daily. The FDA will decide whether to approve Replimune's RP1 virus for treating advanced melanoma later this month. A New Jersey man's unusual lung cancer may have been sparked by his decade-plus history of vaping. New research hints that SSRIs can be repurposed to fight off cancer. During his testimony before the House Appropriations Committee, RFK opined on abortions, vaccines, and MLK Jr. We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/pc-components/cpus/intel-arrow-lake-refresh-might-not-have-a-new-npu-after-all-latest-reports-indicate-a-clock-speed-bump-only'>Intel Arrow Lake refresh might not have a new NPU after all — latest reports indicate a clock speed bump only</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 14:58:08
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. Just a few days ago, Intel's upcoming Arrow Lake-S desktop refresh was leaked again, and this time, we learned that it's allegedly coming in the second half of 2025. Paired with a new NPU and higher clock speeds, the refresh would still be binned on Intel's 20A node and bring modest improvements to the lineup. However, a new tweet from leaker Jaykihn now suggests that there won't be any upgrades to AI capability in Arrow Lake 2.0, as it's said to retain the same NPU present in the current processors. Intel introduced the upgraded NPU 4 in last year's Lunar Lake. If the tipster is to be believed, even two years later, Intel's desktop CPUs will still be equipped with an outdated AI module that cannot compete with mobile-first offerings from AMD or Apple. ARL-S and HX Refresh will not receive NPU changes.This is contradictory to the preliminary information published a year ago.July 18, 2025 Let's be clear, AMD has somewhat gone down the same road with its gen-over-gen refresh upgrades, relying more on X3D improvements down the line, rather than major architectural breakthroughs, though that's reportedly about to change. Last week, CEO Lip-Bu Tan said that Intel is "not in the top 10 semiconductor companies" in the world anymore — not something you'd want hear from your leader, even if it's an exaggeration. Panther Lake will finally bring Intel's long-awaited 18A process to the market, the Blue Team's Hail Mary that should propel them a few ranks in bleeding-edge chip manufacturing. Therefore, even if Arrow Lake's refresh—regardless of it having the new NPU or not—looks underwhelming, Intel is still alive and doing exciting things we can all look forward to. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Hassam Nasir is a die-hard hardware enthusiast with years of experience as a tech editor and writer, focusing on detailed CPU comparisons and general hardware news. When he's not working, you'll find him bending tubes for his ever-evolving custom water-loop gaming rig or benchmarking the latest CPUs and GPUs just for fun. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/a-huge-new-lab-in-sweden-is-testing-the-6g-powered-future-of-connected-cars-and-drones-2000631279'>A Huge New Lab in Sweden Is Testing the 6G-Powered Future of Connected Cars and Drones</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 14:24:01
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Owned by the Research Institutes of Sweden (RISE), AstaZero has just unveiled the world's most advanced connected vehicle proving ground—an ambitious leap into a 6G-powered future where every movement on the road could be coordinated, controlled, and optimized in real time. AstaZero is not an average vehicle test track. It is a full-scale, independent research environment built to test the automated transport systems of tomorrow to ensure confidence and safety. Think of it as a real-world lab where self-driving cars, AI-powered drones, and connected emergency vehicles are pushed to their limits. At the heart of this latest breakthrough are multiple 5G networks and a cutting-edge computing facility—marking a first for any open, brand-neutral proving ground. With 3G networks being phased out globally, mission-critical systems like ambulances, fire trucks, and police vehicles are under pressure to modernize. AstaZero's newly launched facility provides the first real opportunity to test innovative systems in controlled yet dynamic, real-life scenarios. Powered by edge computing, vehicles can now process data locally instead of relying on far-off cloud centers. Without advanced, integrated testing, safer roads remain a dream. In these types of systems, three key factors are crucial: reliability, ultra-fast communication, and intelligent decision-making.” That is the level of consistency required for “mission-critical” scenarios, where even a split-second failure could cost lives. When asked what type of real-world scenarios are most challenging to simulate at AstaZero and how they overcome them, Janevik described the complexity of multiple testing domains with a future scenario: The footage is used by both the rescue crew to assess and follow the situation, but also by central management, which needs to make decisions on things such as rerouting of traffic and the deployment of further teams and other authorities like police and medical teams. Then imagine that the drone also creates a local map update with static objects such as a crashed vehicle or cones for traffic redirection and dynamic ones such as personnel or fires. To ensure such a complex system works, the testing and design teams need to factor in elements like connectivity disruption and technology integration across numerous manufacturers and telecom companies, which is what AstaZero offers. Beyond roads and intersections, AstaZero's proving ground is designed to test limitless scenarios. Whether cyclists swerving through traffic or simulated pedestrians crossing at unpredictable times, the site can orchestrate complex environments. Janevik says, “We test collision avoidance technology to auto-brake vehicles for different scenarios, but more importantly, the site provides robust testing to ensure highly repeatable results in a wider spectrum of conditions.” Janevik believes in the impact of this approach on “unique testing scenarios for smaller machine learning models with AI-based decision-making to prove that these can make the right decisions with ongoing updates.” The only limits are what the engineers can imagine, and Janevik sees this as their goal—to live their vision and help societies accelerate into safe, sustainable, and automated transportation systems of the future. This is especially critical in Europe, where road fatality statistics have stagnated. As EU Commissioner for Sustainable Transport and Tourism Apostolos Tzitzikostas has said, “Too many lives are still lost on our roads every year.” Any vehicle manufacturer, telecom provider, or AI developer can pay to use the facility to test and refine their systems. That neutral status is intended to ensure consistency and fairness across global standards, which is especially important as the European New Car Assessment Programme rolls out new vehicle-to-everything benchmarks between 2026 and 2032. Already a recognized test organization by the Global Certification Forum, AstaZero has taken a lead role in helping shape those standards. With edge computing enabling decentralized, real-time responses, the next generation of smart vehicles will be able to prevent accidents before they happen, minimize traffic delays, and drastically improve energy efficiency. Get the best tech, science, and culture news in your inbox daily. News from the future, delivered to your present. After years of hype, Tesla's self-driving taxi service is finally live. Tesla hopefuls are waiting on autonomous taxis as Musk faces an increasingly steep uphill battle. We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/review/lettuce-grow-indoor-farmstand/'>Lettuce Grow's Indoor Farmstand Is Perfect, Except for a Few Bugs (Literally)</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 14:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>All products featured on WIRED are independently selected by our editors. However, when you buy something through our retail links, we may earn an affiliate commission. Upon receiving the Lettuce Grow Indoor Farmstand in the mail, I did not expect that I'd be enjoying some tea before I'd even unwrapped all the parts. With a Dollar Tree Property Brother?” my husband asked, peering over my shoulder as I unpacked various tubes and parts. And indeed, among the boxes was a glossy handout of a slightly younger-looking Zooey, standing with a man who did vaguely resemble her current husband, Jonathan Scott, of Property Brothers fame. Turns out it was her ex-husband, film producer Jacob Pechenik, with whom she had created this indoor hydroponic gardening system in 2019. Even though they split shortly thereafter, they continued to run Lettuce Grow together after their 2020 divorce, and an Instagram photo from July 1 even shows Deschanel flanked by Pechenik on one side and Scott on the other, debuting a Lettuce Grow collab with Costco. Apparently Pechenik runs day-to-day operations and Deschanel continues to promote the company through social media, according to a 2023 People interview with the former couple. (Deschanel and Pechenik have two children together.) Anyway, perhaps as befitting a celebrity endorsement, the Lettuce Grow is quite dramatic-looking for an indoor hydroponic garden, evoking a giant, space-age version of the terra cotta strawberry planter you probably remember from your grandma's house. Even better, it delivers on its promises of growing many plants and vegetables indoors—even peppers and tomatoes—within a small footprint. As far as indoor hydroponic garden assemblies go, Lettuce Grow's was easy enough for pretty much anyone to figure out—second-easiest of the four systems I'm currently testing, behind only the Gardyn (9/10, WIRED Recommends). I tested the medium, 24-slot indoor version for six weeks in a low-light corner near my downstairs bathroom. I recommend ordering after you've received and assembled your Farmstand. My Farmstand included two old-school analog timers, the kind with the infuriating little prongs that must be toggled. Lettuce Grow offers a smart timer upgrade for $24, which I also tested. The company also has an app, which kept disconnecting from the device and which I ended up abandoning halfway through. Of these, I preferred the smart timer, and I was able to set the lights to turn off at night. (Note that the water sprayed by the pump does make a startlingly loud splashing sound due to the Farmstand's cavernous interior, so you may not want it in a home office or bedroom or anywhere the noise could become a disturbance.) All products featured on WIRED are independently selected by our editors. Generous 1-pound bags of calcium nitrate and Jack's water-soluble fertilizer are included with Farmstands, as well as a pH testing kit (which must be administered weekly), an extra-long pipette, scoops, and pH adjuster liquid. Filling the Farmstand's 20-gallon base was a bit cumbersome, as the QR-code-accessible video instructions (there were no paper instructions) said to use a garden hose—no easy feat when you're indoors. Once-a-week maintenance consisted of a couple gallons' worth of water to top off, fertilizer additions, and pH testing and/or balancing. However, there was one significant problem with receiving pregrown plants: pests. Within a couple of weeks of receiving my seedlings, I noticed small white flecks on both my bok choy and cutting-celery plants. Days later, the flecks had erupted into a full-fledged whitefly infestation that spanned multiple plants. Spraying with insecticidal soap was a daily chore but had little effect. I had two other bug-free hydroponic gardens set up in the same vicinity as the Farmstand, whose plants had been grown from seed. There seemed to be no explanation for the Farmstand's outbreak other than that the seedlings had arrived already infested with eggs. Sure enough, a search of Lettuce Grow's Farmstand Community Facebook group revealed pest infestations on incoming seedlings to be a pervasive and long-standing problem. The four light rings seemed to use a negligible amount of power and gave off no heat, and the futuristic look garners plenty of attention—much like Zooey herself. All products featured on WIRED are independently selected by our editors. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.technologyreview.com/2025/07/18/1120466/a-major-ai-training-data-set-contains-millions-of-examples-of-personal-data/'>A major AI training data set contains millions of examples of personal data</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.technologyreview.com', 'title': 'MIT Technology Review'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 13:08:26
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Personally identifiable information has been found in DataComp CommonPool, one of the largest open-source data sets used to train image generation models. Thousands of images—including identifiable faces—were found in a small subset of DataComp CommonPool, a major AI training set for image generation scraped from the web. The bottom line, says William Agnew, a postdoctoral fellow in AI ethics at Carnegie Mellon University and one of the coauthors, is that “anything you put online can [be] and probably has been scraped.” The researchers found thousands of instances of validated identity documents—including images of credit cards, driver's licenses, passports, and birth certificates—as well as over 800 validated job application documents (including résumés and cover letters), which were confirmed through LinkedIn and other web searches as being associated with real people. (In many more cases, the researchers did not have time to validate the documents or were unable to because of issues like image clarity.) When it was released in 2023, DataComp CommonPool, with its 12.8 billion data samples, was the largest existing data set of publicly available image-text pairs, which are often used to train generative text-to-image models. While its curators said that CommonPool was intended for academic research, its license does not prohibit commercial use as well. CommonPool was created as a follow-up to the LAION-5B data set, which was used to train models including Stable Diffusion and Midjourney. While commercial models often do not disclose what data sets they are trained on, the shared data sources of DataComp CommonPool and LAION-5B mean that the data sets are similar, and that the same personally identifiable information likely appears in LAION-5B, as well as in other downstream models trained on CommonPool data. CommonPool researchers did not respond to emailed questions. And since DataComp CommonPool has been downloaded more than 2 million times over the past two years, it is likely that “there [are]many downstream models that are all trained on this exact data set,” says Rachel Hong, a PhD student in computer science at the University of Washington and the paper's lead author. “You can assume that any large-scale web-scraped data always contains content that shouldn't be there,” says Abeba Birhane, a cognitive scientist and tech ethicist who leads Trinity College Dublin's AI Accountability Lab—whether it's personally identifiable information (PII), child sexual abuse imagery, or hate speech (which Birhane's own research into LAION-5B has found). Indeed, the curators of DataComp CommonPool were themselves aware it was likely that PII would appear in the data set and did take some measures to preserve privacy, including automatically detecting and blurring faces. But in their limited data set, Hong's team found and validated over 800 faces that the algorithm had missed, and they estimated that overall, the algorithm had missed 102 million faces in the entire data set. On the other hand, they did not apply filters that could have recognized known PII character strings, like emails or Social Security numbers. “Filtering is extremely hard to do well,” says Agnew. There are other privacy issues that the face blurring doesn't address. Another privacy mitigation measure comes from Hugging Face, a platform that distributes training data sets and hosts CommonPool, which integrates with a tool that theoretically allows people to search for and remove their own information from a data set. But as the researchers note in their paper, this would require people to know that their data is there to start with. “Even if someone finds out their data was used in a training data sets and … exercises their right to deletion, technically the law is unclear about what that means,”  says Tiffany Li, an associate professor of law at the University of San Francisco School of Law. Even if you filter, you're still going to have private data in there, just because of the scale of this. CommonPool was built on web data scraped between 2014 and 2022, meaning that many of the images likely date to before 2020, when ChatGPT was released. And with web scrapers often scraping data from each other, an image that was originally uploaded by the owner to one specific location would often find its way into other image repositories. “I might upload something onto the internet, and then … a year or so later, [I] want to take it down, but then that [removal] doesn't necessarily do anything anymore,” says Agnew. The researchers also found numerous examples of children's personal information, including depictions of birth certificates, passports, and health status, but in contexts suggesting that they had been shared for limited purposes. “It really illuminates the original sin of AI systems built off public data—it's extractive, misleading, and dangerous to people who have been using the internet with one framework of risk, never assuming it would all be hoovered up by a group trying to create an image generator,” says Ben Winters, the director of AI and privacy at the Consumer Federation of America. “We have the GDPR in Europe, we have the CCPA in California, but there's still no federal data protection law in America, which also means that different Americans have different rights protections,” says Marietje Schaake, a Dutch lawmaker turned tech policy expert who currently serves as a fellow at Stanford's Cyber Policy Center. Besides, these privacy laws apply to companies that meet certain criteria for size and other characteristics. They do not necessarily apply to researchers like those who were responsible for creating and curating DataComp CommonPool. Machine-learning researchers have long operated on the principle that if it's available on the internet, then it is public and no longer private information, but Hong, Agnew, and their colleagues hope that their research challenges this assumption. “What we found is that ‘publicly available' includes a lot of stuff that a lot of people might consider private—résumés, photos, credit card numbers, various IDs, news stories from when you were a child, your family blog. These are probably not things people want to just be used anywhere, for anything,” says Hong. Hopefully, Schaake says, this research “will raise alarm bells and create change.” Some people believe chatbots like ChatGPT can provide an affordable alternative to in-person psychedelic-assisted therapy. Discover special offers, top stories, upcoming events, and more. Try refreshing this page and updating them one more time.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-bubble-is-worse-than-the-dot-com-crash-that-erased-trillions-economist-warns-overvaluations-could-lead-to-catastrophic-consequences'>AI bubble is worse than the dot-com crash that erased trillions, economist warns — overvaluations could lead to catastrophic consequences</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 12:36:23
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>The only difference between then and now is that there's more to lose. When you purchase through links on our site, we may earn an affiliate commission. Torsten Sløk, chief economist at American asset company, Apollo Global Management, has warned that the AI companies and their stock prices are more over-inflated than the dot-com companies of the early 2000s, suggesting that an even bigger crash could be coming. A relatively new technology and phenomenon at the time, but one that venture capitalists saw as having earning potential. By the early 2000s, many of the companies involved in the boom had gone bust, and even now, industry giants like Amazon have lost huge portions of their investments, earnings, and market capitalization. That's what Sløk argues is coming for the major AI firms. That's Apple, Microsoft, OpenAI, Meta, Google/Alphabet, Amazon, and a range of other companies. That, he claims, is not going to last, and because the boom is bigger this time, the bust could be even worse. Although Sløk doesn't present a timeline for when any such bust could happen, it's clear even for us non-economists that the money being thrown around by some of the major tech companies is difficult to sustain. OpenAI recently accused Meta of offering $100 million signing bonuses to new AI talent. CoreWeave is investing $6 billion in a new AI center, Amazon might be investing an additional $8 billion in Claude maker, Anthropic. Not to mention Nvidia's push to drive $500 billion in investment in "AI Factories," all while hoping that name catches on. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Even if this wasn't quite to the overhyped levels of the dot-com crash, there are plenty of recent examples of tech trends seeming to encapsulate the future and then failing to deliver. Meta invested tens of billions in the Metaverse and then promptly pivoted to AI as if it never happened. Where each of those was constrained to a single company, or a niche market, though, AI is already everywhere, even without much of a profitable product to show for it. AI holds a lot of promise, perhaps a little like virtual reality, the metaverse, and blockchain technology, but does it warrant the hundreds of billions of investment it's getting already? Sløk argues no, and that when the world catches on, these companies, which have ridden high on a wave of hype and investment, may find their ephemeral silicon empires melt away into sand. What comes after that is even more speculative than a potential downfall, but if the dot-com analogy tracks, we could see huge consolidation, with many of the top companies surviving, but scaling back their investments dramatically. Speculative AI companies would likely fail, while those with more robust revenue streams, like Amazon, Google, and Meta, would likely survive, albeit diminished in their influence. However, perhaps we wouldn't need to see "AI" as a buzzword on every product we buy over the following few years. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York,</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/cyber-security/chinese-state-sponsored-cyberattacks-target-taiwan-semiconductor-industry-security-firm-says-motivation-of-three-separate-campaigns-most-likely-espionage'>Chinese state-sponsored cyberattacks target Taiwan semiconductor industry — security firm says motivation of three separate campaigns 'most likely espionage'</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 11:48:55
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. Chinese-linked hackers have intensified cyber-espionage efforts against Taiwan's semiconductor industry and financial analysts, conducting coordinated attacks between March and June 2025, with some operations still ongoing. Reuters reports that cybersecurity firm Proofpoint has attributed the activity to at least three previously undocumented China-aligned groups—UNK_FistBump, UNK_DropPitch, and UNK_SparkyCarp—while a fourth group, UNK_ColtCentury (also tracked as TAG-100 or Storm-2077), attempted to build trust with its targets before deploying a remote access trojan (RAT) known as Spark. These attacks are believed to be part of Beijing's long-term push for semiconductor self-sufficiency, driven by U.S. export restrictions and Taiwan's dominance in advanced chip manufacturing. The hackers have focused on organizations involved in semiconductor design, manufacturing, testing, and supply chains, as well as investment analysts tracking Taiwan's semiconductor sector. Proofpoint estimates that 15 to 20 organizations were targeted, ranging from medium-sized businesses to major global enterprises, along with analysts at at least one U.S.-headquartered international bank. While Taiwan's major chipmakers, including TSMC, MediaTek, UMC, Nanya, and RealTek, declined or did not respond to comment, Reuters has been unable to confirm which firms were breached or whether any of the attacks succeeded. Opening these files triggered the deployment of Cobalt Strike beacons or a custom C-based backdoor known as Voldemort, previously linked to attacks on over 70 organizations worldwide. UNK_DropPitch, on the other hand, focused on financial analysts at major investment firms, masquerading as staff from a fake investment company and delivering malicious PDF links that downloaded ZIP archives carrying DLL-based payloads. These malicious DLL files, when run using a side-loading trick, installed the HealthKick backdoor or opened a reverse connection to hacker-controlled servers like 45.141.139[.]222. In contrast, UNK_SparkyCarp used a different tactic, sending fake account security emails that led victims to phishing sites such as accshieldportal[. ]com, using a custom tool to intercept and steal login credentials. TeamT5, a Taiwanese cybersecurity firm, has reported an uptick in email-based threats aimed at Taiwan's semiconductor industry. This strategy of targeting peripheral (secondary) sectors—such as raw materials, logistics, or consulting—underscores a broader effort to compromise the supply chain by exploiting its less-protected edges. Proofpoint researchers, including threat expert Mark Kelly, have warned that entities not previously on the radar are now being singled out. In late 2023, it was discovered that the Chimera group breached Europe's NXP—the continent's largest chipmaker—remaining undetected for over two years and stole sensitive chip design IP. Kelly noted that attackers sometimes sent just one or two highly targeted emails, while other campaigns involved as many as 80 emails to infiltrate entire organizations. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. China's embassy in Washington responded to the reports by reiterating that cyberattacks are a global issue and that China “firmly opposes and combats all forms of cybercrime”. As such, these operations show clear alignment with Chinese state interests, as the targeting, tools, and tactics bear the hallmarks of China-linked cyber-espionage groups. Hassam Nasir is a die-hard hardware enthusiast with years of experience as a tech editor and writer, focusing on detailed CPU comparisons and general hardware news. When he's not working, you'll find him bending tubes for his ever-evolving custom water-loop gaming rig or benchmarking the latest CPUs and GPUs just for fun. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/eddington-director-ari-aster-couldnt-stand-living-in-the-internet-so-he-made-a-movie-about-it/'>'Eddington' Director Ari Aster Couldn't Stand ‘Living in the Internet.' So He Made a Movie About It</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-18 11:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Also like a lot of us, the experience left him feeling pretty bad. But unlike most people, the director of Hereditary, Midsommar, and Beau is Afraid wasn't just doomscrolling on Twitter to pass the time. In theaters on July 18, the film deftly explores how social media and the internet in general have fractured modern society, placing us all in our own personally tailored worlds—and then descends into violence when those worlds collide. Aster depicts this twisted vision of modern society by regularly pointing his camera straight at the Facebook and Twitter feeds of his main characters, giving the audience a look into the conspiracy theories and memes influencing their every decision. “I also cultivated different algorithms to see what somebody else might be receiving. That was very helpful in making the film, even in post, when we were deciding what tweets to show on certain phones.” These glimpses into the interior lives of Eddington's characters—the movie stars Joaquin Phoenix as a populist sheriff who runs for mayor against a corrupt, liberal incumbent played by Pedro Pascal—help ground a story that pivots wildly at times from cryptic political commentary to heightened carnage. “Society has been atomized and fractured over the last however many years,” he says. Eddington takes this theory and makes it a baseline reality, exploring a world where no two characters seem to be living in the same reality or even speaking the same language, whether that divide is political or generational. In one scene, a teenage boy sits at the dinner table and explains why he needs to reject his own whiteness. His parents' response is a mix of shock and confusion. “This is a movie about people living in different realities who are unreachable to each other,” Aster says, musing that the modern internet has changed humanity in ways we likely still don't fully understand. “I do think the technological revolution is a mostly dehumanizing one,” he adds. Phoenix's character will often return home to hear some disembodied voice spouting baseless claims through the speakers of an abandoned laptop. Later, his wife (Emma Stone) or mother-in-law (Deirdre O'Connell) will regurgitate those fringe theories over breakfast. “One thing was inspired by somebody I heard on the street in New York with a microphone,” he says. Others were pulled from different corners of the internet.” Aster's overall goal with Eddington was to convey the overwhelming feeling of being online today, while still making a compelling movie. “It was important to get as many voices in the cacophony and represent as many corners of the internet as possible—to make a coherent story about the incoherent miasma we are living in,” he says. Eddington may primarily be a movie about how social media is breaking our brains, but there's another technological innovation Aster was careful to represent in his movie: artificial intelligence. Meanwhile, just outside of town, another crisis is being cooked up.” In a recent interview with Letterboxd, the director opined that it's “obviously already too late” to stop AI. But when pressed about the pros and cons of artificial intelligence, Aster describes it with a mix of wonder and fear. As a director, he worries the ability to create transcendent art is being “flattened” by generative AI tools, while at the same time admitting that it's opening up the film industry to more people than ever. “It's been democratized in an exciting way,” he says. “There are more possibilities now, but something's also going away.” “In the beginning, when these systems were hallucinating and creating weird imagery — 12 fingers, bizarre stuff—that was more interesting to me,” he says. Despite sometimes feeling like a Coen Brothers western on amphetamines, Eddington is impressively grounded throughout its nearly two-and-a-half-hour runtime—until the final act. After Phoenix's character kills Pascal's and then frames the local BLM protesters for the murder, a plane full of actual anti-fascist terrorists flies into town and starts blowing everything up. “At the end, he gets to live in his own action movie,” Aster says. “I definitely wanted the movie to start feeling like Call of Duty or Grand Theft Auto.” While Aster leaves the meaning of this sequence up for interpretation, there's one clear way to understand Eddington's finale. The result feels like watching an alt-right fever dream in which the woke terrorists we all know never existed suddenly show up on your doorstep with guns and explosives. “I wanted to give as broad a picture of the environment as I could without being dismissive or condescending,” Aster says. “I see all these characters as people who care about the world and know something's wrong. In your inbox: Our biggest stories, handpicked for you each day WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            