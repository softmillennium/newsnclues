
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - TECHNOLOGY Article Summaries - 2025-12-09</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            TECHNOLOGY
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/openai-economic-research-team-ai-jobs/'>OpenAI Staffer Quits, Alleging Company's Economic Research Is Drifting Into AI Advocacy</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 17:30:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>One of these employees, Tom Cunningham, left the company entirely in September after concluding it had become difficult to publish high-quality research, WIRED has learned. OpenAI chief strategy officer Jason Kwon addressed these concerns in an internal memo following Cunningham's departure. In a statement to WIRED, OpenAI spokesperson Rob Friedlander said the company hired its first chief economist, Aaron Chatterji, last year and has since expanded the scope of its economic research. The alleged shift comes as OpenAI deepens its multibillion-dollar partnerships with corporations and governments, cementing itself as a central player in the global economy. Experts believe the technology OpenAI is developing could transform how people work, although there are still large questions about when this change will happen and to what extent it will impact people and global markets. Since 2016, OpenAI has regularly released research on how its own systems could reshape labor and shared data with outside economists. An outside economist who previously worked with the company alleges that OpenAI is increasingly publishing work that casts its technology in a favorable light. Earlier this week, OpenAI published a report in which it surveyed enterprise users who claim that the company's AI products have saved them an average of 40 to 60 minutes of time a day, and that companies throughout the economy have “significant headroom” to increase their AI adoption. When former head of policy research Miles Brundage left OpenAI in October of 2024, he said the company had become so high-profile that it was “hard for me to publish on all the topics that are important to me.” He added that while some constraints are expected, he felt that OpenAI had become too restrictive. Sharing gloomy statistics about AI's potential impact on the economy could complicate OpenAI's fragile public image. While the Trump administration has championed AI's potential, White House advisers have pushed back on claims that the technology will eliminate jobs, which has become an increasingly urgent issue for many Americans. Roughly 44 percent of young people in the US fear that AI will reduce job opportunities, according to a November survey from the Harvard Kennedy School's Institute of Politics. While companies often highlight research that benefits them, today's leading AI labs are given an unusual level of authority to self-report the risks and capabilities of the technology they're racing to deploy. Silicon Valley leaders have mounted $100 million lobbying campaigns to keep it this way, fighting against proposed state-level AI regulations that could constrain the industry. OpenAI's allegedly cautious posture stands in contrast to its rival Anthropic. David Sacks, the White House special adviser for AI and crypto, accused Anthropic of running a “sophisticated regulatory capture strategy based on fear-mongering.” OpenAI's economic research efforts are currently managed by Chatterji, who led a significant September report on how people around the world are using ChatGPT. It was released months after Anthropic published a similar paper on how people use its chatbot, Claude. Sources tell WIRED that Chatterji reports to OpenAI's chief global affairs officer, Chris Lehane, reflecting how the team is tightly integrated with the company's political and policy strategy. Lehane previously worked at Airbnb, where he helped the company defeat Prop F, a ballot measure in San Francisco that would have severely restricted the company's ability to operate. He also served as the special assistant counsel to former President Bill Clinton, where he earned a reputation as the “master of disaster.” WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/12/09/openai-anthropic-and-block-join-new-linux-foundation-effort-to-standardize-the-ai-agent-era/'>OpenAI, Anthropic, and Block join new Linux Foundation effort to standardize the AI agent era</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 17:28:36
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>As AI moves beyond chatbots and toward systems that can take actions, the Linux Foundation is launching a new group dedicated to keeping AI agents from splintering into a mess of incompatible, locked-down products. Anchoring the AAIF at launch are donations from Anthropic, Block, and OpenAI. Other members in the AAIF include AWS, Bloomberg, Cloudflare, and Google, signaling an industry-level push for shared guardrails so that AI agents can be trustworthy at scale. In OpenAI engineer Nick Cooper's view, protocols are essentially a shared language that lets different agents and systems work together without every developer reinventing integrations from scratch. Jim Zemlin, executive director of the Linux Foundation, put it more bluntly in conversations around the launch: The goal is to avoid a future of “closed wall” proprietary stacks, where tool connections, agent behavior, and orchestration are locked behind a handful of platforms. “By bringing these projects together under the AAIF, we are now able to coordinate interoperability, safety patterns, and best practices specifically for AI agents,” Zemlin said. Block — the fintech company behind Square and Cash App — isn't known for AI infrastructure, but it's making an openness play with Goose. AI tech lead Brad Axen frames it as proof that open alternatives can match proprietary agents at scale, with thousands of engineers using it weekly for coding, data analysis, and documentation. Donating MCP to AAIF signals that the protocol won't be controlled by a single vendor. That governance point is central to why the Linux Foundation created a new umbrella at all. But Zemlin of the Linux Foundation argues that funding doesn't equal control: Project roadmaps are set by technical steering committees, and no single member gets unilateral say over direction. Still, the big question is whether AAIF becomes real infrastructure or just another industry logo alliance. For OpenAI's Cooper, success would look like an evolution of standards: “I don't want it to be a stagnant thing. I don't want these protocols to be part of this foundation, and that's where they sat for two years. There's also a more subtle consequence: Even with open governance, one company's implementation could become the default simply because it ships fastest or gains the most usage. He points to open source history — like Kubernetes “winning” the container race — as evidence that “dominance emerges from merit and not vendor control.” For developers and enterprises, the short-term appeal is clear: less time building custom connectors, more predictable agent behavior across codebases, and simpler deployment in security-conscious environments. Rebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence. Show your CFO the marketing proof they want!Join a free webinar hosted by Pantheon on Tuesday December 9 at 10am PT to learn where spend delivers & how to build a 2026 strategy grounded in real results. Claude Code is coming to Slack, and that's a bigger deal than it sounds SpaceX reportedly in talks for secondary sale at $800B valuation, which would make it America's most valuable private company Andy Jassy says Amazon's Nvidia competitor chip is already a multibillion-dollar business</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/openai-anthropic-and-block-are-teaming-up-on-ai-agent-standards/'>OpenAI, Anthropic, and Block Are Teaming Up to Make AI Agents Play Nice</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 17:06:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>OpenAI, Anthropic, and Block have cofounded a new open source organization—the Agentic AI Foundation—to promote standards for artificial intelligence agents. This includes Anthropic's Model Context Protocol (MCP), which allows agents to connect and interact; OpenAI's Agents.md, which lets programs and websites specify rules for coding agents; and Goose, a framework for building agents developed by Block. “MCP is used by many companies, but there are others [who don't use it],” says Nick Cooper, who leads work on the protocol at OpenAI. Cooper says that making MCP an open standard should encourage developers and companies to embrace it and build systems that integrate agentic AI. The new foundation reflects a nascent shift from chat-based AI systems to greater use of programs that take actions on behalf of users. This kind of agentic AI promises a potentially lucrative new paradigm in which AI agents use the web and negotiate with one another to power all sorts of applications. Consumers may, for example, use AI assistants to buy and book things, while businesses use AI agents to manage transactions and customer interactions. “Open source is going to play a very big role in how AI is shaped and adopted in the real world,” Narayanan says. The question of openness seems crucial to AI right now. US companies mostly make money by offering access to powerful closed models through application programming interfaces, or APIs. Meta previously released the weights for its best model, Llama, so that anyone could download and run it, although the company has recently signaled a shift to a more closed approach. Some worry that this picture could give Chinese firms a big strategic advantage over time. OpenAI also has a number of open source efforts, including a model called gpt-oss and Codex CLI, software for the command line interface for its models. Although there is nothing in the standards requiring people to use foundation models from OpenAI, Anthropic, or Block, they believe that openness should ultimately benefit their businesses. Manik Surtani, head of open source at Block, says the company's Goose agent, which taps into a wide range of LLMs to perform actions on a computer, has soared in popularity over the past year. “MCP, Agents.md, and Goose have become essential tools for developers building this new class of agentic technologies," said Jim Zemlin, executive director of the Linux Foundation, in a statement. Open standards may be technologically neutral, but if these agentic tools become globally dominant they could confer the US companies behind them considerable influence. This is an edition of Will Knight's AI Lab newsletter. Big Interview: Palantir's CEO Alex Karp goes to war Livestream: What businesses need to know about agentic AI WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/microsoft-investing-17-5b-in-india-to-accelerate-ai-infrastructure-skills-training-and-more/'>Microsoft investing $17.5B in India to accelerate AI infrastructure, skills training and more</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 16:21:48
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Microsoft is pouring $17.5 billion into India — its largest investment in Asia — to boost the country's AI infrastructure and diffusion, the company announced Tuesday. Microsoft CEO Satya Nadella is in the country this month as part of a multi-city “India AI” tour. He met with Prime Minister Narendra Modi in New Delhi on Tuesday and will deliver a keynote address on Wednesday: “Leading in the New Age of AI.” Microsoft also announced that 310 million informal workers India will benefit from advanced AI capabilities being integrated into two key digital public platforms of the Ministry of Labour and Employment — e-Shram and the National Career Service. Microsoft employs 22,000 people across Bengaluru, Hyderabad, Pune, Gurugram, Noida and other cities, representing numerous company business lines. Elsewhere on Tuesday, Microsoft President Brad Smith announced new commitments to Canada, adding $5.4 billion over the next two years to its continued investment in building out digital and AI infrastructure in the country. Have a scoop that you'd like GeekWire to cover? Microsoft and OpenAI tweak the terms of their cloud deal, enabling $500B Stargate AI project ‘I'm good for my $80 billion': What Microsoft CEO Satya Nadella really meant by his Stargate zinger Microsoft's financial disclosures show how OpenAI is fueling growth — and taking a toll on profits</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/ifixit-made-an-ai-assistant-to-help-you-fix-your-gadgets-and-its-free-for-now-2000697275'>iFixit Made an AI Assistant to Help You Fix Your Gadgets (and It's Free, for Now)</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 16:10:42
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>iFixit, the internet's go-to for repair guides and spare parts, just launched a new mobile app with what sounds like a genuinely useful AI chatbot. Starting today, iOS and Android users can download the iFixit app and chat directly with the new FixBot to get curated expert advice on how to fix everything from a cracked phone screen to a faulty dishwasher. The team at iFixit says it spent two years building the chatbot, which utilizes a combination of AI models for its language, voice, and vision capabilities. What makes FixBot stand out from a general chatbot like ChatGPT or Gemini is its laser focus on repairs. FixBot won't answer questions that are not about fixing things, and it's trained on iFixit's 125,000 repair guides, community forums, and a huge repository of PDF manuals. To use the bot, users can type or vocally explain their issue to the bot, or they can even just snap a photo of whatever needs fixing. The bot will then walk users through a step-by-step repair, pulling answers from the iFixIt library, even if that means surfacing something buried on page 500 of a PDF manual. It will also provide links to buy the spare parts you need. Its voice command features are also designed to help anyone who's elbow-deep in a repair and can't reach their phone. Sometimes, like any AI chatbot, FixBot can get things wrong. And iFixit doesn't have a guide for every device, appliance, or car on Earth. In those cases, FixBot will do what it can with manufacturer docs, targeted web searches, and guides from similar models. It's probably best to think of the app as a guy you know who is particularly handy around the house, rather than a full-blown expert. The app also comes loaded with other new tools, including iFixIt's entire library of guides optimized for mobile, a workbench to track your repair projects, and a toolkit to help users maintain their smartphones. The new app and all its features are currently available for free for a limited time, but a paid tier is in the works. Musk says he's going to make 1 million robots per year by 2030. Slop may be seeping into the nooks and crannies of our brains. The idea sounds similar to Trump's "freedom cities" first pitched in 2023.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/ancient-construction-site-at-pompeii-sheds-light-on-romes-miraculous-self-healing-cement-2000697080'>Ancient Construction Site at Pompeii Sheds Light on Rome's Miraculous Self-Healing Cement</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 16:00:40
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>In Pompeii, researchers have investigated building materials in partially constructed rooms that shed light on this very question by providing insight into ancient Roman cement. A study published today in Nature Communications provides further evidence that they used “hot mixing”—mixing quicklime (dry, heated limestone) with volcanic rocks, volcanic ash, and water, triggering a chemical reaction that produces heat. In 2023 Admir Masic, a physical chemist at the Massachusetts Institute of Technology (MIT), and colleagues published a paper describing how ancient Romans created such long-lasting cement, deducing the process of hot mixing from the cement's chemical composition. As the hot mixture solidifies, it locks highly reactive lime into small gravel-like components. However, their study used samples from a wall that might not be representative of other concrete structures throughout the Roman Empire. Vitruvius wrote that Romans mixed water into lime to produce a paste-like material before adding other ingredients. The site preserved features including containers of concrete construction materials, raw material piles, and tools still sitting where they'd been left behind by workers almost 2,000 years ago. “I expected to see Roman workers walking between the piles with their tools,” Masic admitted. So yes, I got emotional looking at a pile of dirt. The concrete samples had the lime casts previously mentioned in Masic's 2023 study, and a premixed dry raw material pile included intact quicklime fragments, an important early step in the creation process of hot-mixed concrete. They also identified volcanic ash and aggregates—in construction, they are mixed with cement or other materials to create concrete or mortar—further bolstering the hot mixing theory. The team's analysis allowed them to differentiate hot-mixed lime from the slaked lime (heated limestone combined with water) Vitruvius had reported, he added. “These results revealed that the Romans prepared their binding material by taking calcined limestone (quicklime), grinding them to a certain size, mixing it dry with volcanic ash, and then eventually adding water to create a cementing matrix.” Romans in Pompeii in 79 CE, anyway. The team also discovered weights and measurement tools, which they propose may have been used to maintain concrete pouring ratios and build straight, even walls. “The way these pores in volcanic ingredients can be filled through recrystallization is a dream process we want to translate into our modern materials. We want materials that regenerate themselves.” In fact, Masic started a company that uses the wisdom from ancient Roman concrete to create durable modern concretes. It seems like Vitruvius won't have reason to turn in his grave. So maybe Vitruvius was writing about hot-mixing the entire time. The “ultrablack” fabric could soon become part of cameras, solar panels, telescopes, and more. SquidKid is a small bioreactor housing real, glowing bacteria for children to nurture and raise. A new study identified over 68,000 more miles of ancient Roman roads than were previously known. 1,700-year-old ancient Roman burial grounds have come to light in southern France. This tiny chip can withstand temperatures up to 1,500 degrees and could one day sit inside the core of a nuclear reactor, delivering critical real-time data.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/?p=903986'>Seattle startup Casera emerges from PSL to help hospital managers clear bottlenecks with help from AI</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 16:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Casera, a new healthcare technology startup in Seattle, is spinning out of Pioneer Square Labs with a unique approach to hospital operations: using “agentic AI” to automate the work of case managers and speed up patient flow. The company is tackling a thorny problem in healthcare: unnecessary length of stay driven by operational friction. Delays in communication, payer authorization and discharge planning can add time to a patient's stay — and thousands of dollars in expenses for hospitals each day, according to Casera. But he said Casera is attacking a different layer of the problem by focusing on “getting things done versus telling what to do.” “Not trying to be another legacy dashboard and analytics player,” he told GeekWire. Casera is working with a design partners across major health systems in three states. Casera's other co-founder is CTO Alex Levin, who previously started revenue intelligence company MD Clarity (acquired by private equity). A third early leader, Jhayne Pana, was previously an assistant nurse manager with MultiCare Health. PSL previously spun out Kevala, a healthcare staffing software company that was acquired earlier this year. University of Washington scientists and students are using AI to create real medicines. Better treatments for cancer, autoimmune diseases, viruses and more are now on the horizon thanks to groundbreaking work with artificial intelligence from a team of scientists at the University of Washington's Institute for Protein Design. Led by Nobel Prize winner David Baker, this team of Huskies uses AI tools to create proteins — biology's building blocks — that lay the foundation for new medicines. Microsoft and Providence create AI that unlocks tumor insights at a scale previously out of reach Longtime legal leader Pallavi Wahi on leading Arnold & Porter's new office and navigating the AI moment Seattle startup studio Pioneer Square Labs recruits tech experts for new advisory board Julie Sandler, managing director at Pioneer Square Labs, will shift to venture partner role</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=46205724'>Apple's Slow AI Pace Becomes a Strength as Market Grows Weary of Spending</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 15:10:39
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>- Everyone else: "We mainly build huge AI compute clusters to process large amount of data and create value, at high cost for ramp-up and operation. "- Apple: "We mainly build small closed-down AI compute-chips we can control, sell them for-profit to individual consumers and then orchestrate data-processing on those chips, with setup and operational cost all paid by the consumer. "I can't think of any company which has comparable know-how and, most of all, a comparable sell-out scale to even consider Apple's strategy.No matter what they do, they will sell hundreds of millions compute devices for the foreseeable future. - Apple: "We mainly build small closed-down AI compute-chips we can control, sell them for-profit to individual consumers and then orchestrate data-processing on those chips, with setup and operational cost all paid by the consumer. "I can't think of any company which has comparable know-how and, most of all, a comparable sell-out scale to even consider Apple's strategy.No matter what they do, they will sell hundreds of millions compute devices for the foreseeable future. I can't think of any company which has comparable know-how and, most of all, a comparable sell-out scale to even consider Apple's strategy.No matter what they do, they will sell hundreds of millions compute devices for the foreseeable future. There are at current point that only small percent of their userbase have iPhone or iPad with 8GB RAM that somehow can run any AI models even open source and be of any use. Those mainstream macbook air also can have max 32 GB RAM.And for the current price of cheap online AI where e.g. perplexity provides so many promo for PRO version for like less $10 per year and all ai providers give good free models with enough rate limit for many users I don't see apple hardware like particularly bought because of AI compute-chips - at least not non-pro users.If the loose AI though and because of that won't have good AI integrations they will loose also eventually in hardware. OSS Whisper v3 turbo was available ages ago but apple still support only few languages. 3rd party keyboard cannot integrate so well with audio input and all sux in this case because platform limitation. They don't even provide option to sell iPhone with bigger RAM. Those mainstream macbook air also can have max 32 GB RAM.And for the current price of cheap online AI where e.g. perplexity provides so many promo for PRO version for like less $10 per year and all ai providers give good free models with enough rate limit for many users I don't see apple hardware like particularly bought because of AI compute-chips - at least not non-pro users.If the loose AI though and because of that won't have good AI integrations they will loose also eventually in hardware. OSS Whisper v3 turbo was available ages ago but apple still support only few languages. 3rd party keyboard cannot integrate so well with audio input and all sux in this case because platform limitation. And for the current price of cheap online AI where e.g. perplexity provides so many promo for PRO version for like less $10 per year and all ai providers give good free models with enough rate limit for many users I don't see apple hardware like particularly bought because of AI compute-chips - at least not non-pro users.If the loose AI though and because of that won't have good AI integrations they will loose also eventually in hardware. OSS Whisper v3 turbo was available ages ago but apple still support only few languages. 3rd party keyboard cannot integrate so well with audio input and all sux in this case because platform limitation. If the loose AI though and because of that won't have good AI integrations they will loose also eventually in hardware. OSS Whisper v3 turbo was available ages ago but apple still support only few languages. 3rd party keyboard cannot integrate so well with audio input and all sux in this case because platform limitation. They roll out hardware to consumers they can use for AI once their service is ready, with users paying for that rollout until then.Meanwhile they have started to deploy a marketplace ecosystem for AI tasks on iOS, where Apple has the first right-to-refuse, allowing the user to select a (revenue-share-vetted) 3rd party provider to complete the task.So until Apple is ready, the user can select OpenAI (or soon other providers) to fulfill an AI-task, and Apple will collect metrics on the demand of each type of task.This will help them prioritize for development of own models, to finally make use of their own marketplace rules to direct the business away from third parties to themselves.My guess is that they will offer a mixed on-device/cloud AI-service that will use the end-users hardware where possible, offloading compute from their clouds to the end-users hardware and energy-bill, with a "cheap" subscription price undercutting others on that AI-marketplace. Meanwhile they have started to deploy a marketplace ecosystem for AI tasks on iOS, where Apple has the first right-to-refuse, allowing the user to select a (revenue-share-vetted) 3rd party provider to complete the task.So until Apple is ready, the user can select OpenAI (or soon other providers) to fulfill an AI-task, and Apple will collect metrics on the demand of each type of task.This will help them prioritize for development of own models, to finally make use of their own marketplace rules to direct the business away from third parties to themselves.My guess is that they will offer a mixed on-device/cloud AI-service that will use the end-users hardware where possible, offloading compute from their clouds to the end-users hardware and energy-bill, with a "cheap" subscription price undercutting others on that AI-marketplace. So until Apple is ready, the user can select OpenAI (or soon other providers) to fulfill an AI-task, and Apple will collect metrics on the demand of each type of task.This will help them prioritize for development of own models, to finally make use of their own marketplace rules to direct the business away from third parties to themselves.My guess is that they will offer a mixed on-device/cloud AI-service that will use the end-users hardware where possible, offloading compute from their clouds to the end-users hardware and energy-bill, with a "cheap" subscription price undercutting others on that AI-marketplace. This will help them prioritize for development of own models, to finally make use of their own marketplace rules to direct the business away from third parties to themselves.My guess is that they will offer a mixed on-device/cloud AI-service that will use the end-users hardware where possible, offloading compute from their clouds to the end-users hardware and energy-bill, with a "cheap" subscription price undercutting others on that AI-marketplace. My guess is that they will offer a mixed on-device/cloud AI-service that will use the end-users hardware where possible, offloading compute from their clouds to the end-users hardware and energy-bill, with a "cheap" subscription price undercutting others on that AI-marketplace. Until then it might be more profitable to just forward AI-tasks to OpenAI and others and let them burn more money. But if anything I think that they have been shipping (or trying to ship) too fast. There are potentially interesting scenarios there but the fact is that any time you touch my intimate personal (and work) data and do something meaningful I want it to work pretty much all the time. And current models aren't really there yet in my view. There are lots of scenarios that do work incredibly well right now (coding most obviously). People have been complaining for years that Apple isn't shipping fast enough in this area. But if anything I think that they have been shipping (or trying to ship) too fast. There are potentially interesting scenarios there but the fact is that any time you touch my intimate personal (and work) data and do something meaningful I want it to work pretty much all the time. And current models aren't really there yet in my view. There are lots of scenarios that do work incredibly well right now (coding most obviously). There are potentially interesting scenarios there but the fact is that any time you touch my intimate personal (and work) data and do something meaningful I want it to work pretty much all the time. And current models aren't really there yet in my view. There are lots of scenarios that do work incredibly well right now (coding most obviously). In general I would agree, but Siri is honestly still so bad. Tell that to almost anything they've shipped in the last 5-10 years. It's gotten so bad that I wait halfway through entire major OS version before upgrading. Every new thing they ship is almost guaranteed to be broken in some way, ranging from minor annoyance to fully unusable.I buy Apple-everything, but I sure wish there were better options. A few months ago, MCP-style tool calling seemed like the clear standard. Now even Anthropic is shifting toward "code-mode" and reusable skills.For Apple, reliable tool calling is critical because their AI needs to control apps and the whole device. My bet: Apple's AI will be able to create its own Shortcuts on the fly and call them as needed, with OSA Script support on Mac. For Apple, reliable tool calling is critical because their AI needs to control apps and the whole device. My bet: Apple's AI will be able to create its own Shortcuts on the fly and call them as needed, with OSA Script support on Mac. I certainly never heard anyone complain in real life. But admittedly, most of those people are established adults who've figured out an effective rhythm to their home and work life and aren't longing for some magic remedy or disruption. They're not necessarily weary, and they were curious at first, but it seems like they're mostly just waiting for either the buzz to burn off or for some "it just works" product to finally emerge.I imagine there are younger people wowed by the apparent magic of what we have now and excited that they might use it punch up the homework assignments or emails or texts that make them anxious, or that might enjoy toying with it as a novel tool for entertainment and creative idling. Maybe these are some of the people in your "real life"There are a lot of people out there in "real life", bringing different perspectives and needs. I imagine there are younger people wowed by the apparent magic of what we have now and excited that they might use it punch up the homework assignments or emails or texts that make them anxious, or that might enjoy toying with it as a novel tool for entertainment and creative idling. Maybe these are some of the people in your "real life"There are a lot of people out there in "real life", bringing different perspectives and needs. What I meant specifically was that I don't remember anyone complaining about AI features getting in the way or being shoehorned. That particular complaint seems popular only on Reddit or HN. Being able to search your organisation's documents is kind of a killer feature, provided they make it work reliably. I am yet to see ai functionality ppl are dying for. Not to say Apple isn't also degrading their OS with bad design changes, but "more AI" is not something users are clamoring for. Microsoft has been criticized for investing in AI heavily. But it actually makes sense for Microsoft if you consider the nature of their business. Unfortunately, Microsoft sucks at product management, so instead of creating useful stuff that users want and are ready to pay for, they created stuff that no one understands, no one can use, and no one wants to pay for. Apple already has the consumers, they might as well save a few (hundred?) Kind of funny how that worked out.I still think they're really dropping the ball. They could have local models running on devices, interfacing with a big cloud partner (Google, OpenAI, etc.) They could have local models running on devices, interfacing with a big cloud partner (Google, OpenAI, etc.) Adding a few milliseconds of network latency for contacting a server and getting a vastly superior result is going to be preferable in nearly all scenarios.Arguments can be made for privacy or lack of connectivity, but it probably does not matter to most people. Even if it was significantly better, inference is still slow. Adding a few milliseconds of network latency for contacting a server and getting a vastly superior result is going to be preferable in nearly all scenarios.Arguments can be made for privacy or lack of connectivity, but it probably does not matter to most people. Arguments can be made for privacy or lack of connectivity, but it probably does not matter to most people. I hope they adopt the same model with AI - leverage whatever frontier model is best and provide their own privacy infrastructure in front.At some point Apple will figure out a way to provide the right info from your calendar, messages, email etc as context and couple this with a bunch of secure tools for creating calendar entries, etc. Agentic AI will then be something I personally benefit from. At some point Apple will figure out a way to provide the right info from your calendar, messages, email etc as context and couple this with a bunch of secure tools for creating calendar entries, etc. Agentic AI will then be something I personally benefit from. https://www.engadget.com/big-tech/judge-puts-a-one-year-limi...Limits are now being placed on it as of a couple days ago Limits are now being placed on it as of a couple days ago ), reality sets in and those hyped-up investors realize that it's not as much of a short-term game as they told themselves it would be... It's not the same, but PMs and VPs at my company think we can vibe code our way out of migrating a 1.6 million line codebase to a newer language / technology. Or that our problems can be solved by acquiring an AI startup, whose front end looks exactly the same as every other AI startup's front page, and slapping a new CSS file that looks like that startup on top of our existing SPA because their product doesn't actually do anything. The reason there was such a narrative is because Wall Street and Silicon Valley are both narrative machines with little regard for veracity, and they are also not that smart (at least according to people who successfully beat their system, such as Buffett). I think the decision is first a self-serving one that's in line with how they want their devices and services to operate, but it also happens to be (in my opinion) the future-proof way of integrating consumer AI. I find a lot of the low-key things helpful: I use an app at the same time and place every day, and it's nice to have a handy one-tap way to open it. It does a decent job organizing photos and letting me search text in screenshots. This will create distress opportunities that cash-rich companies like APPL may seize. Might be a private equity deal, might be in the public markets as some of the players dip hard after IPO.As this plays out, APPL's silicon has unified memory, power consumption and native acceleration that gives it an edge running SLMs and possibly LLMs at scale. Wouldn't shock me to see APPL introduce a data-center solution. As this plays out, APPL's silicon has unified memory, power consumption and native acceleration that gives it an edge running SLMs and possibly LLMs at scale. Wouldn't shock me to see APPL introduce a data-center solution. Apple has generally been a company that waits, gets criticized for being behind, and then produces a better version (more usable, better integrated, etc), claims it is new, and everybody buys it. Meanwhile a few people moan about how Apple wasn't actually the first to make it. Siri has somehow regressed over the years and visual intelligence only works in demos. Siri has somehow regressed over the years and visual intelligence only works in demos. At least the MLX team has been shipping an impressive product.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/pebble-index-01-smart-ring-microphone-saving-your-thoughts-2000697194'>Pebble Is Making a Smart Ring for Saving All Your Fleeting Thoughts</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 15:00:02
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Pebble smartwatch maker Eric Migicovsky, who recently reacquired the Pebble brand (now under his new company Core Devices) and revived the e-paper-based wearable, calls the $99 Index 01 smart ring an “external memory” for your brain. Unlike the Oura Ring 4 Ceramic, Samsung Galaxy Ring, and countless other multifunctional smart rings designed to track your health and fitness, Pebble's Index 01 is a single-purpose wearable. In a blog post detailing the Index 01, Migicovsky says it's as “small as a wedding band,” made of stainless steel, is water-resistant, and comes in three colors. It doesn't require an internet connection or a subscription fee. This lets you use your adjacent thumb to press and hold the microphone button, which Migicovsky says has a “satisfying click-feel”—perfect for one-handed use. He says that he had initially made it an app for the Pebble smartwatch, but it couldn't be used with one hand and he also found “lift-to-wake gestures and wake-works” to be “too unreliable.” Audio recordings are first saved to the internal memory, streamed to the Pebble app on your phone (iPhone or Android), converted to text, and then an on-device large language model (LLM) turns that into an action such as adding it to your note and reminders.” Clearly, he's not a fan of AI devices like the controversial (and sucky) Friend pendant. It's a simple gadget built with privacy at its core. He says, “an optional cloud storage system for backing up recordings is available,” but it hasn't been built yet. As I scrolled down Migicovsky's detailed FAQ on the Index 01, a few things stood out to me. Migicovsky says that adding charging circuitry would have made the Index 01 bulkier and also more expensive. If you use it less often, the battery may last longer. Pre-orders for the Index 01 start today at a discounted $75, but that will increase to $99 after shipping starts in March 2026. You'll get eight sizes to choose from (6 through 13). This being a Pebble device—built on the principles of open source and DIY—users will be able to hack and customize the Index 01. Migicovsky says you'll be able to program the button for single and double presses, add your own voice actions, and even send audio recordings to your own app or server. It's like if Plaud were just a bit more creepy. The Pebble Time 2 and Pebble 2 Duo already seem like the wearables you want if you can't stand other smartwatches. Oura hopes its AI will help guide you toward better health. Samsung asked a judge to prove it didn't infringe on any patents filed by Oura, but the judge didn't think anything is at stake. Eric Migicosvky never found a smartwatch to fill the void left by Pebble, so he's bringing it back under a new name.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/12/09/pebbles-founder-introduces-a-75-ai-smart-ring-for-recording-brief-notes-with-a-press-of-a-button/'>Pebble's founder introduces a $75 AI smart ring for recording brief notes with a press of a button</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 15:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>After rebooting the Pebble smartwatch brand, founder Eric Migicovsky is expanding his company's device lineup with a new smart wearable: an AI-powered smart ring known as Index 01. AI only comes into play via the open source, speech-to-text, and AI models that run locally on your smartphone through the Pebble mobile app. (And this is a press-and-hold gesture, too, which means you can't start the ring's recording and then let go to surreptitiously record a conversation.) The ring is also not a fitness tracker or sleep monitor. It doesn't record details about your heart rate or health. “I'm not trying to build some AI assistant thing,” Migicovsky told TechCrunch in an interview. “I think of [the ring] as external memory for my brain … That's what this is. Plus, the ring has been designed to be highly reliable and privacy-preserving, he says, as all your thoughts are stored on your phone, not in the cloud. Migicovsky's ring enters a growing market for voice-note wearables. Last month, Sandbar, a New York-based startup founded by former Meta employees, unveiled its Stream Ring, which also lets users record thoughts via a touch-activated microphone. However, unlike Index 01's no-subscription model, Sandbar's $249 ring offers both a free tier with limited AI interactions and a $10-per-month Stream Pro subscription for unlimited chats and early access to features. Migicovsky has been wearing his own ring for three months now and says he cannot imagine going back to a world where he doesn't always have a memory device with him. The ring solves this problem, he adds, without becoming another device you need to charge. At that rate, he'll get about two years of usage. This makes sense for recording briefer, personal thoughts and notes, even when you don't have your phone handy, but it wouldn't work for recording a longer chat, like a presentation, meeting, or in-person interview of some kind. The ring also supports more than 100 languages and has a bit of on-device memory for times when you're not in Bluetooth range of your device, where the recording is ultimately saved and transcribed. If you own a Pebble smartwatch or one from another brand, your recorded thought can even appear on the watch's screen so you can verify it's correct. The ring works with Pebble's mobile app, which offers notes and reminders but can optionally integrate with your phone's calendaring system, too, or other apps, like Notion. Because of its open nature, the ring's button is already programmable. In addition to the press-and-hold gesture, you can program the ring to do other things with a single or double press, like play or pause your music or control the shutter on your phone's camera. You could use it to send a message through the universal chat app Beeper, which Migicovsky also created, or you could add your own voice actions via MCP. “I didn't earn any money during Pebble — we exited, but it was not a great exit,” Migicovsky admits. This year, however, he decided to reboot the Pebble project after Google open sourced PebbleOS, which opened the door to new hardware. With his new company, Core Devices, Migicovsky plans to do things differently. Still, the founder doesn't regret his previous choices, he clarifies. “I wouldn't have gone back and changed anything. Some companies are phenomenal when they raise money and build a big team, and I tried that … What I'm doing now is trying an alternative path, which is [to] start from profitability,” he says. The new company is a small team of five, self-funded, and focused on sustainability. So far, Core Devices has shipped the Pebble 2 Duo smartwatch with a black-and-white display. Show your CFO the marketing proof they want!Join a free webinar hosted by Pantheon on Tuesday December 9 at 10am PT to learn where spend delivers & how to build a 2026 strategy grounded in real results. Claude Code is coming to Slack, and that's a bigger deal than it sounds Creator IShowSpeed sued for allegedly punching, choking viral humanoid Rizzbot SpaceX reportedly in talks for secondary sale at $800B valuation, which would make it America's most valuable private company Andy Jassy says Amazon's Nvidia competitor chip is already a multibillion-dollar business Company backed by Donald Trump Jr.'s firm nabs $620M government contract</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/software/windows/this-github-script-claims-to-wipe-all-of-windows-11s-ai-features-in-seconds-removewindowsai-can-disable-every-single-ai-feature-in-the-os-from-copilot-to-recall-and-more'>This GitHub script claims to wipe all of Windows 11's AI features in seconds — "RemoveWindowsAI" can disable every single AI feature in the OS, from Copilot to Recall and more</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 14:21:08
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. Windows is becoming more AI-focused with every passing update, and the latest major revision — 25H2 — added so many AI features that some might genuinely be opposed to upgrading. Most of the additions are opt-in, while others work automatically in the background, and Microsoft has already said how it wants Windows to become an agentic OS one day. That's where this new script comes in, claiming it can rid your operating system of all the AI shenanigans Microsoft has piled on. "RemoveWindowsAI" is a script created by zoicware, available on GitHub, that does exactly what it says: remove every AI feature in Windows 11, while guiding users to disable others that require manual intervention. The creator says any new AI features added in preview builds won't be targeted with this script until they become a part of the stable release channel that sends out updates to everyone. This makes sense because, otherwise, there'd be simply too much to deal with since Insider builds are Microsoft's testing playground for AI. There's also a separate guide for manually disabling AI features that the script can't handle, including Gaming Copilot, OneDrive AI, and Windows Studio Effects — all pretty simple toggles. As mentioned before, any new features that do become part of mainline Windows will be added to the script or at least the GitHub page if they require conscious action. We tested it ourselves, and it works just as intended; the GUI command is easier to use if you're not comfortable playing around with admin settings. There's even a "Revert Mode" toggle to restore all the AI functionality you've disabled, so you're not losing these features forever. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Hassam Nasir is a die-hard hardware enthusiast with years of experience as a tech editor and writer, focusing on detailed CPU comparisons and general hardware news. When he's not working, you'll find him bending tubes for his ever-evolving custom water-loop gaming rig or benchmarking the latest CPUs and GPUs just for fun. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/semiconductors/intel-boosts-indias-chip-push-with-new-tata-group-strategic-partnership-includes-manufacturing-and-packaging-of-intel-products-for-local-markets'>Intel boosts India's chip push with new Tata Group strategic partnership — includes manufacturing and packaging of Intel products for local markets</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 13:33:39
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>New MoU aims to expand chip manufacturing, packaging, and AI PC development across India. When you purchase through links on our site, we may earn an affiliate commission. Intel has signed a strategic partnership with the Tata Group, one of India's biggest global enterprises, in a bid to boost the country's indigenous semiconductor and compute ecosystem. According to the announcement, the deal focuses on consumer and enterprise hardware enablement via an MoU (Memorandum of Understanding), which will include manufacturing and packaging of Intel products for local markets as well as advanced packaging in India. As per a report by the Indian Express, the Tata Group is working on building two semiconductor facilities in India, valued at around $14 billion, including a fabrication plant in the state of Gujarat and an OSAT (Outsourced Semiconductor Assembly and Test) in the north-eastern state of Assam. Additionally, the two companies are exploring an opportunity to scale tailored AI PC solutions for both consumer and enterprise markets in India, with an aim to become the global top five market by 2030. We see this as a tremendous opportunity to collaborate with Tata to rapidly scale in one of the world's fastest-growing compute markets, fuelled by rising PC demand and rapid AI adoption across India,” said Intel CEO Lip-Bu Tan. Prior to the aforementioned deal, the biggest chip project in India was announced earlier this year by Tata Electronics, in partnership with Taiwan's Powerchip Semiconductor Manufacturing Corp., valued at $11 billion. Apart from the Tata Group, this initiative includes key global players such as Micron Technologies, Clas-SiC Wafer Fab, and Foxconn. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Kunal Khullar is a contributing writer at Tom's Hardware. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/former-medio-amazon-and-expedia-leaders-launch-new-ai-focused-investment-firm/'>Former Medio, Amazon and Expedia leaders launch new AI-focused investment firm</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 13:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Veteran tech operators with ties to Seattle are launching a new investment firm aimed at what they see as two of the biggest opportunities in today's economy: AI and cyber intelligence. VQ Capital is a “thesis-driven, AI-native investment platform” that partners with multibillion-dollar family offices. Lent is teaming up on VQ Capital with longtime colleague John Kim. Kim later went on to become a product exec at Expedia, Vrbo, and PayPal. The firm argues that the old pattern of gradual, Moore's Law-style progress has given way to what it calls an “era of compounding change,” driven by hardware advances, new AI models and large-scale data. The firm describes its approach as a hybrid of private equity discipline and venture-style investing. After Nokia acquired Medio, Lent worked at HERE Technologies for two years before launching real estate tech startup Plunk, which closed in 2024. His most recent gig was with Auger, a well-funded logistics startup in Bellevue led by former Amazon exec Dave Clark. Your company's success depends on finding and keeping great talent—whether it's an all-star engineer or a world-class salesperson. That's why GeekWire and Prime Team Partners have teamed up on GeekWork, a new initiative designed to help employers connect with outstanding candidates. Learn more about GeekWork by contacting GeekWire co-founder John Cook at [email protected]. Tech Moves: Washington names broadband leader; Greater Seattle Partners gets interim president/CEO; Microsoft legal exec departs Tech Moves: Ex-Payscale CEO Scott Torrey joins Smartsheet; Apple taps Microsoft VP to lead AI efforts Tech Moves: Expedia names first AI chief; Textio founder joins Microsoft; T-Mobile exec departs Former Amazon leader's supply chain tech startup Auger names 11 execs after $100M Series A round As Madrona turns 30, longtime Seattle firm keeps investing in its backyard — and beyond West Point grads lead new Seattle investment firm using AI-fueled model to find startups</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/semiconductors/trump-approves-nvidia-h20-exports-to-china-25percent-fee-applies'>Trump approves Nvidia H200 exports to China, with 25% fee attached — report suggests that companies will have to follow strict Beijing rules to import foreign chip, AMD and Intel to benefit from policy shift</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-12-09 12:50:30
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. The U.S. will allow Nvidia to export its H200 chips to "approved customers" in China, President Donald Trump announced on Monday, setting off a fresh round of political and regulatory manoeuvring on both sides of the Pacific. The decision authorises shipments of Nvidia's second-tier Hopper-generation chip in exchange for a 25% fee collected when parts arrive in the United States for security review before re-export. H200 sits below Nvidia's latest Blackwell architecture yet remains far ahead of any processor China can legally import today. China restricted tech companies from buying the H20, arguing its performance gains over domestic alternatives were too modest to justify continued reliance on U.S. parts. The Financial Times reports that Chinese regulators have been discussing ways to allow only limited access to H200 — including an approval process where buyers must explain why domestic chips cannot meet their needs — and could bar the public sector from purchasing Nvidia hardware altogether. The provisional opening nonetheless matters to China's largest cloud providers. Alibaba, Tencent, and ByteDance have adopted domestic accelerators for some inference workloads but continue to prefer Nvidia products for training and maintaining large models, often sending jobs overseas where access to H100-class compute remains unrestricted. The bipartisan "SAFE CHIPS Act" introduced last week seeks to prevent the administration from approving exports of advanced chips, including H200, for 30 months. The announcement also coincided with the Justice Department's announcement of "Operation Gatekeeper", which alleges a smuggling network routed Nvidia parts into China and Hong Kong despite existing controls, piling yet more pressure on Washington to create a regulated channel for hardware that continues to leak across borders. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Whether H200 reaches China at scale now depends on two competing gatekeepers. Washington is attempting to shape the market through controlled exports and taxes, while Beijing reportedly weighs measures that would keep foreign accelerators available only where domestic suppliers cannot yet compete. Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, & reviews in your feeds. Although his background is in legal, he has a personal interest in all things tech, especially hardware and microelectronics, and anything regulatory. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            