
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - SCIENCE Article Summaries - 2025-11-18</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            SCIENCE
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.popularmechanics.com/science/a69317133/tiny-molecule-particle-accelerator/'>Scientists Built a Particle Accelerator That's Just One Molecule In Size</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.popularmechanics.com', 'title': 'Popular Mechanics'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-11-18 14:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Often in physics, if you want to investigate the very small, you need to build something very big. However, a new study led by scientists at MIT shows that you don't always need massive mega-machines to explore some of the most foundational mysteries of the universe. In this new study, published last month in the journal Science, scientists accurately measured the energy of electrons in a radium atom—when paired with a fluoride atom to form the molecule radium monofluoride—which acted as its own atom-sized particle accelerator. The team also noted a slight shift in electron energy levels, confirming that these electrons briefly penetrated the radium atom's nucleus and providing an incredible opportunity to precisely map radium for the first time. “When you put this radioactive atom inside of a molecule, the internal electric field that its electrons experience is orders of magnitude larger compared to the fields we can produce and apply in a lab,” Silviu-Marian Udrescu, a co-author of the study and Ph.D. student from MIT, said in a press statement. According to physicists, pear-shaped atoms significantly enhance our ability to look for time (T) and charge-parity (CP) symmetry violations that lie beyond the Standard Model. In this well-established model, atoms are forbidden to have a permanent electric dipole moment (EDM)—the measurement of two equal and opposite charges separated by a small distance—but previous estimates suggest that an EDM signature could be enhanced nearly 1,000 times in a pear-shaped atom, thanks to its asymmetrical charge and mass. The exploration of these symmetry violations directly impacts physicists' ongoing search for an answer (or several answers) to the perplexing question of matter-antimatter asymmetry. This technique offers up a new way for scientists to map the atom's “magnetic distribution”—an important step in exploring the deeper mysteries of matter-antimatter asymmetry. “Our results lay the groundwork for subsequent studies aiming to measure violations of fundamental symmetries at the nuclear level,” Ronald Fernando Garcia Ruiz, a co-author of the study from MIT, said in a press statement. “This could provide answers to some of the most pressing questions in modern physics.” Up to this point, Garcia Ruiz and his team have only studied these atoms in random orientations at high temperature. However, a future study will cool molecules of radium monofluouride to control their orientations, so that scientists can accurately map their internal structure. “It's like being able to measure a battery's electric field. Experts Found a Mass Grave of Roman Soldiers</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.nature.com/articles/s41576-025-00907-1'>Harnessing artificial intelligence to advance CRISPR-based genome editing technologies</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.nature.com', 'title': 'Nature'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-11-18 13:47:48
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript. Nature Reviews Genetics (2025)Cite this article CRISPR-based genome editing technologies, including nuclease-based editing, base editing and prime editing, have revolutionized biological research and modern medicine by enabling precise, programmable modification of the genome and offering new therapeutic strategies for a wide range of genetic diseases. Artificial intelligence (AI), including machine learning and deep learning models, is now further advancing the field by accelerating the optimization of gene editors for diverse targets, guiding the engineering of existing tools and supporting the discovery of novel genome-editing enzymes. In this Review, we summarize key AI methodologies underlying these advances and discuss their recent noteworthy applications to genome editing technologies. We also discuss emerging opportunities, such as AI-powered virtual cell models, which can guide genome editing through target selection or prediction of functional outcomes. Finally, we identify key directions where the integration of AI methods is poised to have a substantial impact going forward. This is a preview of subscription content, access via your institution Access Nature and 54 other Nature Portfolio journals Get Nature+, our best-value online-access subscription cancel any time Subscribe to this journal Receive 12 print issues and online access $259.00 per year only $21.58 per issue Buy this article Prices may be subject to local taxes which are calculated during checkout Zheng, Y. et al. Precise genome-editing in human diseases: mechanisms, strategies and applications. Google Scholar Adli, M. The CRISPR tool kit for genome editing and beyond. Google Scholar Pixley, K. V. et al. Genome-edited crops for improved food security of smallholder farmers. Article PubMed Google Scholar Jinek, M. et al. A programmable dual-RNA-guided DNA endonuclease in adaptive bacterial immunity. Google Scholar Chavez, M., Chen, X., Finn, P. B. & Qi, L. S. Advances in CRISPR therapeutics. Article PubMed Google Scholar Chen, P. J. & Liu, D. R. Prime editing for precise and highly versatile genome manipulation. Article PubMed Google Scholar Villiger, L. et al. CRISPR technologies for genome, epigenome and transcriptome editing. Article PubMed Google Scholar Porto, E. M., Komor, A. C., Slaymaker, I. M. & Yeo, G. W. Base editing: advances and therapeutic opportunities. Google Scholar Urnov, F. D., Rebar, E. J., Holmes, M. C., Zhang, H. S. & Gregory, P. D. Genome editing with engineered zinc finger nucleases. Article PubMed Google Scholar Joung, J. K. & Sander, J. D. TALENs: a widely applicable technology for targeted genome editing. Article PubMed Google Scholar Pacesa, M., Pelea, O. & Jinek, M. Past, present, and future of CRISPR genome editing technologies. Article PubMed Google Scholar Winter, J., Shirguppe, S. & Perez-Pinera, P. Protein engineering technologies for development of next-generation genome editors. Google Scholar Hu, J. H. et al. Evolved Cas9 variants with broad PAM compatibility and high DNA specificity. Google Scholar Yoon, P. H. et al. Structure-guided discovery of ancestral CRISPR–Cas13 ribonucleases. Google Scholar Altae-Tran, H. et al. Uncovering the functional diversity of rare CRISPR–Cas systems with deep terascale clustering. Google Scholar Wang, Z. et al. Robust enzyme discovery and engineering with deep learning using CataPro. Google Scholar Senior, A. W. et al. Improved protein structure prediction using potentials from deep learning. Article PubMed Google Scholar Jumper, J. et al. Highly accurate protein structure prediction with AlphaFold. Google Scholar Abramson, J. et al. Accurate structure prediction of biomolecular interactions with AlphaFold 3. Google Scholar Baek, M. et al. Accurate prediction of protein structures and interactions using a three-track neural network. Google Scholar Simon, E., Swanson, K. & Zou, J. Language models for biological research: a primer. Article PubMed Google Scholar Nambiar, T. S., Baudrier, L., Billon, P. & Ciccia, A. CRISPR-based genome editing through the lens of DNA repair. Google Scholar Li, T. et al. CRISPR/Cas9 therapeutics: progress and prospects. Google Scholar Zetsche, B. et al. Cpf1 is a single RNA-guided endonuclease of a class 2 CRISPR–Cas system. Google Scholar Badon, I. W., Oh, Y., Kim, H. J. & Lee, S. H. Recent application of CRISPR–Cas12 and OMEGA system for genome editing. Article PubMed Google Scholar Hino, T. et al. An AsCas12f-based compact genome-editing tool derived by deep mutational scanning and structural analysis. Article PubMed Google Scholar Abudayyeh, O. O. et al. C2c2 is a single-component programmable RNA-guided RNA-targeting CRISPR effector. Google Scholar Altae-Tran, H. et al. The widespread IS200/IS605 transposon family encodes diverse programmable RNA-guided endonucleases. Google Scholar Marquart, K. F. et al. Effective genome editing with an enhanced ISDra2 TnpB system and deep learning-predicted omegaRNAs. Google Scholar Karvelis, T. et al. Transposon-associated TnpB is a programmable RNA-guided DNA endonuclease. Google Scholar Kannan, S. et al. Evolution-guided protein design of IscB for persistent epigenome editing in vivo. Article PubMed Google Scholar Xu, C. et al. Conversion of IscB and Cas9 into RNA-guided RNA editors. Article PubMed Google Scholar Enache, O. M. et al. Cas9 activates the p53 pathway and selects for p53-inactivating mutations. Google Scholar Kosicki, M., Tomberg, K. & Bradley, A. Repair of double-strand breaks induced by CRISPR–Cas9 leads to large deletions and complex rearrangements. Google Scholar Leibowitz, M. L. et al. Chromothripsis as an on-target consequence of CRISPR–Cas9 genome editing. Google Scholar Komor, A. C., Kim, Y. B., Packer, M. S., Zuris, J. & Liu, D. R. Programmable editing of a target base in genomic DNA without double-stranded DNA cleavage. Google Scholar Gaudelli, N. M. et al. Programmable base editing of A*T to G*C in genomic DNA without DNA cleavage. Google Scholar Xu, F. et al. Breaking genetic shackles: the advance of base editing in genetic disorder treatment. Google Scholar Davies, K., Philippidis, A. & Barrangou, R. Five years of progress in CRISPR clinical trials (2019–2024). CRISPR J. Article PubMed Google Scholar Musunuru, K. et al. Patient-specific in vivo gene editing to treat a rare genetic disease. Article PubMed Google Scholar Grunewald, J. et al. Transcriptome-wide off-target RNA editing induced by CRISPR-guided DNA base editors. Google Scholar Anzalone, A. V. et al. Search-and-replace genome editing without double-strand breaks or donor DNA. Google Scholar Anzalone, A. V. et al. Programmable deletion, replacement, integration and inversion of large DNA sequences with twin prime editing. Article PubMed Google Scholar Yarnall, M. T. N. et al. Drag-and-drop genome insertion of large sequences without double-strand DNA cleavage using CRISPR-directed integrases. Article PubMed Google Scholar Pandey, S. et al. Efficient site-specific integration of large genes in mammalian cells via continuously evolved recombinases and prime editing. Article PubMed Google Scholar Doman, J. L., Sousa, A. A., Randolph, P. B., Chen, P. J. & Liu, D. R. Designing and executing prime editing experiments in mammalian cells. Google Scholar Chen, P. J. et al. Enhanced prime editing systems by manipulating cellular determinants of editing outcomes. Google Scholar Doman, J. L. et al. Phage-assisted evolution and protein engineering yield compact, efficient prime editors. Google Scholar Yan, J. et al. Improving prime editing with an endogenous small RNA-binding protein. Google Scholar Nelson, J. W. et al. Engineered pegRNAs improve prime editing efficiency. Article PubMed Google Scholar Li, X. et al. Highly efficient prime editing by introducing same-sense mutations in pegRNA or stabilizing its structure. Google Scholar Fei, J. et al. Mismatch prime editing gRNA increased efficiency and reduced indels. Google Scholar Gilbert, L. A. et al. Genome-scale CRISPR-mediated control of gene repression and activation. Google Scholar et al. CRISPR-mediated modular RNA-guided regulation of transcription in eukaryotes. Google Scholar Chavez, A. et al. Highly efficient Cas9-mediated transcriptional programming. Google Scholar Nunez, J. K. et al. Genome-wide programmable transcriptional memory by CRISPR-based epigenome editing. Google Scholar Hilton, I. B. et al. Epigenome editing by a CRISPR–Cas9-based acetyltransferase activates genes from promoters and enhancers. Google Scholar Li, J. et al. Programmable human histone phosphorylation and gene activation using a CRISPR/Cas9-based chromatin kinase. Google Scholar Konstantakos, V., Nentidis, A., Krithara, A. & Paliouras, G. CRISPR–Cas9 gRNA efficiency prediction: an overview of predictive tools and the role of deep learning. Nucleic Acids Res. Google Scholar Sherkatghanad, Z., Abdar, M., Charlier, J. & Makarenkov, V. Using traditional machine learning and deep learning methods for on- and off-target prediction in CRISPR/Cas9: a review. Google Scholar Dixit, S., Kumar, A., Srinivasan, K., Vincent, P. & Ramu Krishnan, N. Advancing genome editing with artificial intelligence: opportunities, challenges, and future directions. Article PubMed Google Scholar Chari, R., Mali, P., Moosburner, M. & Church, G. M. Unraveling CRISPR–Cas9 genome engineering parameters via a library-on-library approach. Google Scholar Kim, H. K. et al. In vivo high-throughput profiling of CRISPR–Cpf1 activity. Article PubMed Google Scholar Zhang, G., Luo, Y., Dai, X. & Dai, Z. Benchmarking deep learning methods for predicting CRISPR/Cas9 sgRNA on- and off-target activities. Article PubMed Google Scholar Kim, H. K. et al. Deep learning improves prediction of CRISPR–Cpf1 guide RNA activity. Article PubMed Google Scholar Kim, H. K. et al. SpCas9 activity prediction by DeepSpCas9, a deep learning-based model with high generalization performance. Google Scholar Chuai, G. et al. DeepCRISPR: optimized CRISPR guide RNA design by deep learning. Google Scholar Xiang, X. et al. Enhancing CRISPR–Cas9 gRNA efficiency prediction by data integration and deep learning. Google Scholar & Feng, H. Prediction of CRISPR–Cas9 on-target activity based on a hybrid neural network. Google Scholar Hou, Y. et al. Leveraging protein language models for cross-variant CRISPR/Cas9 sgRNA activity prediction. Google Scholar Lin, Z. et al. Evolutionary-scale prediction of atomic-level protein structure with a language model. Article PubMed Google Scholar Elkayam, S., Tziony, I. & Orenstein, Y. DeepCRISTL: deep transfer learning to predict CRISPR/Cas9 on-target editing efficiency in specific cellular contexts. Google Scholar Liu, Q., Cheng, X., Liu, G., Li, B. & Liu, X. Deep learning improves the ability of sgRNA off-target propensity prediction. Chen, Q. et al. Genome-wide CRISPR off-target prediction and optimization using RNA–DNA interaction fingerprints. Ozden, F. & Minary, P. Learning to quantify uncertainty in off-target activity for CRISPR guide RNAs. Nucleic Acids Res. Tahsin, A. et al. CRISPR-Embedding: CRISPR/Cas9 off-target activity prediction using DNA k-mer embedding. Computational Struct. Du, W. et al. A versatile CRISPR/Cas9 system off-target prediction tool using language model. Cheng, X. et al. Modeling CRISPR–Cas13d on-target and off-target effects using machine learning approaches. Wessels, H. H. et al. Prediction of on-target and off-target activity of CRISPR–Cas13d guide RNAs using deep learning. Article PubMed Shen, M. W. et al. Predictable and precise template-free CRISPR editing of pathogenic variants. Chen, W. et al. Massively parallel profiling and predictive modeling of the outcomes of CRISPR/Cas9-mediated double-strand break repair. Nucleic Acids Res. Allen, F. et al. Predicting the mutations generated by repair of Cas9-induced double-strand breaks. Leenay, R. T. et al. Large dataset enables prediction of repair after CRISPR–Cas9 editing in primary T cells. Naert, T. et al. Precise, predictable genome integrations by deep-learning-assisted design of microhomology-based templates. Article PubMed Huang, T. P., Newby, G. A. & Liu, D. R. Precision genome editing using cytosine and adenine base editors in mammalian cells. Article PubMed Arbab, M. et al. Determinants of base editing outcomes from target library analysis and machine learning. Song, M. et al. Sequence-specific prediction of the efficiencies of adenine and cytosine base editors. Article PubMed Marquart, K. F. et al. Predicting base editing outcomes with an attention-based deep learning algorithm trained on high-throughput target library screens. Koblan, L. W. et al. Efficient C*G-to-G*C base editors developed using CRISPRi screens, target-library analysis, and machine learning. Kim, N. et al. Deep learning models to predict the editing efficiencies and outcomes of diverse base editors. Article PubMed Zhou, X. et al. Comprehensive evaluation and prediction of editing outcomes for near-PAMless adenine and cytosine base editors. Walton, R. T., Christie, K. A., Whittaker, M. N. & Kleinstiver, B. P. Unconstrained genome targeting with near-PAMless engineered CRISPR–Cas9 variants. Yuan, T. et al. Deep learning models incorporating endogenous factors beyond DNA sequences improve the prediction accuracy of base editing outcomes. Zhang, C. et al. Prediction of base editor off-targets by deep learning. Kim, H. K. et al. Predicting the efficiency of prime editing guide RNAs in human cells. Article PubMed Li, Y., Chen, J., Tsai, S. Q. & Cheng, Y. Easy-Prime: a machine learning-based prime editor design tool. Mathis, N. et al. Predicting prime editing efficiency and product purity by deep learning. Article PubMed Yu, G. et al. Prediction of efficiencies for diverse prime editing systems in multiple cell types. Article PubMed Mathis, N. et al. Machine learning prediction of prime editing efficiency across diverse chromatin contexts. Article PubMed Koeppel, J. et al. Prediction of prime editing insertion efficiencies using sequence features and DNA repair determinants. Liu, F. et al. Design of prime-editing guide RNAs with deep transfer learning. Alipanahi, R., Safari, L. & Khanteymoori, A. DTMP-prime: a deep transformer-based model for predicting prime editing efficiency and pegRNA activity. Nucleic Acids 35, 102370 (2024). Janssen, S. M. & Lorincz, M. C. Interplay between chromatin marks in development and disease. Article PubMed McCutcheon, S. R., Rohm, D., Iglesias, N. & Gersbach, C. A. Epigenome editing technologies for discovery and medicine. Article PubMed Yang, Q. et al. EpiCas-DL: predicting sgRNA activity for CRISPR-mediated epigenome editing by deep learning. Article PubMed Mu, W. et al. Machine learning methods for predicting guide RNA effects in CRISPR epigenome editing experiments. Preprint at bioRxiv https://doi.org/10.1101/2024.04.18.590188 (2024). Consortium, E. P. An integrated encyclopedia of DNA elements in the human genome. Batra, S. S. et al. Predicting the effect of CRISPR–Cas9-based epigenome editing. Preprint at bioRxiv https://doi.org/10.1101/2023.10.03.560674 (2025). Zhao, F. et al. A strategy for Cas13 miniaturization based on the structure and AlphaFold. Pan, L. et al. Optimization of CRISPR/Cas12f1 guide RNAs using AlphaFold3 for enhanced nucleic acid detection. Leman, J. K. et al. Macromolecular modeling and design in Rosetta: recent methods and frameworks. Article PubMed Jurtz, V. et al. NetMHCpan-4.0: improved peptide–MHC class I interaction predictions integrating eluted ligand and peptide binding affinity data. Article PubMed Raghavan, R. et al. Rational engineering of minimally immunogenic nucleases for gene therapy. Watson, J. L. et al. De novo design of protein structure and function with RFdiffusion. Park, J. C. et al. AI-generated MLH1 small binder improves prime editing efficiency. Article PubMed Ruffolo, J. & Madani, A. Designing proteins with language models. Article PubMed He, Y. et al. Protein language models-assisted optimization of a uracil-N-glycosylase variant enables programmable T-to-G and T-to-C base editing. Article PubMed Perrotta, R. M. et al. Machine learning and directed evolution of base editing enzymes. Preprint at bioRxiv https://doi.org/10.1101/2024.05.17.594556 (2024). Silverstein, R. A. et al. Custom CRISPR–Cas9 PAM variants via scalable engineering and machine learning. Chen, K. et al. Lung and liver editing by lipid nanoparticle delivery of a stable CRISPR–Cas9 ribonucleoprotein. Article PubMed Wang, Y. et al. Directed evolution: methodologies and applications. Article PubMed Wittmann, B. J., Johnston, K. E., Wu, Z. & Arnold, F. H. Advances in machine learning for directed evolution. Article PubMed Jiang, K. et al. Rapid in silico directed evolution by a protein language model with EVOLVEpro. Article PubMed & Barrangou, R. Mining microbial organisms to discover and characterize novel CRISPR–Cas systems. Faure, G. et al. TIGR-Tas: a family of modular RNA-guided DNA-targeting systems in prokaryotes and their viruses. Saito, M. et al. Fanzor is a eukaryotic programmable RNA-guided endonuclease. Jiang, K. et al. Programmable RNA-guided DNA endonucleases are widespread in eukaryotes and their viruses. Huang, J. et al. Discovery of deaminase functions by structure-based protein clustering. Article PubMed Xu, K. et al. Structure-guided discovery of highly efficient cytidine deaminases with sequence-context independence. Article PubMed Li, W. et al. Discovering CRISPR–Cas system with self-processing pre-crRNA capability by foundation models. Nguyen, E. et al. Sequence modeling and design from molecular to genome scale with EVO. Nijkamp, E., Ruffolo, J. A., Weinstein, E. N., Naik, N. & Madani, A. ProGen2: exploring the boundaries of protein language models. Article PubMed Ruffolo, J. A. et al. Design of highly functional genome editors by modelling CRISPR–Cas sequences. Nammi, B. et al. CasGen: a regularized generative model for CRISPR cas protein design with classification and margin-based optimization. Preprint at bioRxiv https://doi.org/10.1101/2025.02.28.640911 (2025). Jiang, J. et al. A review of transformer models in drug discovery and beyond. Article PubMed Chen, Y. et al. All-RNA-mediated targeted gene integration in mammalian cells with rationally engineered R2 retrotransposons. Article PubMed Fell, C. W. et al. Reprogramming site-specific retrotransposon activity to new DNA sites. Article PubMed Witte, I. P. et al. Programmable gene insertion in human cells with a laboratory-evolved CRISPR-associated transposase. Durrant, M. G. et al. Bridge RNAs direct programmable recombination of target and donor DNA. Perry, N. T. et al. Megabase-scale human genome rearrangement with programmable bridge recombinases. Rood, J. E., Hupalowska, A. Toward a foundation model of causal cell and tissue biology with a perturbation cell and tissue atlas. Article PubMed Bunne, C. et al. How to build the virtual cell with artificial intelligence: priorities and opportunities. Roohani, Y. H. et al. Virtual cell challenge: toward a turing test for the virtual cell. Article PubMed Cui, H. et al. Towards multimodal foundation models in molecular cell biology. Article PubMed Qu, Y. et al. CRISPR-GPT for agentic automation of gene-editing experiments. Huang, K. et al. Biomni: a general-purpose biomedical AI agent. Preprint at bioRxiv https://doi.org/10.1101/2025.05.30.656746 (2025). Canty, R. B. et al. Science acceleration and accessibility with self-driving labs. Frangoul, H. et al. CRISPR–Cas9 gene editing for sickle cell disease and beta-thalassemia. Article PubMed Raguram, A., Banskota, S. & Liu, D. R. Therapeutic in vivo delivery of gene editing agents. Tan, F., Dong, Y., Qi, J., Yu, W. & Chai, R. Artificial intelligence-based approaches for AAV vector engineering. Laxmi, B., Devi, P. U. M., Thanjavur, N. & Buddolla, V. The applications of artificial intelligence (AI)-driven tools in virus-like particles (VLPs) research. Article PubMed Cui, H. et al. LUMI-lab: a foundation model-driven autonomous platform enabling discovery of new ionizable lipid designs for mRNA delivery. Preprint at bioRxiv https://doi.org/10.1101/2025.02.14.638383 (2025). Wang, W. et al. Artificial intelligence-driven rational design of ionizable lipids for mRNA delivery. Witten, J. et al. Artificial intelligence-guided design of lipid nanoparticles for pulmonary gene therapy. Article PubMed Xu, Y. et al. AGILE platform: a deep learning powered approach to accelerate LNP development for mRNA delivery. Dorsey, P. J., Lau, C. L., Chang, T. C., Doerschuk, P. C. & D'Addio, S. M. Review of machine learning for lipid nanoparticle formulation and process development. Article PubMed Li, B. et al. Combinatorial design of nanoparticles for pulmonary mRNA delivery and genome editing. Zhang, H. et al. Algorithm for optimized mRNA design improves stability and immunogenicity. Chu, Y. et al. A 5\Prime; UTR language model for decoding untranslated regions of mRNA and function predictions. Morrow, A. K. et al. ML-driven design of 3′ UTRs for mRNA stability. Preprint at bioRxiv https://doi.org/10.1101/2024.10.07.616676 (2024). Castillo-Hair, S. et al. Optimizing 5′ UTRs for mRNA-delivered gene editing using deep learning. Mao, D. et al. AI-MARRVEL—a knowledge-driven AI system for diagnosing mendelian disorders. NEJM AI https://doi.org/10.1056/aioa2300009 (2024). Avsec, Ž. et al. AlphaGenome: advancing regulatory variant effect prediction with a unified DNA sequence model. Preprint at bioRxiv https://doi.org/10.1101/2025.06.25.661532 (2025). Birgmeier, J. et al. AMELIE speeds mendelian diagnosis by matching patient phenotype and genotype to primary literature. Duong, D. & Solomon, B. D. Artificial intelligence in clinical genetics. Teodoro, D., Naderi, N., Yazdani, A., Zhang, B. A scoping review of artificial intelligence applications in clinical trial risk assessment. Berman, H. M. et al. The Protein Data Bank. Nucleic Acids Res. Burley, S. K. et al. Updated resources for exploring experimentally-determined PDB structures and computed structure models at the RCSB Protein Data Bank. Nucleic Acids Res. Article PubMed Abolhasani, M. & Kumacheva, E. The rise of self-driving labs in chemical and materials sciences. Szymanski, N. J. et al. An autonomous laboratory for the accelerated synthesis of novel materials. Greener, J. G., Kandathil, S. M., Moffat, L. & Jones, D. T. A guide to machine learning for biologists. Article PubMed Eraslan, G., Avsec, Z., Gagneur, J. Deep learning: new computational modelling techniques for genomics. Article PubMed LeCun, Y., Bengio, Y. & Hinton, G. Deep learning. Article PubMed Bommasani, R. et al. On the opportunities and risks of foundation models. Preprint at https://doi.org/10.48550/arXiv.2108.07258 (2021). Sengar, S. S., Hasan, A. B., Kumar, S. & Carroll, F. Generative artificial intelligence: a systematic review and applications. Tools Appl. Hayes, T. et al. Simulating 500 million years of evolution with a language model. Article PubMed Bock, C. et al. High-content CRISPR screening. Baysoy, A., Bai, Z., Satija, R. & Fan, R. The technological landscape and applications of single-cell multi-omics. Article PubMed Dixit, A. et al. Perturb-Seq: dissecting molecular circuits with scalable single-cell RNA profiling of pooled genetic screens. Jaitin, D. A. et al. Dissecting immune circuits by linking CRISPR-pooled screens with single-cell RNA-seq. Article PubMed Datlinger, P. et al. Pooled CRISPR screening with single-cell transcriptome readout. Roohani, Y., Huang, K. & Leskovec, J. Predicting transcriptional outcomes of novel multigene perturbations with GEARS. Article PubMed Yu, H., Qian, W., Song, Y. & Welch, J. D. PerturbNet predicts single-cell responses to unseen chemical and genetic perturbations. Toneyan, S. & Koo, P. K. Interpreting cis-regulatory interactions from large-scale deep neural networks. Xing, H. & Yau, C. GPerturb: Gaussian process modelling of single-cell perturbation data. Cui, H. et al. scGPT: toward building a foundation model for single-cell multi-omics using generative AI. Article PubMed Theodoris, C. V. et al. Transfer learning enables predictions in network biology. Adduri, A. K. et al. Predicting cellular responses to perturbation across diverse contexts with State. Preprint at bioRxiv https://doi.org/10.1101/2025.06.26.661135 (2025). Hao, M. et al. Large-scale foundation model on single-cell transcriptomics. Article PubMed Zeng, Y. et al. CellFM: a large-scale foundation model pre-trained on transcriptomics of 100 million human cells. Dhainaut, M. et al. Spatial CRISPR genomics identifies regulators of the tumor microenvironment. Baysoy, A. et al. Spatially resolved in vivo CRISPR screen sequencing via perturb-DBiT. Preprint at bioRxiv https://doi.org/10.1101/2024.11.18.624106 (2024). Saunders, R. A. et al. Perturb-Multimodal: A platform for pooled genetic screens with imaging and sequencing in intact mammalian tissue. Binan, L. et al. Simultaneous CRISPR screening and spatial transcriptomics reveal intracellular, intercellular, and functional transcriptional circuits. Megas, S. et al. Celcomen: spatial causal disentanglement for single-cell and tissue perturbation modeling. Preprint at https://doi.org/10.48550/arXiv.2409.05804 (2024). Li, Y., Stanojevic, S. & Garmire, L. X. Emerging artificial intelligence applications in spatial transcriptomics analysis. The authors acknowledge funding support from the GSK Chair Professorship, Leslie Dan Faculty of Pharmacy start-up fund, Princess Margaret Cancer Center operating fund, Natural Sciences and Engineering Research Council of Canada (RGPIN-2023-05124), Canada Research Chairs Program (CRC-2022-00575), National Institutes of Health (NIH) (1R01HL174773), Canadian Institutes of Health Research (PJH-185722, PJT-190109, PJT-192011, PJT-195669), Cystic Fibrosis Foundation (LI23G0, LI23I0), Cystic Fibrosis Canada (1188219), New Frontiers in Research Fund — Exploration (NFRFE-2023-00203), Accelerate Translation grant from the Acceleration Consortium (518240) and Canada Foundation for Innovation — John R. Evans Leaders Fund (43711). Institute of Biomedical Engineering, University of Toronto, Toronto, Ontario, Canada Tyler Thomson, Gen Li & Bowen Li Leslie Dan Faculty of Pharmacy, University of Toronto, Toronto, Ontario, Canada Tyler Thomson, Gen Li, Amy Strilchuk & Bowen Li Department of Computer Science, University of Toronto, Toronto, Ontario, Canada Haotian Cui & Bo Wang Vector Institute for Artificial Intelligence, Toronto, Ontario, Canada Haotian Cui & Bo Wang Peter Munk Cardiac Centre, University Health Network, Toronto, Ontario, Canada Department of Laboratory Medicine and Pathobiology, University of Toronto, Toronto, Ontario, Canada Department of Chemistry, University of Toronto, Toronto, Ontario, Canada Princess Margaret Cancer Centre, University Health Network, Toronto, Ontario, Canada Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar researched the literature, contributed substantially to discussions of the content and wrote the article. All authors reviewed and/or edited the manuscript before submission. Correspondence to Bowen Li. The authors declare no competing interests. Nature Reviews Genetics thanks the anonymous reviewer(s) for their contribution to the peer review of this work. Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. A type of recurrent neural network (RNN) model that learns patterns in sequences, reading them in both forward and backward directions, to help capture context from past and future information. Deep learning models that process data with a grid-like structure, such as images or sequences, by applying convolutional filters to learn spatial patterns and hierarchical feature representations. A branch of machine learning that uses multilayered artificial neural networks to automatically learn latent representations of data for tasks such as prediction, classification and generation. A large-scale pretrained model built on diverse data that can be adapted to a wide range of downstream tasks with minimal task-specific tuning. Vector representations of fixed-length sub-sequences (k-mers) from biological sequences that capture their contextual and semantic properties for use in machine learning models. A deep learning model that learns the statistical patterns of a language or biological sequence to predict and generate new text or sequences. A machine learning method used to model the probability of a specific outcome, such as single guide RNA (sgRNA) activity, based on user-supplied features. A mechanism that projects input sequences into multiple attention heads, each learning different relationships among tokens, and then combines them to capture diverse contextual information. A neural network technique that applies convolutional filters of different kernel sizes to the same input so that the model can capture both local and global features simultaneously. A representation method that converts categorical variables into binary vectors where only the position corresponding to the category is set to 1 and all others are 0. The efficiency with which a given single guide RNA (sgRNA) directs its associated nuclease to induce edits. Typically measured as the frequency of insertions or deletions (indels) at the target site. Developed through protein engineering of the protospacer adjacent motif (PAM)-interacting domain of SpCas9, this variant recognizes NRN or NYN PAMs (where R = A/G, Y = C/T), effectively allowing nearly any sequence in the genome to be targeted. A machine learning technique used to classify data into different categories (for example, high versus low-performing single guide RNA (sgRNA)) based on user-provided features. A deep learning model based on self-attention mechanisms that process input sequences while efficiently capturing long-range dependencies. The ability of a model to make predictions on tasks or classes it was never explicitly trained on by leveraging generalized knowledge learned during pretraining. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. Reprints and permissions Thomson, T., Li, G., Strilchuk, A. et al. Harnessing artificial intelligence to advance CRISPR-based genome editing technologies. Nat Rev Genet  (2025). Version of record: 18 November 2025 Anyone you share the following link with will be able to read this content: Sorry, a shareable link is not currently available for this article. Provided by the Springer Nature SharedIt content-sharing initiative Nature Reviews Genetics (Nat Rev Genet) ISSN 1471-0064 (online) ISSN 1471-0056 (print) © 2025 Springer Nature Limited Sign up for the Nature Briefing: Translational Research newsletter — top stories in biotechnology, drug discovery and pharma.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.popularmechanics.com/science/a69440323/never-before-seen-creature-fossilized-puke/'>Scientists Found a Never-Before-Seen Creature Inside 110-Million-Year-Old Fossilized Puke</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.popularmechanics.com', 'title': 'Popular Mechanics'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-11-18 13:30:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>About 110 million years ago, two pterosaurs were probably wandering around the shore when they were snapped up by a hungry predator—one which apparently couldn't hold them down. We may earn commission if you buy from a link. Even the most ferocious dinosaurs sometimes bit off more than they could chew (or swallow). In one such instance, what was supposed to be inner came right back up, fossilized for over a hundred million years, and it ended up gathering dust in the back room of a museum—until scientists realized this half-digested mass contained the bones of a pterosaur species that had gone undiscovered. Fossilized vomit is not usually where anyone expects to identify an unknown species. When a team of paleontologists examined it up close, they realized they were looking at the crushed remains of several fish and two nameless pterosaurs. The fossils seem unremarkable at a glance, an almost indistinguishable jumble of bones against yellow-tinged carbonate rock. It was when the research team observed two upper jaw and two lower jaw fragments that they realized whatever carnivore was stalking prey that fateful day must have been especially ravenous, because it snapped up two pterosaurs in its jaws before downing four fish. That must have been more than its stomach could handle. This means it fed by running its snout full of bristle-like teeth through the water like a sieve to catch small crustaceans and other small sea creatures. While it is not the only known filter-feeing pterosaur, it is now the sole member of an entirely new pterosaur genus. Bakiribu has features that echo older specimens of closely related species in Germany and younger bones from Argentina. It is closest to Ctenochasmatidae, a diverse and widespread clade of pterosaurs that took to the skies during the Late Jurassic and Early Cretaceous. Some ctenochasmatids, such as Ctenochasma, Pterodaustro guinazui, Gegepterus changi and Pterofiltrus qiui belonged to a subgroup with elongated snouts and rows of fine teeth that suggest they were filter feeders. Evolutionarily falling somewhere between the older Ctenochasma and younger Pterodaustro, Bakiribu suggests a transitional phase in ctenochasmatine pterosaurs. Its snout is more elongated and denser than that of Ctenochasma, with more teeth, but not quite as much as that of Pterodaustro. What exactly ate these pterosaurs is unknown, but the researchers suspect it could have been a Spinosaurus. It most likely ended up with skeletal overload in its stomach and was unable to keep the entire meal down. This goes to show that new discoveries can surface in the unlikeliest of places, and that even the fiercest dinosaurs were prone to puking. Her work has appeared in Popular Mechanics, Ars Technica, SYFY WIRE, Space.com, Live Science, Den of Geek, Forbidden Futures and Collective Tales. She lurks right outside New York City with her parrot, Lestat. When not writing, she can be found drawing, playing the piano or shapeshifting.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.nature.com/articles/s41558-025-02480-1'>Increasing risk of mass human heat mortality if historical weather patterns recur</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.nature.com', 'title': 'Nature'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-11-18 11:30:18
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript. The potential death toll of exceptional extreme heat events is crucial for climate risk analysis and adaptation planning but may not be captured by existing projections. Here we combine machine learning-based projections of five historical European heat waves under present or future global temperatures with empirical exposure–response functions to quantify the potential for extreme heat events to generate mass mortality. For example, if August 2003 meteorological conditions recur at the recent annual global temperature anomaly of 1.5 °C, we project 17,800 excess deaths across Europe in one week, rising to 32,000 at 3 °C. This mortality is comparable to peak COVID-19 mortality in Europe and is not substantially reduced by climate adaptation currently observed across Europe. Our results suggest that while mitigating further global warming can reduce heat mortality, mass mortality events remain plausible at near-future temperatures despite current adaptations to heat. Climate change is increasing the frequency and magnitude of extreme heat events1,2,3,4, threatening human health5. Additional warming is projected to generate more intense heat events than even recent record-breaking events6, with the potential for mass mortality events similar to those witnessed in Europe in the summer of 20037, especially during exceptionally hot years such as 20238,9. Projections of increased heat-related mortality from climate change are now numerous10,11,12,13,14,15. However, these projections generally focus on the long-term population burden of non-optimal temperatures rather than the death toll of individual high-impact events. Exceptional extreme heat events require distinct management strategies compared with typical population burdens, as they can strain health and emergency services beyond what occurs at milder temperatures16. Preparedness for hospital overcrowding and health system surge capacity should therefore be benchmarked to a plausible extreme scenario rather than an average projection17. Quantifying plausible scenarios of extreme events under future climate change requires careful methodological treatment, and there are reasons to believe that existing projections do not capture the most extreme mortality events. In particular, the relatively short records of observations and most global climate model (GCM) simulations make it difficult to assess the probabilities of the most extreme events18. While progress has been made using large initial-condition ensembles to quantify very rare heat mortality19, some of the most extreme events may be poorly captured even by ensembles with many members20. Additionally, GCMs underestimate trends in the frequency and persistence of atmospheric circulation patterns that have contributed to recent rapid warming of heat extremes in populous regions such as Europe21,22,23,24,25,26. To complement existing work, a promising approach is to develop ‘storylines' of heat waves that are physically plausible and dynamically consistent. This conditional approach, which emphasizes plausibility rather than probability27, enables exploration of extreme outcomes28,29 and stress tests of adaptation strategies17,30. Plausible storylines must also account for the documented ability of humans to adapt to repeated heat exposure and to change behaviour following past extreme heat episodes31. Major heat-mortality events require several ingredients: large-scale physical drivers of elevated temperatures as well as human health responses to the resulting heat stress. Extreme heat events tend to occur when atmospheric high-pressure systems interact with dry soils to produce land–atmosphere feedbacks that amplify heat accumulation6,21,32,33. In turn, prolonged exposure to high ambient temperatures impairs the ability of the body to dissipate heat, leading to elevated core temperature, increased cardiovascular strain and a heightened risk of heat-related illness and death34. Here we focus on the combination of these geophysical and physiological ingredients in Europe. Hot extremes are increasing more rapidly in Europe than the rest of the hemisphere22,23,26, and tens of thousands of deaths across the continent have been linked to recent summer heat35,36, with climate change causing more than half37. As a result, Europe is a particularly important setting in which to study the risk of mass heat-mortality events. We combine two existing approaches to quantify the risk of mass heat mortality across Europe (Methods). First, we use a recently developed machine learning framework38. In this framework, convolutional neural networks (CNNs) are trained on an ensemble of GCMs from the sixth phase of the Coupled Model Intercomparison Project (CMIP6) to predict daily temperatures in three Intergovernmental Panel on Climate Change (IPCC) regions of Europe from (1) the annual global mean temperature (GMT) in the preceding 12 months, (2) the calendar day and (3) modelled daily meteorological conditions. Then, meteorological conditions from ERA5 reanalysis are used as out-of-sample inputs to the trained neural networks to predict ‘counterfactual' versions of historical heat waves at varying annual GMT. Our method learns the representation in the GCMs of the meteorological drivers of individual extreme heat events, allowing us to quantify the intensity of surface temperature extremes conditional on historical meteorological patterns, independent of projected changes in the frequency or persistence of those patterns. We predict counterfactual events at varying annual GMT from the preceding 12 months, rather than long-term mean GMT, because individual hot years are plausible before long-term climate targets are reached39, these years pose substantial regional climate risks40 and GMT in the previous 12 months is directly detectable in observations41. For this study, we produce counterfactual estimates of five multiweek periods of extreme heat that occurred in July 1994, August 2003, July 2006, June 2019 and August 2023 (Fig. We choose these illustrative events, which had differing durations and spatial extents, because each corresponds to a continuous period of Europe-wide temperature anomalies (date ranges shown in Extended Data Fig. 1), shows spatial patterns of anomalous atmospheric pressure and soil moisture (Fig. 1g) and spans a wide range of human influence on the climate (for example, annual GMT anomaly in the preceding 12 months of 0.5 °C in July 1994 versus 1.3 °C in August 2023). a–c, Daily mean temperatures in June, July and August (JJA) in our out-of-sample machine learning predictions and ERA5 reanalysis, for the IPCC regions of the Mediterranean (a), Western and Central Europe (b) and Northern Europe (c). Inset maps show region definitions. d–f, Time series of annual hottest 7 days (Tx7d) from ERA5 (black) and out-of-sample predictions (red) over the Mediterranean (d), Western and Central Europe (e) and Northern Europe (f). Red line shows the mean prediction and shading shows 95% CI across GCMs and random seeds used in training (Methods). g, Meteorological conditions during five selected extreme heat events, with 500-mb geopotential height (GPH) in top row, soil moisture in middle row and temperature in bottom row. Inset text in bottom row denotes the GMT anomaly (versus 1850–1900) in the previous 12 months. h, Counterfactual temperature anomalies during each of the five heat waves at annual GMT anomalies of 1.5 °C and 3 °C above the pre-industrial baseline. Meteorological anomalies are relative to the location and day-of-year mean over 1979–2023 and averaged over the days defined for each event (Extended Data Fig. Maps in g and h created with Cartopy v0.24.0 with shapefile boundaries from Eurostat (https://ec.europa.eu/eurostat/web/gisco/geodata/statistical-units/territorial-units-statistics) under a Creative Commons license CC BY 4.0. Second, we use longitudinal data on temperature and weekly mortality over 2015–2019 from 924 subnational regions of Europe to estimate exposure–response functions that relate ambient temperature to mortality risk (Methods). We control for location-specific seasonal and trending factors, isolating plausibly exogenous variation in daily temperature to measure the causal effect of temperature on mortality. We then calculate mortality from each event at each annual GMT anomaly and compare it to a long-term average baseline without global warming. We estimate and propagate uncertainty throughout the calculation, resulting in mortality projections that incorporate variation in both the counterfactual event predictions and exposure–response function (Methods). These tools allow us to explicitly separate the effects of climate change and weather variability on mortality. We can leverage the diverse library of weather patterns simulated by GCMs to learn nonlinear relationships between meteorological patterns and surface heat extremes, along with the heterogeneity of responses to global warming across those patterns38. Whereas previous studies of climate change and mortality in Europe have been limited to linear scaling to capture multiple events37 or computationally intensive custom simulations for an individual event42, our approach allows us to leverage an ensemble of CMIP6 simulations to predict temperature profiles resulting from different historical meteorological conditions at different annual GMTs. In this way, our out-of-sample application of these learned relationships to actual meteorological patterns grounds our analysis in weather systems that have historically produced extreme heat. After training on GCMs, our machine learning predictions compare well with summer daily temperatures in ERA5 across Europe when using ERA5 meteorological fields as out-of-sample inputs (Fig. They also specifically predict variation in the temperature of the hottest week in each region (Fig. We observe a small cold bias in Northern Europe (Fig. 1f), potentially because the most extreme days in the GCM training data are slightly cooler than the tail of the ERA5 distribution in this region (Supplementary Fig. In the construction of counterfactual events, we use a ‘delta' method that bias-corrects the predictions (Methods). Finally, we find close correspondence between predicted and true temperatures when evaluating on held-out GCM data across a wide range of annual GMT anomalies (Supplementary Fig. Together, these results indicate that our approach is capable of closely reproducing sequences of hot days at a range of annual GMT values when provided with particular historical meteorological patterns, despite not seeing those precise patterns in training. Turning to our illustrative heat waves, while the weather patterns associated with each event vary, they share common characteristics: anomalous high-pressure systems and dry soils across the continent, resulting in elevated temperatures in many countries (Fig. Without global warming, each event would have been cooler (Extended Data Fig. 2); likewise, with additional warming, a given meteorological pattern produces steadily larger temperature anomalies (Fig. 1h and Extended Data Fig. The difference between the actual event magnitude and the magnitude at different annual GMT varies by event, both because the actual events occurred at different GMT and because the machine learning approach learns different responses to global warming conditioned on the particular meteorological pattern38. Across annual GMT of 1.5 °C, 2 °C, 3 °C and 4 °C, the August 2003 conditions yield the highest temperatures of all events, emphasizing the severity of the weather conditions during that event (Fig. Similarly, July 1994, for which historical temperature anomalies were relatively moderate among the illustrative events, produces among the most severe anomalies at standardized GMTs. High temperatures are empirically associated with increased mortality risk across Europe (Fig. We specifically find that the temperature–mortality relationship is moderated by the long-term mean temperature of a region, as found elsewhere11; for example, the minimum mortality temperature (MMT) is 14.5 °C in the coolest third of regions and 19.7 °C in the warmest third of regions. This heterogeneity may reflect the greater return on adaptation investments such as air conditioning in warmer regions. However, the slope of the exposure–response curve is steeper for warmer areas despite their higher MMT, potentially reflecting limits to adaptation to the hottest conditions. For all regions, the nonlinear increase in mortality risk above the MMT means that greater extreme heat intensity is expected to increase mortality across the continent (Fig. Relationship between daily temperatures and change in cumulative weekly mortality rate in subnational regions across Europe over 2015–2019, as a function of the mean temperature (computed over 2000–2019) of each region. Curves show examples for the coolest third (yellow), middle third (orange) and warmest third (red) of regions. Shading shows 95% CIs derived from bootstrap resampling by country (Methods). Effects are accumulated across the contemporaneous week and the following 3 weeks by including three lags in the regression (Methods). Map shows 2000–2019 annual mean temperature for each region for which we have mortality data, which is the spatial variation we use in measuring adaptation. Lower inset points show the population-weighted Europe-wide average temperature during each event at a range of annual GMTs above the pre-industrial baseline. Map created with Cartopy v0.24.0 with shapefile boundaries from Eurostat (https://ec.europa.eu/eurostat/web/gisco/geodata/statistical-units/territorial-units-statistics) under a Creative Commons license CC BY 4.0. Each extreme heat event is projected to generate thousands of weekly excess deaths across Europe at the recent annual GMT of 1.5 °C (ref. 43), with increasing impacts in response to higher annual GMT (Fig. The largest death tolls are associated with the 1994 and 2003 conditions, with 26,500 (95% confidence interval (CI) 22,400–31,100) and 32,000 (CI 26,700–38,800) weekly excess deaths following 12-month mean GMT of 3 °C, respectively (Fig. While less likely than more moderate temperatures given current emissions trends, 12-month periods with mean GMT of 4 °C are still plausible under gradual decarbonization40 and would generate 37,500 (CI 29,500–46,400) and 45,100 (CI 37,000–55,600) excess deaths in a single week across Europe if 1994 or 2003 meteorological conditions recurred, respectively. The other three events are associated with weekly peaks of 25,600 (CI 21,000–30,700), 18,800 (CI 16,100–22,100) and 20,900 (CI 16,700–25,800) excess deaths, respectively, following 12-month mean GMT of 3 °C. Excess mortality is slightly negative in the weeks following the event, consistent with mortality displacement (Methods), although not enough to offset the peak of the event. a–e, Europe-wide weekly excess mortality during extreme heat events based on meteorological conditions from July 1994 (a), August 2003 (b), July 2006 (c), June 2019 (d) and August 2023 (e) across a range of annual global temperatures. Solid line shows average projection and shading shows 95% range in a year with GMT 3 °C above the pre-industrial baseline. Grey shading shows mortality at 0 °C, meaning the mortality that would have occurred without global warming. The x axis spans 2 weeks before the event begins to 3 weeks after it ends to illustrate the lagged effects of the event on mortality (Methods). f–j, Sources of uncertainty in the peak death toll from the July 1994 (f), August 2003 (g), July 2006 (h), June 2019 (i) and August 2023 (j) events. For each uncertainty source, the other dimensions are held at their average values and lines show variation across each value of the relevant dimension. These death tolls reflect the underlying effect of hot temperatures without climate change, combined with the influence of climate change in intensifying these events. Comparing each event to its counterfactual at 0 °C allows us to isolate the contribution of climate change to event mortality (red lines versus grey shading in Fig. For example, at the peak of a 2003-like event at 3 °C, we project climate change to produce an additional 23,000 excess deaths on top of 9,000 that would have occurred without warming, making anthropogenic warming responsible for 72% of the death toll (Supplementary Table 2). Uncertainty in mortality from each event (shading in Fig. 3a–e) results from differences across GCMs used for machine learning training, uncertainty in the machine learning training process and sampling uncertainty in the exposure–response function (Methods). Examining the contribution of each source of uncertainty while holding the others constant reveals that sampling uncertainty in the exposure–response function (‘regression uncertainty') is the dominant source across all five illustrative events (Fig. While the GCMs we use for training do not span the full CMIP6 ensemble (Methods), our subset does include both high- and low-sensitivity GCMs. The higher-sensitivity GCMs have lower mortality projections than the lower-sensitivity GCMs (Supplementary Fig. 3), making it unlikely that global climate sensitivity is the primary driver of GCM uncertainty in the mortality response to increasing GMT. The spatial distribution of mortality during each event differs, governed by the location of temperature anomalies (Fig. 1), variation in exposure–response functions (Fig. 2) and spatial variation in the effect of global warming (Supplementary Fig. For example, under 1994-like conditions, the greatest mortality occurs in Germany, Poland and Eastern Europe, whereas under 2023-like conditions, mortality is highest in Spain, Italy and the Balkans (Extended Data Fig. Given that European countries undertook adaptation to heat following previous events such as 200331 and we observe heterogeneity in exposure–response functions that may indicate adaptation (Fig. 2), we explore the potential for additional future adaptation to mitigate mortality from these events. Specifically, we allow the mean temperature of each region to evolve in the future according to pattern scaling coefficients derived from CMIP6 GCMs (Supplementary Figs. Following other work11, our approach to estimating adaptation thus relies on extrapolating current heterogeneity in exposure–response functions and assumes that future societies will continue to adapt with the same pattern as has been recently observed. Across the five illustrative events we study, incorporating adaptation reduces peak mortality by only 10% on average (Fig. For example, peak mortality during 2003 meteorological conditions following 12 months with mean GMT of 3 °C is projected to be 32,000 in our main projections and 28,800 (CI 21,300–36,200) when allowing additional adaptation. These results imply that there is limited potential for currently deployed adaptation approaches to reduce the mortality impacts of these extreme climate events. Each bar shows the peak weekly mortality at 3 °C for each set of meteorological conditions. The yellow bars show our main calculation (that is, the peak of the 3 °C curve in Fig. 3), which incorporates existing adaptation through spatial heterogeneity in exposure–response functions. The blue bars show the same calculation after accounting for additional future climate adaptation by allowing exposure–response curves to evolve with future climate change (Methods). Bar heights show average projections and error bars show 95% range across each combination of GCM, random seed and regression bootstrap (n = 12,500). Grey text denotes the percentage reduction in mortality from additional future adaptation. Several caveats and analytical choices should be considered when evaluating these results. For instance, we use all-age mortality rather than age-stratified rates to maximize data coverage (Methods), meaning we do not account for future shifts in age structure. However, we find an extremely similar exposure–response function for the over-65 years population as for all ages (Supplementary Fig. 7), meaning that our main response is probably already driven primarily by mortality among the elderly. Additionally, previous work has projected that changes in age structure are likely to increase heat-related mortality in Europe by 1–3%, implying that such changes would only slightly affect our results44. Our use of annual GMT as a predictor differs from other work defining global warming as a multidecade smoothed value45. Our goal is to quantify the mortality risks associated with the possibility that historical meteorological conditions recur in years that are globally hotter than the historical years in which those conditions occurred. While smoothed GMT isolates long-term global warming, realized climate risks reflect the combination of the forced response and internal variability, and individual extreme years such as 2023 have seen dangerous local heat conditions as a result of this combination8,9. Quantifying the intensity of plausible heat waves at specific annual GMTs thus provides critical information for risk assessment. Additionally, our projections are conditional on weather patterns that are rare by definition. It is possible that these mortality events would not take place even with substantial warming if the corresponding meteorological conditions do not occur again. Conversely, even more severe events could be produced if weather patterns occur that were not witnessed in the short observational record. Further, our results reveal a latent potential for meteorological patterns that did not cause substantial excess mortality in the past to do so in the future if they occur at higher annual GMTs. For example, at equivalent annual GMT, the July 1994 meteorological conditions produce the highest cumulative mortality and second highest peak mortality of any of the illustrative events (Supplementary Table 1). This finding also illustrates the reason that we avoid calculating ‘observed' mortality from each event at the time it actually occurred. Each event occurred at a different level of warming and potentially a different degree of human adaptation to heat. Indeed, in other recent work, we show that the temperature–mortality relationship in France is very different before 2003, meaning that calculating ‘observed' heat mortality in 2003 may require a more sophisticated exposure–response function46. Our forward-looking approach allows us to analyse a range of known meteorological conditions at the same GMT levels, permitting standardized comparisons between historically different events with a single exposure–response function that reflects recent adaptation. To further contextualize the magnitude of the death tolls we calculate, we compare them to weekly confirmed COVID-19 deaths across the same regions of Europe for which we have mortality data (Fig. For example, the most severe 10% of weeks of COVID-19 had between 27,900 and 34,100 confirmed deaths. For an annual GMT of 3 °C, the weekly death toll from 2003-like conditions is comparable to these peak weeks of COVID-19, and for an annual GMT of 4 °C, the weekly death tolls of 1994-, 2003- and 2006-like conditions would exceed even the single worst week of COVID-19 in Europe (Extended Data Fig. It is notable that our results suggest limited potential for existing patterns of adaptation to mitigate these mass mortality events. This result may occur because, although warmer regions in Europe have higher MMTs, they also have steeper exposure–response curves above those MMTs (Fig. However, our approach to adaptation is based solely on extrapolating observed spatial heterogeneity as a function of mean temperature. If other factors, such as income, change in the future, this could further affect the exposure–response function. To explore this issue, we run an additional regression where temperature is simultaneously interacted with both mean temperature and mean income11, and we find that mean temperature generates much greater heterogeneity than income, providing confidence that our main findings capture the most important axis of heterogeneity at present (Supplementary Fig. More broadly, our results are consistent with other work emphasizing that heat still poses a major public health threat despite putative progress since the deadly 2003 summer47,48,49, and point to the need for new approaches to emerge if adaptation is to be more effective. Our results reveal a substantial death toll from potential future extreme heat events in Europe. These results are based on historically observed meteorological patterns combined with plausible twenty-first-century global temperature anomalies, making them physically realistic storylines of high-magnitude heat events. We specifically distinguish between the contributions of climate change and natural variability conditional upon these realistic patterns, revealing that climate change is already a dominant contributor to mortality during extreme heat events, and its contribution could reach 70–80% of deaths at higher global temperature anomalies. Our characterization of specific, plausible high-magnitude outcomes is an important complement to existing heat-mortality projections and can help inform health system preparedness and planning. Most importantly, our results demonstrate that even if global temperatures are stabilized, substantial and new adaptation measures may be required to reduce the continent-wide threat of extreme heat to population health. We draw weekly mortality data from the Eurostat database (data code ‘demo_r_mweek3'). Different regions make data available over different time periods; we limit our analysis to 2015–2019 to match the most common period of data availability, following other work35. Where possible, we use all-age, all-sex mortality rates from NUTS3 (third administrative level below country) regions, except in Germany, where we only have these data at the NUTS1 level. This yields a total of 924 regions with continuous mortality rate data over 2015–2019. Age-group-specific rates (for example, over 65 years) are available for only a slightly smaller number of regions (n = 908), so we use all-age rates to maximize coverage in our preferred specification. Our historical climate data come from the E-OBS station-based dataset50 and the ERA5 reanalysis51. We use E-OBS daily surface temperature when possible, including for the initial definitions of each extreme event and the mortality calculations. E-OBS data are spatially averaged to the appropriate NUTS regions, weighting grid cells within regions by the population of each grid cell. We use ERA5 for the out-of-sample machine learning predictions (Fig. 1) and maps of historical meteorological conditions (Fig. We use a machine learning architecture recently developed and validated by ref. 38 to produce counterfactual versions of historical extreme heat events. Following this approach, we train CNNs on an ensemble of GCM realizations, with the goal of predicting daily mean temperature anomalies over a specified region given daily meteorological conditions and the annual GMT anomaly. The predictors for each day are daily sea level pressure (SLP), daily GPH fields at the 700-mb, 500-mb and 250-mb levels, daily soil moisture between 0 cm and 10 cm, the calendar day, an indicator variable for each GCM and the GMT anomaly over the previous 12 months. Before training, the meteorological predictors are detrended with respect to the grid cell, calendar day and GMT and then standardized by subtracting the grid-cell calendar-day mean and dividing by the grid-cell calendar-day standard deviation38. The detrended and standardized surface pressure, GPH and soil moisture are the factors we refer to as ‘meteorological conditions' throughout the text. Using detrended and standardized anomalies in this process means that these meteorological conditions explain day-to-day variation in temperature, but do not contain the signal of global warming. Daily mean temperature anomalies (the predictands) are referenced to the 1979–2023 period, with GMT anomalies relative to the same period when used in training. However, we note that throughout the text we refer to GMT anomalies relative to 1850–1900. In our experimental setup, we train the CNN on a pooled set of CMIP6 simulations: three realizations each of five GCMs (CanESM5, HadGEM3-GC31-LL, MIROC6, MPI-ESM1-2-LR and UKESM1-0-LL). We combine the historical and shared socioeconomic pathway (SSP) 5-8.5 simulations to create a 1850–2100 dataset for each realization. These five GCMs are chosen because they each archive three-dimensional daily atmospheric fields of each input variable from several realizations of the GCM. While these data requirements prevent us from using a wider range of CMIP6 models, these five GCMs are representative of the range of climate sensitivities in the CMIP6 ensemble52. Since this analysis focuses on summer heat waves, we train each CNN on CMIP6 data from May through September. We then apply the model to predict daily temperature anomalies using predictor data from ERA5. One set of predictions uses the observed GMT time series, whereas the other sets use counterfactual GMT values but maintain the other daily predictors from the reanalysis. The result is a set of counterfactual temperature time series that maintain realistic day-to-day weather conditions but vary according to the annual GMT anomaly. While we train the CNN on a pooled set of realizations, we include an indicator variable for each GCM which allows the CNN to make separate predictions based on differences between individual GCMs. This indicator variable is one-hot encoded and provided to the neural network after the convolutional layers along with the calendar day and GMT inputs (similar to ref. In training, we also vary the random seed five times to account for random differences in model training. This procedure yields 25 total predictions for each counterfactual event and GMT anomaly, five random seeds each for five GCMs. We use a ‘delta' method to apply the CNN predictions to E-OBS gridded observations. For each day in the event of interest, we take the difference between the counterfactual CNN predictions on that day and the original CNN predictions for that day using the actual GMT. We then apply these deltas to the E-OBS observed data for that day to calculate counterfactual daily time series. Finally, we aggregate these counterfactual gridded daily temperature data into averages at the NUTS region level as with the original observations. 38, the CNNs were trained to predict temperature in regions chosen for their relevance to specific historical extremes. In our application, we would like to apply these predictions to a set of events, each with slightly different spatial footprints. We therefore train the CNNs to predict temperature change on land in each of three regions as defined by the IPCC: the Mediterranean, Western and Central Europe and Northern Europe53. The events manifest differently in each of these regions, with temperatures generally highest in the Mediterranean region and lowest in Northern Europe (Supplementary Fig. We then apply the deltas for each region uniformly to the grid cells within each region. When training the CNNs, the input SLP, GPH and soil moisture fields are defined by broader regions of approximately 35° latitude and 85° longitude centred on the IPCC regions38. We use panel regression with fixed effects to measure the causal effect of temperature on mortality across Europe. This widely used approach11,12,54,55,56 involves regressing mortality rates on a nonlinear function of temperature, along with vectors of intercepts (fixed effects) that non-parametrically remove seasonal or annual average factors separately for each region. We also account for heterogeneity across regions by interacting temperature with the 2000–2019 average temperature of each region, allowing the temperature exposure–response curve to vary on the basis of the long-term climate of a region. This approach leverages cross-sectional variation in temperature to assess societal adaptation to extreme heat, in effect asking whether the same temperature level has a different effect in a region that is warmer on average than a region that is cooler on average. Cross-sectional variation is less amenable to causal identification since there may be other factors (for example, income and demographics) that are correlated with both average temperature and heat sensitivity. Nevertheless, assessing heterogeneity by mean temperature is a well-established strategy for identifying present and future climate adaptation11,57,58,59,60, so we adopt it here while acknowledging the potential for additional relevant axes of heterogeneity. Our approach is also similar to multistage methods that have been used in other recent papers to estimate variation in exposure–response functions (for example, refs. 13,61,62), although we run a single regression that accommodates variations across regions rather than pooling time-series regressions from separate regions. Specifically, we estimate the following regression relating contemporaneous and lagged temperature T to log mortality rates M in region i, week w and year y with ordinary least squares: The region–year fixed effects \({\mu }_{{iy}}\) and region–week fixed effects \({\delta }_{{iw}}\) remove the influence of long-term trends and seasonal cycles that could confound the temperature–mortality relationship and do so separately for each region. The \({\bar{T}}_{i}\) term denotes the 2000–2019 mean temperature in each region i. We estimate distributed lag models that sum the impact on mortality of contemporaneous and lagged temperature exposure, with j indexing weekly lags. As discussed below, our main model uses 3 weeks of lagged temperatures. Regressions are weighted by the population of each region. A key consideration is that mortality rates are provided at the weekly scale but temperature extremes can impact mortality rates on daily timescales. We require a strategy that preserves daily nonlinearities while matching the weekly scale of the mortality data. We thus follow previous work11 and sum the daily mean temperature from each day d within week w after a fourth-order polynomial transformation has been applied to the temperature of each day: We estimate independent coefficients for each of the summed polynomial terms in equation (2). Because weekly mortality rates are the sum of daily mortality rates (given constant population), calculating the effects of daily sums preserves the nonlinear effect of each individual day on weekly mortality rates. We use daily mean temperature following earlier work11, but using daily maximum or daily minimum temperatures yields only small differences in exposure–response functions (Supplementary Fig. We use lags in the regression to incorporate delayed effects of temperature. These delayed effects could arise simply as a result of additional mortality if people die several days after heat exposure. They could also manifest as ‘displacement' or ‘harvesting,' where mortality is abnormally low after heat waves since the heat accelerated the deaths of people who would have died soon regardless of the heat. Indeed, we do observe some displacement following the events (Fig. 3), as the lag-2 and lag-3 regression coefficients are negative (Supplementary Fig. We use three lags in our main analysis following earlier work35, but re-estimating the model using six lags yields similar results, with potentially slightly more displacement in additional weeks (Supplementary Fig. Our main regression is estimated over 2015–2019, as the period over which the greatest number of regions have continuous mortality data. Alternatively, we estimate the regression using all observations from 2000–2019, although different regions have different numbers of observations over this period. We find a very similar response, although the mortality response to high temperatures is slightly stronger when including data further back in time (Supplementary Fig. 7), consistent with other evidence of moderate adaptation to heat over this period31,49. Because the 2015–2019 sample uses a balanced set of regions with continuous data and accounts for previous adaptation to heat, we use it in our main analysis. When we test an additional interaction with income (Supplementary Fig. 8), we calculate income as the 2000–2019 mean of log annual gross domestic product (GDP) per capita. GDP per capita is defined in Euros, GDP-deflated to account for inflation and purchasing-power-parity adjusted. Our central calculation compares a series of abnormally hot days at a given GMT level to a long-term mean baseline without global warming (Extended Data Fig. We perform this calculation by applying the exposure–response function (Fig. 2) to the temperature time series in each region and comparing it to the same prediction when applied to the baseline time series. Because our outcome is log mortality, the difference between each prediction yields a percentage change in mortality due to experiencing the temperature at each GMT instead of the baseline temperature. We then multiply this percentage change by the average number of deaths in each region observed over 2015–2019 to calculate the additional mortality from each event. Because these deaths are relative to an underlying baseline number of deaths, we refer to them as ‘excess deaths' or ‘excess mortality.' Note that we generally refer to the events predicted by the machine learning method for different GMT anomalies as ‘counterfactual' events, whereas we use ‘baseline' to refer to a long-term average without the event. One key methodological question in this procedure is the construction of the baseline temperature from which excess deaths are calculated. We are interested in the total number of excess deaths associated with each event, not just those caused by climate change. We therefore construct a baseline which does not include either climate change or extreme heat events. This is done in two steps: We use the machine learning approach described above to construct counterfactual estimates for every summer day between 1980 and 2023 at 0 °C GMT. We subtract the ‘delta' from this procedure from the E-OBS observations to construct a counterfactual dataset at 0 °C over the entire observational time period (that is, not just for each event). This yields a 44-year counterfactual temperature time series for each region that includes daily weather variability and extreme heat events, but not the influence of climate change. We then take the long-term average across 1980–2023 from this counterfactual time series for each calendar day in each region. The result of this calculation is an estimate of the average seasonal cycle in each region at an annual GMT anomaly of 0 °C. Because the influence of climate change was removed from these observed temperatures, this baseline does not include global warming, and because it was averaged over all years for each calendar day, it does not include deviations from the seasonal cycle (that is, it does not include extreme heat events). The black dashed line in Extended Data Fig. 2 shows the Europe-wide average of these baseline temperatures over the time period of each event. Our regression approach (equation (1)) accounts for current adaptation to heat by allowing exposure–response functions to vary according to the 2000–2019 mean temperature of the region. This approach assumes that vulnerability to temperature during the 2015–2019 data period fully reflects efficient levels of adaptation investment (such as installing air conditioning, taking indoor jobs rather than working outdoors or implementing heat action plans in cities), justifiable on the basis of longer-term (2000–2019) exposures. In the future, especially in light of rising incomes, we might expect additional such actions, which could reduce the death toll that we project. We project future adaptation under the assumption that changes in the long-run mean temperatures of regions directly translate into additional adaptation actions. We thus require an estimate of future long-run (20-year) mean temperature in each region, with which to adjust the exposure–response functions (Fig. However, our approach predicts event intensity using annual global temperature, a quantity which does not directly translate into local mean temperatures over the previous 20 years. Therefore, we adopt a pattern scaling approach, following the IPCC Sixth Assessment report63, to simulate increased 20-year mean temperatures in each European subnational district depending on a given annual GMT. We use 27 models from the CMIP6 (ref. 64), spanning the historical and SSP3-7.0 experiments65. For each year, we calculate GMT anomalies (relative to 1850–1900) and local mean temperature anomalies over the previous 20 years for each European region (relative to 2000–2019). For example, for 2069 in the region that encompasses Berlin, we have the GMT change in 2069 and the regional mean temperature change over 2049–2068. The relationship between these two quantities yields a coherent spatial pattern across Europe (Supplementary Fig. 6) that is reflective of the forced response63. We note that extreme temperatures in Europe are rising faster than both local and global averages and CMIP6 models generally underestimate this higher scaling23,24, but changes in local 20-year mean temperatures in CMIP6 models scale with GMT quite similarly to their scaling in E-OBS observations (Supplementary Fig. In each calculation of event mortality at each annual GMT, we predict the additional mean temperature change (relative to 2000–2019) of each region given the GMT, slope and intercept, and add this additional temperature change to the 2000–2019 mean temperature of the region. This new mean temperature value is then used in the calculation of the mortality of each region from their exposure–response functions (Fig. 2), allowing the exposure–response functions to evolve in the future given a projection of changing local mean temperatures. Finally, we implement two sensitivity tests of this adaptation approach. In the first test, we calculate analogous scaling factors from observations rather than GCMs, by regressing regional 20-year-running-mean temperature change from E-OBS against HadCRUT global mean temperature anomalies. We then assume that the rate of local mean warming of each region continues linearly into the future. In the second test, we simply assume that the mean temperature of each European region changes by the same amount as the GMT level (that is, we assume a one-to-one scaling between global and local mean temperature). In both cases, we find effects of adaptation that are very similar to our main analysis (Supplementary Fig. Our analysis incorporates uncertainty from each step in the calculation. First, when estimating the empirical exposure–response functions, we estimate uncertainty by bootstrap resampling 500 times (‘Exposure–response functions' section). We block-bootstrap by country, meaning we preserve temporal correlation within NUTS regions and spatial correlation across regions within countries (akin to clustering standard errors by country). Second, when making counterfactual temperature predictions for historical weather patterns using the machine learning architecture (‘Counterfactual extreme heat events' section), we make 25 different counterfactual event predictions for each extreme heat event at each annual GMT anomaly (making a different prediction for each of five random seeds within each of five different GCMs). We calculate each final mortality projection 12,500 times (5 × 5 × 500), once for each combination of regression bootstraps, random seeds and GCMs. 3, we hold two dimensions of uncertainty at their mean values and show all values across the remaining dimension (for example, each of 500 different results for each regression bootstrap while averaging across GCMs and random seeds). When we incorporate adaptation (‘Adaptation to climate change' section), we pool all model-years and calculate a random sample of 100 pattern scaling coefficients from this pooled sample. Then, in each of the 12,500 mortality calculations, we randomly sample one of these sets of pattern scaling coefficients. Given the multiple dimensions of uncertainty that we account for, we round each value in the main text to three significant figures to avoid reporting overly precise results. Further information on research design is available in the Nature Portfolio Reporting Summary linked to this article. Replication data are available via Zenodo at https://doi.org/10.5281/zenodo.14812821 (ref. Source data are provided with this paper. Replication code are available via Zenodo at https://doi.org/10.5281/zenodo.14812821 (ref. & Tebaldi, C. More intense, more frequent, and longer lasting heat waves in the 21st century. Rahmstorf, S. & Coumou, D. Increase of extreme events in a warming world. Fischer, E., Sippel, S. & Knutti, R. Increasing probability of record-shattering climate extremes. Diffenbaugh, N. S. et al. Quantifying the influence of global warming on unprecedented extreme climate events. Hot weather and heat extremes: health risks. Prediction and projection of heatwaves. Robine, J.-M. et al. Death toll exceeded 70,000 in Europe during the summer of 2003. Extreme terrestrial heat in 2023. Min, S.-K. Human influence can explain the widespread exceptional warmth in 2023. Hsiang, S. et al. Estimating economic damage from climate change in the United States. Valuing the global mortality consequences of climate change accounting for adaptation costs and benefits. & Greenstone, M. Climate change, mortality, and adaptation: evidence from annual fluctuations in weather in the US. Projections of temperature-related excess mortality under climate change scenarios. Vicedo-Cabrera, A. M. et al. Temperature-related mortality impacts under and beyond Paris Agreement climate change scenarios. Garcı́a-León, D. et al. Temperature-related mortality burden and projected change in 1368 European regions: a modelling study. Climate change and extreme heat events: how health systems should prepare. Stress testing the capacity of health systems to manage climate change-related shocks and stresses. Gessner, C., Fischer, E. M., Beyerle, U. & Knutti, R. Very rare heat extremes: quantifying and understanding using ensemble reinitialization. Rapid increase in the risk of heat-related mortality. Fischer, E. M. et al. Storylines for unprecedented heatwaves based on ensemble boosting. Contribution of changes in atmospheric circulation patterns to extreme temperature trends. Rousi, E., Kornhuber, K., Beobide-Arsuaga, G., Luo, F. & Coumou, D. Accelerated western European heatwave trends linked to more-persistent double jets over Eurasia. Singh, J., Sippel, S. & Fischer, E. M. Circulation dampened heat extremes intensification over the Midwest USA and amplified over Western Europe. Vautard, R. et al. Heat extremes in Western Europe increasing faster than simulated due to atmospheric circulation trends. Kornhuber, K., Bartusek, S., Seager, R., Schellnhuber, H. J. & Ting, M. Global emergence of regional heatwave hotspots outpaces climate model simulations. Patterson, M. North-West Europe hottest days are warming twice as fast as mean summer days. Shepherd, T. G. et al. Storylines: an alternative approach to representing uncertainty in physical aspects of climate change. Sutton, R. T. Climate science needs to take risk assessment much more seriously. Kelder, T. et al. How to stop being surprised by unprecedented weather. Sillmann, J. et al. Event-based storylines to address climate risk. Fouillet, A. et al. Has the impact of heat waves on mortality changed in France since the European heat wave of summer 2003? A study of the 2006 heat wave. Fischer, E. M., Seneviratne, S. I., Lüthi, D. & Schär, C. Contribution of land–atmosphere coupling to recent European summer heat waves. Miralles, D. G., Teuling, A. J., Van Heerwaarden, C. C. & De Arellano, J. V.-G. Mega-heatwave temperatures due to combined soil desiccation and atmospheric heat accumulation. Ballester, J. et al. Heat-related mortality in Europe during the summer of 2022. Gallo, E. et al. Heat-related mortality in Europe during 2023 and the role of adaptation in protecting health. Beck, T. M. et al. Mortality burden attributed to anthropogenic warming during Europe's 2022 record-breaking summer. Trok, J. T., Barnes, E. A., Davenport, F. V. & Diffenbaugh, N. S. Machine learning–based extreme event attribution. Predicted chance that global warming will temporarily exceed 1.5 °C. Diffenbaugh, N. S. & Barnes, E. A. Data-driven predictions of peak warming under rapid decarbonization. Cannon, A. J. Twelve months at 1.5 °C signals earlier than expected breach of Paris Agreement threshold. Mitchell, D. et al. Attributing human mortality during extreme heat waves to anthropogenic climate change. The year 2024 set to end up as the warmest on record. Copernicus Monthly Climate Bulletin https://climate.copernicus.eu/year-2024-set-end-warmest-record (2024). Chen, K. et al. Impact of population aging on future temperature-related mortality at different global warming levels. Approaching 1.5 °C: how will we know we've reached this crucial warming mark?. Callahan, C. W. et al. Quantifying the contributions of climate change and adaptation to mortality from unprecedented extreme heat events. Bittner, M.-I., Matthies, E. F., Dalbokova, D. & Menne, B. Are European countries prepared for the next big heat-wave?. Keller, R. C. Fatal Isolation: The Devastating Paris Heat Wave of 2003 (Univ. Burke, M. et al. Are We Adapting to Climate Change? Working Paper 32985 (NBER, 2024); https://doi.org/10.3386/w32985 & Jones, P. D. An ensemble version of the E-OBS temperature and precipitation data sets. Context for interpreting equilibrium climate sensitivity and transient climate response from the CMIP6 Earth system models. Chen, D. et al. in Climate Change 2021: The Physical Science Basis (eds Masson-Delmotte, V. et al.) 147–286 (Cambridge Univ. & Moretti, E. Extreme weather events, mortality, and migration. Barreca, A., Clay, K., Deschenes, O., Greenstone, M. & Shapiro, J. S. Adapting to climate change: the remarkable decline in the US temperature–mortality relationship over the twentieth century. Burke, M. et al. Higher temperatures increase suicide rates in the United States and Mexico. & Hsiang, S. M. Social and economic impacts of climate. Carleton, T. A. Crop-damaging temperatures increase suicide rates in India. Heutel, G., Miller, N. H. & Molitor, D. Adaptation and the mortality effects of temperature across US climate regions. Gasparrini, A. et al. Mortality risk attributable to high and low ambient temperature: a multicountry observational study. The burden of heat-related mortality attributable to recent human-induced climate change. Lee, J. Y. et al. in Climate Change 2021: The Physical Science Basis (eds Masson-Delmotte, V. et al.) Ch. Eyring, V. et al. Overview of the Coupled Model Intercomparison Project Phase 6 (CMIP6) experimental design and organization. The Scenario Model Intercomparison Project (ScenarioMIP) for CMIP6. Callahan, C. W. Replication materials for ‘Increasing risk of mass human heat mortality if historical weather patterns recur'. We thank members of the Environmental Change & Human Outcomes and Climate & Earth System Dynamics groups at Stanford University for helpful feedback. We thank the Stanford Doerr School Center for Computation and Stanford Research Computing Center for providing computational resources that contributed to our results. We acknowledge funding support from Stanford University. Present address: Paul H. O'Neill School of Public & Environmental Affairs, Indiana University, Bloomington, IN, USA Present address: Frank Batten School of Leadership and Public Policy, University of Virginia, Charlottesville, VA, USA Doerr School of Sustainability, Stanford University, Stanford, CA, USA Christopher W. Callahan, Jared Trok, Noah S. Diffenbaugh & Marshall Burke Center on Food Security and the Environment, Stanford University, Stanford, CA, USA Andrew J. Wilson, Sam Heft-Neal & Marshall Burke School of Public Health, University of California San Diego, La Jolla, CA, USA National Bureau of Economic Research, Cambridge, MA, USA Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar provided feedback on the analysis and interpretation of results. wrote the first draft of the paper with all authors providing feedback. Correspondence to Christopher W. Callahan. The authors declare no competing interests. Nature Climate Change thanks Qingchun Guo, Mónica Rodrigues and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Each plot shows temperatures anomalies from June through August, calculated as the population-weighted mean across all European subnational regions for which we have mortality data. Anomalies are calculated with respect to each region and day of year. Gray shading shows the periods that we define as each event. Panel (a) shows the July 1994 event, panel (b) shows the August 2003 event, panel (c) shows the July 2006 event, panel (d) shows the June 2019 event, and panel (e) shows the August 2023 event. Time series of observed (from E-OBS; black solid line), baseline without warming or heat waves (black dashed line), and counterfactual event (red colored lines) temperatures across Europe. Europe-wide temperatures are calculated as the population-weighted average across all subnational regions for which we have temperature data. Gray shading denotes the periods we define as the ‘events'; these dates are originally defined using Europe-wide temperature anomalies (Extended Data Fig. 1) but are shown here for clarity. Panel (a) shows the July 1994 event, panel (b) shows the August 2003 event, panel (c) shows the July 2006 event, panel (d) shows the June 2019 event, and panel (e) shows the August 2023 event. Colored lines show average counterfactuals and shading shows 95% confidence intervals across 25 combinations of GCMs and random seeds. Each panel shows the regional mortality rate, in deaths per 100,000 population, in the peak week of each counterfactual heat wave at 3 °C. Peak weeks are defined as the week of maximum Europe-wide excess deaths (that is, maximum point in Fig. White regions are those for which we do not have population or mortality data. Maps created with Cartopy v0.24.0 with shapefile boundaries from Eurostat (https://ec.europa.eu/eurostat/web/gisco/geodata/statistical-units/territorial-units-statistics) under a Creative Commons license CC BY 4.0. Red bars show peak weekly mortality from each set of meteorological conditions (that is, the peaks of the curves in Fig. Bar widths show mean projection and error bars show 95% range. Gray shading shows the deciles of Europe-wide weekly confirmed COVID-19 deaths. For example, the darkest gray shading shows the range of the top 10% of weeks of COVID-19 deaths, the second-to-darkest shading shows the range of the top 10–20% of weeks, and so on. Mortality at varying global temperature levels for each illustrative extreme heat event. Mortality with and without adaptation for each event. Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. et al. Increasing risk of mass human heat mortality if historical weather patterns recur. Version of record: 18 November 2025 Anyone you share the following link with will be able to read this content: Sorry, a shareable link is not currently available for this article. Provided by the Springer Nature SharedIt content-sharing initiative Sign up for the Nature Briefing: Anthropocene newsletter — what matters in anthropocene research, free to your inbox weekly.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.nature.com/articles/d41586-025-03349-1'>Introducing the j-metric: a true measure of what matters in academia</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.nature.com', 'title': 'Nature'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-11-18 11:30:12
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). More than half a century ago, information scientist Derek De Solla Price observed that the scientific literature was growing exponentially, doubling every 10–15 years1. Little did he know that this observation would spawn not just a field of study, but an entire industry devoted to counting, measuring, weighing and indexing every aspect of academic output2. Today, the modern academic doesn't just publish — they generate metrics. Ultimately, they produce ‘units of assessment', according to the UK Research Assessment Framework (REF), which the United Kingdom uses to allocate £2 billion (US$2.7 billion) in public research funding across its universities. And they certainly don't read any more — who has time when there are metrics to massage? Oh, sweet summer child, to quote a popular line from Game of Thrones. Within a decade, the h-index had metastasized across disciplines. Search committees began sorting candidates by h-index; promotion committees set h-index thresholds; graduate students started checking their h-indices with the frequency and anxiety typically reserved for checking a dating app. But why stop at one number when you could have dozens? The Leiden Manifesto5 actually had to remind us that “quantitative evaluation should support qualitative, expert assessment” — a bit like reminding people that food should be chewed before swallowing. Naturally, these metrics are justified as ensuring accountability to taxpayers, who surely lie awake at night wondering about h-indices rather than, say, whether scientists have cured cancer or explained consciousness. This captures what truly matters in academic work: physical heft. I call it the j-index, and its calculation is refreshingly straightforward: No longer must we worry about citation cartels (in which authors cite each others' publications to boost citation counts) or gaming the system through self-citation. The j-index is immune to such manipulation — unless the books are printed on heavy paper stock, which should be discouraged through strict guidelines on acceptable paper weights. This is an article from the Nature Careers Community, a place for Nature readers to share their professional experiences and advice. Subscribe to Nature Briefing: Careers, an unmissable free weekly round-up of help and advice for working scientists. Kulczycki, E. The Evaluation Game: How Publication Metrics Shape Scholarly Communication (Cambridge Univ. Publishing nightmare: a researcher's quest to keep his own work from being plagiarized How ChatGPT and other AI tools could disrupt scientific publishing On the move: why PhD students study abroad in 2025 Researching sustainable food production, with help from the cows Could China's cautious new research strategy stifle its science-leadership ambitions? ‘Godfather of AI' becomes first person to hit one million citations Influential list of highly cited researchers now shuts out more scientists: here's why The US government shutdown is over: what's next for scientists Pressure to publish is rising as research time shrinks, finds survey of scientists China should undertake more risky research to close the Nobel gap Job Title: Associate or Senior Editor, Nature Methods Location: New York, Jersey City, Shanghai, or Beijing – Hybrid working pattern Deadline: Dece... Publishing nightmare: a researcher's quest to keep his own work from being plagiarized How ChatGPT and other AI tools could disrupt scientific publishing An essential round-up of science news, opinion and analysis, delivered to your inbox every weekday. Sign up for the Nature Briefing newsletter — what matters in science, free to your inbox daily.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.nature.com/articles/d41586-025-03713-1'>Google DeepMind won a Nobel prize for AI: can it produce the next big breakthrough?</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.nature.com', 'title': 'Nature'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-11-18 11:27:56
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). An abstract metal sculpture dominates the central space at Google DeepMind's London headquarters. Then Hassabis set his sights even higher: in 2019, he told colleagues that his goal was to win Nobel prizes with the company's AI tools. Chemistry Nobel goes to developers of AlphaFold AI that predicts protein structures Chemistry Nobel goes to developers of AlphaFold AI that predicts protein structures AlphaFold is just one in a string of science successes that DeepMind has achieved over the past decade. When he co-founded the company in 2010, Hassabis, a neuroscientist and game developer, says his aim was to make “a world-class scientific research lab, but in industry”. Establishing an AI ethics board was a condition of the firm's agreement to be acquired by Google in 2014 for around US$400 million, according to media reports. “We're applying AI to nearly every other scientific discipline now,” says Hassabis. But the climate for this marriage of science and industry has changed drastically since the release of ChatGPT in 2022 — an event that Hassabis calls a “wake-up moment”. The arrival of chatbots and the large language models (LLMs) that power them led to an explosion in AI usage across society, as well as a scramble by a growing number of well-funded competitors to achieve human-level artificial general intelligence (AGI). Google DeepMind is now racing to release commercial products — including iterations of the firm's Gemini LLMs — almost weekly, while continuing its machine-learning research and producing science-specific models. The acceleration has made doing responsible AI harder, and some staff are unhappy with the firm's more commercial outlook, say several former employees. At Google DeepMind's slick headquarters in London's King's Cross technology hub, gleaming geometric sculptures and the smell of espresso hang in the reception hall. It's a far cry from the humble origins of the company, which sought to build general AI systems by melding ideas from neuroscience and machine learning. “They were absolutely just super geniuses,” says Joanna Bryson, a computer scientist and researcher in AI ethics at the Hertie School in Berlin. The laboratory pioneered the deep-learning AI technique, which uses simulated neurons to learn associations in data after studying real-world examples, as well as reinforcement learning, in which a model learns by trial, error and reward. Protein folding ticked a crucial box for Hassabis: it is a ‘root node' problem that, once solved, opens up branches of downstream research and applications. Today, a spin-off from DeepMind, Isomorphic Labs, is seeking to use AlphaFold in drug discovery. And DeepMind's AlphaFold database of more than 200 million protein-structure predictions has been used in a range of research efforts, from improving bee immunity to disease in the face of global population declines to screening for antiparasitic compounds to treat Chagas disease, a potentially life-threatening parasitic infection4. Science is not just a source of problems to solve; the firm tries to approach all of its AI development in a scientific way, says Pushmeet Kohli, who leads the company's science efforts. Staff members at many other AI firms are more like engineers, applying ingenuity but not doing basic discovery, says Jonathan Godwin, chief executive of the AI firm Orbital Materials in London, who was a researcher at Google DeepMind until the end of 2022. John Jumper and Pushmeet Kohli speak to researcher Olaf Ronneberger in the DeepMind offices.Credit: Alecsandra Dragoi for Nature But replicating the success of AlphaFold will be tough: “Not many scientific endeavours work like that,” says Godwin. Google DeepMind is throwing its resources at several problems for which it thinks AI could speed development, and which could have “transformative impact”, says Kohli. These include weather forecasting5 and nuclear fusion, which has the potential to become a clean, abundant energy source. The company picks projects through a strict selection process, but individual researchers can choose which to work on and how to tackle a problem, he says. AI models that work on such problems often require specialized data and researchers to program knowledge into them. One project that shows promise, says Kohli, is AlphaGenome, which launched in June as an attempt to decipher long stretches of human non-coding DNA and predict their possible functions6. But the challenge is harder than for AlphaFold, because each sequence yields multiple valid functions. Materials science is another area in which the company hopes that AI could be revolutionary. Materials are hard to model because the complex interactions of atomic nuclei and electrons can only be approximated. Learning from a database of simulated structures, DeepMind developed its GNoME model, which in 2023 predicted 400,000 potential new substances7. Now, Kohli says, the team is using machine learning to develop better ways to simulate electron behaviour, ones that are learnt from example interactions rather than by relying on the principles of physics. The end goal is to predict materials with specific properties, such as magnetism or superconductivity, he says. “We want to see the era where AI can basically design any material with any sort of magical property that you want, if it is possible,” he says. John Jumper and Pushmeet Kohli in the headquarters building.Credit: Alecsandra Dragoi for Nature Google DeepMind has a dedicated committee on responsibility and safety that works across the company and is consulted at each major stage of development, says Anna Koivuniemi, who runs its ‘impact accelerator', an effort to scour society for areas in which AI could make a difference. Committee members stress-test the idea to see what could go wrong, including by consulting externally. “People don't really want random videos of themselves being generated and put on a social-media network; they want limitless energy or diseases being cured,” he says. But DeepMind now has company in the quest to use AI for science. For AI companies and researchers, OpenAI's 2022 release of ChatGPT changed everything. Chemistry Nobel goes to developers of AlphaFold AI that predicts protein structures AI tools are designing entirely new proteins that could transform medicine A Chinese AI model taught itself basic physics — what discoveries could it make? A Chinese AI model taught itself basic physics — what discoveries could it make? Chemistry Nobel goes to developers of AlphaFold AI that predicts protein structures AI tools are designing entirely new proteins that could transform medicine An essential round-up of science news, opinion and analysis, delivered to your inbox every weekday. Sign up for the Nature Briefing newsletter — what matters in science, free to your inbox daily.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.scientificamerican.com/article/why-a-little-heartbeat-irregularity-can-be-good-for-you/'>Fitness Watches Track Heartbeat Variability, and More Change Is Healthier Than Less</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.scientificamerican.com', 'title': 'Scientific American'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-11-18 11:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Heart Rate Irregularity Sounds Bad, but Here's Why You Want a Bit of It Milliseconds of variability, now detected by fitness watches, can improve well-being Earlier this year I got an Oura ring to track the state of my health. Soon I was obsessing over my sleep and activity scores. The reports were generally positive except for one: heart rate variability, or HRV. That's a measure of how much the time between heartbeats changes. Every morning, in bright red, my ring's app singled out HRV and told me: “Pay attention.” That didn't sound good, although I had no idea why. Before wearable fitness watches, rings and bracelets became so common and started including HRV as a data point, I had never heard of it. “I don't think HRV is used in day-to-day clinical medical practice,” says Bryan Wilner, an electrophysiologist at the Baptist Health Miami Cardiac and Vascular Institute. “But it's gained a lot more popularity in regular consumers with these noninvasive monitors.” And as reams of data are collected from hundreds of thousands of people like me, the measure has the potential to become a far more significant tool for diagnosis and therapy, although it isn't there yet. If you're enjoying this article, consider supporting our award-winning journalism by subscribing. The average person's heart rate is between 60 and 100 beats per minute when they're at rest, but it fluctuates all day long. Standing up after lying down changes your heart rate, as does jogging or fielding stressful questions at work. The time between beats changes, too, and that's what HRV captures. Unlike arrhythmias, which are potentially dangerous disruptions in the heart's electrical activity, HRV measures the very slight variation in periods—a matter of milliseconds—between consecutive heartbeats, tracked over a few minutes or longer. Stress, anxiety, high blood pressure, inadequate sleep, dehydration and new medicines are among the many things that can lower HRV. In people recovering from heart attacks or living with heart failure, low HRV is associated with a higher risk of death and further illness. “There is no specific number for what's bad, what's good,” says Attila Roka, an electrophysiologist at the CHI Health Clinic Heart Institute and an assistant professor at Creighton University in Omaha. Anywhere from roughly 20 to 70 milliseconds is considered within normal range. The measure is highly individual, although it generally goes down with age. Mine hovered around an unusual 14 for weeks, and that's why my ring alerted me. Cutting-edge pacemakers and defibrillators monitor it, too, and experts are investigating the use of HRV with heart disease patients to predict the onset of atrial fibrillation (Afib) in time to prevent it, says Pamela Mason, chief of cardiac electrophysiology at UVA Health in Virginia. Afib is an irregular, rapid heart rhythm that can lead to blood clots and other problems. Physicians also use Holter monitors, small devices that patients wear on their chests for a few days, to capture a full picture of cardiac activity, including HRV. Devices like Apple watches and Oura rings work by looking at pulse fluctuations rather than electrical heart signals. “HRV is most powerful when you're measuring it over several weeks and can see a graphic trend on how it's being affected by everything that's going on in your life.” HRV might one day be used to assess mental health. Conditions such as depression and bipolar disorder are likely to be associated with dysregulated nervous system activity. Even among people without medical or psychiatric disorders, studies have found a link between decreasing parasympathetic activity and emotional upset, suggesting HRV tracks psychological states. Low HRV, in relatively healthy people, does have some remedies. For people like me, Mason's advice is to not obsess. Instead consider what you could do to take better care of yourself. Prodded by red HRV alerts, I drank more water and consumed less caffeine, went to bed earlier, and engaged in vigorous exercise more regularly. Lydia Denworth is an award-winning science journalist and contributing editor for Scientific American. If you enjoyed this article, I'd like to ask for your support. Scientific American has served as an advocate for science and industry for 180 years, and right now may be the most critical moment in that two-century history. If you subscribe to Scientific American, you help ensure that our coverage is centered on meaningful research and discovery; that we have the resources to report on the decisions that threaten labs across the U.S.; and that we support both budding and working scientists at a time when the value of science itself too often goes unrecognized. In return, you get essential news, captivating podcasts, brilliant infographics, can't-miss newsletters, must-watch videos, challenging games, and the science world's best writing and reporting. There has never been a more important time for us to stand up and show why science matters.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.nature.com/articles/d41586-025-03721-1'>Beyond growth — why we need to agree on an alternative to GDP now</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.nature.com', 'title': 'Nature'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-11-18 10:41:23
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). Robert Costanza is a professor of ecological economics at the Institute for Global Prosperity, University College London, UK. Joseph Eastoe is a PhD candidate at the Institute for Global Prosperity, University College London, UK. Ida Kubiszewski is an associate professor at the Institute for Global Prosperity, University College London, UK. Schoolchildren in Bhutan, which developed a gross national happiness index to measure the well-being of its citizens. Gross domestic product (GDP) was never designed to be a measure of societal well-being. However, since about 1950, which some call the Anthropocene era, ecological limits, inequality and declining social cohesion have restricted further improvements in well-being. Measuring and modelling what truly matters, not just market transactions, is now essential. Processes are under way to develop indicators that move beyond GDP. In May, the United Nations secretary-general António Guterres appointed a High-Level Expert Group to develop such measures, with a focus on balancing economic, social and environmental dimensions of well-being. This initiative builds on the 2015 Sustainable Development Goals (SDGs): target 19 of SDG17 commits governments to adopt beyond-GDP metrics by 2030. Overcoming decades of structures built around GDP is difficult. Nonetheless, several governments, including those of New Zealand, Scotland, Wales and Bhutan, have experimented with alternatives to GDP1 (see also go.nature.com/3ktuvhv). Others should follow suit, but it will be a steep climb. Shifting all societies from a narrow focus on GDP growth to a comprehensive understanding of the multiple factors that support well-being and prosperity, and of how these factors interact over space and time, demands consensus on another approach2. Over the past seven decades, researchers and institutions have proposed hundreds of alternatives to GDP. Paradoxically, this proliferation has helped GDP to keep its privileged status, by creating the impression that there is little agreement on what sustainable and inclusive well-being means or how to measure it. In fact, there is much that these approaches do agree on. Here, we identify areas of common ground and propose four ways forward: universally adopting the goal of sustainable and inclusive well-being; establishing agreed metrics to evaluate progress towards this goal; developing models that incorporate the drivers and dynamics of well-being; and addressing institutionalized societal ‘addictions' that reinforce unsustainable behaviours. The concept of sustainable and inclusive well-being — encompassing the well-being of all people and of the ecosystems that sustain life — is emerging as a widely accepted overarching policy goal that can provide common ground for beyond-GDP metrics, models and policies. By assigning a central role to natural ecosystems and planetary boundaries, the concept acknowledges that human prosperity depends on healthy ecological systems. It also demands that human societies prevent significant harm to other species, protect the rights of future generations and guarantee that all people today have access to essential resources, services and participatory forms of decision-making. Employment is a core factor in many indicators of well-being.Credit: Elen Marlen/Getty A 2009 report on the measurement of economic performance and social progress, chaired by economist Joseph Stiglitz, laid the groundwork for moving beyond GDP3. Full international enforcement should follow; however, this might depend on a more-receptive US administration and stronger demand from civil society. Converging on an approach to evaluating sustainable and inclusive well-being is important if policymakers and organizations such as the UN are to embed these measures into official reporting and budgetary processes. Although more than 200 beyond-GDP indicators have been proposed, they share many similarities. These 19 core factors are common to most beyond-GDP indicators5. Researchers and policymakers, led by an international convening body such as the UN, should now establish a core set of around 20 components to serve as the backbone of national statistical reporting and UN frameworks. The expert group has committed to an inclusive process that invites contributions from all stakeholders. After this, intergovernmental processes will consider their recommendations. To build a better world, stop chasing economic growth To build a better world, stop chasing economic growth Other efforts include the UN System of Environmental Economic Accounting and the UN System of National Accounts 2025 initiative, which are revising economic accounts to include more well-being components. The UN can also play a central part in strengthening institutional capacity and securing stable funding to support the regular production of national estimates. The world is awash with big data, so directing even a fraction of these resources towards measuring sustainable and inclusive well-being would enhance global monitoring and policy effectiveness. GDP has retained its dominance partly because it is embedded in the models that underpin national accounts and policy analyses. For example, the input–output model developed by economist Wassily Leontief6 tracks monetary flows across sectors and into ‘final demand', defined as GDP. Why we need to measure people's well-being — lessons from a global survey Why we need to measure people's well-being — lessons from a global survey Mainstream macroeconomic models also place growth at the centre of policy evaluation. For example, standard computable general equilibrium models assume a high degree of substitutability among factors of production, implying that labour or technology can largely replace natural resources. Most importantly, they are optimization models that are intended to maximize a single objective — GDP — rather than being designed to evaluate policies against multiple goals, as is required for sustainable and inclusive well-being. Young people at a cultural arts centre in Kibera, an informal settlement in Nairobi, perform a traditional African dance.Credit: Eva-Maria Krafczyk/dpa/Alamy Hoekstra, R. Replacing GDP by 2030: Towards a Common Language for the Well-being and Sustainability Community (Cambridge Univ. An Empirical Application of Equilibrium Analysis (Harvard Univ. Costanza, R. Addicted to Growth: Societal Therapy for a Sustainable Well-being Future (Routledge, 2022). Miller, W. R. & Rollnick, S. Motivational Interviewing: Helping People Change 3rd edn (Guilford, 2012). To build a better world, stop chasing economic growth Why we need to measure people's well-being — lessons from a global survey Extending the Sustainable Development Goals to 2050 — a road map The UK must not lose its focus on science and innovation The TrumpRx website won't slash drug prices — but this will Carbon credits are failing to help with climate change — here's why Leaders at COP30 should promote solar and wind power over mega-dams Bill Gates's climate comments are a dangerous distraction Distorted representations of age and gender are reflected in AI models Job Title: Associate or Senior Editor, Nature Methods Location: New York, Jersey City, Shanghai, or Beijing – Hybrid working pattern Deadline: Dece... To build a better world, stop chasing economic growth Why we need to measure people's well-being — lessons from a global survey Extending the Sustainable Development Goals to 2050 — a road map An essential round-up of science news, opinion and analysis, delivered to your inbox every weekday. Sign up for the Nature Briefing newsletter — what matters in science, free to your inbox daily.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.nature.com/articles/s41467-025-65586-2'>High-efficiency atmospheric water harvesting enabled by ultrasonic extraction</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.nature.com', 'title': 'Nature'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-11-18 10:34:38
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript. Nature Communications volume 16, Article number: 9947 (2025) Cite this article Atmospheric water harvesting technology, which extracts moisture from ambient air to generate water, is a promising strategy to realize decentralized water production. However, the prohibitively high energy consumption of heat-induced evaporation process of water extraction hinders the technology deployment. Here we demonstrate that vibrational mechanical actuation can be used instead of heat to extract water from moisture harvesting materials, offering about forty-five-fold increase in the extraction energy efficiency. We report the energy consumption for water extraction below the enthalpy of water evaporation, thus breaking the thermal limit of the energy efficiency inherent to the state-of-the-art thermal evaporation and making atmospheric water harvesting technology economically feasible for adoption on scale. Many communities worldwide are located in arid climate zones and experience a shortage of fresh water resources, which severely inhibits their land development and creates harsh humanitarian conditions for their populations1. More than half of Mexico's national territory lies in the arid and semi-arid climate zones, including the Chihuahuan and Sonoran deserts, which extend northward into the United States. The Colorado River is drying up at an alarming rate, putting these areas at even higher risk of freshwater shortages. Similarly, in southern Ukraine, desertification of thousands of hectares of fertile steppe land may occur following the breach of the Kakhovka Dam by the Russian army in 2023, with potentially grave consequences for the world food supply. The situation is even more dire in the Middle East, where only three major rivers supply the vast region with fresh water, and where most land areas are arid. In many cases, the climate problems are exacerbated by the economic and security-related ones, which make the costs of the industrial installations for water purification prohibitive for communities in need2,3. Fortunately, the Earth's atmosphere provides a vast resource of fresh water. Fog harvesting has been ubiquitously practiced by plants, animals, and humans throughout history4,5,6,7,8,9,10. However, the majority of the 12,900 billion tons of fresh water stored in the atmosphere11 is not available as fog, which only forms when the relative humidity (RH) of air approaches 100%. Accordingly, there is a need for atmospheric water harvesting (AWH) technologies that can operate in arid or semi-arid climates or in regions where large-scale installations are impractical due to economic or security reasons12,13,14,15,16,17,18. These typically fall into two major categories, including (i) active refrigeration technology19,20 to cool air below the dew point and promote condensation20,21,22,23, and (ii) sorption-desorption technology that employs porous hydrophilic sorbents to collect moisture from air, followed by water extraction via the heating-induced evaporation-condensation process12,21,24,25. However, the former technology is hard to scale down to realize affordable decentralized water production, while the latter one, in its current state of development, exhibits prohibitively high energy consumption associated with the heat-driven process of water desorption from AWH materials. The temperature needed to release the captured water from a sorbent can be as high as 160 °C for conventional desiccants such as silica gel, zeolite, and activated alumina26,27,28. Desorption temperatures of other recently-developed sorbents, including hydrogels15, metal-organic frameworks (MOFs)12,21, and anhydrous and hydrated salt couples13 are in the 60 °C–80 °C range, which makes water release an energy-intensive process29,30. Furthermore, all the AWH prototypes demonstrated to date exhibit at least an order of magnitude higher energy consumption than the predicted thermodynamic limit of about 2MJ/kg at 30% RH29. This is a major bottleneck of the sorption-desorption AWH technology, which limits its contribution to the United Nations' 6th Sustainable Development Goals (SDG6)31. The ongoing efforts to increase water harvesting capability and reduce the energy consumption mostly focus either on engineering more efficient sorbents (i.e., capable of sorbing higher weight of water per gram of material)32,33 or/and on designing autonomous AWH systems that can utilize solar energy12,13,21,33. Since the energy consumption occurs during the desorption process, finding alternative technologies to replace heat-driven evaporation is the key to achieving a breakthrough in the AWH technology feasibility. Recent studies showed that re-engineering the sorbent structure to facilitate water evaporation at lower temperatures, e.g., by incorporating a secondary network of reconfigurable phase-change polymers30, or by combining heating with other external stimuli, such as sunlight or laser illumination can increase the evaporation efficiency, even beyond the thermodynamic limit34. Here, we propose an alternative method of moisture extraction, which uses vibrational mechanical actuation enabled by piezoelectric materials (Fig. S1) to extract water from AWH sorbents. We draw inspiration from prior studies that used piezoelectric actuators35 and Si-based Micro-Electro-Mechanical-system (MEMS)36 for atomization of liquids. We show that this method offers at least a forty-five-fold reduction of the energy needed to extract the same mass of water as the standard evaporation-condensation technique. While demonstrated here for hydrogels, the technique is very general and may be used with other sorbents, including MOFs, superabsorbent fibers and textiles, salts, and desiccants. Since the alternative technology is not based on the heating-induced evaporation, its efficiency is not bound by the thermal limit derived for the conventional desorption process, offering promise for further efficiency improvements. a The ultrasonic extractor comprises a PZT-crystal piezoelectric transducer and a stainless-steel (SS) porous membrane through which the desorbed water is extracted from a sorbent material under vibrational actuation. The black dashed box shows the transducer structure, including an Ag-coated PZT ring topped with a thin layer of water-resistant resin attached to the SS membrane and encased in a silicone elastomeric ring. The red dashed box shows the structure of the micro-machined nozzles on the SS membrane, which assist in directing the flow of water out of the device. b The diagram of the system assembly and sorption/desorption stages of the moisture harvesting process utilizing a sorbent material and a micro-actuator. The top Ag layer and the SS membrane are connected to the electrode wires. c A CAD model of the system custom-designed to collect the moisture extracted from the sorbent by the actuator. d A photograph of the FDM-printed device prototypes with hydrogel sorbents in the process of moisture harvesting from ambient air. The inset shows a close-up view of the collected water droplets on the glass enclosure. e Efficiency values of the moisture extraction achieved in this study compared with the state-of-the-art literature data (here, s = short actuation period; l= long actuation period; s_m = multiple repetitive cycles of short actuation periods). Scale bars: 50 µm (a); 15 mm (d). Figure 1a illustrates a piezoelectric-ceramic-based single-head ultrasonic actuator used in this study for water extraction from several AWH hydrogels (AWH-Hs). High-voltage-driven lead zirconate titanate (PZT) ring converts applied electrical power into the in-plane displacement of the ring, which in turn causes out-of-plane mechanical oscillation of the steel mesh membrane clamped to the ring. Mechanical oscillation of the membrane is accompanied by the Joule heating caused by ferroelectric hysteresis loss of the PZT material when driven at high frequency37, as illustrated in Fig. Here, we show that a synergetic impact of the mechanical actuation and device heating facilitates moisture extraction from AWH-Hs, reduces the extraction time, and increases the system energy efficiency. The first prototype device utilizing this water extraction method is shown in Fig. 1e, we plot the energy efficiency of water extraction \(\eta\), which is defined as a ratio of the enthalpy of water vaporization \({h}_{{lv}}\) (\({h}_{{lv}}=2.257{M}{\rm{J}}/{\rm{kg}}\) at 100 °C) and the energy consumption of the device needed for the extraction of a unit mass of water from a sorbent, \(E\) [MJ/kg]: \(\eta={h}_{{lv}}/E\)29,38,39 (see Supplementary Note 4 and Supplementary Table 4). In an ideal thermal process, where the enthalpy of desorption is identical to the enthalpy of vaporization of water, all the heat provided to the system is used for water evaporation, i.e., \(E={h}_{{lv}}\). In this work, we refer to this ideal thermal process with \(\eta=100\%\) as the thermal limit. In any real thermal water release process, the heat provided is used not only to evaporate water, but also to sensibly heat the system and sorbent, and is partially lost to the ambient, leading to \(\eta < 100\%\). Conversely, an efficient non-thermal extraction method (such as, e.g., vibrational actuation) can have a specific energy consumption lower than the enthalpy of vaporization of water, \({h}_{{lv}}\). Then, the energy efficiency of the water release process can in principle exceed 100%. Figure 1e compares the efficiency of our device operated with a polyacrylamide and lithium chloride (PAM-LiCl) hydrogel sorbent with that of the-state-of-the-art AWH devices40,41,42,43,44. The extraction efficiency values plotted in Fig. 1e for different systems account for the specific heat of both water and other solids used in the system (i.e., sorbent materials, heaters, enclosures, etc.) Each of the devices in Fig. 1e represents a single-stage system without heat recovery, and thus these efficiency values are all less than 100%. Our device shown in Fig. 1a–d demonstrated energy efficiency of almost 428%, exceeding the state-of-the-art efficiency of 9.5%39,45 by a factor of ~45 (Fig. In the following, we analyze the performance of the system operated with hydrogel-based sorbents, but the concept is much broader, encompassing a variety of AWH materials and actuator types, and showing a potential to further increase the efficiency. We synthesized three types of PAM-LiCl AWH hydrogels (see Methods), which incorporate lithium (Li⁺) and chloride ions (Cl⁻) as essential elements for their ability to adsorb water molecules from atmosphere (Fig. Hydrogels had the same salt and polymer content, but different amounts of N,N'-methylenebisacrylamide (MBA) crosslinker, and thus exhibited different crosslinking densities. Hydrogels labeled HG-A, HG-B, and HG-C had crosslinker-to-monomer mass ratios of 0.1, 0.5, and 10 mg/g, respectively. HG-A had very low rigidity, while HG-C could stand on its own outside a Petri dish without collapsing (Fig. As a result, HG-A hydrogel demonstrated greater resistance to tearing when manually stretched, in contrast to the more rigid HG-C, which can be torn easily (Fig. The differences in the hydrogels micro-structure and surface morphology are revealed by the scanning electron microscope (SEM) images, with HG-A exhibiting a low-density structure (Fig. We also included in our study a commercial hydrogel (a cross-linked glycerol- 2-Acrylamido-2-methylpropanesulfonic acid sodium salt hydrogel), and labeled it HG-M. a A schematic of the structure of a PAM-LiCl hydrogel with solvated lithium (Li⁺) and chloride (Cl⁻) ions diffused into a polymer network. b Photographs of synthesized PAM-LiCl hydrogels inside and outside a Petri dish, illustrating the contrast between the samples with the highest (HG-A) and the lowest (HG-C) storage moduli. c Optical images of the HG-A and HG-C hydrogels under manual stretching. d,e SEM images of HG-A (d) and HG-C (e) samples. f Mechanical properties of hydrogels measured at 25 °C and with an oscillatory load at 6.3 rad/s. g Water uptake (g/g) of hydrogels at four different RH levels at 25 °C. Scale bars: 12 mm (b); 24 mm (c), 200 µm (d); 300 µm (e). The four types of AWH-Hs were compared by their elastic storage moduli (see Methods), which provide a measure of how much energy is stored in the material when it is subjected to a periodically oscillating load, and their loss moduli, which measure the material's ability to dissipate applied stress through heat (Fig. The progressively higher storage moduli of hydrogels with higher MBA content validate the strategy of engineering sorbents with desired mechanical properties by varying the density of chemical crosslinks47. All the PAM-LiCl sorbents exhibited loss moduli lower than their storage moduli, and thus the resultant phase shift between the mechanical deformation and the sorbent material response, \(\tan \delta=G{\prime} {\prime} /G{\prime} < 1\). This indicates the elasticity and ability of these materials to bounce back to their original shape as long as the applied deformation is below their yield point48. These data are similar to those previously reported for salt-free PAM hydrogels49, suggesting that the high salt content does not play a major role in their mechanical properties, which are mostly controlled by the polymer crosslinking density. In turn, the commercial hydrogel (HG-M) exhibited higher values of storage and loss moduli as well as \(\tan \delta\) value, thus demonstrating higher mechanical strength than PAM-LiCl AWH-Hs, but slightly lower elasticity. Figure 2g shows that all three PAM-LiCl AWH-Hs exhibit high water uptake in different environments, from arid to very humid, between 15 and 85% RH (see Supplementary Movie 3 for water harvesting at ~15% RH). This is consistent with recent reports on PAM-based hydrogels and hygroscopic PAM-LiCl composite hydrogels exhibiting a large capability to capture moisture30,32. Water harvesting capacity at the same RH level is similar for all the PAM-LiCl AWH-Hs regardless of their crosslinking density32,50,51. In contrast, the commercial HG-M did not demonstrate any water sorption capability at low RH (15 and 30%). The goal of the study is to use a piezoelectric actuator to generate and transmit a pressure wave into the AWH hydrogels to facilitate water extraction. To optimize the actuator geometry and performance, several candidate devices were evaluated. Based on prior literature for water atomization, we targeted a resonance frequency in the 100-160 kHz range35,36,52,53. Four piezoelectric ultrasound transducers with resonance frequencies ranging from ~107–115 kHz to ~165 KHz were designed and analyzed (Supplementary Fig. Three devices had similar geometry but differed by the size of micro-nozzles perforated in their metallic membranes. The fourth device (PZ-D) had a comparatively lower diameter to thickness aspect ratio, ensuring higher ( ~ 165KHz) resonance frequency (see Supplementary Table 1). All the four devices demonstrated comparable piezoelectric coefficients (\({d}_{33}=\sim 435-440{\rm{pC}}/{\rm{N}}\)), which were measured using “quasi-static” or “Berlincourt” method, employing a static force sensor and piezoelectric meter (see Methods and Supplementary Fig. The piezoelectric charge coefficient, denoted as \({d}_{33}\), is determined by applying a unit stress in the direction 3 (i.e., z-axis) that induces polarization in direction 3 (i.e., in the same direction as the polarization of the ceramic element). All four devices were designed such that the diameter of the piezoelectric ceramic ring was at least ten times larger than its thickness (\(d > 10t\)) to maximize their displacement amplitude54. The efficiency of the piezoelectric devices in converting electric energy into mechanical energy was evaluated by their effective electromechanical coupling coefficients (\({k}_{{\rm{eff}}}\))55,56, which were found to be around 0.19 for the low-frequency devices and 0.17 for the high-frequency device (Supplementary Fig. The rest of the electrical power is dissipated as heat, leading to some temperature increase of the actuator and AWH-H sorbents. First, the nozzle size was varied to improve water extraction through the membrane without degrading the resonant behavior of the actuator, as resonance frequencies of piezoelectric devices are sensitive to variations in the membrane mass and stiffness57. PZ-A, PZ-B, and PZ-C devices were designed to each have 1000 nozzles with diameters of 10, 70, and 100 µm, respectively (Supplementary Fig. Figure 3a compares the water conductance through the membranes with different nozzle sizes measured using a forward-osmosis (FO) configuration (see Methods and Supplementary Fig. The water transport rate through the PZ-C membrane was found to be the highest, owing to its larger nozzle size. a The effect of the increased nozzle size on water conductivity through the porous membrane as determined by a forward-osmosis experiment. Here and in (b,c), the data for membranes in PZ-A, PZ-B, and PZ-C transducers with nozzle sizes of 10, 70, and 100 µm are color-coded as orange, pink, and blue, respectively. PZ-D actuator had the same nozzles as PZ-A. b,c Deflection amplitudes (b) and corresponding RMS velocities (c) of the four transducers subjected to a sinusoidal input signal at 1 Vpp measured at resonant frequencies of ~110 KHz for PZs A, B, and C, and ~165 kHz for PZ-D. d Experimental modal analysis of the porous membrane attached to the ring of PZ-C transducer at 1 Vpp actuation. e–g The deflection maps across the PZ-C membrane at frequencies of 110 KHz (e), 89 (f), and 115 KHz (g) measured by a PICOSCALE vibrometer under 1 Vpp (0.35 Vrms) sinusoidal signal input. h Simulated (COMSOL Multiphysics®) displacement and velocities of the PZ-C membrane plate under higher voltages. i,j The simulated (i) and measured (j) impedance spectra of the PZ-C actuator. AWH-Hs are actuated by the motion of the free-standing portion of the membrane that is not clamped to the PZT ring (Fig. 1a), and both the magnitude and velocity of its movement need to be maximized for efficient extraction. The diameters of these areas measured 7.8 mm for PZ-A, B, C actuators, and 5 mm for the PZ-D device. Figure 3b compares the maximum displacement amplitudes measured within the nozzle areas (M) of the membranes and the peripheral nozzle-free (P) areas, while Fig. 3c shows the corresponding RMS values of the deflection velocity. The transducers operating at lower frequencies (PZs-A, B, C) exhibit larger amplitude and velocity, both within the nozzle area and the periphery, compared to the higher-frequency device (PZ-D). For all the devices, the displacement amplitudes and velocities are higher in the center than on the periphery, as expected. PZ-C actuator membrane exhibited the largest displacements and RMS velocities. We attribute this to the larger nozzle diameter, which reduced the weight of the membrane, lowered its inertia, and modified its vibrational modes spectrum, leading to better coupling between the piezo oscillations and the membrane vibrations. The resonant spectra of the membranes integrated in the actuators were measured by using a vibrometer at 1 Vpp (Fig. Experimentally mapped vibrational mode profiles of the PZ-C membrane at its three dominant frequencies (89, 110, and 115 KHz) are shown in Fig. S11-S12 visualize spatial amplitude and phase distributions of these vibrational modes. The actuation voltage of 1 Vpp was used for the above measurements to prevent the displacement amplitude over-range, as the vibrometer is not capable of detecting displacements larger than half-wavelength in magnitude (\(\lambda /2=775{\rm{nm}}\)). However, during the desorption process, the device is actuated by a much larger voltage of ~114 Vpp using an amplifier with a high gain to boost the signal strength. To evaluate the displacement and velocity of the PZ-C actuator membrane at its operational voltage, we simulated the device performance via finite-element modeling with the COMSOL Multiphysics software (Fig. Modeling predicts that both the membrane displacement and the speed grow linearly with applied voltage, reaching the values of 111 µm and 77 m/s, respectively, at 70 V. The simulated spectrum of the PZ-C device (Fig. 3i) exhibits a characteristic Fano feature with the resonance (107 KHz) and anti-resonance (109 KHz) frequencies, which is in good agreement with the corresponding spectrum measured experimentally in the fabricated PZ-C device (Fig. The measured spectra for devices PZ-A, PZ-B and PZ-D are shown in Supplementary Fig. The resonance frequency of device PZ-D was measured to be around 170 ± 5 KHz. Finally, our finite-element simulations of the PZ-C membrane oscillations (see Methods) reveal the vibrational mode pattern forming under the piezo actuation and predict the values of M displacement (790 nm) (Supplementary Fig. S14) and corresponding velocity (0.54 m/s) (Supplementary Fig. S15) at 1 Vpp, which is in reasonable agreement (within the order of magnitude) with their experimentally measured counterparts (i.e., 373 nm and 0.18 m/s, respectively). Figure 4a illustrates an actuator, which includes a PZT ring and a membrane and acts both as a mechanical transducer and as a Joule heater. To analyze and optimize the extraction process, the AWH-H samples were soaked in the DI water and placed on top of the membrane (Fig. 4b, c and Supplementary Fig. We first used a commercial hydrogel (HG-M) to evaluate the efficiency of water extraction and to establish an optimum experimental protocol of sorbent actuation. To visually capture the water extraction process, a green laser was focused across the path of the ejected water droplets, and photographs were captured using the burst mode of a digital camera with the shutter speed of 1/30th of a second (Fig. These experiments revealed that—differently from the conventional evaporation-driven extraction process—water is released in the liquid form, although droplets large enough to be captured by our camera are visually observable for only a few seconds after the onset of piezo actuation. a A schematic and a photograph of the actuator, comprising a steel membrane acting as a Joule heater and an ultrasound-generating piezoelectric component (PZT ring). b,c Photographs of an HG-M sample on the actuator and of the water droplets ejecting under stimulation (scale bars 16 mm). d Desorption kinetics measured as a function of the HG-M moisture content (quantified as a total initial weight of the specimen soaked in water). e Desorption kinetics as a function of the sample geometry. f Desorption kinetics as a function of the transducer actuation frequency. g An IR image visualizing the Joule heating of the actuator operating at a 1.5 W power (applying ~114 Vpp) and a 110 KHz frequency. h,i The rate of water extraction and membrane temperature under piezo actuation (h) and Joule heating (i). The energy consumption is calculated and listed for each curve in (d–f) and (h,i). We conducted four series of experiments to evaluate the role of the sorbent size, weight, moisture content, and nozzle size as well as the actuation frequency on the water extraction efficiency (Fig. First, HG-M samples of 3 mm diameter and 1 mm thickness were submerged in DI water for of 30, 60, and 120 s, respectively. The samples were weighed before being positioned in the center of the mesh membrane of a PZ-A actuator (7.8 mm diameter and 10 µm nozzle size). The wet samples having initial weights of 0.06, 0.07 and 0.11 g, respectively, were exposed to piezoelectric stimulation for 10 minutes, and their weight loss is reported in Fig. 4d as a function of time. The heaviest sample exhibited the best performance in terms of energy consumption (9.8 MJ/kg), about 35% lower than 15 MJ/kg value measured for the samples with lower moisture content. We attribute the observed improvement to the better contact between the vibrating mesh membrane and a heavier specimen. Second, we studied the effects of both sorbent mass and geometry by testing specimens of varying sizes under the same actuation protocol. Samples with diameters of 3, 6, and 9 mm and thicknesses of 1 mm were submerged in DI water for 120 s each, and their weight loss kinetics under actuation are reported in Fig. The largest and heaviest ( ~ 0.4 g loaded weight) sample exhibited the lowest energy consumption of 4.8 MJ/kg. The plots in Fig. 4d, e indicate that (i) the energy consumption per unit mass of extracted water does not always correlate positively with the percentage of the sample weight loss under actuation, (ii) higher efficiency is achieved when the sample fully covers the actuator membrane, and (iii) heavier samples with higher moisture content exhibit higher energy efficiency. This suggests that the optimum sample weight (achieved for a certain geometry and moisture content) needs to be found to minimize the energy consumption, as extra-heavy samples can dampen the membrane vibrations, reducing extraction efficiency. Third, we compared the extraction efficiency achieved by using different actuator membrane geometries (Supplementary Fig. As expected, the PZ-C actuator with the nozzle size of ~100 µm demonstrated lower energy consumption (7.7 MJ/kg) than PZ-A (16.6 MJ/kg), while PZ-B actuator with the nozzle size of ~70 µm had performance similar to that of PZ-C. The increased energy efficiency of PZ-C actuator can likely be attributed not only to the higher diffusion rates (Fig. 3a) but also to the larger membrane displacement and higher velocity (Fig. Finally, piezo actuators operating at different frequencies, PZ-C (107 KHz) and PZ-D (165 KHz) with similar nozzle numbers and sizes, were used to extract moisture from HG-M samples of 3 mm diameter and 1 mm thickness, after they were submerged in DI water for 60 s. PZ-D actuator exhibited the highest energy consumption of 25.2 MJ/kg, indicating that the operating frequency plays a very important role in the water release process. For all the experiments in Fig. 4d–i, the piezo actuator was driven by using a miniaturized and portable printed circuit board (PCB) electronic driver system at a constant ~70% duty cycle (defined as the ratio of the time during which the system is in an activated state (ON) and the overall duration of each cycle that comprises a series of ON-OFF cycles). Our modeling predicts that the axisymmetric displacement and velocity in the out-of-plane vibrations of the membrane at an applied voltage of 40 Vrms or ~114 Vpp reach ~60 µm and ~45 m/s, respectively (Supplementary Fig. At the same time, infrared imaging (see Methods) reveals that the actuator can exhibit a temperature rise of >20 °C within 60 s while working at 70% duty cycle and 1.5 W supplied power applying ~114 Vpp (Fig. It returns to the ambient temperature within a comparable time frame after actuation stops (Supplementary Fig. This fast increase in temperature facilitates desorption of water from hydrogels50, and the combined effect of fast temperature rise and hydrogel vibration synergistically drive quick and efficient water release. The rate of water extraction and the energy consumption of the piezo-actuation and Joule heating methods are compared in Fig. Both the Joule heater (a bare stainless-steel membrane) and the piezo actuator were powered with 1.5 W, and the weight loss process of DI water-loaded HG-Ms was measured for a period of 10 min. The samples were actuated for 1 min-long intervals and weighed after each minute, with both the weight loss and its derivative plotted in Fig. The bottom panels of Fig. 4h, i show the temperatures of the membranes measured by K-type thermocouple sensors, which were deliberately kept at the same level by choosing the 1 min-long actuation periods (see Methods). The piezo-actuated specimen regained its original weight within a span of 7 minutes under piezo actuation at 42 °C (Fig. In contrast, the sample subjected to water evaporation via Joule heating did not regain its initial dry weight even after 10 min at 41 °C (Fig. These data also revealed that the piezo-driven extraction consumed a significantly lower amount of energy (7 MJ/kg), a reduction of approximately 74% compared to the Joule-heater-induced evaporation (28 MJ/kg). A piezo actuation duty cycle can be further optimized to mitigate the generation of heat and increase efficiency58. It is important to ensure that the sorbent maintains its structural integrity under a combination of mechanical and heat stimuli during the water extraction process. The inspection of HG-M specimens and the piezo membrane after multiple tests showed no visible damage on the hydrogel and no significant material residue left on the membrane, as evidenced by the SEM image (Supplementary Fig. The very few nozzles that appeared jammed were easily cleared by rinsing the membrane with DI water, thereby enabling its repetitive utilization. Surface topography scans of the membrane also revealed a relatively even terrain (Supplementary Figs. We used a hydrophone to measure the transmittance and attenuation of the ultrasound wave emitted from the actuator (see Supplementary Fig. S23) and passing through the hydrogel55 (Fig. Figure 5b illustrates the signal captured by the hydrophone while it is in contact with the hydrogel when the actuator is driven periodically, ON for 10 s, OFF for 5 s (see also Supplementary Movie 6). These measurements revealed increased acoustic wave attenuation in thicker hydrogel samples (as expected59) and for hydrogels with higher storage moduli (Fig. The HG-C hydrogel, with 100 times higher crosslinker content than HG-A, exhibits a much higher storage modulus and about the same loss modulus (\({G}_{A}^{{\prime} }=1098,{G}_{A}^{{\prime} {\prime} }=240;{G}_{C}^{{\prime} }=2855,{G}_{C}^{{\prime} {\prime} }=241\)), translating into higher attenuation of the ultrasound wave (Fig. HG-M hydrogel demonstrated a similar trend of the output voltage decrease with the increased thickness and stiffness (Supplementary Fig. The COMSOL-simulated 2D image of the actuator-hydrogel system is shown in the inset for HG-A. It shows the high-intensity sound pressure level at the hydrogel-actuator interface, which attenuates away from the actuator surface. These observations are in agreement with prior studies of medical-grade hydrogels60. a A setup for measuring transmittance and attenuation of acoustic waves propagating through hydrogel samples. A sample is placed between the actuator (transmitter) and a sensor (receiver), and the transmitted signal is measured as the output voltage. b Input and output voltages measured under periodic actuation of an HG-A sample. c The output voltage as a function of hydrogel stiffness and thickness. The COMSOL-simulated sound pressure level intensity (a.u.) in the hydrogel is shown in the inset for HG-A. d,e Water extraction rates from HG-A and HG-C gels and the corresponding energy consumption during ultrasonic actuation with 70% duty cycle. f Anomalous diffusion model describes the moisture extraction process under ultrasonic actuation. g,h Extraction rates and the associated energy costs during actuation with 30% duty cycle. i Cyclic stability of the desorption behavior of HG-A hydrogel. Next, we compared the extraction efficiency of HG-A and HG-C samples with comparable weight (0.2 and 0.19 g, respectively) and equal moisture content equilibrated at ~80% RH (Fig. HG-A exhibited a higher weight loss of ~22% and energy consumption of ~12 MJ/kg under the 10-minute-long stimulation by the PZ-C actuator with ~114 Vpp and 70% duty cycle, while HG-C lost only ~12% of its weight and exhibited a much higher energy consumption of 21 MJ/kg under the same conditions. We fit the experimental data by using the Korsmeyer-Peppas (K-P) kinetic model, which establishes an exponential dependence of the fractional mass release on time \(t\) (see Methods): \(m(t)/{m}_{0}=k{{\rm{e}}}^{{nt}}\)61,62 (Fig. This model is commonly employed to analyze the release mechanism of pharmaceutical drugs from polymers, when more than one release phenomena are involved (\(k\) is a constant incorporating the sample structural and geometric characteristics, and the value of release exponent \(n\) quantifies the release process). The fitted values of the release exponent \(n\) were \(0.65\pm 0.1\) for HG-A \(0.82\pm 0.1\) for HG-C, indicating a swelling-controlled diffusion mechanism, rather than the Fickian (static) diffusion with \(n=0.45\)63. The non-Fickian (dynamic) behavior observed in our experimental data can be characterized as an anomalous diffusion, and indicates the presence of an additional molecular relaxation process under a combined action of ultrasound, mechanical pressure, and heat64. A similar anomalous diffusion is observed for the ultrasound-triggered release of antibiotics from hydrogel carriers65. The ANOVA tests indicate that there is no statistically significant variance (\(p > \alpha=0.05\)) between the \(n\)-values of the K-P model fitting for HG-A and HG-C samples (Supplementary Fig. However, a higher fitted n value for HG-C suggests that, owing to its high modulus, the water release mechanism in this hydrogel deviates further from the Fickian behavior than that in HG-A, translating into higher energy consumption. S26 reveals the differences in the evolution of vibrational modes associated with both water molecules and polymer functional groups like methylene (-CH2-) and amino group (-NH2) during the sorption-desorption cycle, which underlie the differences in the relaxation process dynamics of hydrogels of varying stiffness. To quantify synergistic and separate impacts of Joule heating and mechanical actuation on moisture extraction, we measured the moisture extraction rate in a cycle of periodic activation and deactivation of the PZ-C piezo-actuator (Fig. The plots reveal a persistent reduction of AWH-H weight even during the actuator off time periods, which indicates a temperature-driven water vapor release due to the high vapor pressure of the water in the hydrogel51. With this hybrid approach, we further increased extraction efficiency and reduced the energy consumption (to 10.2 MJ/kg and 12.4 MJ/kg for HG-A and HG-B, respectively). These data also reveal that increased mechanical rigidity of hydrogels reduces the rate of water release not only during the ultrasonic actuation but also by evaporation. The thermogravimetric analysis confirmed that when exposed to the same heating under the same environmental conditions, the stiffer HG-B and HG-C specimens released less moisture than HG-A (Supplementary Fig. Despite the differences in the extraction efficiency, both HG-A and HG-C hydrogel samples exhibited consistent absorption and desorption cycles, indicating cyclic stability (Fig. S28), while the intermediate-stiffness HG-B samples exhibited unstable performance (Supplementary Fig. S29) and were excluded from further analysis. Comparative analysis of the data in Fig. 5d–i suggests that the water extraction process can be further improved by the duty cycle and sample size optimization. We used our complete assembled system shown in Fig. 1c-d (see also Supplementary Fig. S30 and Supplementary Movie 7) to probe extraction efficiency from HG-A and HG-C specimens of varying moisture content. HG-A specimens were equilibrated at 77% RH, and then actuated for 25 min with a duty cycle of ~30–32%, equivalent to 8.75 min of piezo actuation time. These experiments revealed the reduction of energy consumption down to 5.25 MJ/kg for a medium-heavy ( ~ 1.73 g) sample, which covers the entire surface of the membrane. Similarly, for HG-C hydrogel, the optimized energy consumption of 6.2 MJ/kg was achieved with a ~ 1.65 g specimen (Supplementary Figs. Accordingly, the duty cycle needs to be optimized for environmental conditions, to compromise between the water harvesting amount per day and the corresponding energy consumption per unit mass of water. To further optimize the system performance, we (i) reduced the actuation time to 2 min, (ii) performed a test using three identical actuators and samples simultaneously under 2 min extraction cycles (Supplementary Figs. S33-35), and (iii) tested a single large HG-A sample with a diameter of 34 mm under multiple consecutive 2 min extraction cycles (Fig. Under these optimized conditions, during each 2-minute-long extraction cycle in each of the tests, energy consumption was recorded to be below the thermal limit of 2.25 MJ/kg66, thus yielding extraction efficiency in excess of 100% (see Supplementary Note 5 for detail). Average energy consumption of 0.535 MJ/kg (corresponding to 428% efficiency) has been measured over ten 1 h-long sorption cycles run at 75% RH, separated by eleven 2 min-long ultrasonic extraction cycles (Fig. Figure 6a shows the extracted water mass and energy consumption for each extraction cycle. The lowest energy consumption of 0.47 MJ/kg (corresponding to 481% efficiency) was recorded during several cycles shown in Fig. a, b Comparison of two strategies for water extraction from a large HG-A specimen ( >16 mm diameter): ten 1 h sorption cycles separated by 2 min- extraction periods (a) and 25 cycles of repeated 2 min extraction periods following one 24 h-long sorption cycle (b).c A comparative analysis of energy consumption between actuator-enabled water extraction and the state-of-the-art thermally driven evaporation process42. Here, si_l = a single device actuated over a long period; ar_l = an array device actuated over a long period; si_s = a single device actuated over a short period; ar_s = an array device actuated over a short period; si_s_m = a single device actuated over multiple short periods. d A comparative analysis of the daily water yield between the current work and previously reported state-of-the art AWH devices (the data is summarized in Supplementary Table 7). e, f Dynamic changes of HG-A (e) and HG-C (f) samples monitored in-situ through impedance-phase angle spectroscopy. g A schematic illustration of the machine learning model training on the measured impedance and phase angle data. The model uses a deep neural network for classification, which is shown in the confusion matrix. In contrast, when the 2 min actuation cycles have been run consecutively, without allowing for the sorption period in between, the energy consumption progressively increased with the cycle number, while the amount of the extracted water reduced. The lowest average energy consumption of 0.336 MJ/kg (corresponding to 671.1% efficiency) has been recorded for the first extraction cycle from the largest 34 mm-diameter sample (Fig. Both, energy consumption and extracted water mass values plateaued after about 20 extraction cycles equivalent to 40 min of continued actuation (Fig. Figure 6c summarizes the extraction efficiencies recorded under different actuating cycles and with different sorbent samples described above and compares these values to those of the highest-efficiency AWH setups reported in prior literature. Recent thermodynamic models of thermally-driven atmospheric water extraction predict the highest realistic thermal efficiency of 60%, corresponding to thermal energy consumption to 3.75 MJ/kg45. Real-world devices demonstrate even lower efficiencies, with the highest recorded efficiency of 10%67, and the currently achieved minimum energy consumption of 22.5 MJ/kg. In stark contrast, the average energy consumption and efficiency over ten sorption-extraction cycles were measured to be 0.535 MJ/kg and 428%, respectively (Fig. 6c), because the ultrasonic extraction process is not fundamentally restricted by the thermal limit inherent to evaporation-driven techniques. The data in Fig. 6a shows that by using ultrasound desorption mechanism, the total daily water yield is almost entirely constrained by the sorption rate. PAM-LiCl hydrogels used in this work adsorb the same amount of moisture from air with 75% RH in 40 min as can be extracted by piezo actuation in 2 min. We can estimate the daily yield of water that can be harvested from a scaled-up system with a 1-m2 sorbent area [L/m²/day] by extrapolating the results of cyclic sorption-desorption testing of a single prototype device with a large sorbent over 10 h at 75% RH, i.e., by using the data shown in Fig. This simple scaling strategy assumes that multiple identical actuators with hydrogel samples identical to those used in our study are deployed in the form of a two-dimensional (2D) horizontal array with the total area of the sample surface equal to 1 m2. We further assumed that each actuator is powered separately and the energy consumption per device is the same as measured in our experiments. Under such assumptions, the average daily productivity value is predicted to be ~3.25 L/m²/day and an average energy consumption of 0.576 MJ/kg (Supplementary Note 5). It should be emphasized that ultrasonic extraction does not require exposing sorbent surface to sunlight. Accordingly, AWH devices can be stacked vertically on top of each other with no limitation in principle to the number of vertical rows. Adding more 2D device arrays by stacking them vertically will increase the yield by 3.25 L day⁻¹ per each row without increasing the installation horizontal footprint. For instance, using an installation with 5 vertical rows of devices, the productivity of our system can be increased fivefold to 16.25 L day⁻¹ per m2 of land footprint. Figure 6d and Supplementary Table 7 compare the estimated productivity of our system with those of previously reported AWH materials and systems. Replacing PAM-LiCl hydrogels with sorbents exhibiting higher sorption rate (such as e.g., a hygroscopic interconnected porous gel68) can further increase daily yield. Vertical stacking or vertical arrangement of sorbents have already been used in the state-of-the-art AWH systems with thermal extraction to increase per-m2 yield68,69. However, except for the vertically oriented sorbent setup employing integrated Joule heaters69, such installations require either manual batch processing of sorbent layers or conveyor-belt-like rotating sorbents to achieve solar exposure for thermal extraction. Remarkably, the lowest energy consumption of 0.336 MJ/kg (0.09 kWh/kg) per a single cycle measured in this work (Fig. 6b) is not only below the ideal thermal limit, but also below the dewing limit at 75% RH. Dewing limit defines the ideal minimum energy consumption of conventional dehumidification technologies, which cool air to its dewing point to promote water condensation (Supplementary Note 6). At 75% RH and ambient temperature of 25 °C, the minimum energy required for dewing is 0.58 MJ/kg (0.16 kWh/kg). Our preliminary technoeconomic analysis of the scaled-up system performance indicates the viability of commercializing our system. The estimated cost of water extracted from air at 75% RH is 0.19 $/L, which is lower than the cost of bottled water in various countries worldwide, including USA, UK, Canada and Australia (see Supplementary Note 7 and Supplementary Figs. 37a illustrates that—owing to the low cost of hydrogel—its lifespan does not have a noticeable effect on the water costs, while Supplementary Fig. 37b shows the estimated water costs as a function of the device lifespan in the range from 1 to 45 years. Given the observed dependence of the extraction energy efficiency on the sample moisture content, in-situ monitoring and dynamic optimization of the sorption-extraction cycle under variable environmental conditions could help to improve the system performance during the field operation. Fourier-transform infrared spectroscopy (FTIR) may be used to monitor the changes in the sorbent properties (Supplementary Note 3, Supplementary Fig. S26, and Supplementary Table 3), but it cannot be deployed for continuous in-situ monitoring. Fortunately, the piezoelectric actuator itself can be used not only for moisture extraction but also for real-time process monitoring. Piezoelectric materials exhibit both direct and inverse piezoelectric effects, translating into their ability to either convert applied force into measurable electric quantity or convert electric potential into quantifiable displacement, respectively70. By taking advantage of the direct piezoelectric effect, the actuator can be used as an in-situ sensor71,72. This sensing capability is illustrated in Fig. 6e, f, which show changes in the impedance ( | Z | , Ω) and phase angle ( | θ | , o) of a PZ-C actuator loaded with either HG-A or HG-C hydrogel during the process of atmospheric moisture adsorption at ~20% RH and 20 °C. To evaluate the potential of using this sensing modality for continuous in-situ monitoring and control of the sorption process, we developed a deep learning model and demonstrated its capability to recognize absorption patterns of different hydrogels (Fig. Impedance variations datasets were collected during atmospheric moisture absorption cycles at ~20% RH and 20 °C. We used 77% of all the datasets for training and the rest 23% for testing. Following 200 epochs of training, the model successfully classified the impedance data and was able to distinguish between absorption patterns of HG-A and HG-C hydrogels, achieving an impressive prediction accuracy of 100% as shown in the confusion matrix (Fig. This monitoring and classification capability shows promise in designing fully automated systems that can switch from sorption to extraction once the optimum conditions are reached. Combining embedded sensing capability with deep learning tools for real-time data classification will allow for identifying abnormalities in the system performance and adjusting the system operation to the changes in the environment. This study demonstrated moisture extraction by vibrational actuation with high efficiency from two different hydrogel systems. These results give reason to expect that ultrasound actuation can facilitate moisture extraction from other sorbents. This hypothesis is independently supported by literature evidence on increased drying rate of textiles73, seaweed74, and zeolite75 under ultrasonic actuation. Each material system would need to be evaluated separately under optimized actuation conditions, moisture content, and sorbent geometry, which will be the subject of our future work. Under this non-thermal extraction scenario, the kinetics of both the sorption and desorption processes under the optimized vibrational actuation for each type of sorbent will play an important role. Accordingly, the known sorbents, including various types of hydrogels, metal-organic frameworks, micro- and nano-fiber mats, and combinations thereof, will need to be re-evaluated and re-engineered to enhance their compatibility with the alternative extraction method. Internal nano- and micro-scale structure of sorbents will further play an important role in the efficiency of this process and needs to be investigated (e.g., size and shape of the pores, surface-to-volume ratio, stiffness, etc). The overall shape of the sorbent sample can be engineered to provide acoustic resonances matched to the actuator driving frequencies. Finally, each sorbent may exhibit its overall highest efficiency when actuated not only by a different frequency but also around a different point in its sorption curve, calling for further fundamental studies and optimization efforts. Scaling up this alternative extraction technology will necessitate further research into ultrasound-induced degradation of various sorbent materials. The robustness, cyclic stability, and efficacy for long term water harvesting capability of PAM-LiCl HG-A hydrogel composites have been previously demonstrated in numerous works30,32,46. Our initial lab-scale testing confirms that these sorbents maintain structural integrity after multiple piezo actuation cycles, as evidenced by absence of any traces of polymer residue in collected water filtered by a VWR filter paper (see Supplementary Notes 5,8). Our observations and spectroscopic analyses (Supplementary Fig. S26) also agree with prior independent studies of polymers and hydrogels subjected to piezo actuation, which have demonstrated resilience to vibrational deformations76,77 and self-healing performance78. Similarly, in this work, we did not observe any material degradation or performance loss of either HG-A or HG-M hydrogels during multiple actuation cycles (Fig. 6a, b and Supplementary Figs. The degradation resistance of other sorbents will need to be evaluated separately. Some may prove incompatible with this method of extraction, others may need to be re-engineered to improve their mechanical properties so they can withstand vibrational forces over many regeneration cycles. It should also be noted that a traditional photothermal method of moisture extraction from sorbents also causes their accelerated degradation. For example, solar radiation causes rapid UV-triggered photooxidative degradation of polymers via chain scission and formation of free radicals79,80, which for some polymers is further accelerated in the presence of moisture and at higher temperatures81,82,83. Prior studies demonstrated that 368 nm UV irradiation can effectively degrade hydrogels84. Likewise, MOFs may also deteriorate under UV and sunshine exposure85. Even when the sorbents themselves are not directly exposed to sunlight during the moisture extraction process, long exposure of solar absorbers and constructional elements of the AWH system to sunlight, high temperatures, and moisture accelerate their ageing. Long-term studies of sorbent degradation under various stimuli (sunlight, moisture swings, temperature swings, and ultrasound signals) will need to be done for any sorbent considered for outdoor AWH operation to evaluate their lifetimes under different operational scenarios in real-life applications. The manufacturer-indicated lifespan of piezoelectric actuators used in this study86 is 45 years. In prior studies, the NASA Jet Propulsion Laboratory conducted life testing on commercial piezoelectric PZT actuators, pre-stressed to 18 MPa, for up to 100 billion cycles over 580 days, revealing no discernible damage or substantial performance decline87. Several strategies can be additionally implemented to preserve long lifespans of actuators used in AWH systems. A waterproof silicon-based membrane may replace the metal membrane in the actuator used in this study, maintaining a comparable displacement and velocity profile52. Silicon coating over metallic or other corrosion-prone elements can be used to enhance corrosion resistance88. Alternatively, corrosion-resistant ultrasonic transducers can be used, e.g., those based on monocrystal fibers89,90 or on hydrophobic polymers such as polyvinylidene fluoride (PVDF)91. Salt-containing sorbents like the LiCl-infused hydrogels HG-A,B, and C used in this work may present additional challenges associated with water extraction in the liquid form under ultrasonic actuation. Measured Li ion concentration in the extracted water varied between 1.5 and 15.2 ppm (or mg/L), comparable to the concentrations measured a recent study of bottled water in multiple countries (see Supplementary Note 7). While there are no regulatory thresholds for lithium either in the USA or globally, our future work will focus on the synthesis and testing of Li-free sorbents with high water uptake to limit the risk of water contamination and to reduce the cost of the technology. It is important to emphasize that the alternative extraction methodology is equally applicable to Li-free hydrogels (such as e.g., HG-M gels shown in this work) and is expected to be fully compatible with other previously demonstrated sorbents that do not contain salts. In our devices, we estimate the energy consumption to be roughly equally divided between the mechanical actuation (49%) and heating (51%), see Supplementary Note 10. The parasitic heat generated by a piezo actuator is used to heat a sorbent, and still contributes to the water extraction, but with lower efficiency than mechanical actuation. The effective electromechanical coupling coefficients of our prototype actuators was quite low, ranging from 17 to 19%. By designing a 1-3 composite piezoelectric transducer array device instead of a single ring-shaped actuator, an electromechanical coupling coefficient of 35% can be achieved92. High-efficiency single-crystal piezoelectric materials exhibit even significantly higher electromechanical coupling factors, which can be complemented by the optimized transducer array design, promising further efficiency enhancement. Furthermore, arraying small devices is not the most efficient way of scaling the system up, which likely overestimates the daily energy consumption while underestimating the energy efficiency of extraction. The effectiveness of large-area PZT-based ultrasound transduction has been demonstrated in various unrelated studies. For example, an interconnected network comprising hundreds of miniaturized PZT actuators has been employed over a 20 cm x 20 cm area, utilizing only 6 W of electric power, resulting in efficient transduction intensity at a depth up to 8mm93. Similarly, larger piezoelectric components could be utilized in arrays, akin to those employed in sonar applications for underwater wireless communication, which are inherently designed with a larger footprint area extending up to several sq. Future research could implement these strategies to test the AWH sorbents with a custom-made actuator array over a large surface area and associated electronic circuits for optimum power supply to the array, which may yield higher energy efficiency than we predict based on the simple approach described above. The vibrational extraction requires the use of a photovoltaic (PV) cell—or another solar-to-electricity energy converter—to generate electric power to drive a piezo actuator if operated autonomously without access to the electric grid. While solar power can be used to directly heat a sorbent material, there are multiple arguments for the use of a PV cell to convert and store solar energy to power an outdoor AWH system (even if ultrasonic extraction is not used). First, conversion of solar energy into low-grade heat in a solar-thermal absorber is a less efficient process than conversion of solar energy to electricity with a PV cell (see Supplementary Note 11)95,96,97. Second, the daily water yield per land area can be maximized by designing vertically-oriented systems68,69 integrated with ultrasonic actuators or Joule heaters for extraction, and by optimizing the sorption-desorption cycle duration to operate around the clock. Third, other auxiliary devices can be powered by the PV-generated electricity, including sensors to monitor environmental conditions and fans to promote air convection to improve vapor diffusion68,98. Finally, AWH systems with vibrational extraction can be designed to run autonomously, avoiding manual batch-drying process98 and adapting their sorption/extraction cycles to varying environmental conditions. To summarize, our work offers the experimental demonstration of the energy consumption of moisture extraction from AWH sorbents below both the thermal limit and the dewing limit. This major improvement in energy efficiency may promote AWH technology commercialization. We synthesized polyacrylamide hydrogels based on a simple, one-pot approach, where polymer, salt, initiator, crosslinker, and accelerator, were all mixed in water. For all hydrogels, we first dissolved the 16.72 g lithium chloride ( ≥99%) salt in a beaker with 50 mL deionized (DI) water. The solution was continuously mixed with a magnetic stirring bar, covered to prevent evaporation, and then left to cool down to room temperature. We added sequentially 4.18 g of acrylamide ( ≥ 99%), the N,N'-MBA (99%) as crosslinker (50 mg for HG-C, 2.5 mg for HG-B and 0.5 mg for the HG-A) and 14.2 mg of ammonium persulfate (APS) ( ≥ 98%) as initiator. We degassed the mixed solution for 10 min under vacuum in a dessicator. Finally, we added 12 μL of N,N,N′,N′-tetramethylethylendiamin (TEMED) ( ≥ 99%) as accelerator. 4 mL of solution were poured into a petri dish, covered with the lid, and left to gelate at room temperature overnight. All the chemicals were purchased from Sigma-Aldrich and used as received. The dynamic vapor sorption isotherms were characterized using an environmental simulation chamber (BINDER GmbH). Initially, the samples were dried at a temperature of 95 °C, for a duration of 24 hours using a gravity convection oven (MTI Corporation). Subsequently, the weight of the samples that had been dried in the oven was measured using an analytical balance (OHAUS Corporation). Next, the oven-dried samples were treated inside the environmental chamber under varying RHs (15, 30, 55, 85%) at a constant 25 °C temperature and at a maximum stage time of 720 min, ensuring that the specimen weight reached an equilibrium state. In addition to our designed hydrogel, we also used a commercially available hydrogel (HG-M) (a cross-linked glycerol- 2-acrylamido-2-methylpropanesulfonic acid sodium salt hydrogel, Medela). Finally, the water uptake was quantified by calculating the ratio of the water content in the sample at equilibrium to its oven-dried weight. The findings are shown as the mean ± standard deviation. Rheological experiments were conducted using a rheometer (HR-20, TA Instruments). For all the experiments, a 25 mm parallel plate geometry was employed to ensure accurate loading on the hydrogel specimens. A circular mold was used to fabricate gelled disks, which were formed into a diameter of 25 mm for utilization underneath the parallel plate. Before conducting the tests, the samples were given a five-minute period to reach a state of equilibrium, ensuring that both mechanical and thermal factors were balanced. The temperature was controlled using a built-in Peltier system. The experiments involving the oscillatory frequency and strain/amplitude sweeps were carried out at 25 °C. Temperature sweep experiments were conducted at an angular frequency of 6.28 rad/s and 0.1% strain. Thermogravimetric analysis was conducted to evaluate the desorption behavior and thermal stability of the hydrogels using a thermal analysis system (TGA 5500, TA Instruments). Approximately 10 mg of samples were put into a titanium pan in the presence of nitrogen gas and were heated gradually at a rate of 1 °C/min until they reached a temperature of 50 °C. The surface morphology of the hydrogel specimens was examined using an SEM (Zeiss Sigma 300 VP). Hydrogels were completely dehydrated to prevent off-gassing during sputtering and SEM imaging. To prepare the samples and visualize them under the SEM, they were stuck to aluminum stubs with double-sided carbon tape. Next, a sputter coater (Desk V, Denton) was used to apply a 10 nm thin film coating of gold/palladium (Au/Pd) (60:40) in presence of argon gas. A conventional diffusion cell was used to conduct the forward osmosis test and assess the efficacy of water penetration through the porous stainless-steel membranes employed in this investigation. The experimental configuration closely resembled a recent study99. The porous membrane was installed between two glass cells, each having a capacity of 7 ml. The left cell is referred as the NaCl-solution cell, and the right one is the DI-water solution cell, (see Supplementary Fig. A 2 M NaCl solution was made by dissolving 0.81 g of NaCl in 7 ml of DI water. The right cell contained 7 ml of DI-water with conductivity in the µS (micro-siemens) range. As the water conductivity increased, reaching the mS (milli-siemens) range, the ion mass began to transport through the membrane from the ion-cell to the DI-cell. This occurred under vigorous mixing at a speed of 1350 RPM at room temperature, driven by the concentration gradient. The conductance measurements were conducted using a conductivity probe (SevenCompact, Mettler Toledo) for a duration of 10 minutes for each of the three SS membranes. The solid housing for the piezoelectric transducer was modeled in SOLIDWORKS and parts were printed using a Bambu Lab X1-Carbon Combo 3D printer. Aside from the glass domes, all parts within the assembly have a hole with a 12 mm diameter in the center to allow droplets to fall into the bottom dome since water can be harvested from the hydrogel on both sides (top and bottom) of the piezoelectric transducer. Two-ring structures, top and bottom insulators, are used to hold two glass domes in place. Cuts are made into the assembly to allow the domes to slide into the case. The top insulator is 8 mm tall, has an outer diameter of 33 mm, and an inner diameter of 25 mm, allowing for a perfect fit of the glass dome, which had an outer diameter of slightly below 25 mm. The wire track that houses the piezoelectric device is 8 mm tall and has an outer diameter of 20 mm and an inner diameter of 17 mm. Also, it has a cut that is 2 mm deep to hold the piezoelectric ring and provides a cavity to allow wiring and ambient moisture access into the case. The support platform connects the top and bottom insulators. The bottom insulator and the tripod together host the bottom glass dome. Each leg of the tripod is 38 mm long. The piezoelectric transducer used in our system was circular in shape (see Supplementary Table 1-2 for detail), where a piezoelectric ring made of lead zirconate titanate (PZT) polycrystal was affixed to a porous stainless-steel membrane. To fabricate the transducer for our system, the membrane and the PZT rings were purchased from Dongguan Norvis Electronic Corporation and securely fastened. The PZT was affixed to the porous membrane by clamping one side, while the other side was covered with a hydrophobic epoxy resin. Porous membranes with three different nozzle sizes (10, 70, and 100 µm) were used with PZT crystals of two different frequencies to build the low ( ~ 110 kHz) and high ( ~ 165 kHz) frequency actuators. Piezo drivers were used to actuate the transducer at two different duty cycles of 70 ± 3% and 30 ± 3%, operating at RMS voltages of 40 and 30 V, respectively. The driver boards were powered at 1.5 W using a DC power supply to drive the piezoelectric transducers. A Berlincourt meter was employed to measure the piezoelectric coefficients, d33 (pC/N), of the PZT crystals used in fabricating the four transducers. During the measurement of the coefficients, both a static force and a dynamic force are exerted on the sample. The tool controls and maintains a constant dynamic force of 0.25 N/110 Hz, while the static force of around ~1 N was manually controlled. The static force is measured using a static force sensor to assure consistent measurements (see Supplementary Fig. The electrical phase-impedance spectrum of the transducer devices was measured using an impedance spectroscopy (Solartron SI 1260, AMETEK). The impedance spectrum was screened to obtain two key parameters, the anti-resonance (fa) and resonance (fr) frequencies. The evaluation of the effectiveness of piezoelectric devices in converting electric energy into mechanical energy was conducted based on their effective electromechanical coupling coefficient (keff)56,92 using the following equation: \({k}_{{eff}}=\sqrt{({f}_{a}^{2}-{f}_{r}^{2})/{f}_{a}^{2}}\). The vibrational modes of the steel membrane and PZT ring were analyzed using a PICOSCALE Vibrometer (SmarAct Metrology GmbH & Co. KG), which is a laser scanning vibrometer employing confocal optics and Michelson interferometry. The sample was actuated using the built-in signal generator of the vibrometer. In this case, the device was connected to a general-purpose input/output (GPIO1 from the vibrometer controller), which is used to output an electrical signal and directly feed it to the device using an adapted BNC cable. First, microscopic imaging was used to identify the specific area of interest on the membrane and PZT ring for the modal analysis (see Supplementary Fig. The membrane was analyzed at two distinct locations: the core and the periphery. Measurements on the periphery of the membrane and PZT were consistently conducted at a significant distance from the electrode cable. To uncover the local resonances, a linear sweep excitation ranging from 1 Hz to 500 kHz, with a duration of 0.01 s and an amplitude of 1 Vpp was generated and output via the GPIO1. For each identified local resonance, a 2D modal analysis was performed. During this analysis, the interferometric laser beam is raster-scanned over the sample while the amplitude and phase of the vibrations are extracted using dual-phase lock-in demodulation. For this application, a single-frequency sinusoid is output at GPIO1, which is also used as the reference signal for the lock-in amplifier. The recorded time series is post-processed using the FFT (Fast Fourier Transform) algorithm to convert the signal from time domain into frequency domain in the form \(x\left(t\right)=A\sin (\omega t)\) to reduce the noise and reveal the resonances. The velocity (\(v\)) of the device at its resonance frequency (\({f}_{d}\)) was then calculated as \(v={dx}/{dt}=\omega \cdot A\cdot \cos (\omega t)\), where \(x\) is the displacement signal and \(\omega\) is the angular frequency. Maximum velocity value is then estimated as \({v}_{\max }=\omega \cdot A=2\pi {f}_{d}A.\) The amplitude A of the signal can be easily retrieved by performing the Fourier analysis of the recorded time-series, and the RMS value of the velocity at the peak amplitude value is calculated as \({v}_{{RMS}}=0.7{v}_{\max }.\) In the case of a linear sweep excitation, the energy of the signal is spread over a large bandwidth. In order to retrieve the real amplitude of the motion, a correction factor is applied: \(k=\sqrt{({f}_{1}-{f}_{0}){dt}}\), where \({f}_{1}\) and \({f}_{0}\) are the highest and the lowest frequencies, respectively, and \({dt}\) is the duration of the sweep. In our calculations, a correction factor of \(k=70.71\) was used. During the experimental analysis and 2D imaging of vibrational modes, the displacement signal is demodulated on-the-fly using a digital dual-phase lock-in amplifier, and no correction factor to retrieve the actual amplitude is needed. The resulting 2D image of the sample deflection is post-processed to retrieve the maximum displacement value. Elemental mapping, surface roughness imaging, and atomization photography Zeiss Sigma 300 VP was used to capture SEM images of the membrane nozzles and PZT material. The tool also employed Energy Dispersive X-ray (EDX) technology for elemental mapping of the PZT devices and provides precise information about their composition. A laser scanning confocal microscope (VK-X250, Keyence) was used to do non-contact surface profiling and roughness assessment of the membrane after the extraction cycle. The Nikon D5300 DSLR camera was used to capture the atomization process of water as it was expelled from the hydrogel and funneled through the nozzles of the porous membrane incorporated into the transducer. A green crossline was generated using a 520 nm green laser module (OXLasers), with the focal point positioned below the nozzle axis. This improved the process of envisioning for photography. T-slotted aluminum extrusions were used to build a platform for mounting the transducer between two L-shaped joint brackets to perform imaging experiments. To monitor and visualize hydrogel heating caused by the PZT transducer heat generation, an infrared (IR) thermal camera (FLIR ETS320, Teledyne FLIR LLC) was utilized. IR imaging was also used to monitor the process of hydrogel cooling to ambient temperature after the actuation process. Due to the challenge of IR-imaging a highly polished surface such as a metallic stainless-steel membrane in our device, we used Dr. Scholl's™ spray to deposit a thick opaque layer onto the membrane, and during imaging, emissivity (ε) value of 0.95 was set in the IR camera. We used an acoustic sensor hydrophone (H Instruments) to measure and quantify the force exerted by a piezoelectric transducer as a function of voltage (V). To conduct the acoustic experiment, the transducer was placed within a petri dish and the hydrogel samples were attached to the device. The acoustic sensor was linked to its amplifier board operating at 9 V that had a gain of 25 dB with bandwidth up to 120 kHz and placed on the hydrogel surface. The transmitted and received waveforms were recorded. Our device served as the transmitter, while the acoustic sensor functioned as the receiver. The resulting output voltage was measured for hydrogel samples of varying thickness. We used a multi-channel calibrated commercial K-type thermocouple (HT-9815, RISE PRO) to measure the temperature of a free-standing (i.e., not clamped to the PZT) stainless steel membrane used as the Joule heater. The transducer device received a power supply of 1.5 W in order to maintain a consistent temperature for a comparative analysis. Throughout the experiment, either Joule heating or ultrasonic actuation were applied for 1 min each, followed by a subsequent short deactivation period to weigh the amount of weight loss. The weight loss (%) of the hydrogel was calculated by comparing the extracted mass to the initial mass of the sample. Fourier transform infrared (FTIR) spectroscopy was used to investigate the changes in the vibrational spectra of hydrogels with different level of cross-linking and varying moisture content. FTIR with a built-in attenuated total internal reflectance (ATR) capability was used (iS50, ThermoFisher). The raw FITR spectra were deconvoluted into distinct Gaussian peaks corresponding to individual vibrational modes of polymer and trapped water molecules. The energy consumption, E [MJ/kg], required for moisture extraction was calculated as follows: \(E=P/m=(({\rm{power}},{kWh})\cdot ({duty\; cycle},\%) \cdot 3.6\cdot {10}^{6}\cdot {10}^{-6})/{10}^{-3}\left[\right. {MJ}\cdot {{kg}}^{-1} > \), where \(P\) is input energy [MJ], and \(m\) [kg] is the extracted mass. Using the energy consumption (E), the efficiency of the water release process of our device, \(\eta > \), is calculated as \(\eta={h}_{{lv}}/E\), where \({h}_{{lv}}=2.257\left[\right. {\rm{MJ}}/{\rm{kg}}\) is the enthalpy of vaporization of water (see Supplementary Note 4). Agilent 5100 DVD was used to test the quality of the ultrasonically-extracted water from PAM-LiCl hydrogels via a coupled plasma optical emission spectrometer (ICP-OES) elemental analysis, similar to the test methods reported in recent studies of AWH hygroscopic gels30. Prior to testing with the Agilent 5100 DVD, the extracted water was collected using VWR sterile syringe filters. Multiple desorbed specimens were tested. COMSOL Multiphysics® was used to simulate vibrational modes of the transducer device consisting of a PZT ring clamped to a steel membrane with nozzles100. Solid Mechanics and Electrostatics modules were used to study the deformation dynamics, and a 3D asymmetrical model was constructed to facilitate visualization (see also Supplementary Note 2). Using a voltage sweep, the displacement and velocity were studied, and the phase-impedance spectrum was analyzed employing a frequency sweep. Simulating the nozzle dispersion pattern akin to the manufactured membrane proved challenging in COMSOL. Consequently, all the nozzles were uniformly distributed, and a diameter of 50 μm was used to accommodate around 800 nozzles. The simulation results for impedance, velocity, and displacement exhibited a high degree of agreement with the experimental data, without significant deviation. This simulation technique was also employed to visualize the behavior of ultrasonic radiation in hydrogel. For this study purpose, the Young's modulus (E) was determined from the storage modulus of our hydrogel utilizing the formula \(E=2G(1+\mu )\), where \(\mu\) represents the Poisson ratio and storage modulus was used as the magnitude for \(G\). The density was estimated at approximately 1200 kg/m3 according to literature101, and a Poisson's ratio of 0.5 is often employed for hydrogels. Following the calculation, the inputs were entered into COMSOL to simulate the sound pressure induced by the actuator in the hydrogel volume. We used Edge Impulse machine learning platform102 to build a deep neural network, which was used to categorize and distinguish between different types of hydrogels during the sorption process. The neural network was trained using the measured dynamic changes in the phase angle and impedance of the transducer loaded with hydrogel samples, which were continuously sorbing moisture at ~20% RH and ~19 °C. The trained model has three hidden layers, with a total of 100 neurons, and exhibited accuracy of 100%. The training phase used 77% of the datasets, while the remaining 23% were allocated for testing the model. The data supporting the plots within the main text are available in Supplementary Information. Additional data relevant to this study are available from the authors upon request. Four billion people facing severe water scarcity. The future of seawater desalination: energy, technology, and the environment. Shannon, M. A. et al. Science and technology for water purification in the coming decades. Estrela, M. J., Valiente, J. A., Corell, D. & Millán, M. M. Fog collection in the western Mediterranean basin (Valencia region, Spain). Hou, Y., Chen, Y., Xue, Y., Zheng, Y. & Jiang, L. Water collection behavior and hanging ability of bioinspired fiber. Ju, J. et al. A multi-structural and multi-functional integrated fog collection system in cactus. & de Rautenbach, C. The implementation of fog water collection systems in South Africa. Park, K.-C., Chhatre, S. S., Srinivasan, S., Cohen, R. E. & McKinley, G. H. Optimal design of permeable fiber network structures for fog harvesting. Wang, Y. et al. Biomimetic water-collecting fabric with light-induced superhydrophilic bumps. Zhang, L., Wu, J., Hedhili, M. N., Yang, X. & Wang, P. Inkjet printing for direct micropatterning of a superhydrophobic surface: toward biomimetic fog harvesting surfaces. Schneider, S. H., Root, T. L. & Mastrandrea, M. D. No Title. Kim, H. et al. Water harvesting from air with metal-organic frameworks powered by natural sunlight. Li, R., Shi, Y., Shi, L., Alsaedi, M. & Wang, P. Harvesting Water from Air: Using Anhydrous Salt with Sunlight. McHugh, T. A., Morrissey, E. M., Reed, S. C., Hungate, B. & Schwartz, E. Water from air: an overlooked source of moisture in arid and semiarid regions. Nandakumar, D. K. et al. A super hygroscopic hydrogel for harnessing ambient humidity for energy conservation and harvesting. The UN World Water Development Report: Water for a Sustainable World. UN World Water Dev. Zhou, X., Lu, H., Zhao, F. & Yu, G. Atmospheric water harvesting: a review of material and structural designs. Boriskina, S. V. et al. Nanomaterials for the water-energy nexus. Wahlgren, R. V. Atmospheric water vapour processor designs for potable water production: a review. Wikramanayake, E. D., Ozkan, O. & Bahadur, V. Landfill gas-powered atmospheric water harvesting for oilfield operations in the United States. Kim, H. et al. Adsorption-based atmospheric water harvesting device for arid climates. Nilsson, T. Initial experiments on dew collection in Sweden and Tanzania. Guan, H., Sebben, M. & Bennett, J. Radiative- and artificial-cooling enhanced dew collection in a coastal area of South Australia. Ji, J. G., Wang, R. Z. New composite adsorbent for solar-driven fresh water production from the atmosphere. & Wang, L. W. Experimental investigation on two solar-driven sorption based devices to extract fresh water from atmosphere. Chua, H. T., Ng, K. C., Chakraborty, A., Oo, N. M. & Othman, M. A. Adsorption characteristics of silica Gel + Water Systems. & LeVan, M. D. Adsorption equilibrium of carbon dioxide and water vapor on zeolites 5A and 13X and silica gel: pure components. Desai, R., Hussain, M. & Ruthven, D. M. Adsorption of water vapour on activated alumina. I —- equilibrium behaviour. Feng, Y., Wang, R. & Ge, T. Pathways to energy-efficient water production from the atmosphere. Lu, H. et al. Tailoring the desorption behavior of hygroscopic gels for atmospheric water harvesting in arid climates. Sadoff, C. W., Borgomeo, E. & Uhlenbrook, S. Rethinking water for SDG 6. Extreme water uptake of hygroscopic hydrogels through maximized swelling-induced salt loading. Zhao, F. et al. Highly efficient solar vapour generation via hierarchically nanostructured gels. Plausible photomolecular effect leading to water evaporation exceeding the thermal limit. Guerra-Bravo, E., Lee, H.-J., Baltazar, A. & Loh, K. J. Vibration analysis of a piezoelectric ultrasonic atomizer to control atomization rate. Sharma, P., Quazi, M., Vazquez, I. R. & Jackson, N. Investigation of droplet size distribution for vibrating mesh atomizers. Zheng, J., Takahashi, S., Yoshikawa, S., Uchino, K. & de Vries, J. W. C. Heat generation in multilayer piezoelectric actuators. Kim, H., Rao, S. R., LaPotin, A., Lee, S. & Wang, E. N. Thermodynamic analysis and optimization of adsorption-based atmospheric water harvesting. Li, A. C. et al. Thermodynamic limits of atmospheric water harvesting with temperature-dependent adsorption. Almassad, H. A., Abaza, R. I., Siwwan, L., Al-Maythalony, B. & Cordova, K. E. Environmentally adaptive MOF-based device enables continuous self-optimizing atmospheric water harvesting. Rapid cycling and exceptional yield in a metal-organic framework water harvester. LaPotin, A. et al. Dual-stage atmospheric water harvesting device for scalable solar-driven water production. Shan, H. et al. Exceptional water production yield enabled by batch-processed portable water harvester in semi-arid climate. Xu, J. et al. Ultrahigh solar-driven atmospheric water production enabled by scalable rapid-cycling water harvester with vertically aligned nanocomposite sorbent. Li, A. C., Díaz-Marín, C. D., Zhong, Y., Gaugler, L. C. & El Fil, B. Thermodynamic Limits of Sorption-based Atmospheric Water Harvesting Using Hygroscopic Hydrogels. Díaz-Marín, C. D. et al. Physics-based prediction of moisture-capture properties of hydrogels. Bouklas, N. & Huang, R. Swelling kinetics of polymer gels: comparison of linear and nonlinear theories. & Aguilar, E. Essential guide to hydrogel rheology in extrusion 3d printing: how to measure it and why it matters? The influence of swelling on elastic properties of polyacrylamide hydrogels. Díaz-Marín, C. D. et al. Kinetics of sorption in hygroscopic hydrogels. Díaz-Marín, C. D. et al. Heat and mass transfer in hygroscopic hydrogels. Sharma, P. & Jackson, N. Vibration analysis of MEMS vibrating mesh atomizer. Zhou, H., Shi, L., Tan, J. & Huang, S. The design of medical micro atomization device based on piezoelectric actuators. Hooker, M. Properties of PZT-Based Piezoelectric Ceramics Between −150 and 250 C. at https://ntrs.nasa.gov/citations/19980236888 (1998). Characterization method of the Joule heating efficiency of electric textiles and influence of boundary conditions. In Lead-Free Piezoelectric Mater. & Guo, S. Frequency shifts in a piezoelectric body due to a surface mass layer with consideration of the layer stiffness. Manuel, T. J. et al. Ultrasound neuromodulation depends on pulse repetition frequency and can modulate inhibitory effects of TTX. Lee, K. H. et al. Ultrasound-driven two-dimensional Ti3C2Tx mxene hydrogel generator. The effect of acoustic radiation force on osteoblasts in cell/hydrogel constructs for bone repair. Costa, P. & Sousa Lobo, J. M. Modeling and comparison of dissolution profiles. Hornsby, T. K., Kashkooli, F. M., Jakhmola, A., Kolios, M. C. & Tavakkoli, J. Kinetic modelling of ultrasound-triggered chemotherapeutic drug release from the surface of gold nanoparticles. Lee, P. I. Kinetics of drug release from hydrogel matrices. Fosca, M., Rau, J. V. & Uskoković, V. Factors influencing the drug release from calcium phosphate cements. Tran Vo, T. M., Potiyaraj, P., del Val, P. & Kobayashi, T. Ultrasound-triggered amoxicillin release from chitosan/ethylene glycol diglycidyl ether/amoxicillin hydrogels having a covalently bonded network. Wilson, C. T. et al. Design considerations for next-generation sorbent-based atmospheric water-harvesting devices. Yang, X., Chen, Z., Xiang, C., Shan, H. & Wang, R. Enhanced continuous atmospheric water harvesting with scalable hygroscopic gel driven by natural sunlight and wind. Zou, H. et al. High-Efficiency Atmospheric Water Harvesting and Irrigation Recycling in Greenhouse Using Hygroscopic Composite Gels. Akdogan, E. K., Allahverdi, M. & Safari, A. Piezoelectric composites for sensor and actuator applications. Zhang, Q. et al. Flexible multifunctional platform based on piezoelectric acoustics for human–machine interaction and environmental perception. Lan, B. et al. Multichannel gradient piezoelectric transducer assisted with deep learning for broadband acoustic sensing. Dupuis, E. D., Momen, A. M., Patel, V. K. & Shahab, S. Electroelastic investigation of drying rate in the direct contact ultrasonic fabric dewatering process. Zhu, X., Zhang, Z., Hinds, L. M., Sun, D.-W. & Tiwari, B. K. Applications of ultrasound to enhance fluidized bed drying of ascophyllum nodosum: drying kinetics and product quality assessment. Daghooghi-Mobarakeh, H. et al. Ultrasound-assisted regeneration of zeolite/water adsorption pair. Comprehensive facilitating of water oxidation reaction by ultrasonic attenuation of hydrogen-bonded structure of water. A., Tagaya, M. & Kobayashi, T. Effect of ultrasound on the aqueous viscosity of several water-soluble polymers. Huebsch, N. et al. Ultrasound-triggered disruption and self-healing of reversibly cross-linked hydrogels for drug delivery and enhanced chemotherapy. Madsen, M. V., Tromholt, T., Norrman, K. & Krebs, F. C. Concentrated Light for Accelerated Photo Degradation of Polymer Materials. Cai, L., Wang, J., Peng, J., Wu, Z. Observation of the degradation of three types of plastic pellets exposed to UV irradiation in three different environments. Rujnić Havstad, M., Tucman, I., Katančić, Z. Influence of ageing on optical, mechanical, and thermal properties of agricultural films. Lundin, T., Cramer, S. M., Falk, R. H. & Felton, C. Accelerated weathering of natural fiber-filled polyethylene composites. Fernández-González, V., Andrade-Garda, J. M., López-Mahía, P. & Muniategui-Lorenzo, S. Impact of weathering on the chemical identification of microplastics from usual packaging polymers in the marine environment. Li, W. et al. A facile synthetic approach to UV-degradable hydrogels. Kim, V. et al. Copper-based two-dimensional metal–organic frameworks for fenton-like photocatalytic degradation of methylene blue under UV and sunlight irradiation. Reliability & Lifetime of Multilayer Piezo Actuators. Sherrit, S. et al. Piezoelectric multilayer actuator life test. Zhao, J., Wang, P., Ma, H., Cheng, X. Essential role of Si in enhancing corrosion resistance of high strength low alloy steels in marine environment. Alves Nogueira, F. E. et al. New piezoelectric generator (PG) based on a lithium tantalate (LiTaO 3) monocrystal fiber. High-performance piezoelectric generator based on a monocrystalline linbo3 fiber. Platte, M. PVDF ultrasonic transducers. Shuvo, I. I. Microfabrication and characterization of a new box-shaped high frequency (7.5 MHz) low aperture 2D phased ultrasound transducer array [Master's thesis]. Li, S. et al. Stretchable Electronic Facial Masks for Sonophoresis. Polmar, N. The U.S. Navy: Tails for Warships. Boriskina, S. V. et al. Heat meets light on the nanoscale. Boriskina, S. V. et al. Roadmap on optical energy conversion. P Wurfel The chemical potential of radiation. Xu, J. et al. All-in-one hybrid atmospheric water harvesting for all-day water production by natural sunlight and radiative cooling. Fabrication of a Desalination Membrane with Enhanced Microbial Resistance through Vertical Alignment of Graphene Oxide. COMSOL AB, Stockholm, Sweden. Conde, M. R. Properties of aqueous solutions of lithium and calcium chlorides: formulations for use in air conditioning equipment design. Diab, M. S. & Rodriguez-Villegas, E. Performance Evaluation of Embedded Image Classification Models Using Edge Impulse for Application on Medical Images. This work has been supported by the Abdul Latif Jameel Water and Food Systems (J-WAFS) Lab at the Massachusetts Institute of Technology (S.V.B.). thanks his mother (late Jahanara Begum) and extends gratitude to Waleed Akbar, Tammy Lee, Joseph Paradiso, Mitchell Thompson, Steven Nagle, Jim Bales, and Mark Feldmeier for useful discussions, and to Rohit Karnik for access to his laboratory facilities. The authors thank Simo Pajovic for the help with the literature search for the data on theoretical and experimentally reported efficiency values of PV and solar-thermal energy converters. This work was carried out in part by using MIT.nano and ISN facilities at MIT. Media Lab, Massachusetts Institute of Technology, Cambridge, MA, USA Ikra Iftekhar Shuvo Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA Ikra Iftekhar Shuvo, Carlos D. Díaz-Marín & Svetlana V. Boriskina SmarAct Metrology GmbH & Co. KG, Oldenburg, Germany Marvin Christen & Michael Lherbette Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA, USA Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar Search author on:PubMed Google Scholar prepared the hydrogel samples. performed all the material and device characterizations. designed, prototyped, and tested the portable collection system. characterized and analyzed the vibrational modes of actuators. carried out numerical modeling. and C.D.D-M. performed techno-economic analysis. analyzed and interpreted the results. drafted the manuscript with input from all other authors. Correspondence to Svetlana V. Boriskina. Provisional Patent Application has been filed (inventors: S.V. Nature Communications thanks Chao Chang and the other anonymous reviewer(s) for their contribution to the peer review of this work. A peer review file is available. Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Open Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by-nc-nd/4.0/. Shuvo, I.I., Díaz-Marín, C.D., Christen, M. et al. High-efficiency atmospheric water harvesting enabled by ultrasonic extraction. Version of record: 18 November 2025 Anyone you share the following link with will be able to read this content: Sorry, a shareable link is not currently available for this article. Provided by the Springer Nature SharedIt content-sharing initiative © 2025 Springer Nature Limited Sign up for the Nature Briefing newsletter — what matters in science, free to your inbox daily.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.scientificamerican.com/article/personalized-mrna-vaccines-will-revolutionize-cancer-treatment-if-federal/'>Personalized Cancer Vaccines Are Almost Here—But Federal Funding Cuts Could Derail Them</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.scientificamerican.com', 'title': 'Scientific American'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-11-18 10:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Personalized mRNA Vaccines Will Revolutionize Cancer Treatment—If Funding Cuts Don't Doom Them Vaccines based on mRNA can be tailored to target a cancer patient's unique tumor mutations. But crumbling support for cancer and mRNA vaccine research has endangered this promising therapy As soon as Barbara Brigham's cancerous pancreatic tumor was removed from her body in the fall of 2020, the buzz of a pager summoned a researcher to the pathology department in Memorial Sloan Kettering's main hospital in New York City, one floor below. Brigham, now 79, was recovering there until she felt well enough to go home to Shelter Island, near the eastern tip of Long Island. These sections were embedded in hot paraffin and cut into slices a fraction of the thickness of a human hair, which were prepped, stained and mounted on glass slides to be photographed again. Made of messenger RNA (mRNA) suspended in tiny fat particles, the vaccine was essentially a set of genetic instructions to help Brigham's immune system go after the mutant proteins unique to her tumor cells. It was, in other words, her very own shot. If you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today. “I'm a little crippled here and there with arthritis,” Brigham says, but “I never sit still.” And she remains free of pancreatic cancer. Brigham's recovery came as part of a small phase 1 clinical trial conducted by Memorial Sloan Kettering in partnership with pharmaceutical companies Genentech and BioNTech—the latter, along with Pfizer, helped to produce the first approved mRNA vaccine for COVID-19. Brigham was one of 16 patients in the study who received the vaccine, administered in tandem with standard drugs, and one of eight who experienced a significant immune response. Six of those eight patients are still in remission, along with one of the eight others who did not show much immune response to the vaccine. Pancreatic cancer can be exceptionally fast-growing, and its first signs—weight loss, cramping, a touch of jaundice—are easily missed, so by the time it is diagnosed it is almost always lethal. The results of Brigham's trial were also an early sign that mRNA vaccines may be effective for a wide variety of cancers: whereas pancreatic cancer is known for its low rate of mutations, the earliest data on personalized mRNA vaccines came from studies of melanoma, which researchers had targeted specifically because it tends to mutate so frequently. An earlier phase 2 trial in patients with advanced melanoma found that for those who received both a personalized mRNA vaccine and so-called immune checkpoint inhibitors, the risk of death or recurrence decreased by almost half compared with those who got only checkpoint inhibitors. In each case, the vaccine is additive: administered after surgery and with standard drugs. The shot's job is to prime the immune system to recognize abnormal proteins arising from mutations and attack any lingering malignancy that escaped conventional treatments—or stamp out future recurrence. Seeing promising results in fundamentally different kinds of tumors has motivated researchers to pursue personalized mRNA vaccines much more broadly. In doing so, they've developed an approach at the nexus of several important trends, pairing insights about our immune system's response to cancer with advances in vaccine production spurred by the COVID pandemic, the rise of algorithms powered by artificial intelligence, and the plummeting cost of genetic sequencing. Today there are at least 50 active clinical trials in the U.S., Europe and Asia targeting more than 20 types of cancer. A melanoma trial led by pharmaceutical companies Moderna and Merck has now reached phase 3, the last step before a medicine can be approved for public consumption. In the first weeks of the second Trump administration, U.S. cancer research was thrown into unprecedented turmoil as federal grants were terminated en masse. According to one Senate analysis, funding from the National Cancer Institute was cut by 31 percent in just the first three months of 2025. By March cancer researchers worried that mRNA vaccines were facing particular scrutiny. KFF Health News reported that Michael Memoli, acting director of the National Institutes of Health, had asked that any grants, contracts or collaborations involving mRNA be flagged for Health and Human Services Secretary Robert F. Kennedy, Jr., best known prior to assuming that role as one of the nation's most prominent anti-vaccine campaigners. Suddenly, the optimism around personalized mRNA vaccines was overshadowed by a sense that the public investment that sustained cancer research was being dismantled piece by piece. Much of cancer's biological power comes from the fact that to the body, it doesn't always seem like a pathogen. Physicians long hypothesized that there was a link between cancer and swelling—a critical sign that the immune system “sees” an enemy to ward off. In the 1890s William Coley, now known as the father of immunotherapy, successfully spurred remission in patients with inoperable tumors by injecting them with bacteria like those that cause strep throat. But the mechanisms behind Coley's treatments were poorly understood, and for decades after his discovery, researchers weren't sure our immune systems could detect cancer at all. Because doctors didn't know exactly how the body perceives and responds to cancer, early treatments were highly invasive and highly toxic: The first tactic was major surgery on the organs where cancer was taking root. Over time oncologists narrowed and refined these approaches incrementally, using more precise surgery, more focused radiation and chemo that killed fewer normal cells as collateral. Still, the dream was to harness immunotherapy, which represented a dramatic departure from the usual tactics in seeking to use the human body's own systems to go after cancer in a more targeted way. As demand for COVID vaccines has slackened, there has been a rush to apply mRNA technology to a long list of illnesses. Some forms of cancer use fibrous tissue called stroma to construct shields that make it difficult for immune cells to penetrate or attack tumors. Other cancers take advantage of the balancing act our immune systems are always performing when they decide how heavily to invest the body's defenses in warding off a given threat. Some tumors produce proteins that can shut down key immune cells. Tumors may even recruit immune cells to promote the growth of blood vessels that will supply them with oxygen and nutrients. As scientists learned more about how cancer manipulates the immune system, they started identifying ways to thwart it. Inside our cells, proteins are constantly being chopped up into smaller sequences of amino acids, some of which are then presented on the cell surface as part of what's collectively known as the major histocompatibility complex, or MHC—essentially the immune system's tool for differentiating self and foreign molecules. When the immune system detects a protein from a pathogen, it's supposed to dispatch killer T cells to eliminate the invader. Some cancers can interfere with this process by hijacking the checkpoint proteins that keep our immune system from revving out of control and using them to turn T cells off. Starting in the mid-1990s, several research teams found success by treating mice with checkpoint inhibitors, then a new class of drugs designed to keep tumor cells from concealing their identity and signaling, effectively, “nothing to see here.” Thirty years on, checkpoint inhibitors have become a transformative tool in cancer treatment, especially for melanoma. The research that went into developing checkpoint inhibitors showed conclusively that immune cells detect cancer much in the same way they identify other pathogens: through differences in protein structure determined by DNA—a crucial insight. Researchers are still trying to understand all the mechanisms that play a role in determining who does respond, but one key factor is whether the immune system is able to recognize tumor cells on the basis of their mutations. Jason Luke, a melanoma researcher who now serves as chief medical officer of mRNA-medicine start-up Strand Therapeutics, helped to design several ongoing clinical trials of mRNA vaccines for cancer. He explains that both checkpoint inhibitors and mRNA vaccines build on our deep evolutionary adaptation for fighting pathogens by identifying the proteins they shed in our bodies. In contrast, mRNA vaccines have the potential to work even in patients whose cancers haven't spurred much immune response. The trick, Luke says, is using computational tools to decipher which of a given tumor's mutations are most likely to be found by the immune system. On a Monday morning last April, I visited surgical oncologist Vinod Balachandran at his lab on the eighth floor of the Memorial Sloan Kettering Cancer Center. Balachandran led the trial Brigham participated in, and he now is director of a center for cancer vaccines that the institution launched in 2024. The work that culminated in Brigham's vaccine grew out of research into a subset of pancreatic cancer survivors known as exceptional responders—the small percentage of people who make it to the five-year mark after a diagnosis. “These patients, you know, they're very rare,” Balachandran says. When Balachandran joined the faculty in 2015, his research on long-term survivors relied on tissue samples taken more than a decade earlier. In 2017 Balachandran and his collaborators published a study demonstrating that some patients with pancreatic ductal adenocarcinoma had more cells able to recognize the unique proteins that mutant tumor cells produced and that their immune systems seemed to develop a kind of long-term memory to fight recurrence. In some cases, immune cells with receptors that could bind to these cancer proteins persisted in the blood for more than a decade after the tumors that spawned them were removed. What if, Balachandran wondered, we could equip the 92 percent of patients who are not naturally exceptional responders with the same kinds of biological tools? “If you can teach the immune system to recognize the proteins in, say, pancreatic cancer, perhaps that could provide a blueprint,” he says. As tumors grow and metastasize, they undergo a kind of compressed evolution in which normal cells with the host's DNA accrue mutations that cause them to divide and multiply abnormally, forming an ever larger group of closely related tumor clones. Balachandran compared this growing family tree of tumor clones with new variants in a group of viruses, like the Alpha, Delta and Omicron variants of SARS-CoV-2, which emerged as the COVID-19 pandemic wore on. “At some point—we don't think immediately—the immune system starts to notice,” says Benjamin Greenbaum, Balachandran's colleague at Memorial Sloan Kettering's Olayan Center for Cancer Vaccines, who led the computational work behind the vaccine given to Brigham. “So then the question really became, Can we try to estimate what the immune system is really seeing in cancer?” To develop a workable mRNA vaccine, Greenbaum and Balachandran had to both sequence the DNA of the cancerous tumors they were targeting and develop a framework for going after the right neoantigens—those abnormal proteins that offer clues to a tumor's underlying mutations. One overarching goal of their collaboration is to discern meaningful patterns in the frequency of the sequences across patients and across cancer types. Which ones show up reliably under certain conditions or look most distinctive to the body's immune defenses? For decades researchers pursuing vaccines and other immune treatments for cancer had focused on melanoma because melanoma tumors have a high rate of genetic mutations. “It looks very different to the immune system than many other types of cancers do,” says Michael Postow, a medical oncologist at Memorial Sloan Kettering who is involved in clinical trials of mRNA vaccines for melanoma. With the results from the 2017 study of exceptional responders in hand, Balachandran was able to flip that argument on its head. Even if vaccines appear to be well suited for melanoma, there's always a degree of uncertainty in selecting the right antigens to target. What is more, not every antigen that corresponds to either self or not self is reliably expressed on the surface of the corresponding cell. A neoantigen that seems characteristic of the tumor might have a profile nearly identical to that of another self-antigen somewhere else in the body. In that case, a vaccine based on that neoantigen might fail to elicit much of an immune response, or it could provoke a response against the wrong target. The study revealed a potential liability in a strategy for personalized mRNA vaccines that focused on melanoma: melanoma's high rate of mutations gives rise to a large pool of plausible vaccine targets, but it presents just as many chances to guess wrong. A given tumor could have as many as 10,000 distinct proteins on the surface of its cells; you couldn't possibly target every one. But in pancreatic cancer, Balachandran realized, the smaller number of mutations might improve the odds of picking a suitable antigen to target. That insight underpinned the pitch Balachandran brought to Ugur Sahin, co-founder and CEO of German biotech company BioNTech. Together with Moderna, the company demonstrated the vaccine's safety through billions of doses administered worldwide with very few side effects. Not only was mRNA safe for vaccine delivery, but, as Sahin knew from experience, it is also a flexible platform for genetic information. BioNTech's COVID vaccine built on 30 years of work by Sahin and company co-founder Özlem Türeci that was originally intended for vaccines targeting cancer. As global demand for COVID vaccines has slackened, there has been a mounting rush to apply mRNA technology to a long list of illnesses, including malaria, flu, tuberculosis and norovirus. Despite treatment advances, it remains broadly incurable and is a leading cause of death as life expectancies improve across the world. Moderna employed under 1,000 people and had manufactured fewer than 100,000 total doses of its clinical-stage vaccines. Once its SpikeVax received emergency use authorization from the U.S. Food and Drug Administration, the company quadrupled its workforce and produced more than a billion doses in just 18 months. The task facing Scott Nickerson, who oversees Moderna's manufacturing for individualized neoantigen therapies, was to reengineer a process perfected for producing mRNA vaccines for millions of people in batches of thousands of liters. For personalized vaccines, each batch would be a few milliliters at most and would have to be turned around in weeks. To get there, Moderna is investing heavily in automation, partnering with a robotics firm to prepare sterile kits of raw materials for each batch and thereby minimize operator touch time on the manufacturing floor. The hope is that rather than following a single large batch of vaccine through the entire manufacturing process, workers will eventually be able to move from one small batch to the next after setup. At both Moderna and BioNTech, the complex logistics of conducting the dozens of different quality-control tests required for each production run falls to algorithms powered by AI. Before being approved for release, doses of SpikeVax underwent 40 distinct tests that tracked the chemistry, biochemistry, microbiology and sterility of every vial. Refinements have since compressed that test to eight days, Nickerson says. At the same time, the background science is, at least in theory, easily adapted from work that's already been done. Lennard Lee, an adviser to the U.K.'s National Health Service overseeing the rollout of clinical trials for cancer vaccines, says the pandemic gave regulators there a running start on trials for mRNA cancer vaccines. In that interval, as manufacturers work to reduce production times and costs, clinical trials will evaluate alternative dosage and delivery mechanisms, Lee says. Although current protocol is for vaccines to target micrometastases—small groups of cancer cells that spread to other parts of the body and linger after cancerous tumors are removed surgically—there's no shortage of adjustments that might follow from more data or improved screening. Or maybe one could even administer a prophylactic shot that prevents tumor formation in the first place? With a unified health system and world-class research and manufacturing facilities, Lee says, the U.K. is well positioned to advance research that would answer such questions. In President Donald Trump's first term, threatened cuts to the NIH never quite materialized. Society is not going to let that happen, Merad thought. “This is an operation,” Merad says, gesturing to the building where she works, which is dotted with six-figure pieces of equipment and has an entire floor dedicated to rearing mice used in research. We have to pay service contracts because we have instruments that need to be serviced all the time.” These are not expenses that can be easily paused or restarted based on the fate of a single grant. Senate Republicans convened a hearing entitled “The Corruption of Science and Federal Health Agencies,” featuring the false claim that as many as three out of four deaths from COVID were caused by mRNA vaccines deployed to stop the pandemic. (In fact, COVID vaccinations saved an estimated 2.5 million lives between 2020 and 2024, according to a study published earlier this year.) He eventually replaced them with his own advisory committee, which includes several anti-vaccine stalwarts. Kennedy has also slashed research funding for mRNA vaccines. In August he canceled nearly $500 million supporting the development of mRNA vaccines against viruses such as SARS-CoV-2 and influenza. After my visit to Memorial Sloan Kettering, Balachandran's team shared a chart that plotted Brigham's immune response to her personalized mRNA vaccine. Above them a cluster of brightly colored lines showed the share of her body's T cells targeting the specific mutant proteins in her cancerous tumor. At first, when Brigham's tumor was removed, cells trained to go after each cancer clone were somewhere on the order of one in 500,000 T cells in her blood. A few months after surgery, when she'd had four doses of the vaccine, the lines shot up almost vertically, showing that the most common cancer fighter at that point accounted for around one in 20 to one in 50 T cells—an increase of more than 20,000-fold. Those T cells dipped a bit in the months before Brigham's last booster shot, given almost a year after her tumor was removed. But they remained in the same range even three years on. A phase 2 clinical trial evaluating the safety and efficacy of the vaccine in a larger patient group is currently underway. The vaccine for Brigham's cancer was just nine tiny vials of liquid administered through an IV, a private message that only her immune system was meant to decode. But the effort that delivered that coded message was a deeply collective enterprise, one that stretches back through the hundreds of thousands of tissue samples collected, stored and analyzed at Memorial Sloan Kettering, each one taken from the body of a patient who might not have survived their cancer. Rowan Moore Gerety is a reporter and audio producer in Phoenix, Ariz., and author of Go Tell the Crocodiles: Chasing Prosperity in Mozambique (The New Press, 2018). If you enjoyed this article, I'd like to ask for your support. Scientific American has served as an advocate for science and industry for 180 years, and right now may be the most critical moment in that two-century history. If you subscribe to Scientific American, you help ensure that our coverage is centered on meaningful research and discovery; that we have the resources to report on the decisions that threaten labs across the U.S.; and that we support both budding and working scientists at a time when the value of science itself too often goes unrecognized. In return, you get essential news, captivating podcasts, brilliant infographics, can't-miss newsletters, must-watch videos, challenging games, and the science world's best writing and reporting. There has never been a more important time for us to stand up and show why science matters.</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            