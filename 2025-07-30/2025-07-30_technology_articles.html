
<html>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" type="image/x-icon" href="../images/favicon.ico">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
        <title id="title">News'n'Clues - TECHNOLOGY Article Summaries - 2025-07-30</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <style>
            .menu { color: #444444; }
            .copyright { margin: 0 auto; }
            p { font-family: serif; }
            body {  background-color: #2c2c2c; font-family: Arial, sans-serif; font-size: 20px; color: #f4f4f4;  }
            a { text-decoration: none; color: #f4f4f4; }
            .section { margin-bottom: 20px; }
            .heading {
                font-size: 2rem;
                font-weight: bold;
                background: linear-gradient(90deg, #fc4535, #1a6198);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
                line-height: 1.3; /* Prevents letters from being cut off */
                padding-bottom: 5px; /* Ensures space below the text */
                margin: 30px;
            }
            .hidden {
                display: none;
            }            
            
        </style>
    </head>
    <body>
        <div id="banner" class="w-full">
            <img src="../images/banner.jpg" alt="News Banner">
        </div>

        <div id="title" class="w-full flex items-center" style="background-color: #fc4535;">
          <a href="../index.html"><img src="../images/logo.jpg" alt="News Logo" class="h-auto"></a>
          <div class="flex-grow text-center">
              <div id="title_heading" class="text-4xl font-bold mb-4" style="color:#1a6198;">Article Summaries</div>
          </div>
        </div>
        <div id='category_heading' class="section text-center heading">
            TECHNOLOGY
        </div>
        <div id="articles">
            
                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/crypto-justin-sun-blue-origin-date/'>Blue Origin sets the date for controversial crypto billionaire's $28M trip to space</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 20:58:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>In a posting to the X social-media platform, Sun said he was “proud to join Blue Origin's NS-34 mission and continue encouraging youth to pursue their dreams in science and space.” And in a follow-up posting, Sun claimed the title of “the youngest Chinese commercial astronaut.” Until recently, Sun was the subject of a federal investigation over alleged market manipulation and unregistered sales of crypto asset securities. That case was put on hold in February, and a couple of months later, Sun earned a place of prominence at a crypto dinner with President Donald Trump by purchasing the biggest share of the $TRUMP meme coin. It's not clear what impact Sun's travails have had on the timing of his spaceflight. Back in 2021, Sun was the winning bidder in an auction for a seat on Blue Origin's first crewed flight, which was set for later that year. However, Blue Origin said soon afterward that the winner — who at that time was anonymous — had to pass up the first flight due to scheduling conflicts. If all goes according to plan, Blue Origin's autonomously controlled New Shepard rocket ship will send the NS-34 crew members on what's expected to be a 10-minute-long suborbital space odyssey. Blue Origin doesn't typically reveal how much its customers are paying for their flights. Sun isn't the only controversial crypto figure to take a trip on New Shepard. In response to emailed inquiries, a Blue Origin representative told GeekWire that the company works with a third party to accept crypto payments for spaceflights. This report was originally published on July 21 and has been updated to reflect Blue Origin's announcement of the NS-34 launch date. Have a scoop that you'd like GeekWire to cover? Blue Origin's latest suborbital space trip hits milestones – and throws in a mystery Blue Origin sets the date for its first crewed suborbital space trip in 21 months Blue Origin sends six people on suborbital space trip, marking a first for researchers Blue Origin puts a lunar spin on suborbital research flight of New Shepard rocket ship</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/googles-newest-ai-model-acts-like-a-satellite-to-track-climate-change/'>Google's Newest AI Model Acts Like a Satellite to Track Climate Change</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 18:57:44
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Google's newest AI model is going to scour the Earth and, ideally, help it out. Crucially, once the model has supposedly done this it will also, apparently, explain where we might be able to best put things in place to help our world. AlphaEarth Foundations, an offshoot of Google's DeepMind AI model, aims to leverage machine learning and all the gobs and gobs of data that Google has absorbed about our planet over the last two decades, in order to understand how specific areas are changing over time. The model uses a system called “embeddings” that takes terabytes of data collected from satellites every day, analyzes it, and compresses it down to save storage space. The result is a model of different filters overlaid over maps that are color coded to indicate material properties, vegetation types, groundwater sources, and human constructions such as buildings and farms. Google says the system will act as a sort of “virtual satellite,” letting users call up on demand detailed information about any given spot on the planet. The goal, Google says, is for users of the service to be able to better understand how specific ecosystems on the planet work, including how air quality, sunlight, groundwater, and even human construction projects vary and change across a landscape. It has also supposedly outlined variations in Canadian agricultural land use that are invisible to the naked eye. Google's new model assigns colors to AlphaEarth Foundations' embedding fields. Chris Brown, a research engineer at Google DeepMind, says that historically, there have been two main problems for making reliable information about the planet more accessible: Getting overloaded with too much data; and that information being inconsistent. “Now, the challenge is to unify all the ways that we have to observe and model our planet and get a complete picture.” Google, of course, has been at this for a while. While AlphaEarth isn't a broader consumer-facing application, Google Earth has had its own similar timelapse feature since 2021 that shows how global geography has changed over decades—largely due to climate change. Google has also gotten into the game of putting more specific types of satellites into orbit, such as ones that are designed to spot wildfires from space. But sucking up petabytes of satellite images and finding the trends is, weirdly, a more straightforward task for AI. Google says the models can generate accurate enough data about an ecosystem down to an area of 10 meters—and while it may get some things wrong, it is apparently 23.9 percent more accurate than similar AI models. (Goggle didn't name which ones it was talking about, but companies such as Privateer have been at this for years.) How AlphaEarth Foundations works: by taking non-uniformly sampled frames from a video sequence to index any position in time, the model creates a continuous view of the location while outlining measurements. Google has worked with partners to test the new system, such as MayBiomas in Brazil and the Global Ecosystems Atlas, which aim to better classify undermapped ecosystems including dense rainforests, deserts, and wetlands. After working with Google to test AlphaEarth for the past 18 months or so, Azeved says the software has made it easier to analyze great swathes of rainforest yet keep that data from overwhelming their storage capabilities. “We were not even scratching everything that would be possible,” Azeved says. It's worth noting here that this is separate from the more consumer-friendly Google Earth. Previously, Google's Earth Engine processes and analyzes satellite data that has then been used to create interactive, high-resolution maps of deforestation across the world and compile detailed views of bodies of water—rivers, lakes, oceans, and seas—and how these had changed over time. No stranger to privacy concerns, Google is eager to wave off any worries people might have about this new system scouring pictures from the sky. In your inbox: Five new newsletters by deeply sourced experts</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/gamers-are-furious-about-the-censorship-of-nsfw-games-and-theyre-fighting-back/'>Gamers Are Furious About the Censorship of NSFW Games—and They're Fighting Back</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 18:51:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Trade organizations across the games industry and gamers are speaking out against censorship campaigns taking place across Steam and Itch.io in an effort to help developers who have been unfairly impacted. The push against adult content is being driven by Australian conservative group Collective Shout, whose pressuring of payment processors has forced platforms to mass deindex NSFW content. On platforms like Bluesky, users are compiling lists of “censored artists” with NSFW pieces and unsearchable Itch pages, whether it's games or comics, many of whom identify their work as LGBTQ+ or kink friendly. WIRED was able to find several of these pages via Google, all of which were tagged by their creators in that document as LGBT and NSFW, but not with Itch's search tools. In a statement given to WIRED, executive director Jakin Vela says that the IGDA is “seriously alarmed” by the delistings and payment disruptions of adult-themed games on Steam and Itch. Over the past few months, Collective Shout has been campaigning to get “rape and incest” games removed from online platforms. The group began applying pressure to payment processors such as Visa and Mastercard; Valve removed hundreds titles, some of which included incest. Other developers, however, such as the creators of horror game Vile: Exhumed, say their games did not violate these standards. “It was banned for ‘sexual content with depictions of real people,' which, if you played it, you know is all implied, making this all feel even worse. “To ensure that we can continue to operate and provide a marketplace for all developers, we must prioritize our relationship with our payment partners and take immediate steps towards compliance.” The company has suspended its Stripe payments on 18+ content “for the foreseeable future” and is “actively reaching out to other payment processors that are more willing to work with this kind of content.” The company has a longstanding policy of not working with adult content services. In a previous statement to WIRED, Collective Shout campaigns manager Caitlin Roper said the organization had had “no communication with payment processors” outside of an open letter. In a blog posted July 28, however, Collective Shout says it “approached payment processors because Steam did not respond to us.” Corcoran told WIRED that Collective Shout had not spoken to Itch. It essentially sidesteps a platform's own rules for what it will allow and puts that decision directly in the hands of payment processors, which impacts what companies are allowed to sell. “Platforms have long had terms of service restricting content such as non-consensual acts, rape, incest, and material that violates payment processor guidelines,” says Vela. “The concern today is not the existence of these rules, but rather that their enforcement is adversely impacting games that do not actually violate these restrictions, often without warning or explanation.” Corcoran told WIRED that he believes the confusion stems from Itch not providing clear information on users' dashboard about indexing eligibility of pages. “A handful of devs incorrectly assumed their pages were affected by our July 24th change and posted statements on social media,” he said. “Press publications picked up these posts without any further verification which led to an incorrect narrative being spread further.” Corcoran said that pages that were incorrectly assumed delisted were “due to our existing indexing eligibility rules outlined in our indexing guide, related to missing requirements like files uploaded, cover images, or in a few cases a ‘first time seller' review process.” The German games industry association, game, has called developers' artistic freedom “fundamental to games as a cultural medium.” Managing director Felix Falk said in a statement that restrictions from payment service providers and gaming platforms should not override what's legally allowed, and that service providers like Visa, Mastercard, and PayPal's terms and conditions should not conflict with free expression. The IGDA is advocating for concerned parties to contact financial institutions like Mastercard and Visa directly, as well as support online petitions that ask these companies to stop interfering with entertainment and sex work. “Mastercard and Visa have increasingly used their financial control to pressure platforms into censoring legal fictional content,” reads the campaign for a Change.org petition with over 185,000 signatures. “Entire genres of books, games, films, and artwork are being demonetized or deplatformed—not because they're illegal, but because they offend the personal values of executives or activist groups” One artist who makes adult content, who asked to remain unnamed out of fear of their financial accounts being affected, tells WIRED that they were “hung up on twice by Visa” on Tuesday. The second time I was told by a clearly frustrated rep that he would not connect me to a supervisor, and that Visa is no longer answering questions about policy.” The artist describes Collective Shout and Morality in Media as “puritanical groups using the very real and legitimate fears of child exploitation to push through their right-wing policies.” In the adult entertainment industry, platforms have faced similar pressures involving anti-porn groups claiming to fight sexual exploitation by using payment processors to get content banned. Visa and Mastercard previously cut off payments to Pornhub; OnlyFans briefly banned, and then reversed a stance on sexually explicit content due to bank influence. Just this week, new child online safety laws in the UK kicked in that now require millions of adults to submit to ID document uploads, face scans, credit card checks, and more to access pornography; similar age-verification laws have been implemented in over 20 states. Critics say although these measures are aimed at protecting kids, they open the door for a mountain of privacy and surveillance problems. “We could not rely on user-provided tagging to be accurate enough for a targeted approach, so a broader review was necessary to be thorough” the post reads. Losing PayPal, for instance, would prevent us from sending payouts to many people.” The company says it is still waiting for final determinations from its payment processors. “Itch.io can definitely have more transparency here,” says Corcoran, “and we're sorry for the stress we caused to any developers who were caught up in the confusion.” Update: 7/30/2025, 3:39 PM EDT: WIRED has updated the article with a comment from Itch.io</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/artificial-intelligence/metas-zuckerberg-outlines-vision-for-personal-superintelligence-in-a-letter-says-that-unlike-rivals-his-approach-isnt-about-automating-everything'>Meta's Zuckerberg outlines vision for 'personal superintelligence' in a letter — says that, unlike rivals, his approach isn't about automating everything</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 18:14:50
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. But today, the Meta CEO staked his next big bet on what he calls “personal superintelligence.” Unlike past efforts, this one isn't just about virtual spaces or avatars: It's about building AI that feels like an extension of yourself, and it's going to require some of the most powerful hardware stacks on the planet. “This is not about automating all valuable work,” he wrote. “It's about empowering individuals with intelligence tailored to their lives.” That's a subtle jab at OpenAI's and Google's increasingly centralized AI strategies — ones that push AGI as a force of mass replacement rather than augmentation. In the past few months alone, Meta has funneled billions into AI R&D, recruiting top talent from OpenAI, Google DeepMind, and Anthropic. The new Meta Superintelligence Labs — headed by former Scale AI CEO Alexandr Wang — will reportedly be responsible for developing foundation models such as Llama, alongside deeper research into AI architecture and inference. Of course, running those models at scale requires more than talent: it demands infrastructure. Lots of it.Sources close to Meta's datacenter expansion say the company is already deploying custom accelerators in limited workloads alongside traditional NVIDIA H100s and A100s. Meanwhile, there's speculation that Meta may be co-developing AI silicon in-house for future iterations of its Llama-based models, echoing Google's TPU strategy. At the very least, Meta has ramped up its own MTIA (Meta Training and Inference Accelerator) program, with next-gen silicon rumored to be taped out later this year.Whether these chips will directly power "personal superintelligence" experiences remains unclear. But if Meta plans to deliver real-time, private AI companions at the edge or in VR devices, rather than purely cloud-delivered interactions, the hardware stack will need to be both extremely fast and extremely efficient. Since then, Meta's Reality Labs division has racked up over $60 billion in losses, much of it spent on hardware such as Quest headsets, haptic gloves, and AR displays that are still struggling to gain traction. These are numbers that make Intel's gloomy present and future look acceptable in comparison.That said, unlike the metaverse, AI has immediate product-market fit. The only constraint now is how fast the hardware can scale — and whether Meta can compete with Nvidia, AMD, and custom players such as Tenstorrent or Cerebras, in pushing the performance-per-watt frontier.Zuckerberg's tone was optimistic, but measured. But behind the scenes, it's quickly becoming a material one — with all the heat, silicon, and supply chain pressure that comes with it.Follow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Hassam Nasir is a die-hard hardware enthusiast with years of experience as a tech editor and writer, focusing on detailed CPU comparisons and general hardware news. When he's not working, you'll find him bending tubes for his ever-evolving custom water-loop gaming rig or benchmarking the latest CPUs and GPUs just for fun. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/amazon-q2-earnings-preview-ai-bets-cloud-growth-and-tariff-changes-in-the-spotlight/'>Amazon Q2 earnings preview: AI bets, cloud growth, and tariff changes in the spotlight</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 17:16:50
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Amazon's infrastructure investments and cloud business will go under the microscope Thursday when the company reports second-quarter financial results — with Wall Street looking for signs that the tech giant's big bet on artificial intelligence is translating into growth. The company disappointed investors in May with a softer-than-expected forecast for Q2 operating profits, but analysts are more optimistic heading into the earnings report. Wedbush analysts cited “encouraging US retail data, healthy advertiser sentiment, strong AWS demand, and continued efficiency gains across the business that should drive upside to margin expectations,” in a July 30 research report previewing Amazon's earnings. Here are the latest Wall Street estimates, according to Yahoo Finance: Analysts' projections would put Amazon near the midpoint of its prior revenue forecast and toward the high end of its projected operating income range. Like other tech giants, Amazon is spending big to build out infrastructure for AI and cloud services. Other areas to watch: Amazon's Project Kuiper satellite internet venture, its partnership and investment in AI startup Anthropic, and whether the company signals further increases in capital spending as it races to build out infrastructure for the next phase of generative AI. Amazon earnings preview: Cloud growth, AI demand, and tariff risks in focus Amazon earnings preview: AWS cloud growth, AI demand, trade wars among key issues to watch Amazon earnings preview: Analysts watching AWS growth, retail margins, Project Kuiper Expedia warns of lower travel demand but stock rises 7% after Q2 earnings</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.wired.com/story/electric-vehicles-china-takeover/'>Everything You Wanted to Know About China's Auto Industry Takeover</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.wired.com', 'title': 'WIRED'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 17:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>All products featured on WIRED are independently selected by our editors. For one thing, after substantial government support and poaching of top Western talent, China's car industry is about to dominate globally with charging rates, ranges, luxury design, technology, and sheer volumes. Moreover, it's no longer content with serving its own enormous market as Chinese brands make serious inroads across Australia and Europe. WIRED senior editor and auto obsessive Jeremy White hosted a Reddit AMA earlier this month to directly answer your questions about the future of cars and EVs as the global market dramatically shifts. Questions and responses have been edited for clarity. Musk's horrific journey into politics aside, do you think Tesla has a future, with pressure from BYD and its failure to develop a cheaper model, among other challenges? So let's keep in mind that Tesla still sells a lot of cars. That said, Tesla has an aging fleet, it has a CEO with his attention diverted very much elsewhere, and, most of all, right now it has a brand and reputation problem. Musk's DOGE antics have directly hit the company—even their finance chief Vaibhav Taneja was forced to admit so on its April earnings call, saying “unwarranted hostility towards our brand and our people had an impact in certain markets.” And the Cybertruck has been an unmitigated disaster. It needs a new cheap electric car, and no amount of dressing up the Model Y in new clothes is going to cut it. It also needs to look at its autonomous tech, because Chinese brands all favoring Lidar are beating it there too. Let's face it, the Chinese brands have learned a great deal from Tesla and are now coming for Elon's lunch—and, right now, Tesla is not really in a position to compete. How long can the board put up with these dismal sales figures? But one thing is for sure: it cannot carry on like this. Will China really be able to make inroads into the European market given the combination of tariffs and European consumer preference for their own homegrown brands? Chinese automaker BYD now outsells Tesla in Europe, and it is now launching its premium brand, Denza, there too—think Audi or BMW level. More are on their way of course, but the consumer preference has not seen people turning away from China EVs so far, it seems. At the end of 2024, over 75 percent of the European highway network had chargers that were at most 50 km apart, whereas only just over a third of the US interstate highways achieved this. There's so much work to be done here, and the scale gap is absolutely enormous: the US will supposedly need 28 million EV charging ports by 2030 to support 33 million EVs. Japan also arguably started with economy cars and moved up, while China is trying to compete across all segments, from budget (see Xiaomi's new answer to the Model Y) to luxury (see BYD's Yang Wang! Japan perfected existing internal combustion engine technology, as well as production of course; China is betting on next-gen platforms. China's speed-over-patience approach seems to be working, apart from in one key area: as Japan took much longer to build its industry, it had much longer to develop lasting brand loyalty and premium positioning. Chinese auto brands are going too fast to do that right now, I'd say. How are the Japanese and Korean automakers reacting to China? Or is it mostly the same as most Western manufacturers? One could say their reaction has been more desperate and aggressive, maybe because of their proximity and the threat they face. Honda and Nissan's $58 billion merger that was floated, then called off, is a good example. Hyundai has cut its long-term vehicle sales targets as it gears up for aggressive marketing by Chinese rivals. But, ultimately, they face the same problem of the rise of China EV companies as North American and European carmakers do. The US auto sector has increasingly relied on a heavily integrated supply chain between Canada and Mexico, which Trump's tariff regime has thrown into chaos. Does a disunited North American auto sector have any real hope of mounting a challenge to Chinese auto makers? The Chinese challenge isn't primarily about supply-chain efficiency though—it's about tech, pricing, and what buyers think of China's cars. BYD now has nearly one third of China's EV market compared to Tesla's 6 percent, and now Chinese brands are coming for global markets (take a look at Europe and Australia) with pricing that Tesla just can't match unless it has another Model 3 moment. And the Model Y refresh hasn't worked. If American automakers ramp up development on their EV tech, like GM and Ford are trying to do right now, reduced battery costs will happen for sure and they can compete. Leveraging US strengths in trucks, luxury, and long-established brands will be key, too. Basically it all comes down to whether American automakers can innovate fast enough. The tariffs may actually slow that innovation by increasing costs and complexity. So what exactly can we expect coming on the market? Lucid's Air Grand Touring just set a Guinness World Record for the longest EV drive, powering along for 749 miles on a single charge. This is why residual value of EVs is so bad—the tech keeps getting better so quickly that cars like the Porsche Taycan plummet in value after just a year because better incoming tech is making these models look old at a frightening pace. Are any of the new Chinese brands addressing this, like Tesla did with Superchargers but on a bigger scale? Dealing with charging point apps is horrendous and would make anyone think twice about getting a full EV as opposed to a hybrid. Legislation is needed to make these companies play nice with each other, and not just in one country but globally—but you can imagine just how tough that is going to be. So that might explain the slow conversion we are seeing. Apparently, last year the US had nearly 9,000 public fast-charging stations, or about one fast-charging station for every 15 gas stations. As for what China is doing, well, it's being smarter. BYD supposedly wants to build more than 4,000 new ultra-fast charging stations across China, with flash-chargers that can provide a full charge in just 5 to 8 minutes. Basically, Chinese brands are attempting to leapfrog the entire existing infrastructure with ultra-fast charging networks that make the Tesla Supercharger look slow. This could be a much bigger change than retrofitting gas stations. In Europe, there's a company called Dacia that's managed to gain a lot of market share by producing cars that are consistently the cheapest in the market, and it does that by using trailing-edge hardware (a lot of it older Renault parts). I'm curious, why isn't there something similar in the US? I can't say too much here as we're working on a piece right now on this very subject—so keep an eye on WIREDs Gear channel where we put all our auto coverage. Dacia is an interesting example as they have managed to be cheap through a couple of ways: First, the brand offers few to no options, the cars basically come as you find them, and they are not top spec by any means (but they are well-designed). The new design duo they have there are excellent. Second, Dacia also produce some of their cars in China to keep costs down, like the ridiculously cheap Spring, which I tested out and was mighty impressed by. The US needs to get much more into this budget EV space, and that's what Jeff Bezos is trying to do with Slate, of course. In your inbox: Five new newsletters by deeply sourced experts Exclusive: Up To 50% Off 6 Boxes With Factor Promo Code WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=44736646'>Australia widens teen social media ban to YouTube, scraps exemption</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 16:59:43
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>And lets note that the ALP government is very fast and snappy to ban social media, very slow to do important things like:- ban money laundering in real estate- ban gambling advertisingAnd very quick to:- approve massive new coal mines- approve massive new natural gas projectsThe Australian government hates social media because that's where the people get to say what they think of the governmnent - in real time. - ban money laundering in real estate- ban gambling advertisingAnd very quick to:- approve massive new coal mines- approve massive new natural gas projectsThe Australian government hates social media because that's where the people get to say what they think of the governmnent - in real time. - ban gambling advertisingAnd very quick to:- approve massive new coal mines- approve massive new natural gas projectsThe Australian government hates social media because that's where the people get to say what they think of the governmnent - in real time. And very quick to:- approve massive new coal mines- approve massive new natural gas projectsThe Australian government hates social media because that's where the people get to say what they think of the governmnent - in real time. - approve massive new coal mines- approve massive new natural gas projectsThe Australian government hates social media because that's where the people get to say what they think of the governmnent - in real time. - approve massive new natural gas projectsThe Australian government hates social media because that's where the people get to say what they think of the governmnent - in real time. Have a "show me more content like this" button, but again, no auto algorithmic feeds4. Filter out age inappropriate content.would be great for teenagers. I think the problem for YouTube is that it would be great for everyone else, too, so they'd get bombarded by "Hey, I want that version" requests, which would clearly make them less money.There is no moral high ground with basically any online platforms, it's all solely based on financials, and people should realize this. Have a "show me more content like this" button, but again, no auto algorithmic feeds4. Filter out age inappropriate content.would be great for teenagers. I think the problem for YouTube is that it would be great for everyone else, too, so they'd get bombarded by "Hey, I want that version" requests, which would clearly make them less money.There is no moral high ground with basically any online platforms, it's all solely based on financials, and people should realize this. Have a "show me more content like this" button, but again, no auto algorithmic feeds4. Filter out age inappropriate content.would be great for teenagers. I think the problem for YouTube is that it would be great for everyone else, too, so they'd get bombarded by "Hey, I want that version" requests, which would clearly make them less money.There is no moral high ground with basically any online platforms, it's all solely based on financials, and people should realize this. I think the problem for YouTube is that it would be great for everyone else, too, so they'd get bombarded by "Hey, I want that version" requests, which would clearly make them less money.There is no moral high ground with basically any online platforms, it's all solely based on financials, and people should realize this. I think the problem for YouTube is that it would be great for everyone else, too, so they'd get bombarded by "Hey, I want that version" requests, which would clearly make them less money.There is no moral high ground with basically any online platforms, it's all solely based on financials, and people should realize this. There is no moral high ground with basically any online platforms, it's all solely based on financials, and people should realize this. Australia has been going after US big tech for a long time I don't allow them near Instagram either.The chances of kids growing an attention span by seeing interesting stuff in installments of 30 seconds approaches zero really, really fast. Yes there's the possibility telling a fun joke, demonstrating an optical illusion, or some interesting curiosity in under a minute. It's totally different to find that your kid wasted an hour of their life doom scrolling over 150 videos of which they didn't even complete half, or that they spent it seeing half a dozen things videos of dubious quality: if it's half a dozen it's at least feasible to discuss with them why some are better than others.So, I'm very close to just banning YouTube (at the DNS level if required). Which is a shame, because I then can't share the interesting stuff with them, and neither can their teachers. I don't allow them near Instagram either.The chances of kids growing an attention span by seeing interesting stuff in installments of 30 seconds approaches zero really, really fast. Yes there's the possibility telling a fun joke, demonstrating an optical illusion, or some interesting curiosity in under a minute. It's totally different to find that your kid wasted an hour of their life doom scrolling over 150 videos of which they didn't even complete half, or that they spent it seeing half a dozen things videos of dubious quality: if it's half a dozen it's at least feasible to discuss with them why some are better than others.So, I'm very close to just banning YouTube (at the DNS level if required). Which is a shame, because I then can't share the interesting stuff with them, and neither can their teachers. The chances of kids growing an attention span by seeing interesting stuff in installments of 30 seconds approaches zero really, really fast. Yes there's the possibility telling a fun joke, demonstrating an optical illusion, or some interesting curiosity in under a minute. It's totally different to find that your kid wasted an hour of their life doom scrolling over 150 videos of which they didn't even complete half, or that they spent it seeing half a dozen things videos of dubious quality: if it's half a dozen it's at least feasible to discuss with them why some are better than others.So, I'm very close to just banning YouTube (at the DNS level if required). Which is a shame, because I then can't share the interesting stuff with them, and neither can their teachers. And it's not necessarily age/quality rating of content; UX matters. It's totally different to find that your kid wasted an hour of their life doom scrolling over 150 videos of which they didn't even complete half, or that they spent it seeing half a dozen things videos of dubious quality: if it's half a dozen it's at least feasible to discuss with them why some are better than others.So, I'm very close to just banning YouTube (at the DNS level if required). Which is a shame, because I then can't share the interesting stuff with them, and neither can their teachers. So, I'm very close to just banning YouTube (at the DNS level if required). Which is a shame, because I then can't share the interesting stuff with them, and neither can their teachers. Imagine you're the one running a business where you keep repeatedly trying to shove some feature down your user's throat.What's that called in business school? See also: Facebook "efforts" to stop scam advertisements and Marketplace fuckery But you don't need an account to watch most videos on youtube, so this isn't banning all of youtube.. right? Market forces have not yielded a well-curated educational video experience on YouTube. I consider myself somewhat conservative in the traditional sense, and yet the Republican platform is almost diametrically opposed to my values. The major outcome of this legislation should be nothing more than Australian kids being the most familiar with VPN's and very little else, along with other tricks to bypass this. I mean, a legit app, not a 3rd party one that'll get my Google account banned eventually.I had to delete it, using:    $ adb shell pm uninstall --user 0 com.google.android.youtube It lasted a month for me that way; then I installed it, and after a week or two I fell into the old habit of Doomscrolling and had to nuke it again.TikTok/Reels/Shorts format is really, really exploitative on the mind. I had to delete it, using:    $ adb shell pm uninstall --user 0 com.google.android.youtube It lasted a month for me that way; then I installed it, and after a week or two I fell into the old habit of Doomscrolling and had to nuke it again.TikTok/Reels/Shorts format is really, really exploitative on the mind. It lasted a month for me that way; then I installed it, and after a week or two I fell into the old habit of Doomscrolling and had to nuke it again.TikTok/Reels/Shorts format is really, really exploitative on the mind. YouTube to be included in Australia's social media ban for children under 16 - https://news.ycombinator.com/item?id=44732683 - July 2025 (117 comments)(I haven't merged that one hither because it's quite a bit more generic than this one.) Then again, it may be better to do SOMETHING to start making these tech companies take solving these problems themselves seriously. Unlike what happens if they open the app and are pushed to doom scroll through dozens of videos on every 10 min school break. Now governments around the world are acting in unison to happily give those people what they want, and people are suddenly confused and pissed that these laws mean you need to submit proof that you're over 18. And instead of being an annoying checkbox that says "I'm 18. Leave me alone", it's needing to submit a selfie and ID photo to be verified, saved, and permanently bound to your every single action online.People who asked for social media bans for kids got what they wanted. Aren't "sharing platforms" and "social media" the same thing? I understand a long time ago there was a dream that people would produce and share as much content as they consume, and that is what social media was supposed to be in reference to, but that imagined world never happened. Social media, as used to refer to any practical service in the real world, has always been about one-sided content being shared to a mostly consumer-only audience.> increasingly viewed on TV screensAre people digging old Trinitrons out of the trash, or what? > increasingly viewed on TV screensAre people digging old Trinitrons out of the trash, or what? Are people digging old Trinitrons out of the trash, or what? This seems like throwing the baby out with the bathwater, but to be fair AI and really toxic context wasn't as big of a thing when I was in highschool Hopefully this forces Youtube to set up a limited educational version that the Australian government would be ok with. Things like this are generally going to be orders of magnitude better than any YouTube video. > weird how a foundational myth of australia is that we're a nation of subversive larrikins, when in actuality everyone here is an ultracop0: https://nitter.net/tfswebb/status/976299234491121665?lang=en We're seeing the same thing in the UK currently with fuzzy definitions of what does and doesn't need age verification, and even what verification means, and that's leading to completely harmless communities shutting down to avoid having to risk being in the wrong while the megacorps just hoover up some more metadata about users.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/pc-components/cpus/chinese-cpus-are-closing-the-gap-on-amd-next-gen-zhaoxin-chips-feature-96-cores-12-channel-ddr5-memory-and-128-pcie-5-0-lanes'>Chinese CPUs are closing the gap on AMD — next-gen Zhaoxin chips feature 96 cores, 12-channel DDR5 memory, and 128 PCIe 5.0 Lanes</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 16:53:06
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Zhaoxin is cooking up a beast in its labs. When you purchase through links on our site, we may earn an affiliate commission. Zhaoxin, one of China's top fabless semiconductor companies, has announced the company's next-generation KaiXian KX-7000N and Kaisheng KH-50000 processors at the World Artificial Intelligence Conference (WAIC) 2025. The former is a new consumer chip for AI PCs, while the latter is a server chip with specifications that rival AMD's EPYC portfolio. However, considering the significant upgrades in specifications and features, it is reasonable to assume that the Kaisheng KH-50000 adopts a new architecture. Zhaoxin just didn't want to reveal which one yet. This may be higher or lower than the Kaisheng KH-40000, which operates at 2.5 GHz. You may be aware that AMD's Genoa processors include 384MB of L3 cache. Indeed, the Kaisheng KH-50000 could potentially be an identical counterpart to Genoa. Similar to Genoa, the Kaisheng KH-50000 provides 128 PCIe 5.0 lanes and support for 12-channel DDR5 ECC memory, in addition to embracing the Compute Express Link (CXL) interconnect. The Kaisheng KH-50000 supports ZPI (Zhaoxin Processor Interconnect) 5.0, allowing partners to install two or four chips on one motherboard. This enables systems with up to 384 cores. Zhaoxin is riding the AI PC trend. This chip is likely based on the KaiXian KX-7000 but features an added NPU for AI tasks, which is probably what the "N" signifies in its name. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. The KaiXian KX-7000N marks a significant milestone for Zhaoxin, as it is the company's first chip to feature an NPU. However, Zhaoxin did not provide detailed specifications for the KX-7000N, only mentioning that it will have more cores and enhanced support for PCIe 5.0, unlike the current KaiXian KX-7000, which is limited to PCIe 4.0. Companies such as Zhaoxin and Lisuan Technology are making significant advances in hardware. Although Chinese-made processors and graphics cards haven't yet challenged industry giants like Intel, AMD, or Nvidia, that remains a future objective. Currently, their focus is on creating reliable products that deliver a decent enough computing experience. Each progress, big or small, moves China closer to achieving technological independence from the West. Zhiye Liu is a news editor and memory reviewer at Tom's Hardware. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. © Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York,</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.geekwire.com/2025/report-amazon-to-pay-at-least-20m-a-year-in-ai-content-deal-with-new-york-times/'>Report: Amazon to pay at least $20M a year in AI content deal with New York Times</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.geekwire.com', 'title': 'GeekWire'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 16:48:35
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Amazon's deal to license some content from The New York Times for use on the tech giant's artificial intelligence platforms will cost at least $20 million annually, The Wall Street Journal reported Wednesday. The multi-year licensing agreement will bring Times editorial content “to a variety of Amazon customer experiences,” the Times previously said. Amazon could also use Times original content in the Alexa software on its smart speakers and to train its proprietary AI models. “The [Amazon] deal is consistent with our long-held principle that high-quality journalism is worth paying for,” Meredith Kopit Levien, chief executive of the Times, previously said in a note to staff. The New York Times Co. filed a copyright infringement lawsuit against both OpenAI and its partner Microsoft in December 2023, accusing the tech companies of “using The Times's content without payment to create products that substitute for The Times and steal audiences away from it.” A federal judge rejected parts of OpenAI and Microsoft's motion to dismiss the suit in April, writing that the Times' produced “numerous” and “widely publicized” examples of ChatGPT producing material from its articles. Have a scoop that you'd like GeekWire to cover? Amazon inks deal with New York Times to license newspaper's content for AI platforms GeekWire Podcast: Microsoft, Remitly, and the new shape of work — plus, Amazon's NYT AI deal Reports: Microsoft under new antitrust scrutiny over Inflection deal and AI dominance</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/judge-accuses-elon-musk-and-sam-altman-of-gamesmanship-in-court-2000636637'>Judge Accuses Elon Musk and Sam Altman of ‘Gamesmanship' in Court</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 16:35:11
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Elon Musk scored a small win in court on Tuesday in his case against Sam Altman, but the judge wasn't impressed with either side's tactics, reprimanding them for “gamesmanship.” Calling out both sides for having “repeatedly over-litigated the case,” U.S. District Judge Yvonne Gonzalez Rogers granted Musk's motion to strike several of Altman's defenses. This is the latest in Musk's ongoing feud with Altman. Musk claims he was misled into co-founding and funding OpenAI in 2015 under the belief that it would remain a non-profit. The filing frames Musk's case as “a textbook tale of altruism versus greed.” Notably, Musk dropped a similar suit against OpenAI earlier last year. Altman's team responded by filing 55 affirmative defenses, introducing new facts not mentioned in Musk's original complaint. In a December blog post, OpenAI claimed that when Musk was still with the organization, he actually wanted it to become for-profit with himself at the helm. “OpenAI's deflective strategy of wild distraction is wearing thin on everyone,” said Marc Toberoff, Musk's lead lawyer in the case, in a statement emailed to Gizmodo. “We look forward to prosecuting this case on the real issues: OpenAI's ongoing fraud and complete betrayal of its charitable mission.” Attorneys representing Altman did not immediately respond to a request for comment from Gizmodo. Business Insider reported in February that Judge Gonzalez Rogers expressed doubt about Musk's claim of “irreparable harm,” saying, “I have billionaires versus billionaires.” Jury selection for the case is scheduled to begin on March 30. Since then, he launched his own AI for-profit company, xAI, to go head-to-head with OpenAI. Earlier this year, Musk stepped down from his role at the Department of Government Efficiency (DOGE) and got into a public back-and-forth with President Donald Trump on social media. Around the same time, Altman joined Trump for a long one-on-one meeting. Shortly after, Trump publicly praised Altman's AI infrastructure efforts, which Musk has not been shy about criticizing. Get the best tech, science, and culture news in your inbox daily. Liberals are losing interest in all EVs, thanks to Musk. The Tesla CEO retweeted an extremely racist account Wednesday. We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=44733892'>Show HN: An AI agent that learns your product and guides your users</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 16:25:36
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>You can see the agent and tool-calling SDK in action here: https://www.youtube.com/watch?v=UPe0t3A1VpgHow is this different from other AI customer support products?Most AI "copilots" are really just glorified chatbots. They skim your help center and spit out some nonspecific bullet points. Basically some ‘hopes and prayers' that your users will figure it out. And assumes companies are keeping their help center up-to-date with every product change. That means constant screenshots of new product UI or features for accurate instructions.These solutions leverage only a fraction of what's possible with AI, which can now reason about software interfaces extensively.With Frigade AI, we guide the user directly in the product and build on-demand tours based on the current user's state and context. The agents can also take actions immediately on a user's behalf, e.g. inviting a colleague to a workspace or retrieving billing information (via our tool calling SDK).This was only made possible recently. The latest frontier models (GPT 4.1, Claude 4, Gemini 2.5, etc.) are able to reason about UIs and workflows in a way that simply didn't work just 6 months ago. That's why we're so excited to bring this technology to the forefront of complex legacy SaaS applications that are not yet AI enabled.How does it work?1. You can send multiple invitations based on distinct roles.2. Our agent automatically explores and reasons about your application.3. Attach any existing help center resources or training documentation to supplement the agent's understanding. Install the agent assistant Javascript snippet (just a few lines).5. Your users can now start asking questions and get on demand product tours and questions answered in real time without any overhead.This process takes only a few minutes. Once running, you can improve the agent by rating and providing feedback to the responses it provides. These calls can be made with just a few lines of code by describing the tool and its parameters in natural language and passing a single Javascript promise (e.g. make an API call, call a function in your app, etc. ).Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? How is this different from other AI customer support products?Most AI "copilots" are really just glorified chatbots. They skim your help center and spit out some nonspecific bullet points. Basically some ‘hopes and prayers' that your users will figure it out. And assumes companies are keeping their help center up-to-date with every product change. That means constant screenshots of new product UI or features for accurate instructions.These solutions leverage only a fraction of what's possible with AI, which can now reason about software interfaces extensively.With Frigade AI, we guide the user directly in the product and build on-demand tours based on the current user's state and context. The agents can also take actions immediately on a user's behalf, e.g. inviting a colleague to a workspace or retrieving billing information (via our tool calling SDK).This was only made possible recently. The latest frontier models (GPT 4.1, Claude 4, Gemini 2.5, etc.) are able to reason about UIs and workflows in a way that simply didn't work just 6 months ago. That's why we're so excited to bring this technology to the forefront of complex legacy SaaS applications that are not yet AI enabled.How does it work?1. You can send multiple invitations based on distinct roles.2. Our agent automatically explores and reasons about your application.3. Attach any existing help center resources or training documentation to supplement the agent's understanding. Install the agent assistant Javascript snippet (just a few lines).5. Your users can now start asking questions and get on demand product tours and questions answered in real time without any overhead.This process takes only a few minutes. Once running, you can improve the agent by rating and providing feedback to the responses it provides. These calls can be made with just a few lines of code by describing the tool and its parameters in natural language and passing a single Javascript promise (e.g. make an API call, call a function in your app, etc. ).Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? Most AI "copilots" are really just glorified chatbots. They skim your help center and spit out some nonspecific bullet points. Basically some ‘hopes and prayers' that your users will figure it out. And assumes companies are keeping their help center up-to-date with every product change. That means constant screenshots of new product UI or features for accurate instructions.These solutions leverage only a fraction of what's possible with AI, which can now reason about software interfaces extensively.With Frigade AI, we guide the user directly in the product and build on-demand tours based on the current user's state and context. The agents can also take actions immediately on a user's behalf, e.g. inviting a colleague to a workspace or retrieving billing information (via our tool calling SDK).This was only made possible recently. The latest frontier models (GPT 4.1, Claude 4, Gemini 2.5, etc.) are able to reason about UIs and workflows in a way that simply didn't work just 6 months ago. That's why we're so excited to bring this technology to the forefront of complex legacy SaaS applications that are not yet AI enabled.How does it work?1. You can send multiple invitations based on distinct roles.2. Our agent automatically explores and reasons about your application.3. Attach any existing help center resources or training documentation to supplement the agent's understanding. Install the agent assistant Javascript snippet (just a few lines).5. Your users can now start asking questions and get on demand product tours and questions answered in real time without any overhead.This process takes only a few minutes. Once running, you can improve the agent by rating and providing feedback to the responses it provides. These calls can be made with just a few lines of code by describing the tool and its parameters in natural language and passing a single Javascript promise (e.g. make an API call, call a function in your app, etc. ).Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? The agents can also take actions immediately on a user's behalf, e.g. inviting a colleague to a workspace or retrieving billing information (via our tool calling SDK).This was only made possible recently. The latest frontier models (GPT 4.1, Claude 4, Gemini 2.5, etc.) are able to reason about UIs and workflows in a way that simply didn't work just 6 months ago. That's why we're so excited to bring this technology to the forefront of complex legacy SaaS applications that are not yet AI enabled.How does it work?1. You can send multiple invitations based on distinct roles.2. Our agent automatically explores and reasons about your application.3. Attach any existing help center resources or training documentation to supplement the agent's understanding. Install the agent assistant Javascript snippet (just a few lines).5. Your users can now start asking questions and get on demand product tours and questions answered in real time without any overhead.This process takes only a few minutes. Once running, you can improve the agent by rating and providing feedback to the responses it provides. These calls can be made with just a few lines of code by describing the tool and its parameters in natural language and passing a single Javascript promise (e.g. make an API call, call a function in your app, etc. ).Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? The latest frontier models (GPT 4.1, Claude 4, Gemini 2.5, etc.) are able to reason about UIs and workflows in a way that simply didn't work just 6 months ago. That's why we're so excited to bring this technology to the forefront of complex legacy SaaS applications that are not yet AI enabled.How does it work?1. You can send multiple invitations based on distinct roles.2. Our agent automatically explores and reasons about your application.3. Attach any existing help center resources or training documentation to supplement the agent's understanding. Install the agent assistant Javascript snippet (just a few lines).5. Your users can now start asking questions and get on demand product tours and questions answered in real time without any overhead.This process takes only a few minutes. Once running, you can improve the agent by rating and providing feedback to the responses it provides. These calls can be made with just a few lines of code by describing the tool and its parameters in natural language and passing a single Javascript promise (e.g. make an API call, call a function in your app, etc. ).Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? You can send multiple invitations based on distinct roles.2. Our agent automatically explores and reasons about your application.3. Attach any existing help center resources or training documentation to supplement the agent's understanding. Install the agent assistant Javascript snippet (just a few lines).5. Your users can now start asking questions and get on demand product tours and questions answered in real time without any overhead.This process takes only a few minutes. Once running, you can improve the agent by rating and providing feedback to the responses it provides. These calls can be made with just a few lines of code by describing the tool and its parameters in natural language and passing a single Javascript promise (e.g. make an API call, call a function in your app, etc. ).Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? You can send multiple invitations based on distinct roles.2. Our agent automatically explores and reasons about your application.3. Attach any existing help center resources or training documentation to supplement the agent's understanding. Install the agent assistant Javascript snippet (just a few lines).5. Your users can now start asking questions and get on demand product tours and questions answered in real time without any overhead.This process takes only a few minutes. Once running, you can improve the agent by rating and providing feedback to the responses it provides. These calls can be made with just a few lines of code by describing the tool and its parameters in natural language and passing a single Javascript promise (e.g. make an API call, call a function in your app, etc. ).Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? Our agent automatically explores and reasons about your application.3. Attach any existing help center resources or training documentation to supplement the agent's understanding. Install the agent assistant Javascript snippet (just a few lines).5. Your users can now start asking questions and get on demand product tours and questions answered in real time without any overhead.This process takes only a few minutes. Once running, you can improve the agent by rating and providing feedback to the responses it provides. These calls can be made with just a few lines of code by describing the tool and its parameters in natural language and passing a single Javascript promise (e.g. make an API call, call a function in your app, etc. ).Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? Attach any existing help center resources or training documentation to supplement the agent's understanding. Install the agent assistant Javascript snippet (just a few lines).5. Your users can now start asking questions and get on demand product tours and questions answered in real time without any overhead.This process takes only a few minutes. These calls can be made with just a few lines of code by describing the tool and its parameters in natural language and passing a single Javascript promise (e.g. make an API call, call a function in your app, etc. ).Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? Install the agent assistant Javascript snippet (just a few lines).5. Your users can now start asking questions and get on demand product tours and questions answered in real time without any overhead.This process takes only a few minutes. These calls can be made with just a few lines of code by describing the tool and its parameters in natural language and passing a single Javascript promise (e.g. make an API call, call a function in your app, etc. ).Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? Your users can now start asking questions and get on demand product tours and questions answered in real time without any overhead.This process takes only a few minutes. These calls can be made with just a few lines of code by describing the tool and its parameters in natural language and passing a single Javascript promise (e.g. make an API call, call a function in your app, etc. ).Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? This process takes only a few minutes. These calls can be made with just a few lines of code by describing the tool and its parameters in natural language and passing a single Javascript promise (e.g. make an API call, call a function in your app, etc. ).Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? Would love to hear what the HN crowd thinks about this approach! Are you building your own AI agent from scratch, or looking to embed one off the shelf? Personally, I've got some fatigue from most AI solutions being less than half baked. I'd love to see a long form video of letting frigade loose on something like Survey Monkey or whatever. Can I see what users are asking? How did you figure out which ones to start with? Also, have your customers raised concerns about their entire product workflows getting leaked to competitors via the agent?Also, did you consider creating a browser extension so we can use it on sites that aren't yet your customers? Also, did you consider creating a browser extension so we can use it on sites that aren't yet your customers? And we haven't really seen security or privacy issues in terms of competitor leakage. There is more concern around customer data and privacy, and in that regard, we invest heavily in security and have safeguards to help minimize the risk of any customer data issues. A simpler site that jumps straight to the value prop would be nicer.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/fantastic-four-first-steps-deleted-scenes-matt-shakman-marvel-2000636580'>Matt Shakman Thinks What Was Cut From ‘Fantastic Four' Was for the ‘Greater Good'</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 15:30:58
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>It's been just shy of a week since Marvel's latest installment in its ever-expanding cinematic universe, The Fantastic Four: First Steps, released in theaters. In an interview with Collider, Shakman was asked if First Steps, which clocks in at a little under two hours, initially had a longer cut of the film. To ensure everything happens in a sequential manner that will satisfy folks, the film, as with most modern blockbusters, has its fair share of deleted scenes. While not unique to the genre, Fantastic Four became a focal point to fans online who've compiled moments from First Steps trailers that didn't make it to the final cut, giving birth to rumors that the film was purportedly missing at least 30 minutes of content. While Shakman admits that making the film was tricky, forgoing a traditional origin story, but giving viewers enough pieces of Marvel's First Family to understand its quartet and tell a new story with the likes of new cataclysmic threats in the Silver Surfer and Galactus, it's still released as he wanted it to. And, ultimately, you know it's for the greater good. You have to constantly think about the bigger picture. As GamesRadar+ notes, Shakman added that Marvel gave him freedom to make the movie without the rumored executive meddling fans tend to point a finger at whenever they need to explain why it might feel off (especially so in Marvel's case, as the studio has become infamously known for its messy, fix-it-in-post process in recent years). “No, [there] was never anything I had to fight for. It was clear what we were trying to tell from the beginning,” Shakman said. Ahead of his Collider interview, it was already made public that iconic actor John Malkovich had all of his scenes as the Fantastic Four's longtime rival, Red Ghost, cut from the film. Speaking with Variety, Shakman lamented Malkovich's absence in the movie, which became more apparent to fans because he was showcased in the movie's trailers. As with other elements cut from First Steps, Red Ghost's ghosting of the film boiled down to the movie already having too many spinning plates, including a world-eating villain, a surfing harbinger, legacy cameos, a tangle with Mole Man, and a superpowered baby, to make room for Red Ghost. “It was heartbreaking not to include him in the final version of the movie because he's one of my very favorite humans and one of my biggest inspirations,” Shakman told Variety. “As a person who walks the line between theater and film and television, there's no one who is more inspiring than the founder of Steppenwolf Theater Company. Check out when to expect the latest Marvel, Star Wars, and Star Trek releases, what's next for the DC Universe on film and TV, and everything you need to know about the future of Doctor Who. Get the best tech, science, and culture news in your inbox daily. News from the future, delivered to your present. Like 'Superman' before it, 'Fantastic Four: First Steps' got a big audience turnout in its opening weekend. From Mephisto to mutants, from bounty hunters to box sets, Hasbro pulled out all the stops for its Marvel and 'Star Wars' reveals at SDCC this year. Now that the Fantastic Four are in the MCU, we want to hear how you felt about their introductory film. Check out these fandom fits from across the pop culture universe. We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://www.tomshardware.com/tech-industry/hpe-gets-approval-for-usd14b-acquisition-of-juniper-to-defend-ai-networking-edge-against-chinas-huawei-white-house-stepped-in-after-agencies-flagged-national-security-concerns'>HPE gets approval for $14B acquisition of Juniper, to defend AI networking edge against China's Huawei — White House stepped in after agencies flagged national security concerns</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://www.tomshardware.com', 'title': "Tom's Hardware"}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 15:27:38
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>When you purchase through links on our site, we may earn an affiliate commission. When Hewlett Packard Enterprise (HPE) announced its intent to acquire Juniper Networks for $14 billion back in January of 2024, it sparked the usual buzz around consolidation in enterprise tech. But what looked at first like a classic case of portfolio expansion—HPE growing its edge-to-cloud stack by folding in Juniper's networking business—may have had far higher strategic stakes behind the scenes. New reporting from Axios reveals that the U.S. Department of Justice (DOJ) actually had internal conflict over whether to block the deal, with multiple officials arguing it posed competitive concerns. According to sources close to the matter, senior White House and intelligence officials intervened, emphasizing that national security interests overrode any antitrust objections. That intervention seems to have tipped the scales. But according to Axios, at least two DOJ staffers who raised red flags about the merger were pushed out during internal disputes, adding weight to speculation that this wasn't just a regulatory approval, but a calculated strategic move. The deal itself isn't just another high-value acquisition between two legacy tech firms. While HPE and Juniper overlap in networking, the merger is more about aligning U.S. infrastructure players against what national security officials see as an encroaching threat from Chinese-designed networking stacks. In internal meetings, U.S. intelligence officials reportedly argued that Huawei's dominance in global infrastructure isn't just a trade issue, but rather a strategic vulnerability. For many developing countries, Huawei's tightly integrated ecosystem offering networking hardware, cloud services, and AI-backed management software comes at a fraction of the cost of its Western rivals. The concern from Washington was that if U.S. vendors kept competing independently, they'd fail to match Huawei's scale, and American influence in digital infrastructure would continue to erode. Together, the merged company could offer a vertically integrated stack—not unlike Huawei's—targeted toward U.S. allies and sectors with sensitive data flows. It's no coincidence that the deal was finalized just as the U.S. has been urging partner nations to diversify away from Chinese tech across telecom and cloud. Internally, the Justice Department didn't reach this decision lightly. According to Axios, the department's antitrust division initially had reservations, fearing that the consolidation could reduce competition in enterprise networking and edge infrastructure. National security, not market concentration, became the dominant concern. Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. That shift in tone is reflective of a broader trend where traditional antitrust arguments are increasingly being sidelined in favor of geopolitical strategy. A way to ensure that Western tech firms don't just survive but remain relevant in a world where infrastructure dominance is increasingly tied to soft power and national leverage. If executed well, the merger could give the U.S. a more credible alternative to Huawei's offerings, especially in friendly but vulnerable markets like Southeast Asia and Eastern Europe. Ultimately, the success hinges on more than just consolidation. Hassam Nasir is a die-hard hardware enthusiast with years of experience as a tech editor and writer, focusing on detailed CPU comparisons and general hardware news. When he's not working, you'll find him bending tubes for his ever-evolving custom water-loop gaming rig or benchmarking the latest CPUs and GPUs just for fun. Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://gizmodo.com/leak-reveals-colors-for-entire-iphone-17-lineup-including-a-bold-orange-for-the-17-pro-2000636502'>Leak Reveals Colors for Entire iPhone 17 Lineup, Including a Bold Orange for the 17 Pro</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://gizmodo.com', 'title': 'Gizmodo'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 15:03:07
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Looks like the iPhone 17 Pro won't come in sky blue after all. Long-time iPhone leaker Sonny Dickson has shared what he claims are dummy models for the entire iPhone 17 lineup expected to be announced in September. As you can see in his X post, there's an orange shade of the iPhone 17 Pro/17 Pro Max alongside the less flashy black, white, and navy blue. As I've said before, Apple desperately needs to bring some of the more fun colors to the iPhone Pros and orange would be the brightest yet, though dummy models don't always accurately depict colors. For example, dummy leaks suggested the iPhone 16 Pro's Desert Titanium would look copper/bronze, or as I called it, “poop brown.” The actual Desert Titanium iPhone 16 Pros that shipped are more of a champagne/beige gold (and sometimes pink-ish in warmer lighting). Google blessed the Pixel 4 with a vivid “Oh So Orange” colorway way back in 2019. Dickson's X post also offers a preview for the skinny iPhone 17 Air. If accurate, the ultra-thin iPhone 17 Air will come in what appears to be black, white, gold, and light. Not the most eye-catching colors if I'm being honest. Sure, most people will throw a case over their iPhone, but still—if there's any iPhone that you won't want to cover up with a case, it's the one that tells everyone you've got the newest and thinnest iPhone ever made. The regular iPhone 17 could pick up the slack if you're looking for more color pop—supposedly coming in pink, lime green, light blue, white, and black. Orange for the iPhone 17 Pros would be striking. We're *checks calendar* about a month and a half away from Apple announcing the new iPhone 17 family, likely the new Apple Watch Series 11, and possibly even AirPods Pro 3. If you're on the fence about buying Apple products, especially any of the ones I just mentioned, you really should hold off unless you absolutely need a device to function. Get the best tech, science, and culture news in your inbox daily. News from the future, delivered to your present. The haters can't stop Apple's glass from liquefying, and I, for one, am okay with that. Mac fans better get used to finagling graphics settings like all those jaded PC gamers. I'll give you a hint: it's not hardware. We may earn a commission when you buy through links on our sites.</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://techcrunch.com/2025/07/30/how-2-uc-berkeley-dropouts-raised-28-million-for-their-ai-marketing-automation-startup/'>How 2 UC Berkeley dropouts raised $28 million for their AI marketing automation startup</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://techcrunch.com', 'title': 'TechCrunch'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 15:00:00
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>AI-powered marketing automation startup Conversion, founded five years ago by two UC Berkeley dropouts, has raised a $28 million Series A led by Abstract, with participation from True Ventures and HOF Capital. “I told him I had this interest [in entrepreneurship], and four years later, he was actually the first person to write us a check into the company,” Tewari told TechCrunch. James Jiao, Tewari's college roommate at Berkeley — now Conversion's co-founder and CTO — also dreamed of founding his own company, so the two tried building various products, like one for helping marketeers buy product placement ads. “It was originally for us,” Tewari said of his startup's tech. The co-founders enjoyed building their internal marketing tool so much, they wondered if they could sell it and began reaching out to marketing executives for “customer discovery” interviews. “We actually spent like two months doing like 160 customer interviews with VPs of marketing, 50- to 500-employee businesses, and got a much more positive response than we could have imagined,” Tewari said. At age 19, they dropped out of college to work full time on Conversion. As they built their product, ChatGPT burst onto the scene. Conversion has baked AI in, which means it can do things like organize leads and automate personalized follow-up emails. Conversion is nearing $10 million ARR over the past two years, Tewari said, and about 90% of its customers are midsize businesses that have yanked out a legacy app. Besides the legacy marketing automation tools like HubSpot, Adobe Marketo, or Salesforce Pardot, there are other AI native startups like Jasper, Writer AI, Iterable, Copy.ai, and many others. His game plan calls for targeting businesses that use the older marketing tools. The company has raised a total of $30 million between its seed and Series A, the CEO says, and is doing well enough that the founders have each moved into separate apartments where they have their own rooms, and none of their roommates sleep in a closet. Amplify your reach, spark real connections, and lead the innovation charge. A guide to using Edits, Meta's CapCut rival for short-form video editing How a New Jersey startup found an electrifying way to slash copper costs PlayerZero raises $15M to prevent AI agents from shipping buggy code Minnesota activates National Guard as cyberattack on Saint Paul disrupts public services How 2 UC Berkeley dropouts raised $28 million for their AI marketing automation startup</p>
                <br/>
                

                <div id='article_title' class='text-3xl text-gray-300 leading-tight'>
                    <a target='_blank' href='https://news.ycombinator.com/item?id=44721003'>Stop selling “unlimited”, when you mean “until we change our minds”</a>
                </div>
                <div id='article_attribution'  style='mb-1'>
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Source:</span> {'href': 'https://news.ycombinator.com', 'title': 'Hacker News'}&nbsp;&nbsp;&nbsp;
                    <span class='text-1.5xl font-extrabold text-gray-500 leading-tight'>Published:</span> 2025-07-30 03:51:54
                    <i class="fas fa-chevron-down expand-icon text-gray-500" aria-hidden="true"></i>
                </div>
                <p class='hidden' class='text-gray-500'>Trying the app says "you signed up on a different platform, go there" but it doesn't tell me which platform that might be.Trying to cancel on mobile web gives several upgrade options but no cancel options.So, do I need to call my credit card? This is the worst dark pattern on subscription I have seen of any service I have ever paid for!Anthropic had a fairly positive image in my head until they cut off my access and are not giving me a way to cancel my plan.Edit: after mucking with the Stripe credit card payment options I found a cancel plan button underneath the list of all invoices. Trying to cancel on mobile web gives several upgrade options but no cancel options.So, do I need to call my credit card? This is the worst dark pattern on subscription I have seen of any service I have ever paid for!Anthropic had a fairly positive image in my head until they cut off my access and are not giving me a way to cancel my plan.Edit: after mucking with the Stripe credit card payment options I found a cancel plan button underneath the list of all invoices. So there is an option, I just had a harder time finding it then I have had with other services. So, do I need to call my credit card? This is the worst dark pattern on subscription I have seen of any service I have ever paid for!Anthropic had a fairly positive image in my head until they cut off my access and are not giving me a way to cancel my plan.Edit: after mucking with the Stripe credit card payment options I found a cancel plan button underneath the list of all invoices. So there is an option, I just had a harder time finding it then I have had with other services. Anthropic had a fairly positive image in my head until they cut off my access and are not giving me a way to cancel my plan.Edit: after mucking with the Stripe credit card payment options I found a cancel plan button underneath the list of all invoices. So there is an option, I just had a harder time finding it then I have had with other services. Edit: after mucking with the Stripe credit card payment options I found a cancel plan button underneath the list of all invoices. So there is an option, I just had a harder time finding it then I have had with other services. Gemini Advanced offered 2.5 Pro with nearly unlimited rate limits, then nerfed it to 100/day.OpenAI silently nerfed the maximum context window of reasoning models in their Pro plan.Accompanying the nerf is usually a psy op, like nerfing to 50/day then increasing it to 100/day so the anchoring effect reduces the grievance.It's a smart ploy because as much as we like to say there's no moat, the user does face provider switching costs (time and effort), which serves as a mini-moat for status quo provider.So providers have an incentive to rope people in with a loss leader, and then rug pull once they gained market share. Maybe 40% of the top 5% of Claude users are now too accustomed to their Claude-based workflows, and inertia will keep them as customers, but now they're using the more expensive API instead. Anthropic won.Modern bait and switch, although done intelligently so no laws are broken. OpenAI silently nerfed the maximum context window of reasoning models in their Pro plan.Accompanying the nerf is usually a psy op, like nerfing to 50/day then increasing it to 100/day so the anchoring effect reduces the grievance.It's a smart ploy because as much as we like to say there's no moat, the user does face provider switching costs (time and effort), which serves as a mini-moat for status quo provider.So providers have an incentive to rope people in with a loss leader, and then rug pull once they gained market share. Maybe 40% of the top 5% of Claude users are now too accustomed to their Claude-based workflows, and inertia will keep them as customers, but now they're using the more expensive API instead. Anthropic won.Modern bait and switch, although done intelligently so no laws are broken. Accompanying the nerf is usually a psy op, like nerfing to 50/day then increasing it to 100/day so the anchoring effect reduces the grievance.It's a smart ploy because as much as we like to say there's no moat, the user does face provider switching costs (time and effort), which serves as a mini-moat for status quo provider.So providers have an incentive to rope people in with a loss leader, and then rug pull once they gained market share. Maybe 40% of the top 5% of Claude users are now too accustomed to their Claude-based workflows, and inertia will keep them as customers, but now they're using the more expensive API instead. Anthropic won.Modern bait and switch, although done intelligently so no laws are broken. It's a smart ploy because as much as we like to say there's no moat, the user does face provider switching costs (time and effort), which serves as a mini-moat for status quo provider.So providers have an incentive to rope people in with a loss leader, and then rug pull once they gained market share. Maybe 40% of the top 5% of Claude users are now too accustomed to their Claude-based workflows, and inertia will keep them as customers, but now they're using the more expensive API instead. Anthropic won.Modern bait and switch, although done intelligently so no laws are broken. So providers have an incentive to rope people in with a loss leader, and then rug pull once they gained market share. Maybe 40% of the top 5% of Claude users are now too accustomed to their Claude-based workflows, and inertia will keep them as customers, but now they're using the more expensive API instead. Anthropic won.Modern bait and switch, although done intelligently so no laws are broken. Modern bait and switch, although done intelligently so no laws are broken. To the degree there is a moat, I do not think it will be effective at keeping people in. I am happy that there is unlikely to be a dominant single winner like there was for web search or for operating systems. That is, unless there's a significant technological jump, rather than the same gradual improvement that all the AI companies are making. On the rare occasion that it does, I try to circle back and mitigate the root cause so that I can resume a loyalty-free life thereafter. Likewise: a faulty, unproven, hallucinating, error-prone service, however good, was a good value at approx 25 USD/month in an "absolutely all you can eat", wholesale regime ...... now? Hell, “just open a new chat and start over” is an important tool in the toolbox when using these models. I can't imagine a more frustrating experience than opening a new chat to try something from scratch only for it to reply based on the previous prompt that I messed up. Gemini 2.5 Pro is the king of AI coding and literally everything else has to catch up.Trust me, I can't wait until there's a model that can run locally that's as good...but for now there isn't.Always just look at the token cost and get used the token economics. I think people thinking they were somehow cheating and getting away with something similar (or better) for $20/mo are in for a big surprise.I don't know if I would say they should have known better of course. Now it's all coming out into the open and I guess you know the saying, if it's too good to be true... Gemini 2.5 Pro is the king of AI coding and literally everything else has to catch up.Trust me, I can't wait until there's a model that can run locally that's as good...but for now there isn't.Always just look at the token cost and get used the token economics. I think people thinking they were somehow cheating and getting away with something similar (or better) for $20/mo are in for a big surprise.I don't know if I would say they should have known better of course. Now it's all coming out into the open and I guess you know the saying, if it's too good to be true... Trust me, I can't wait until there's a model that can run locally that's as good...but for now there isn't.Always just look at the token cost and get used the token economics. I think people thinking they were somehow cheating and getting away with something similar (or better) for $20/mo are in for a big surprise.I don't know if I would say they should have known better of course. Now it's all coming out into the open and I guess you know the saying, if it's too good to be true... I think people thinking they were somehow cheating and getting away with something similar (or better) for $20/mo are in for a big surprise.I don't know if I would say they should have known better of course. Now it's all coming out into the open and I guess you know the saying, if it's too good to be true... Now it's all coming out into the open and I guess you know the saying, if it's too good to be true... As if google would say that yes, emails are $5/mo, but there's actually a limit on number of emails daily, and also number of characters in the email. It just feels so illegal to nerf a product that much.Same with AI companies changing routing and making models dumber from time to time. I don't know if I would go that far, as there are all kinds of words most terms of service use to somehow make it so that you have already acknowledged and agreed to whatever they decide to do. So a lawyer will probably be helpful there as well. Update 2: just clicked cancel and was offered a promo of 20% off for three months...Update 3: FYI, I logged in to my Claude account via computer (not iOS or Android). Update 3: FYI, I logged in to my Claude account via computer (not iOS or Android). I still revert to gemini pro 2.5 here and there and claude for specific demanding tasks, but bulk token go trough open weight model at the moment. Ugh, anyone who says that and really believes it can no longer see common sense through the hype goggles.It's just stupid and completely 100% wrong, like saying all musicians will use autotune in the future because it makes the music better.It's the same as betting that there will be no new inventions, no new art, no works of genius unless the creator is taking vitamin C pills.It's one of the most un-serious claims I can imagine making. It automatically marks the speaker as a clown divorced from basic facts about human ability It automatically marks the speaker as a clown divorced from basic facts about human ability It's the same as betting that there will be no new inventions, no new art, no works of genius unless the creator is taking vitamin C pills.It's one of the most un-serious claims I can imagine making. It automatically marks the speaker as a clown divorced from basic facts about human ability It's one of the most un-serious claims I can imagine making. It automatically marks the speaker as a clown divorced from basic facts about human ability I've never once seen a model generate code that's as ugly and unreadable as a lot of the low quality code I've seen in my career (especially from Salesforce “devs” for example)And even the ones that do the more creative problem solving can benefit from AI agents helping with research, documentation, data migration scripts, etc. And even the ones that do the more creative problem solving can benefit from AI agents helping with research, documentation, data migration scripts, etc. So heck yeah I'll come clap back on that. There is absolutely something real here, whether you choose to believe it or not. I'd recommend taking a good faith and open minded look at the last few months of developments. See where it can benefit you (and where it still falls way short).So even if you may have arrived at your conclusion years ago, I assure you that things continue to improve by the week. This is not all or nothing, nor does it have to be. So even if you may have arrived at your conclusion years ago, I assure you that things continue to improve by the week. This is not all or nothing, nor does it have to be. The goal isn't to have a lot of it. You aren't going to sell any snake oil with this venomous strategy. I use AI pretty extensively and encourage my folks to use it as well but I've yet to see this come directly from an LLM. We think of them as doing creative stuff but a vast majority is mundane. (though who knows, maybe at some time in the future there will be significant numbers of people programming as a hobby and wanting to be coached by a human...) *: I'm aware of cases like the recent ffmpg assembly usage that gave a big performance boost. When talking about industrial trend lines, I'm OK with admitting 0.001% exceptions. (Apologies if it comes across as snarky or pat, but I honestly think the comparison is reasonable.) (Apologies if it comes across as snarky or pat, but I honestly think the comparison is reasonable.) If a compiler had a 10% chance of erasing your code instead of generating an executable you'd see more people still using assembly. The basic nature of my job is to maintain the tallest tower of complexity I can without it falling over, so I need to take complexity and find ways to confine it to places where I have some way of knowing that it can't hurt me. It's not like there's a new thing that comes along every few years and we all have to jump on or be left behind, and LLMs are the latest. There's definitely a new thing that comes along every few years and people say we have to jump on or be left behind, but it almost never bears out. Many of those ended up being useful, but not essential.I see no indication that LLMs or associated tooling are going to be like compilers and version control where you pretty much can't find anyone making a living in the field without them. I can see them being like IDEs or debuggers or linters where they can be handy but plenty of people do fine without them. I see no indication that LLMs or associated tooling are going to be like compilers and version control where you pretty much can't find anyone making a living in the field without them. I can see them being like IDEs or debuggers or linters where they can be handy but plenty of people do fine without them. Even if things are going the direction you say, though, Kilo is still just a fork of VSCode. Because most companies are just making crud (pun intended). Some will exist, and they may get paid a lot more, but most people won't fall into that category. There are a relative handful of people doing some really cool, novel things. We are not special.What I don't know is the timing. Just as the developer who refused to adopt version control, IDEs, or Stack Overflow eventually became unemployable, those who reject tools that fundamentally expand their problem-solving capacity will find themselves unable to compete with those who can architect solutions across larger possibility spaces on smaller teams.Will it be used for absolutely every problem? No - There are clearly places where humans are needed.But rejecting the enormous impact this will have on the workforce is trading hype goggles for a bucket of sand. No - There are clearly places where humans are needed.But rejecting the enormous impact this will have on the workforce is trading hype goggles for a bucket of sand. Surely you realize there are people out there who solve problems simply by reading the docs and thinking deeply rather than asking SO?The usage of LLM assistance will not become a requirement for employment, at least not for talented programmers. A company gating on the use of LLMs would be preposterously self-defeating. A company gating on the use of LLMs would be preposterously self-defeating. I don't think you should use LLMs for something you can't master without.> will find themselves unable to competeI'd wait a bit more before concluding so affirmatively. The AI bubble would very much like us to believe this, but we don't yet know very well the long term effects of using LLMs on code, both for the project and for the developer, and we don't even know how available and in which conditions the LLMs will be in a few months as evidenced by this HN post. That's not a very solid basis to build on. > will find themselves unable to competeI'd wait a bit more before concluding so affirmatively. The AI bubble would very much like us to believe this, but we don't yet know very well the long term effects of using LLMs on code, both for the project and for the developer, and we don't even know how available and in which conditions the LLMs will be in a few months as evidenced by this HN post. That's not a very solid basis to build on. I'd wait a bit more before concluding so affirmatively. The AI bubble would very much like us to believe this, but we don't yet know very well the long term effects of using LLMs on code, both for the project and for the developer, and we don't even know how available and in which conditions the LLMs will be in a few months as evidenced by this HN post. That's not a very solid basis to build on. To your second point -- With as much capital as is going into data center buildout, the increasing availability of local coding LLMs that near the performance of today's closed models, and the continued innovation on both open/closed models, you're going to hang your hat on the possibility that LLMs are going to be only available in a 'limited or degraded' state?I think we simply don't have similar mental models for predicting the future. I think we simply don't have similar mental models for predicting the future. We don't really know yet, that's my point. See for instance [1] that sees productivity decrease when AI is used. If only masters see a productivity increase, others should not use it... and will still get employed because the masters won't fill in all the positions. In this hypothetical world, masters not using LLMs also have a place by construction.> With as much capital as is going intoYes, we are in a bubble. And some are predicting it will burst.> the continued innovationThat's what I'm not seeing. We are seeing small but very costly improvements on a paradigm that I consider fundamentally flawed for the tasks we are using it for. LLMs still cannot reason, and that's IMHO a major limitation.> you're going to hang your hat on the possibility that LLMs are going to be only available in a 'limited or degraded' state?I didn't say I was going to, but since you are asking: oh yes, I'm not putting my eggs in a box that could abruptly disappear or become very costly.I simply don't see how this thing is going to be cost efficient. The major SaaS LLM providers can't seem to manage profitability, and maybe at some point the investors will get bored and stop sending billions of dollars towards them? I'll reconsider when and if LLMs become economically viable.But that's not my strongest reason to avoid the LLMs anyway:- I don't want to increase my reliance on SaaS (or very costly hardware)- I have not caved in yet in participating in this environmental disaster, and in this work pillaging phenomenon (well, that last part, I guess I don't really have a choice, I see the dumb AI bots hammering my forgejo instance). If only masters see a productivity increase, others should not use it... and will still get employed because the masters won't fill in all the positions. In this hypothetical world, masters not using LLMs also have a place by construction.> With as much capital as is going intoYes, we are in a bubble. And some are predicting it will burst.> the continued innovationThat's what I'm not seeing. We are seeing small but very costly improvements on a paradigm that I consider fundamentally flawed for the tasks we are using it for. LLMs still cannot reason, and that's IMHO a major limitation.> you're going to hang your hat on the possibility that LLMs are going to be only available in a 'limited or degraded' state?I didn't say I was going to, but since you are asking: oh yes, I'm not putting my eggs in a box that could abruptly disappear or become very costly.I simply don't see how this thing is going to be cost efficient. The major SaaS LLM providers can't seem to manage profitability, and maybe at some point the investors will get bored and stop sending billions of dollars towards them? I'll reconsider when and if LLMs become economically viable.But that's not my strongest reason to avoid the LLMs anyway:- I don't want to increase my reliance on SaaS (or very costly hardware)- I have not caved in yet in participating in this environmental disaster, and in this work pillaging phenomenon (well, that last part, I guess I don't really have a choice, I see the dumb AI bots hammering my forgejo instance). And some are predicting it will burst.> the continued innovationThat's what I'm not seeing. We are seeing small but very costly improvements on a paradigm that I consider fundamentally flawed for the tasks we are using it for. LLMs still cannot reason, and that's IMHO a major limitation.> you're going to hang your hat on the possibility that LLMs are going to be only available in a 'limited or degraded' state?I didn't say I was going to, but since you are asking: oh yes, I'm not putting my eggs in a box that could abruptly disappear or become very costly.I simply don't see how this thing is going to be cost efficient. The major SaaS LLM providers can't seem to manage profitability, and maybe at some point the investors will get bored and stop sending billions of dollars towards them? I'll reconsider when and if LLMs become economically viable.But that's not my strongest reason to avoid the LLMs anyway:- I don't want to increase my reliance on SaaS (or very costly hardware)- I have not caved in yet in participating in this environmental disaster, and in this work pillaging phenomenon (well, that last part, I guess I don't really have a choice, I see the dumb AI bots hammering my forgejo instance). And some are predicting it will burst.> the continued innovationThat's what I'm not seeing. We are seeing small but very costly improvements on a paradigm that I consider fundamentally flawed for the tasks we are using it for. LLMs still cannot reason, and that's IMHO a major limitation.> you're going to hang your hat on the possibility that LLMs are going to be only available in a 'limited or degraded' state?I didn't say I was going to, but since you are asking: oh yes, I'm not putting my eggs in a box that could abruptly disappear or become very costly.I simply don't see how this thing is going to be cost efficient. The major SaaS LLM providers can't seem to manage profitability, and maybe at some point the investors will get bored and stop sending billions of dollars towards them? I'll reconsider when and if LLMs become economically viable.But that's not my strongest reason to avoid the LLMs anyway:- I don't want to increase my reliance on SaaS (or very costly hardware)- I have not caved in yet in participating in this environmental disaster, and in this work pillaging phenomenon (well, that last part, I guess I don't really have a choice, I see the dumb AI bots hammering my forgejo instance). We are seeing small but very costly improvements on a paradigm that I consider fundamentally flawed for the tasks we are using it for. LLMs still cannot reason, and that's IMHO a major limitation.> you're going to hang your hat on the possibility that LLMs are going to be only available in a 'limited or degraded' state?I didn't say I was going to, but since you are asking: oh yes, I'm not putting my eggs in a box that could abruptly disappear or become very costly.I simply don't see how this thing is going to be cost efficient. The major SaaS LLM providers can't seem to manage profitability, and maybe at some point the investors will get bored and stop sending billions of dollars towards them? I'll reconsider when and if LLMs become economically viable.But that's not my strongest reason to avoid the LLMs anyway:- I don't want to increase my reliance on SaaS (or very costly hardware)- I have not caved in yet in participating in this environmental disaster, and in this work pillaging phenomenon (well, that last part, I guess I don't really have a choice, I see the dumb AI bots hammering my forgejo instance). We are seeing small but very costly improvements on a paradigm that I consider fundamentally flawed for the tasks we are using it for. LLMs still cannot reason, and that's IMHO a major limitation.> you're going to hang your hat on the possibility that LLMs are going to be only available in a 'limited or degraded' state?I didn't say I was going to, but since you are asking: oh yes, I'm not putting my eggs in a box that could abruptly disappear or become very costly.I simply don't see how this thing is going to be cost efficient. The major SaaS LLM providers can't seem to manage profitability, and maybe at some point the investors will get bored and stop sending billions of dollars towards them? I'll reconsider when and if LLMs become economically viable.But that's not my strongest reason to avoid the LLMs anyway:- I don't want to increase my reliance on SaaS (or very costly hardware)- I have not caved in yet in participating in this environmental disaster, and in this work pillaging phenomenon (well, that last part, I guess I don't really have a choice, I see the dumb AI bots hammering my forgejo instance). > you're going to hang your hat on the possibility that LLMs are going to be only available in a 'limited or degraded' state?I didn't say I was going to, but since you are asking: oh yes, I'm not putting my eggs in a box that could abruptly disappear or become very costly.I simply don't see how this thing is going to be cost efficient. The major SaaS LLM providers can't seem to manage profitability, and maybe at some point the investors will get bored and stop sending billions of dollars towards them? I'll reconsider when and if LLMs become economically viable.But that's not my strongest reason to avoid the LLMs anyway:- I don't want to increase my reliance on SaaS (or very costly hardware)- I have not caved in yet in participating in this environmental disaster, and in this work pillaging phenomenon (well, that last part, I guess I don't really have a choice, I see the dumb AI bots hammering my forgejo instance). I didn't say I was going to, but since you are asking: oh yes, I'm not putting my eggs in a box that could abruptly disappear or become very costly.I simply don't see how this thing is going to be cost efficient. The major SaaS LLM providers can't seem to manage profitability, and maybe at some point the investors will get bored and stop sending billions of dollars towards them? I'll reconsider when and if LLMs become economically viable.But that's not my strongest reason to avoid the LLMs anyway:- I don't want to increase my reliance on SaaS (or very costly hardware)- I have not caved in yet in participating in this environmental disaster, and in this work pillaging phenomenon (well, that last part, I guess I don't really have a choice, I see the dumb AI bots hammering my forgejo instance). I simply don't see how this thing is going to be cost efficient. The major SaaS LLM providers can't seem to manage profitability, and maybe at some point the investors will get bored and stop sending billions of dollars towards them? I'll reconsider when and if LLMs become economically viable.But that's not my strongest reason to avoid the LLMs anyway:- I don't want to increase my reliance on SaaS (or very costly hardware)- I have not caved in yet in participating in this environmental disaster, and in this work pillaging phenomenon (well, that last part, I guess I don't really have a choice, I see the dumb AI bots hammering my forgejo instance). But that's not my strongest reason to avoid the LLMs anyway:- I don't want to increase my reliance on SaaS (or very costly hardware)- I have not caved in yet in participating in this environmental disaster, and in this work pillaging phenomenon (well, that last part, I guess I don't really have a choice, I see the dumb AI bots hammering my forgejo instance). AI presently has a far lower footprint on the globe than the meat industry -- The US Beef industry alone far outpaces the impact of AI.As far as "work pillaging" - There is cognitive dissonance in supporting the freedom of information/cultural progress and simultaneously desiring to restrict a transformative use (as it has been deemed by multiple US judges) of that information.We don't see eye to eye, and I think that's ok. We can re-evaluate our predictions in a year! As far as "work pillaging" - There is cognitive dissonance in supporting the freedom of information/cultural progress and simultaneously desiring to restrict a transformative use (as it has been deemed by multiple US judges) of that information.We don't see eye to eye, and I think that's ok. We can re-evaluate our predictions in a year! Beef has the benefit of seeing an end, though. As methane has a 12 year life, in a stable environment the methane emissions today simply replace the emissions from 12 years ago. Emissions that are essentially permanent, so even if you shut down all AI when you have to take extreme measures, the effects will remain "forever". Whereas AI, even once stabilized, theoretically has no end to its emissions. Emissions that are essentially permanent, so even if you shut down all AI when you have to take extreme measures, the effects will remain "forever". While I might show a lack of perspective, I don't need to do X to reasonably think X can be bad. And/or if the meeting was about burning huge amounts of fuel, the positive impact is even less clear, just like LLMs might just allow us to produce attention-seeking, energy-greedy shitty software at a faster speed (if they indeed work well in the long run).And while I can see how things like ML can help (predicting weather, etc), I'm more skeptical about LLMs.And I'm all for stopping the meat disaster as well.> We don't see eye to eye, and I think that's ok. We can re-evaluate our predictions in a year!Yep :-) While I might show a lack of perspective, I don't need to do X to reasonably think X can be bad. And/or if the meeting was about burning huge amounts of fuel, the positive impact is even less clear, just like LLMs might just allow us to produce attention-seeking, energy-greedy shitty software at a faster speed (if they indeed work well in the long run).And while I can see how things like ML can help (predicting weather, etc), I'm more skeptical about LLMs.And I'm all for stopping the meat disaster as well.> We don't see eye to eye, and I think that's ok. We can re-evaluate our predictions in a year!Yep :-) > AI presently has a far lower footprint on the globe than [X]We see the same kind of arguments for planes, cars, anything with a big impact really. And/or if the meeting was about burning huge amounts of fuel, the positive impact is even less clear, just like LLMs might just allow us to produce attention-seeking, energy-greedy shitty software at a faster speed (if they indeed work well in the long run).And while I can see how things like ML can help (predicting weather, etc), I'm more skeptical about LLMs.And I'm all for stopping the meat disaster as well.> We don't see eye to eye, and I think that's ok. We can re-evaluate our predictions in a year!Yep :-) We see the same kind of arguments for planes, cars, anything with a big impact really. And/or if the meeting was about burning huge amounts of fuel, the positive impact is even less clear, just like LLMs might just allow us to produce attention-seeking, energy-greedy shitty software at a faster speed (if they indeed work well in the long run).And while I can see how things like ML can help (predicting weather, etc), I'm more skeptical about LLMs.And I'm all for stopping the meat disaster as well.> We don't see eye to eye, and I think that's ok. We can re-evaluate our predictions in a year!Yep :-) And/or if the meeting was about burning huge amounts of fuel, the positive impact is even less clear, just like LLMs might just allow us to produce attention-seeking, energy-greedy shitty software at a faster speed (if they indeed work well in the long run).And while I can see how things like ML can help (predicting weather, etc), I'm more skeptical about LLMs.And I'm all for stopping the meat disaster as well.> We don't see eye to eye, and I think that's ok. We can re-evaluate our predictions in a year!Yep :-) And while I can see how things like ML can help (predicting weather, etc), I'm more skeptical about LLMs.And I'm all for stopping the meat disaster as well.> We don't see eye to eye, and I think that's ok. We can re-evaluate our predictions in a year!Yep :-) And I'm all for stopping the meat disaster as well.> We don't see eye to eye, and I think that's ok. We can re-evaluate our predictions in a year!Yep :-) > We don't see eye to eye, and I think that's ok. We can re-evaluate our predictions in a year!Yep :-) I don't know how else one gets information and forms an opinion on the technology except for media consumption or hands-on experience. Note that I count "social media" as media.My proposition is that without hands-on experience, your information is limited to media narratives, and it seems like the "AI is net bad" narrative seems to be the source of perspectives.Skepticism is warranted, and there are a million ways this technology could be built for terrible ends.But, I'm of the opinion that: A) The technology is not hype, and is getting better B) That it can, and will, be built -- Time horizon debatable. My proposition is that without hands-on experience, your information is limited to media narratives, and it seems like the "AI is net bad" narrative seems to be the source of perspectives.Skepticism is warranted, and there are a million ways this technology could be built for terrible ends.But, I'm of the opinion that: A) The technology is not hype, and is getting better B) That it can, and will, be built -- Time horizon debatable. Skepticism is warranted, and there are a million ways this technology could be built for terrible ends.But, I'm of the opinion that: A) The technology is not hype, and is getting better B) That it can, and will, be built -- Time horizon debatable. But, I'm of the opinion that: A) The technology is not hype, and is getting better B) That it can, and will, be built -- Time horizon debatable. Okay, I think I got your intent better, thanks for clarifying.You can add discussion with other people outside software media, or opinion pieces outside media (I would not include personal blogs in "media" for instance, but would not be bothered if someone did), including people who tried and people who didn't. Medias are also not uniform in their views.But I hear you, grounded perspectives would be a positive.> That for it to result in good outcomes for humanity, it requires good people to help shape it in its formative years.I hear you as well, makes perfect sense.OTOH, it's difficult to engage into something that feels fundamentally wrong or a dead end, and that's what LLMs feel like to me. It would be also frightening: the risk that, as a good person, you help shape a monster.The only way out I can see is inventing the thing that will make LLMs irrelevant, but also don't have their fatal flaws. That's quite the undertaking though.We'd not be competing on an equal footing: LLM providers have been doing things I would never have dared even considering: ingesting considerable amount of source materials completely disregarding their licenses, hammering everyone servers, spending a crazy amount of energy, sourcing a crazy amount of (very closed) hardware, burning an insane amount of money even on paid plans. It feels very brutal.Can an LLM be built avoiding any of this stuff? (of course, the discussion has shifted quite a bit! The initial question was if a dev not using the LLMs would remain relevant, but I believe this was addressed at large in other comments already) You can add discussion with other people outside software media, or opinion pieces outside media (I would not include personal blogs in "media" for instance, but would not be bothered if someone did), including people who tried and people who didn't. Medias are also not uniform in their views.But I hear you, grounded perspectives would be a positive.> That for it to result in good outcomes for humanity, it requires good people to help shape it in its formative years.I hear you as well, makes perfect sense.OTOH, it's difficult to engage into something that feels fundamentally wrong or a dead end, and that's what LLMs feel like to me. It would be also frightening: the risk that, as a good person, you help shape a monster.The only way out I can see is inventing the thing that will make LLMs irrelevant, but also don't have their fatal flaws. That's quite the undertaking though.We'd not be competing on an equal footing: LLM providers have been doing things I would never have dared even considering: ingesting considerable amount of source materials completely disregarding their licenses, hammering everyone servers, spending a crazy amount of energy, sourcing a crazy amount of (very closed) hardware, burning an insane amount of money even on paid plans. It feels very brutal.Can an LLM be built avoiding any of this stuff? (of course, the discussion has shifted quite a bit! The initial question was if a dev not using the LLMs would remain relevant, but I believe this was addressed at large in other comments already) But I hear you, grounded perspectives would be a positive.> That for it to result in good outcomes for humanity, it requires good people to help shape it in its formative years.I hear you as well, makes perfect sense.OTOH, it's difficult to engage into something that feels fundamentally wrong or a dead end, and that's what LLMs feel like to me. It would be also frightening: the risk that, as a good person, you help shape a monster.The only way out I can see is inventing the thing that will make LLMs irrelevant, but also don't have their fatal flaws. That's quite the undertaking though.We'd not be competing on an equal footing: LLM providers have been doing things I would never have dared even considering: ingesting considerable amount of source materials completely disregarding their licenses, hammering everyone servers, spending a crazy amount of energy, sourcing a crazy amount of (very closed) hardware, burning an insane amount of money even on paid plans. It feels very brutal.Can an LLM be built avoiding any of this stuff? (of course, the discussion has shifted quite a bit! The initial question was if a dev not using the LLMs would remain relevant, but I believe this was addressed at large in other comments already) > That for it to result in good outcomes for humanity, it requires good people to help shape it in its formative years.I hear you as well, makes perfect sense.OTOH, it's difficult to engage into something that feels fundamentally wrong or a dead end, and that's what LLMs feel like to me. It would be also frightening: the risk that, as a good person, you help shape a monster.The only way out I can see is inventing the thing that will make LLMs irrelevant, but also don't have their fatal flaws. That's quite the undertaking though.We'd not be competing on an equal footing: LLM providers have been doing things I would never have dared even considering: ingesting considerable amount of source materials completely disregarding their licenses, hammering everyone servers, spending a crazy amount of energy, sourcing a crazy amount of (very closed) hardware, burning an insane amount of money even on paid plans. It feels very brutal.Can an LLM be built avoiding any of this stuff? (of course, the discussion has shifted quite a bit! The initial question was if a dev not using the LLMs would remain relevant, but I believe this was addressed at large in other comments already) I hear you as well, makes perfect sense.OTOH, it's difficult to engage into something that feels fundamentally wrong or a dead end, and that's what LLMs feel like to me. It would be also frightening: the risk that, as a good person, you help shape a monster.The only way out I can see is inventing the thing that will make LLMs irrelevant, but also don't have their fatal flaws. That's quite the undertaking though.We'd not be competing on an equal footing: LLM providers have been doing things I would never have dared even considering: ingesting considerable amount of source materials completely disregarding their licenses, hammering everyone servers, spending a crazy amount of energy, sourcing a crazy amount of (very closed) hardware, burning an insane amount of money even on paid plans. It feels very brutal.Can an LLM be built avoiding any of this stuff? (of course, the discussion has shifted quite a bit! The initial question was if a dev not using the LLMs would remain relevant, but I believe this was addressed at large in other comments already) OTOH, it's difficult to engage into something that feels fundamentally wrong or a dead end, and that's what LLMs feel like to me. It would be also frightening: the risk that, as a good person, you help shape a monster.The only way out I can see is inventing the thing that will make LLMs irrelevant, but also don't have their fatal flaws. That's quite the undertaking though.We'd not be competing on an equal footing: LLM providers have been doing things I would never have dared even considering: ingesting considerable amount of source materials completely disregarding their licenses, hammering everyone servers, spending a crazy amount of energy, sourcing a crazy amount of (very closed) hardware, burning an insane amount of money even on paid plans. It feels very brutal.Can an LLM be built avoiding any of this stuff? (of course, the discussion has shifted quite a bit! The initial question was if a dev not using the LLMs would remain relevant, but I believe this was addressed at large in other comments already) The only way out I can see is inventing the thing that will make LLMs irrelevant, but also don't have their fatal flaws. That's quite the undertaking though.We'd not be competing on an equal footing: LLM providers have been doing things I would never have dared even considering: ingesting considerable amount of source materials completely disregarding their licenses, hammering everyone servers, spending a crazy amount of energy, sourcing a crazy amount of (very closed) hardware, burning an insane amount of money even on paid plans. It feels very brutal.Can an LLM be built avoiding any of this stuff? (of course, the discussion has shifted quite a bit! The initial question was if a dev not using the LLMs would remain relevant, but I believe this was addressed at large in other comments already) We'd not be competing on an equal footing: LLM providers have been doing things I would never have dared even considering: ingesting considerable amount of source materials completely disregarding their licenses, hammering everyone servers, spending a crazy amount of energy, sourcing a crazy amount of (very closed) hardware, burning an insane amount of money even on paid plans. It feels very brutal.Can an LLM be built avoiding any of this stuff? (of course, the discussion has shifted quite a bit! The initial question was if a dev not using the LLMs would remain relevant, but I believe this was addressed at large in other comments already) Can an LLM be built avoiding any of this stuff? (of course, the discussion has shifted quite a bit! The initial question was if a dev not using the LLMs would remain relevant, but I believe this was addressed at large in other comments already) (of course, the discussion has shifted quite a bit! The initial question was if a dev not using the LLMs would remain relevant, but I believe this was addressed at large in other comments already) There's also a clear difference between users of this site that come here for all types of content, and users who have "AI" in their usernames.I think that the latter type might just have a bit of a bias in this matter? I'm not sure, I frequently use LLMs for well-scoped math-heavy functions (mostly for game development) where I don't neccessarly understand what's going on inside the function, but I know what output I expect given some inputs, so it's easy for me to kind of blackbox test it with unit tests and iterate on the "magic" inside with an LLM.I guess if I really stopped and focused on math for a year or two I'd be able to code that myself too, but every time I tried to get deeper into math it's either way too complex for me to feel like it's time well spent, and it's also boring. I guess if I really stopped and focused on math for a year or two I'd be able to code that myself too, but every time I tried to get deeper into math it's either way too complex for me to feel like it's time well spent, and it's also boring. I didn't have such cases in mind, was replying to the "navigate complexity at scales human cognition wasn't designed for" aspect. The use cases of these GPT tools are extremely limited. They demo well and are quite useful for highly documented workflows (E.G. they are very good at creating basic HTML/JS layouts and functionality).However, even the most advanced GPT tools fall flat on their face when you start working with any sort of bleeding edge, or even just less-ubiquitous technology. However, even the most advanced GPT tools fall flat on their face when you start working with any sort of bleeding edge, or even just less-ubiquitous technology. The Godot engine is an open-source project that has matured significantly since GPT tools hit the market.The GPTs don't know what the new Godot features are, and there is a training gap that I'm not sure Open AI and their competitors will ever be able to overcome.Do you work on web applications? I've found that GPT tools get pretty stupid once you stop working with HTML/JS. The GPTs don't know what the new Godot features are, and there is a training gap that I'm not sure Open AI and their competitors will ever be able to overcome.Do you work on web applications? I've found that GPT tools get pretty stupid once you stop working with HTML/JS. I've found that GPT tools get pretty stupid once you stop working with HTML/JS. Godot with AI was definitely a worse experience than usual for me. Scenes were generated through a Python script, which was of course written by Claude Code. Personally I have a year of experience working with Unity and online the code examples tend to be of incredibly poor quality. My guess is if AI is trained on the online corpus of game development forums, the output should be absolutely terrible. For the field of game development especially AI is tainted with this poor quality. Commonly you would use predefined rules for this with an LLM tool, I did not use any for my experiment. That would be a one-time task after which the AI will prefer your way of working. This flow is not suitable at the moment for out of the box Claude Code or similar tools which need to be able to independently verify that certain functions or features work as expected.> Do you work on web applications? I've found that GPT tools get pretty stupid once you stop working with HTML/JS.Not really - I work on developer experience and internal developer platforms. That is 80~90% Python, Go, Bash, Terraform and maybe a 10~20% Typescript with React depending on the project. My findings afterwards are;1) Code quality was not good. Personally I have a year of experience working with Unity and online the code examples tend to be of incredibly poor quality. My guess is if AI is trained on the online corpus of game development forums, the output should be absolutely terrible. For the field of game development especially AI is tainted with this poor quality. Commonly you would use predefined rules for this with an LLM tool, I did not use any for my experiment. That would be a one-time task after which the AI will prefer your way of working. This flow is not suitable at the moment for out of the box Claude Code or similar tools which need to be able to independently verify that certain functions or features work as expected.> Do you work on web applications? I've found that GPT tools get pretty stupid once you stop working with HTML/JS.Not really - I work on developer experience and internal developer platforms. That is 80~90% Python, Go, Bash, Terraform and maybe a 10~20% Typescript with React depending on the project. Personally I have a year of experience working with Unity and online the code examples tend to be of incredibly poor quality. My guess is if AI is trained on the online corpus of game development forums, the output should be absolutely terrible. For the field of game development especially AI is tainted with this poor quality. Commonly you would use predefined rules for this with an LLM tool, I did not use any for my experiment. That would be a one-time task after which the AI will prefer your way of working. This flow is not suitable at the moment for out of the box Claude Code or similar tools which need to be able to independently verify that certain functions or features work as expected.> Do you work on web applications? I've found that GPT tools get pretty stupid once you stop working with HTML/JS.Not really - I work on developer experience and internal developer platforms. That is 80~90% Python, Go, Bash, Terraform and maybe a 10~20% Typescript with React depending on the project. Commonly you would use predefined rules for this with an LLM tool, I did not use any for my experiment. That would be a one-time task after which the AI will prefer your way of working. This flow is not suitable at the moment for out of the box Claude Code or similar tools which need to be able to independently verify that certain functions or features work as expected.> Do you work on web applications? I've found that GPT tools get pretty stupid once you stop working with HTML/JS.Not really - I work on developer experience and internal developer platforms. That is 80~90% Python, Go, Bash, Terraform and maybe a 10~20% Typescript with React depending on the project. 3) It was very difficult to debug for Claude Code. This flow is not suitable at the moment for out of the box Claude Code or similar tools which need to be able to independently verify that certain functions or features work as expected.> Do you work on web applications? I've found that GPT tools get pretty stupid once you stop working with HTML/JS.Not really - I work on developer experience and internal developer platforms. That is 80~90% Python, Go, Bash, Terraform and maybe a 10~20% Typescript with React depending on the project. I've found that GPT tools get pretty stupid once you stop working with HTML/JS.Not really - I work on developer experience and internal developer platforms. That is 80~90% Python, Go, Bash, Terraform and maybe a 10~20% Typescript with React depending on the project. That is 80~90% Python, Go, Bash, Terraform and maybe a 10~20% Typescript with React depending on the project. IC10 is a fictional, MIPS-like CPU in the game Stationeers. I just use "AI" instead of Google/SO when I need to find something out.So far it mostly answers correctly, until the truthful answer comes close to "you can't do that". Then it goes off the rails and makes up shit. As a bonus, it seems to confuse related but less popular topics and mixes them up. Specific example, it mixes couchdb and couchbase when I ask about features.The worst part is 'correctly' means 'it will work but it will be tutorial level crap'. Considering how these "AI"s have been trained, I'm sure any promise that my code stays private is worth less than used toilet paper.Gut feeling is the "AI" would be useless because it's a not-invented-here codebase with no discussion on StackOverflow. So far it mostly answers correctly, until the truthful answer comes close to "you can't do that". Then it goes off the rails and makes up shit. As a bonus, it seems to confuse related but less popular topics and mixes them up. Specific example, it mixes couchdb and couchbase when I ask about features.The worst part is 'correctly' means 'it will work but it will be tutorial level crap'. Considering how these "AI"s have been trained, I'm sure any promise that my code stays private is worth less than used toilet paper.Gut feeling is the "AI" would be useless because it's a not-invented-here codebase with no discussion on StackOverflow. Considering how these "AI"s have been trained, I'm sure any promise that my code stays private is worth less than used toilet paper.Gut feeling is the "AI" would be useless because it's a not-invented-here codebase with no discussion on StackOverflow. So it's not that it doesn't work for my flow, it's that I can't trust it without verifying everything so what flow?Edit: there's a codebase that i would love to try an "AI" on... if i wouldn't have to send my customer's code to $random_server with $random_security with $untrustable_promises_of_privacy. Considering how these "AI"s have been trained, I'm sure any promise that my code stays private is worth less than used toilet paper.Gut feeling is the "AI" would be useless because it's a not-invented-here codebase with no discussion on StackOverflow. Considering how these "AI"s have been trained, I'm sure any promise that my code stays private is worth less than used toilet paper.Gut feeling is the "AI" would be useless because it's a not-invented-here codebase with no discussion on StackOverflow. Gut feeling is the "AI" would be useless because it's a not-invented-here codebase with no discussion on StackOverflow. Human cognition wasn't designed to make rockets or AIs, but we went to the moon and the LLMs are here. But the loss of their lives also proves a point: that achievement isn't a function of intelligence but of many more factors like people willing to risk and to give their lives to make something important happen in the world. https://en.wikipedia.org/wiki/Rogers_Commission_Report#Flawe...> Loss itself drives innovation and resolveTrue, but did NASA in 1986 really need to learn this lesson?This isn't (just) rocket science, it's the fundamentals of risk liability, legality and process that should be well established in a (quasi-military) agency such as this. > Loss itself drives innovation and resolveTrue, but did NASA in 1986 really need to learn this lesson?This isn't (just) rocket science, it's the fundamentals of risk liability, legality and process that should be well established in a (quasi-military) agency such as this. True, but did NASA in 1986 really need to learn this lesson?This isn't (just) rocket science, it's the fundamentals of risk liability, legality and process that should be well established in a (quasi-military) agency such as this. This isn't (just) rocket science, it's the fundamentals of risk liability, legality and process that should be well established in a (quasi-military) agency such as this. The urgency that justified those gambles was the Cold War.People have a social tendency to become complacent about catastrophic risks when there hasn't been a catastrophe recently. Speaking out about risk is scary unless there's a culture of people encouraging other to speak out and taking the risks seriously because they all remember how bad things can be if they don't.Someone actually has to stand up and say "if something is wrong I really actually want to and need to know." Speaking out about risk is scary unless there's a culture of people encouraging other to speak out and taking the risks seriously because they all remember how bad things can be if they don't.Someone actually has to stand up and say "if something is wrong I really actually want to and need to know." I see people starting to unlearn working by themselves rapidly and becoming dependant on GPT, making themselves quite useless in the process. They're also entirely helpless when whatever 'AI' tool they use can't fix their problem.This makes them both more replaceable and less marketable than before.It will have and already has a huge impact. But it's kinda like the offshoring hype from a decade ago. Everyone moved their dev departments to a cheaper country, only to later realize that maybe cheap does not always mean better or even good. But it's kinda like the offshoring hype from a decade ago. Everyone moved their dev departments to a cheaper country, only to later realize that maybe cheap does not always mean better or even good. It will have and already has a huge impact. But it's kinda like the offshoring hype from a decade ago. Everyone moved their dev departments to a cheaper country, only to later realize that maybe cheap does not always mean better or even good. But the big thing is using AI to learn new things, explain some tricky math in a paper I am reading, help brain storm, etc. To me this seems to be the single most valuable use case of newer "AI tools"> generating a Bash shell script quicklyI do this very often, and to me this seems to me the second most valuable use case of newer "AI tools"> The value of AI is in improving ourselvesI agree completely.> help brain stormThis strikes me as very concerning. In my experience, AI brainstorming ideas are exceptionally dull and uninspired. People who have shared ideas from AI brainstorming sessions with me have OVERWHELMINGLY come across as AI brained dullards who are unable to think for themselves.What I'm trying to say is that Chat GPT and similar tools are much better suited for interacting with closed systems with strict logical constraints, than they are for idea generation or writing in a natural language. > generating a Bash shell script quicklyI do this very often, and to me this seems to me the second most valuable use case of newer "AI tools"> The value of AI is in improving ourselvesI agree completely.> help brain stormThis strikes me as very concerning. In my experience, AI brainstorming ideas are exceptionally dull and uninspired. People who have shared ideas from AI brainstorming sessions with me have OVERWHELMINGLY come across as AI brained dullards who are unable to think for themselves.What I'm trying to say is that Chat GPT and similar tools are much better suited for interacting with closed systems with strict logical constraints, than they are for idea generation or writing in a natural language. I do this very often, and to me this seems to me the second most valuable use case of newer "AI tools"> The value of AI is in improving ourselvesI agree completely.> help brain stormThis strikes me as very concerning. In my experience, AI brainstorming ideas are exceptionally dull and uninspired. People who have shared ideas from AI brainstorming sessions with me have OVERWHELMINGLY come across as AI brained dullards who are unable to think for themselves.What I'm trying to say is that Chat GPT and similar tools are much better suited for interacting with closed systems with strict logical constraints, than they are for idea generation or writing in a natural language. > The value of AI is in improving ourselvesI agree completely.> help brain stormThis strikes me as very concerning. In my experience, AI brainstorming ideas are exceptionally dull and uninspired. People who have shared ideas from AI brainstorming sessions with me have OVERWHELMINGLY come across as AI brained dullards who are unable to think for themselves.What I'm trying to say is that Chat GPT and similar tools are much better suited for interacting with closed systems with strict logical constraints, than they are for idea generation or writing in a natural language. I agree completely.> help brain stormThis strikes me as very concerning. In my experience, AI brainstorming ideas are exceptionally dull and uninspired. People who have shared ideas from AI brainstorming sessions with me have OVERWHELMINGLY come across as AI brained dullards who are unable to think for themselves.What I'm trying to say is that Chat GPT and similar tools are much better suited for interacting with closed systems with strict logical constraints, than they are for idea generation or writing in a natural language. In my experience, AI brainstorming ideas are exceptionally dull and uninspired. People who have shared ideas from AI brainstorming sessions with me have OVERWHELMINGLY come across as AI brained dullards who are unable to think for themselves.What I'm trying to say is that Chat GPT and similar tools are much better suited for interacting with closed systems with strict logical constraints, than they are for idea generation or writing in a natural language. In my experience, AI brainstorming ideas are exceptionally dull and uninspired. People who have shared ideas from AI brainstorming sessions with me have OVERWHELMINGLY come across as AI brained dullards who are unable to think for themselves.What I'm trying to say is that Chat GPT and similar tools are much better suited for interacting with closed systems with strict logical constraints, than they are for idea generation or writing in a natural language. What I'm trying to say is that Chat GPT and similar tools are much better suited for interacting with closed systems with strict logical constraints, than they are for idea generation or writing in a natural language. Hopefully I am not misunderstanding you and others here, but I think you are mainly complaining about lazy use of AI. but you're right that "I firmly believe that AI will not replace developers, but a developer using AI will replace a developer who does not." Let's be fair - I made it intentionally a little provocative :) What I might not have mentioned is that I've spent the last 5 years and 20,000 or so hours building an IDE from scratch. Not a fork of VSCode, mind you, but the real deal: a new "kernel" and integration layer with abilities that VSCode and its forks can't even dream of. It's a proper race and I'm about to drop the hammer on you. If online models aren't your thing twinny.dev + ollama will make it fully local. This will be another abstraction layer that MANY people will use and be able to accomplish things that would have been impossible to do in a reasonable amount of time in machine code. Now very few laundry doers measure out their detergent by hand. Original posters autotune example was off too - 99% of commercial records use pitch correction. Easy to find autotune errors in live performances on youtube. And for a few decades at least it was true. The technology was shite compared to film photography for a long time. If the user can't feel any difference in quality between human made software, or AI made software, then it does not mater. It is that easy.If AI makes better software, at lower prices, human developers will become obsolete. If AI makes better software, at lower prices, human developers will become obsolete. Is the work super clean, efficient and fully hand-crafted? Is the work super clean, efficient and fully hand-crafted? There's the one doing everything in bare vim with zero assist, just rawdogging function names and library methods from rote memory.And then there's the rest who use all the tools at their disposal to solve problems. Is the work super clean, efficient and fully hand-crafted? Is the work super clean, efficient and fully hand-crafted? They just take it for grated that their IKEA cardboard stuff won't make it through a move and buy a new one.And then there's the one person with the almost century old desk that was handmade from hardwood and is practically indestructible and fully repairable if something cracks. But the vast majority of people either won't care or don't know the difference - mostly because they've never experienced it. They just take it for grated that their IKEA cardboard stuff won't make it through a move and buy a new one.And then there's the one person with the almost century old desk that was handmade from hardwood and is practically indestructible and fully repairable if something cracks. In any case there are better and stronger arguments against LLMs than this. One thing I miss for the other users, i.e. the casual users that never use anywhere near of their quota, is rollover. Even better: provide a counter displaying both remaining usage available and the quota reset time.But companies probably earn so much money from the vast majority of users that having good and clear limits would only empower them to actually benefit as much from the product as they can. But companies probably earn so much money from the vast majority of users that having good and clear limits would only empower them to actually benefit as much from the product as they can. I work at a huge company, and we're experimenting with different ways of using LLMs for users based on different compliance and business needs. The people using all you can eat products like NotebookLM, Gemini, ChatGPT use them much more on average and do more varied tasks. There is a significant gap between low/normal/high users.People using an interface to a metered API, which offers a defined LLM experience consume fewer resources and perform more narrowly scoped tasks.The cost is similar and satisfaction is about the same. People using an interface to a metered API, which offers a defined LLM experience consume fewer resources and perform more narrowly scoped tasks.The cost is similar and satisfaction is about the same. There is no such thing as "unlimited" or "lifetime" unless it's self-hosted. This is somewhat a different issue that's largely accepted by courts and society bar that one neighbour who is incensed they can't run a rack off their home internet that was marketed unlimited. In some cases, people discover creative ways to resell the service. Anthropic mentioned they suspect this was happening.The weirdest part about this whole internet uproar, though, is that Anthropic never offered unlimited usage. The weirdest part about this whole internet uproar, though, is that Anthropic never offered unlimited usage. Only reason I paysfor that plan is anything lower and my provider does not offer rollover. But I guess some people do really need "Eggs: contain eggs" in their egg carton otherwise they will throw a legal fit I was prepared for this though, because the people we went together said how it's going to go, exactly. I was prepared for this though, because the people we went together said how it's going to go, exactly. Digital services and assets have different costs than their physical counterparts, but that just means different limits, not a lack of them. Electrical supply, compute capacity, and storage are all physical things with real world limits to how much they can do.These realities eventually manifest when someone tries to build an "unlimited" service on top of limited components, similar to how you can't build a service with 99.999% reliability when it has a critical piece that can only get to 99.9%. These realities eventually manifest when someone tries to build an "unlimited" service on top of limited components, similar to how you can't build a service with 99.999% reliability when it has a critical piece that can only get to 99.9%. > Stop selling "unlimited", when you mean "until we change our minds"The limits don't go in to affect until August 28th, one month from yesterday. Is there an option to buy the Max plan yearly up front? If there isn't a yearly purchase option, no one is buying unlimited and then getting bait-and-switched without enough time for them to cancel their sub if they don't like the new limits.> A Different Approach: More AI for Less MoneyI think it's really funny that the "different approach" is a limited time offer for credits that expire.I don't like that the Claude Max limits are opaque, but if I really need pay-per-use, I can always switch to the API. I'll happily switch somewhere else.And on the "happily switch somewhere else", I find the "build user dependency" point pretty funny. Yes, I have a few hooks and subagents defined for Claude Code, but I have zero hard dependency on anything Anthropic produces. If another model/tool comes out tomorrow that's better than Claude Code for what I do, I'm jumping ship without a second thought. The limits don't go in to affect until August 28th, one month from yesterday. Is there an option to buy the Max plan yearly up front? If there isn't a yearly purchase option, no one is buying unlimited and then getting bait-and-switched without enough time for them to cancel their sub if they don't like the new limits.> A Different Approach: More AI for Less MoneyI think it's really funny that the "different approach" is a limited time offer for credits that expire.I don't like that the Claude Max limits are opaque, but if I really need pay-per-use, I can always switch to the API. I'll happily switch somewhere else.And on the "happily switch somewhere else", I find the "build user dependency" point pretty funny. Yes, I have a few hooks and subagents defined for Claude Code, but I have zero hard dependency on anything Anthropic produces. If another model/tool comes out tomorrow that's better than Claude Code for what I do, I'm jumping ship without a second thought. > A Different Approach: More AI for Less MoneyI think it's really funny that the "different approach" is a limited time offer for credits that expire.I don't like that the Claude Max limits are opaque, but if I really need pay-per-use, I can always switch to the API. I'll happily switch somewhere else.And on the "happily switch somewhere else", I find the "build user dependency" point pretty funny. Yes, I have a few hooks and subagents defined for Claude Code, but I have zero hard dependency on anything Anthropic produces. If another model/tool comes out tomorrow that's better than Claude Code for what I do, I'm jumping ship without a second thought. I think it's really funny that the "different approach" is a limited time offer for credits that expire.I don't like that the Claude Max limits are opaque, but if I really need pay-per-use, I can always switch to the API. I'll happily switch somewhere else.And on the "happily switch somewhere else", I find the "build user dependency" point pretty funny. Yes, I have a few hooks and subagents defined for Claude Code, but I have zero hard dependency on anything Anthropic produces. If another model/tool comes out tomorrow that's better than Claude Code for what I do, I'm jumping ship without a second thought. I'll happily switch somewhere else.And on the "happily switch somewhere else", I find the "build user dependency" point pretty funny. Yes, I have a few hooks and subagents defined for Claude Code, but I have zero hard dependency on anything Anthropic produces. If another model/tool comes out tomorrow that's better than Claude Code for what I do, I'm jumping ship without a second thought. Yes, I have a few hooks and subagents defined for Claude Code, but I have zero hard dependency on anything Anthropic produces. If another model/tool comes out tomorrow that's better than Claude Code for what I do, I'm jumping ship without a second thought. And what is top tier today, might be trash in a few months. Services are not the same thing as physical goods. - note: "unlimited" does not mean free.quote source: "Apple Just Found a Way to Sell You Nothing" https://www.youtube.com/watch?v=ytkk5NFZGjs quote source: "Apple Just Found a Way to Sell You Nothing" https://www.youtube.com/watch?v=ytkk5NFZGjs Repairs have always come with deductibles.This is standard in virtually every insurance program. There are a lot of studies showing that even the tiniest amount of cost sharing completely changes how people use a service.When something is unlimited and free, it enticed people to abuse it in absurd ways. With hardware, you would get people intentionally damaging their gear to get new versions for free because they know it costs them nothing. There are a lot of studies showing that even the tiniest amount of cost sharing completely changes how people use a service.When something is unlimited and free, it enticed people to abuse it in absurd ways. With hardware, you would get people intentionally damaging their gear to get new versions for free because they know it costs them nothing. With hardware, you would get people intentionally damaging their gear to get new versions for free because they know it costs them nothing. Don't blame the company, it acts within boundaries allowed by its paying customers, and apple customers are known to be... much less critical of the company and its products to be polite, especially given its premium prices. This is patently false and has been for the whole existence of Apple. Just probably not under the delta of importance that you consider. There is a case to be made that they sold a multiple and are changing x or rate limiting x differently, but the tone seems different from that. (https://gist.github.com/eonist/5ac2fd483cf91a6e6e5ef33cfbd1e...)So even if these mystery people Anthropic reference who did run it "in the background, 24/7", they still would've had to stay within usage limits. So even if these mystery people Anthropic reference who did run it "in the background, 24/7", they still would've had to stay within usage limits. The main HN thread yesterday was full of comments complaining about losing unlimited access.It's so weird to watch people get angry about thinking they're losing something they never had. Even Anthropic said less than 5% of accounts would even notice the new limits, yet I've seen countless comments raging that “everyone must suffer” due to the actions of a few abusing the system. The main HN thread yesterday was full of comments complaining about losing unlimited access.It's so weird to watch people get angry about thinking they're losing something they never had. Even Anthropic said less than 5% of accounts would even notice the new limits, yet I've seen countless comments raging that “everyone must suffer” due to the actions of a few abusing the system. Even Anthropic said less than 5% of accounts would even notice the new limits, yet I've seen countless comments raging that “everyone must suffer” due to the actions of a few abusing the system. Some facts for sanity:1- The poster of this blog article is Kilocode who makes a (worse) competitor to Claude Code. I've been getting hit by Reddit ads all day from Kilocode, all blasting Anthropic, with the false claim that their plan was "unlimited".2- No one has any idea yet what the new limits will be, or how much usage it actually takes to be in the top 5% to be affected. The limits go into effect in a few days. We'll see then if all the drama was warranted. 1- The poster of this blog article is Kilocode who makes a (worse) competitor to Claude Code. I've been getting hit by Reddit ads all day from Kilocode, all blasting Anthropic, with the false claim that their plan was "unlimited".2- No one has any idea yet what the new limits will be, or how much usage it actually takes to be in the top 5% to be affected. The limits go into effect in a few days. We'll see then if all the drama was warranted. The limits go into effect in a few days. We'll see then if all the drama was warranted. no, even their announcement blog[0] said:> With up to 20x higher usage limitsin the third paragraph.0: https://www.anthropic.com/news/max-plan > With up to 20x higher usage limitsin the third paragraph.0: https://www.anthropic.com/news/max-plan Can you really ever compete when you are renting someone else's GPUs?Can you really ever compete when you are going up against custom silicon built and deployed at scale to run inference at scale (i.e. TPUs built to run Gemini and deployed by the tens-of-thousands in data centers around the globe)?Meta and Google have deep pockets and massive existing world-class infrastructure (at least for Google, Meta probably runs their php Facebook thing on a few VPS dotted around in some random colos /s ) . They've literally written the book on this.It remains to be seen how much more money OpenAI can burn, but we've started to see how much Anthropic can burn if nothing else. Can you really ever compete when you are going up against custom silicon built and deployed at scale to run inference at scale (i.e. TPUs built to run Gemini and deployed by the tens-of-thousands in data centers around the globe)?Meta and Google have deep pockets and massive existing world-class infrastructure (at least for Google, Meta probably runs their php Facebook thing on a few VPS dotted around in some random colos /s ) . They've literally written the book on this.It remains to be seen how much more money OpenAI can burn, but we've started to see how much Anthropic can burn if nothing else. Meta and Google have deep pockets and massive existing world-class infrastructure (at least for Google, Meta probably runs their php Facebook thing on a few VPS dotted around in some random colos /s ) . They've literally written the book on this.It remains to be seen how much more money OpenAI can burn, but we've started to see how much Anthropic can burn if nothing else. It remains to be seen how much more money OpenAI can burn, but we've started to see how much Anthropic can burn if nothing else. When companies sell unlimited plans, they're making a bet that the average usage across all of those plans will be low enough to turn a profit.These people “abusing” the plan are well within their right to use the API as much as they want. It just didn't fall into the parameters Anthropic had expected.LLM subscriptions need to go away, why can't we just pay as we go? It just didn't fall into the parameters Anthropic had expected.LLM subscriptions need to go away, why can't we just pay as we go? There was not an unlimited plan.> These people “abusing” the plan are well within their right to use the API as much as they want. It just didn't fall into the parameters Anthropic had expected.Correct! And now Anthropic is changing those limits in a month.> LLM subscriptions need to go away, why can't we just pay as we go? Again, I'm confused about why there's so much anger about something that already exists.The subscriptions are nice for people who want a consistent fee and they get the advantage of a better deal for occasional heavy usage. It's amazing that so many people think there was an unlimited plan. There was not an unlimited plan.> These people “abusing” the plan are well within their right to use the API as much as they want. It just didn't fall into the parameters Anthropic had expected.Correct! And now Anthropic is changing those limits in a month.> LLM subscriptions need to go away, why can't we just pay as we go? Again, I'm confused about why there's so much anger about something that already exists.The subscriptions are nice for people who want a consistent fee and they get the advantage of a better deal for occasional heavy usage. It just didn't fall into the parameters Anthropic had expected.Correct! And now Anthropic is changing those limits in a month.> LLM subscriptions need to go away, why can't we just pay as we go? Again, I'm confused about why there's so much anger about something that already exists.The subscriptions are nice for people who want a consistent fee and they get the advantage of a better deal for occasional heavy usage. And now Anthropic is changing those limits in a month.> LLM subscriptions need to go away, why can't we just pay as we go? Again, I'm confused about why there's so much anger about something that already exists.The subscriptions are nice for people who want a consistent fee and they get the advantage of a better deal for occasional heavy usage. Again, I'm confused about why there's so much anger about something that already exists.The subscriptions are nice for people who want a consistent fee and they get the advantage of a better deal for occasional heavy usage. Again, I'm confused about why there's so much anger about something that already exists.The subscriptions are nice for people who want a consistent fee and they get the advantage of a better deal for occasional heavy usage. The subscriptions are nice for people who want a consistent fee and they get the advantage of a better deal for occasional heavy usage. I will never pay for any of these subscriptions however so I haven't verified that.>And now Anthropic is changing those limits in a month.Which indicates the seller was being scammed. Now they're changing the limits so it swings back to being a scam for the user.>I'm confused about why there's so much anger about something that already existsYes but much LLM tooling requires a subscription. I can't use chatgpt.com using my own API key. >And now Anthropic is changing those limits in a month.Which indicates the seller was being scammed. Now they're changing the limits so it swings back to being a scam for the user.>I'm confused about why there's so much anger about something that already existsYes but much LLM tooling requires a subscription. I can't use chatgpt.com using my own API key. Now they're changing the limits so it swings back to being a scam for the user.>I'm confused about why there's so much anger about something that already existsYes but much LLM tooling requires a subscription. I can't use chatgpt.com using my own API key. I can't use chatgpt.com using my own API key. I can't use chatgpt.com using my own API key. And the predictability means my company will pay for it. By actually paying for what you use, you can be a bit more economical and still get a lot of mileage out of it.$100/$200 is still a great deal (as you said), but it does make sense for actually-$2000 users to get charged differently.0: In my hometown, (some) people have unlimited central heating (in winter) for a fixed fee. On warmer days, people are known to open windows instead of turning off the heating. $100/$200 is still a great deal (as you said), but it does make sense for actually-$2000 users to get charged differently.0: In my hometown, (some) people have unlimited central heating (in winter) for a fixed fee. On warmer days, people are known to open windows instead of turning off the heating. On warmer days, people are known to open windows instead of turning off the heating. Because Claude Code is absolutely impossible to use without a subscription? I'm fine with being limited, but I'm not with having to pay more than $200/monthAnybody that feels they're not getting enough out of their subscription is welcome to use API instead. Anybody that feels they're not getting enough out of their subscription is welcome to use API instead. When some users burn massive amounts of compute just to climb leaderboards or farm karma, it's not hard to imagine why providers might respond with tighter limits—not because it's ideal, but because that kind of behavior makes platforms harder to sustain and less accessible for everyone else. Because on the other hand a lot of genuine customers are canceling because they get API overload message after paying $200.I still think caps are frustrating and often too blunt, but posts like that make it easier to see where the pressure might be coming from. I still think caps are frustrating and often too blunt, but posts like that make it easier to see where the pressure might be coming from. where in the launch announcement (https://www.anthropic.com/news/max-plan) did they suggest it provided unlimited inference? why is anthropic tweeting about 'naughty users that ruined it for everyone' ? However instead of  choosing to hoard your usage out of fear of hitting the dreaded limit again, you've kept it again and again, using the product exactly the way it was intended to and now look what you've done." they launched Claude Max (and Pro) as being limited. it was limited before, and it's limited now, with a new limit to discourage 24/7 maxing of it.in what way was there a bait and switch? in what way was there a bait and switch? The sustainable path forward likely involves either much more transparent/clear usage-based pricing or significantly higher flat rates that actually cover heavy usage. Like, if the abuse is separate from amount of use (like reselling; it can be against ToS to resell it even in tiny amounts) then sure, but if you're claiming "excessive" use is "abuse", then it is by any reasonable definition not unlimited. If there is a clear limit to that (and it seems there is now), then stop saying "unlimited" and start selling "X queries per day". You can even let users pay for aditional queries if needed. (yes i know queries is not a proper term to use here, but the principle stands) (yes i know queries is not a proper term to use here, but the principle stands) > The real damage: You're not frustrating 5% of users—you're breaking trust with the exact people who drive growth and adoption.> When developers get "rate limit exceeded" while debugging at 2 AM, they're not thinking about your infrastructure costs—they're shopping for alternatives.Notice a pattern here? > When developers get "rate limit exceeded" while debugging at 2 AM, they're not thinking about your infrastructure costs—they're shopping for alternatives.Notice a pattern here? Claude 4 is good enough that people will pay whatever they ask as long as it's significantly less than the cost of doing it by hand. There are two tiers, explicitly labeled "5x" and "20x", both referring to the increased usage over what you get with Pro. Did all the people complaining that Anthropic reneged on their "promise" of unlimited usage not read anything about what they were signing up to pay $100 or $200/month for? The Max plan clearly said it had higher limits.This fabrication of a backstory is so weird. The Max plan clearly said it had higher limits.This fabrication of a backstory is so weird. And to be clear, the users abusing the "unlimited" rates  they were offering to do absolutely nothing productive (see vibe-coding subreddits) are no better. Claude Max, to my knowledge, was never marketed as "unlimited". Claude Max gives you WAY more tokens then $100/$200 would buy. But it is so hard to explain to product people, that there is a limit how much certain services can scale and be profitably supported. Now we are in the early days of AI. Providers should be honest but won't until forced to.Because just think about it. Another example, in the early days of broadband in Australia a friend's parents were visited by a Telstra manager because he “downloaded more than his entire suburb”. A manager!Really you can't blame the providers; some users will ruin it for everyone. Another example, in the early days of broadband in Australia a friend's parents were visited by a Telstra manager because he “downloaded more than his entire suburb”. A manager!Really you can't blame the providers; some users will ruin it for everyone. Really you can't blame the providers; some users will ruin it for everyone. Gemini did go from a huge free tier to 100 free uses a day, but I expected that.EDIT: let me clarify: I just retired after over 50 very happy years working as a software developer and researcher. My number one priority was always self-improvement: learning new things and new skills that incidentally I could sometimes use to make money for whoever was paying me. AI is awesome for learning and general intellectual pursuits, and pairs nicely with reading quality books, listening to lectures on YouTube, etc. EDIT: let me clarify: I just retired after over 50 very happy years working as a software developer and researcher. My number one priority was always self-improvement: learning new things and new skills that incidentally I could sometimes use to make money for whoever was paying me. AI is awesome for learning and general intellectual pursuits, and pairs nicely with reading quality books, listening to lectures on YouTube, etc. Just below me as I type there's a comment saying they're refusing to cancel a subscription (may not be below me any more when I finish typing).Somewhere lower there's a comment saying they do not show the full price when you subscribe, but add taxes on top of it and leave you to notice the surprise on your credit card statement.Is there an ethical "AI" service anywhere? Somewhere lower there's a comment saying they do not show the full price when you subscribe, but add taxes on top of it and leave you to notice the surprise on your credit card statement.Is there an ethical "AI" service anywhere? Differentiation through honesty: In a market full of fluff, directness stands out. But that may not be a loss—it might actually filter in the right kind of customer, the one who wants to know what they're really getting. But that may not be a loss—it might actually filter in the right kind of customer, the one who wants to know what they're really getting. Let people cook and give them some time find out how to do this. And how does this compare to case with "Unlimited". Overall will the total used be higher or lower? In subscription plans, users who aren't using 100% of their subscription subsidize other users, which is opaque and not really fair. some say they have to define a huge limit and that's it.Limits are sometime hard to define :- they must be such huge, a user (human) finaly understand it's unlimited else he will compare to competitors- but no such huge because the 0.1% of users will try to reach itA fair word could be the one which categorize the type of use :- human : human has physical limit (e.g: typing word to keyboard / per time).- bot : from 1 arduino to heavyweight hardcore clusting, virtualy no limits. Limits are sometime hard to define :- they must be such huge, a user (human) finaly understand it's unlimited else he will compare to competitors- but no such huge because the 0.1% of users will try to reach itA fair word could be the one which categorize the type of use :- human : human has physical limit (e.g: typing word to keyboard / per time).- bot : from 1 arduino to heavyweight hardcore clusting, virtualy no limits. - they must be such huge, a user (human) finaly understand it's unlimited else he will compare to competitors- but no such huge because the 0.1% of users will try to reach itA fair word could be the one which categorize the type of use :- human : human has physical limit (e.g: typing word to keyboard / per time).- bot : from 1 arduino to heavyweight hardcore clusting, virtualy no limits. - but no such huge because the 0.1% of users will try to reach itA fair word could be the one which categorize the type of use :- human : human has physical limit (e.g: typing word to keyboard / per time).- bot : from 1 arduino to heavyweight hardcore clusting, virtualy no limits. A fair word could be the one which categorize the type of use :- human : human has physical limit (e.g: typing word to keyboard / per time).- bot : from 1 arduino to heavyweight hardcore clusting, virtualy no limits. - human : human has physical limit (e.g: typing word to keyboard / per time).- bot : from 1 arduino to heavyweight hardcore clusting, virtualy no limits. - bot : from 1 arduino to heavyweight hardcore clusting, virtualy no limits. “Claude is promising unlimited and it isn't sustainable.”“For a limited time only pay us $20 and get $80 worth of credits.”Look at what these people on HN said!Come on. “For a limited time only pay us $20 and get $80 worth of credits.”Look at what these people on HN said!Come on. I hold them no ill will for rapidly changing pricing models, raising pricing, doing whatever they need to do in what must be a crazy time of finding insane PMF in such a short timeBUT the communication is basically inexcusable IMO. I don't know what I'm paying for, I don't know how much I get, their pricing and product pages have completely different information, they completely hide the fact that Opus use is restricted to the Max plan, they don't tell you how much Opus use you get, their help pages and pricing pages look they were written by an intern and pushed directly to prod. I find out about changes on Twitter/HN before I hear about them from Anthropic.I love the Claude Code product, but Anthropic the company is definitely nudging me to go back to OpenAI.This is also why competition is great though - if one company had a monopoly the pricing and UX would be 20x worse. I don't know what I'm paying for, I don't know how much I get, their pricing and product pages have completely different information, they completely hide the fact that Opus use is restricted to the Max plan, they don't tell you how much Opus use you get, their help pages and pricing pages look they were written by an intern and pushed directly to prod. I find out about changes on Twitter/HN before I hear about them from Anthropic.I love the Claude Code product, but Anthropic the company is definitely nudging me to go back to OpenAI.This is also why competition is great though - if one company had a monopoly the pricing and UX would be 20x worse. I love the Claude Code product, but Anthropic the company is definitely nudging me to go back to OpenAI.This is also why competition is great though - if one company had a monopoly the pricing and UX would be 20x worse. This is also why competition is great though - if one company had a monopoly the pricing and UX would be 20x worse. I don't know why you think everyone is going to suffer. Unlimited for startups work better because they have zero idea on load challenges that come in the future. And they don't have much idea how well their product will be taken in the market.Anthropic got the experience and decided they needed to maximize on reasonableness over customer trust. And they are a startup so we all get this.OTOH there is no such thing as unlimited. You are a sucker for believing in the unlimited myth just like think others are suckers for believing in divine intervention or conspiracy theorists are suckers to believe in unlimited power. Anthropic got the experience and decided they needed to maximize on reasonableness over customer trust. And they are a startup so we all get this.OTOH there is no such thing as unlimited. You are a sucker for believing in the unlimited myth just like think others are suckers for believing in divine intervention or conspiracy theorists are suckers to believe in unlimited power. You are a sucker for believing in the unlimited myth just like think others are suckers for believing in divine intervention or conspiracy theorists are suckers to believe in unlimited power. The problem is that they couldn't even sustain it at this earliest stage. wait until their investors get fed up with pouring money down the drain and demand they make a profit from the median userthat model training and capex to build the giant DCs and fill them with absurdly priced nvidia chips isn't freeas an end user: you will be the one paying for it that model training and capex to build the giant DCs and fill them with absurdly priced nvidia chips isn't freeas an end user: you will be the one paying for it as an end user: you will be the one paying for it On a more serious note, I'm sure most of the people can't fathom or even think about the resources they are consuming when using AI tools. This things doesn't use energy, they consume it like how a black hole sucks light.In some cases, your queries can consume your home's daily energy needs in a hour or so. But hey, this is just a sales pitch from one company I wouldn't trust by taking a dump on another company I wouldn't trust. I cant see a nice little bar with how much I've used versus have left on the given rate limitsWell, that's a scam. you can see here in this Reddit thread from April, when Claude Max was launched, that it was explicitly explained as being limited: https://www.reddit.com/r/ClaudeAI/comments/1jvbpek/breaking_...Max is described as "5-20x more than Pro", clearly indicating both are limited.here's their launch blog post: https://www.anthropic.com/news/max-plan> The new Max plan delivers exactly that. With up to 20x higher usage limits, you can maintain momentum on your most demanding projects with little disruption.obviously everyone wants everything for free, or cheap, and no one wants prices to change in a way that might not benefit them, but the endless whinging from people about how unfair it is that anthropic is limiting access to their products sold as coming with limited access is really extremely tedious even by HN standards.and as pointed out dozens of times in these threads, if your actual worry is running out of usage in a week or month, Anthropic has you covered - you can just pay per token by giving Claude Code an API key. doing that 24/7 will cost ~100x what Max does though, I wonder if that's a useful bit of info about the situation or not? Max is described as "5-20x more than Pro", clearly indicating both are limited.here's their launch blog post: https://www.anthropic.com/news/max-plan> The new Max plan delivers exactly that. With up to 20x higher usage limits, you can maintain momentum on your most demanding projects with little disruption.obviously everyone wants everything for free, or cheap, and no one wants prices to change in a way that might not benefit them, but the endless whinging from people about how unfair it is that anthropic is limiting access to their products sold as coming with limited access is really extremely tedious even by HN standards.and as pointed out dozens of times in these threads, if your actual worry is running out of usage in a week or month, Anthropic has you covered - you can just pay per token by giving Claude Code an API key. doing that 24/7 will cost ~100x what Max does though, I wonder if that's a useful bit of info about the situation or not? here's their launch blog post: https://www.anthropic.com/news/max-plan> The new Max plan delivers exactly that. With up to 20x higher usage limits, you can maintain momentum on your most demanding projects with little disruption.obviously everyone wants everything for free, or cheap, and no one wants prices to change in a way that might not benefit them, but the endless whinging from people about how unfair it is that anthropic is limiting access to their products sold as coming with limited access is really extremely tedious even by HN standards.and as pointed out dozens of times in these threads, if your actual worry is running out of usage in a week or month, Anthropic has you covered - you can just pay per token by giving Claude Code an API key. doing that 24/7 will cost ~100x what Max does though, I wonder if that's a useful bit of info about the situation or not? With up to 20x higher usage limits, you can maintain momentum on your most demanding projects with little disruption.obviously everyone wants everything for free, or cheap, and no one wants prices to change in a way that might not benefit them, but the endless whinging from people about how unfair it is that anthropic is limiting access to their products sold as coming with limited access is really extremely tedious even by HN standards.and as pointed out dozens of times in these threads, if your actual worry is running out of usage in a week or month, Anthropic has you covered - you can just pay per token by giving Claude Code an API key. doing that 24/7 will cost ~100x what Max does though, I wonder if that's a useful bit of info about the situation or not? obviously everyone wants everything for free, or cheap, and no one wants prices to change in a way that might not benefit them, but the endless whinging from people about how unfair it is that anthropic is limiting access to their products sold as coming with limited access is really extremely tedious even by HN standards.and as pointed out dozens of times in these threads, if your actual worry is running out of usage in a week or month, Anthropic has you covered - you can just pay per token by giving Claude Code an API key. doing that 24/7 will cost ~100x what Max does though, I wonder if that's a useful bit of info about the situation or not? and as pointed out dozens of times in these threads, if your actual worry is running out of usage in a week or month, Anthropic has you covered - you can just pay per token by giving Claude Code an API key. doing that 24/7 will cost ~100x what Max does though, I wonder if that's a useful bit of info about the situation or not? You can unsubscribe freely.This sort of entitlement puts me off.</p>
                <br/>
                

        </div>

        <script>
            // Get all article attribution elements
            const articleAttributions = document.querySelectorAll('#article_attribution');

            // Add an event listener to each attribution element
            articleAttributions.forEach(attribution => {
            attribution.addEventListener('click', () => {
                // Get the next paragraph element (the article text)
                const articleText = attribution.nextElementSibling;

                // Toggle the visibility of the article text
                articleText.classList.toggle('hidden');

                // Toggle the expand icon
                const expandIcon = attribution.querySelector('.expand-icon');
                expandIcon.classList.toggle('fa-chevron-down');
                expandIcon.classList.toggle('fa-chevron-up');
            });
            });    
        </script>

        <footer class="text-center text-sm text-gray-500 mt-12">
            <div class="inline-block align-middle">
                <a href="https://www.youtube.com/@news_n_clues" target="_blank" rel="noopener noreferrer"
                    class="flex items-center gap-2 text-red-600 hover:text-red-700 font-semibold transition duration-300 ease-in-out">
                    Watch Daily <span class="italic">News'n'Clues</span> Podcast on
                    <img src="../images/yt.png" width="16" height="16">
                </a>
            </div>
            <div>
                <a href="mailto:newsnclues@gmail.com?subject=News'n'Clues Aggregator Inquiry">SoftMillennium
                    <script>document.write(new Date().getFullYear());</script>
                </a>
                <!--
            <b>Copyright &copy; <script>document.write(new Date().getFullYear());</script> - <a href='mailto:newsnclues@gmail.com?subject=News Aggregator Inquiry'>News And Clues</a></b>
            -->
            </div>
        </footer>
    </body>
</html>
            